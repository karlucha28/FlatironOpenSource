window.COURSE_DATA = {"language":"en","lastDownload":"2022-10-31T12:02:57-04:00","title":"Phase 4","modules":[{"id":47061,"name":"Table of Contents","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"gcb90404d4da63dbc27b36851b560e360","items":[{"id":457725,"title":"Table of Contents (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 31: Principal Component Analysis\" href=\"modules/g7c67143d69f51335e99562b32712bfd8\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43434\" data-api-returntype=\"Module\"\u003eTopic 31: Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 31 Lesson Priorities (Live)\" href=\"pages/topic-31-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-31-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 31 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 32: Recommendation Systems\" href=\"modules/g0e06344ce8eccc6ff781e3cbbfbb9aa9\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43435\" data-api-returntype=\"Module\"\u003eTopic 32: Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 32 Lesson Priorities (Live)\" href=\"pages/topic-32-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-32-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 32 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 33: Clustering\" href=\"modules/gce68bd8eeb6464538bfeaabf4566602f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43436\" data-api-returntype=\"Module\"\u003eTopic 33: Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 33 Lesson Priorities (Live)\" href=\"pages/topic-33-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-33-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 33 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 34: Exploring Time Series Data\" href=\"modules/g7ad5bedda4978b4fa340558c6c6d71ca\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43437\" data-api-returntype=\"Module\"\u003eTopic 34: Exploring Time Series Data\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 34 Lesson Priorities (Live)\" href=\"pages/topic-34-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-34-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 34 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 35: Modeling Time Series Data\" href=\"modules/ge5695df63ab9b4a0c363f3024c5a3cc9\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43438\" data-api-returntype=\"Module\"\u003eTopic 35: Modeling Time Series Data\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 35 Lesson Priorities (Live)\" href=\"pages/topic-35-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-35-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 35 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 36: Big Data and (Py)Spark\" href=\"modules/ga5e985716089f35d6154990b88b1513f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43439\" data-api-returntype=\"Module\"\u003eTopic 36: Big Data and (Py)Spark\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 36 Lesson Priorities (Live)\" href=\"pages/topic-36-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-36-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 36 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 37: Natural Language Processing\" href=\"modules/g42079c4ff48ac0dfe3c3fa1b40ffe628\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43440\" data-api-returntype=\"Module\"\u003eTopic 37: Natural Language Processing\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 37 Lesson Priorities (Live)\" href=\"pages/topic-37-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-37-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 37 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 38: Neural Networks\" href=\"modules/g23a6d31a68ba26c6d7b06ca5047ca55a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43441\" data-api-returntype=\"Module\"\u003eTopic 38: Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 38 Lesson Priorities (Live)\" href=\"pages/topic-38-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-38-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 38 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 39: Tuning Neural Networks\" href=\"modules/g36962a75f13484bc512e7f84c95d4708\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43442\" data-api-returntype=\"Module\"\u003eTopic 39: Tuning Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 39 Lesson Priorities (Live)\" href=\"pages/topic-39-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-39-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 39 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 40: Amazon Web Services\" href=\"modules/g0e7370999d9fba80091511a7fa02df15\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43443\" data-api-returntype=\"Module\"\u003eTopic 40: Amazon Web Services\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 40 Lesson Priorities (Live)\" href=\"pages/topic-40-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-40-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 40 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca title=\"üèÜ Milestones\" href=\"modules/g4ced624eeaf253578a9cdbfadc24c3d5\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43432\" data-api-returntype=\"Module\"\u003eüèÜ Milestones\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca title=\"APPENDIX: More Time Series\" href=\"modules/g9f7eddb4c2ad4c55c1b6f443cdd47aac\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43444\" data-api-returntype=\"Module\"\u003eAPPENDIX\u003c/a\u003e\u003c/p\u003e","exportId":"table-of-contents-live"}]},{"id":47063,"name":"Topic 31: Principal Component Analysis","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g7c67143d69f51335e99562b32712bfd8","items":[{"id":457740,"title":"Topic 31 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan style=\"font-size: 24pt;\"\u003eWelcome to Phase 4!\u003c/span\u003e\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 101.369%; height: 307px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003ePCA\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA - Introduction\" href=\"pages/pca-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/pca-introduction\" data-api-returntype=\"Page\"\u003ePCA - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Unsupervised Learning\" href=\"pages/unsupervised-learning\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/unsupervised-learning\" data-api-returntype=\"Page\"\u003eUnsupervised Learning\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"The Curse of Dimensionality\" href=\"pages/the-curse-of-dimensionality\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/the-curse-of-dimensionality\" data-api-returntype=\"Page\"\u003eThe Curse of Dimensionality\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Curse of Dimensionality - Lab\" href=\"assignments/g27ff2fdc813a820fe3664cf8e0538f87\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187103\" data-api-returntype=\"Assignment\"\u003eCurse of Dimensionality - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"PCA in scikit-learn\" href=\"assignments/gc0f03e96ae12b9559a73a7a051856f69\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187135\" data-api-returntype=\"Assignment\"\u003ePCA in scikit-learn\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA in scikit-learn - Lab\" href=\"assignments/g62781b0f81600caf7cf0ef404029b642\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187136\" data-api-returntype=\"Assignment\"\u003ePCA in scikit-learn - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Integrating PCA in Pipelines - Lab\" href=\"assignments/g9f909bbb881f8a8f09562043a774c457\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187112\" data-api-returntype=\"Assignment\"\u003eIntegrating PCA in Pipelines - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA and Digital Image Processing\" href=\"assignments/g565911fd864b7ec0428d04864ab03532\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187132\" data-api-returntype=\"Assignment\"\u003ePCA and Digital Image Processing\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003csup\u003e1\u003c/sup\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA and Digital Image Processing - Lab\" href=\"assignments/g9e3a49e6940910d53bc3684917edf480\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187133\" data-api-returntype=\"Assignment\"\u003ePCA and Digital Image Processing - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003csup\u003e1\u003c/sup\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA Background: Covariance Matrix and Eigendecomposition\" href=\"assignments/g228826ed11f4a16c8e008a66f71ae8d1\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187134\" data-api-returntype=\"Assignment\"\u003ePCA Background: Covariance Matrix and Eigendecomposition\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Performing Principal Component Analysis\" href=\"assignments/g6747449b9e6df2c0c494613e6764ddf7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187137\" data-api-returntype=\"Assignment\"\u003ePerforming Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Performing Principal Component Analysis - Lab\" href=\"assignments/g5977d47bef596d1748bef4a87eeec33a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187138\" data-api-returntype=\"Assignment\"\u003ePerforming Principal Component Analysis - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Principal Component Analysis\" href=\"quizzes/g3edf2c8c948b9f818582eb3cc62d6ce0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30676\" data-api-returntype=\"Quiz\"\u003eQuiz: Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003csup\u003e1\u003c/sup\u003eThese two lessons use PCA as part of a supervised learning process with SVM. If you haven't gotten to going through the SVM lessons don't worry about the specifics of the algorithm.\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.808%; height: 86px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003ePCA\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Short Video: Solving an Eigenvalue Problem\" href=\"pages/short-video-solving-an-eigenvalue-problem\" data-api-endpoint=\"pages/short-video-solving-an-eigenvalue-problem?module_item_id=mastercourse_15802_382_3377812da0221f6c1688458fea6a2c96\" data-api-returntype=\"Page\"\u003eShort Video: Solving an Eigenvalue Problem\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"PCA Exit Ticket\" href=\"quizzes/g0ce7341539dd4023f20501b0ece6ef8e\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30659\" data-api-returntype=\"Quiz\"\u003ePCA Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\" href=\"quizzes/gd4bb2a176d75638f44ca8a45af7b753e\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30662\" data-api-returntype=\"Quiz\"\u003e‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003csup\u003e2\u003c/sup\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA - Recap\" href=\"pages/pca-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/pca-recap\" data-api-returntype=\"Page\"\u003ePCA - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e\u003csup\u003e2\u003c/sup\u003eCumulative labs may be used for pairing exercises and might not be published yet; contact your instructor if you have questions\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-31-lesson-priorities-live"},{"id":457743,"title":"PCA - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about principal component analysis, or PCA, one of the most famous \u003cem\u003eUnsupervised Learning Techniques\u003c/em\u003e. PCA is a dimensionality reduction technique. It allows you to compress a dataset into a lower dimensional space with fewer features while maintaining as much of the original information as possible.\u003c/p\u003e\n\n\u003ch2\u003eThe Curse of Dimensionality\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is a general mathematical problem relating to the exploding size of space as you continue to add additional dimensions. This can be particularly problematic when dealing with large datasets. The more features you have, the more data you have about the scenario, but the more difficult it might be to exhaustively explore combinations of these features.\u003c/p\u003e\n\n\u003ch2\u003ePCA Use Cases\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is certainly one motivating factor for PCA. If you can't process all of the information at your disposal, then an alternative path around is necessary. Dimensionality reduction techniques such as PCA can be essential in such situations. PCA can also help improve regression and classification algorithms in many cases. In particular, algorithms are less prone to overfitting when the underlying data itself has first been compressed, reducing noise or other anomalies. Finally, PCA can also be helpful for visualizing the structure of large datasets. After all, you are limited to 2 or 3 dimensions when visualizing data. As such, reducing a dataset to 2 or 3 primary features is monumental in creating a visualization.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll explore PCA in depth using scikit-learn, and coding your own version from scratch using NumPy. Throughout this section, keep in mind use cases for PCA such as the curse of dimensionality.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-pca-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-pca-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"pca-introduction"},{"id":457747,"title":"Unsupervised Learning","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll get a high-level overview of unsupervised learning, an entire class of algorithms in machine learning. To date, you've only seen examples of supervised learning tasks such as regression and classification. As the name implies, unsupervised learning is a bit different than these tasks. In supervised learning, you define an \u003ccode\u003eX\u003c/code\u003e and \u003ccode\u003ey\u003c/code\u003e, and the algorithm attempts to generalize this transformation in order to predict \u003ccode\u003ey\u003c/code\u003e given \u003ccode\u003eX\u003c/code\u003e. In unsupervised learning, you do not define an \u003ccode\u003eX\u003c/code\u003e or \u003ccode\u003ey\u003c/code\u003e. Instead, you feed in a given dataset and the unsupervised learning algorithm returns some new representation of the data based on the structure and patterns within the data itself.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine unsupervised learning \u003c/li\u003e\n\u003cli\u003eCompare and contrast supervised and unsupervised learning \u003c/li\u003e\n\u003cli\u003eIdentify real-world scenarios in which you would use unsupervised learning \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSupervised vs. Unsupervised Learning\u003c/h2\u003e\n\n\u003cp\u003eThe main difference between supervised and unsupervised learning are their goals. Supervised learning needs concrete, ground-truth labels to train models that answer very specific questions. Unsupervised learning differs in that the task it is trying to accomplish is much less well-defined - it can usually be summed up as \"are there any natural patterns in this data that are recognizable?\"  To illustrate this, assume that you have a basket of various different kinds of fruit. A supervised learning task would be building an apple classifier that tells us if a given fruit is or isn't an apple, based on the size, shape, color, texture, taste, and any other data that you've encoded for each piece of fruit. An unsupervised learning task on the same data would analyze only the features, and sort them into groups without being told what type of fruit each was. In general, supervised learning uses data to accomplish a clear task while unsupervised learning has no clear task, but is instead used to identify patterns.\u003c/p\u003e\n\n\u003ch2\u003eUnsupervised Learning Tasks\u003c/h2\u003e\n\n\u003cp\u003eThe two most common unsupervised learning tasks are clustering and dimensionality reduction. Clustering groups data into homogeneous groups, where members share common traits. Dimensionality reduction attempts to reduce the overall number of features of a dataset while preserving as much information as possible. With that, let's take a deeper look into some general notes on each.\u003c/p\u003e\n\n\u003ch3\u003eClustering\u003c/h3\u003e\n\n\u003cp\u003eThere are a few different kinds of clustering algorithms, but they all do the same thing - finding different ways to group a dataset based on patterns in the data.  One common use-case for clustering is market segmentation. In market segmentation, you would try to decompose an audience into subsets for more precise targeting for business purposes, such as advertising. Even though there's no way to verify that these groups are correct, in practice it usually does quite well, often providing useful subgroups which can then be individually examined.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-unsupervised-learning/master/images/kmeans.gif\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eSource: \u003ca href=\"https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/\"\u003eGIF by David Sheehan\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3\u003eDimensionality Reduction\u003c/h3\u003e\n\n\u003cp\u003eThe most common dimensionality reduction algorithm is Principal Component Analysis (PCA). Dimensionality reduction algorithms work by projecting data from its current n-dimensional subspace into a smaller subspace, while losing as little information as possible in the process. Dimensionality reduction algorithms still lose \u003cem\u003esome\u003c/em\u003e information, but you can quantify this information loss to make an informed decision about the number of dimensions reduced versus the overall information lost. Dimensionality reduction algorithms are a must-have in any data scientist's toolbox, because they provide a way for us to deal with the \u003cstrong\u003eCurse of Dimensionality\u003c/strong\u003e. The curse of dimensionality is a key concept as datasets scale. In short, as the number of features in a dataset increases, the processing power and search space required to optimize a given machine learning algorithm explodes exponentially. Because this often creates intractable computational problems, dimensionality reduction techniques such as PCA can be an essential preprocessing technique.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-unsupervised-learning/master/images/pca.gif\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eSource: \u003ca href=\"https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579\"\u003eGIF by amoeba\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you explored the differences between supervised and unsupervised learning. You also learned about the types of problems we can solve with unsupervised learning, including clustering and dimensionality reduction. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-unsupervised-learning\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-unsupervised-learning\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"unsupervised-learning"},{"id":457751,"title":"The Curse of Dimensionality","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is an interesting paradox for data scientists. On the one hand, one often hopes to garner more information to improve the accuracy of a machine learning algorithm. However, there are also some interesting phenomena that come along with larger datasets. In particular, the curse of dimensionality is based on the exploding volume of n-dimensional spaces as the number of dimensions, n, increases.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what is meant by the curse of dimensionality and its implications when training machine learning algorithms \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSparseness in N-Dimensional Space\u003c/h2\u003e\n\n\u003cp\u003ePoints in n-dimensional space become increasingly sparse as the number of dimensions increases. That is, the distance between points will continue to grow as the number of dimensions grows. This can be problematic in a number of machine learning algorithms, in particular, when clustering points into groups. Due to the exploding nature of n-dimensional space, there is also an unwieldy number of possible combinations when searching for optimal parameters for a machine learning algorithm. \u003c/p\u003e\n\n\u003cp\u003eTo demonstrate this, you'll generate this graph in the upcoming lab:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-curse-of-dimensionality/master/images/sparsity.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis image demonstrates how the average distance between points and the origin continues to grow as the number of dimensions increases, even though each dimension has a fixed range. Simply increasing the number of dimensions continues to make individual points more and more sparse.\u003c/p\u003e\n\n\u003ch2\u003eImplications\u003c/h2\u003e\n\n\u003cp\u003eThe main implication of the curse dimensionality is that optimization problems can become infeasible as the number of features increases. The practical limit will vary based on your particular computer and the time that you have to invest in a problem. As you'll see in the upcoming lab, this relationship is exponential. For machine learning algorithms that involve backpropagation, or iterative convergence, including Lasso and Ridge regression, this will drastically impact the size of feasible solvable problems.\u003c/p\u003e\n\n\u003cp\u003eThe sparsity of points also has additional consequences. Due to the sheer scale of potential points in an n-dimensional space, as n continues to grow, the probability of seeing a particular point (or even nearby point) continues to plummet. Therefore, it is likely that there are entire regions of an n-dimensional space that have yet to be explored. As such, if no such information from the training set is available regarding such cases, then making predictions regarding these cases will be guesswork. Put another way, with the increasing sparsity of points, you have an ever decreasing proportionate sample of the space. For example, a thousand observations in a 3-dimensional space might be quite powerful and provide sufficient information to determine a relevant classification or regression model. However, a thousand observations in a million-dimensional space is likely to be utterly useless in determining which features are most influential and to what degree. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality presents an intriguing paradox. On the one hand, more features allow one to account for variance and nuances required to accurately model a given machine learning model. On the other hand, as the number of dimensions increases, the accompanying volume of the hyperspace explodes exponentially. As such, the potential amount of information required to accurately model such a space becomes increasingly complex. (This is not always the case; a simple line can still exist in a 10-dimensional space, but the problems one is likely to be tackling when employing 10 features are most likely more complex than a 2-dimensional model.) With this, more and more observations will be required to produce an adequate model.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-curse-of-dimensionality\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-curse-of-dimensionality\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"the-curse-of-dimensionality"},{"id":457755,"title":"The Curse of Dimensionality - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-curse-of-dimensionality-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll conduct some mathematical simulations to further investigate the consequences of the curse of dimensionality.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCreate and interpret a visual demonstrating how sparsity changes with n for n-dimensional spaces \u003c/li\u003e\n\u003cli\u003eDemonstrate how training time increases exponentially as the number of features increases\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g27ff2fdc813a820fe3664cf8e0538f87"},{"id":457759,"title":"Principal Component Analysis in scikit-learn","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-in-scikitlearn\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen the curse of dimensionality, it's time to take a look at a dimensionality reduction technique! This will help you overcome the challenges of the curse of dimensionality (amongst other things). Essentially, PCA, or Principal Component Analysis, attempts to capture as much information from the dataset as possible while reducing the overall number of features.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain at a high level how PCA works \u003c/li\u003e\n\u003cli\u003eExplain use cases for PCA \u003c/li\u003e\n\u003cli\u003eImplement PCA using the scikit-learn library \u003c/li\u003e\n\u003cli\u003eDetermine the optimal number of n components when performing PCA by observing the explained variance \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gc0f03e96ae12b9559a73a7a051856f69"},{"id":457763,"title":"Principal Component Analysis in scikit-learn - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-in-scikitlearn-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen a brief introduction to PCA, it's time to use scikit-learn to run PCA on your own. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement PCA using the scikit-learn library \u003c/li\u003e\n\u003cli\u003eDetermine the optimal number of n components when performing PCA by observing the explained variance \u003c/li\u003e\n\u003cli\u003ePlot the decision boundary of classification experiments to visually inspect their performance \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g62781b0f81600caf7cf0ef404029b642"},{"id":457767,"title":"Integrating PCA in Pipelines - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-pipelines-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-pipelines-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-pipelines-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn a previous section, you learned about how to use pipelines in scikit-learn to combine several supervised learning algorithms in a manageable pipeline. In this lesson, you will integrate PCA along with classifiers in the pipeline. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIntegrate PCA in scikit-learn pipelines \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g9f909bbb881f8a8f09562043a774c457"},{"id":457771,"title":"PCA for Facial Image Recognition","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-digital-image-processing\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll get to explore an exciting application of PCA: PCA can be used for preprocessing facial image recognition data!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse PCA to discover the principal components of image data\u003c/li\u003e\n\u003cli\u003eUse the principal components of a dataset as features in a machine learning model \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g565911fd864b7ec0428d04864ab03532"},{"id":457775,"title":"Image Recognition with PCA - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-digital-image-processing-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll explore the classic MNIST dataset of handwritten digits. While not as large as the previous dataset on facial image recognition, it still provides a 64-dimensional dataset that is ripe for feature reduction.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse PCA to discover the principal components with images \u003c/li\u003e\n\u003cli\u003eUse the principal components of  a dataset as features in a machine learning model \u003c/li\u003e\n\u003cli\u003eCalculate the time savings and performance gains of layering in PCA as a preprocessing step in machine learning pipelines \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g9e3a49e6940910d53bc3684917edf480"},{"id":457779,"title":"PCA Background: Covariance Matrix and Eigendecomposition","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-covariance-matrix-eigendecomp\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-covariance-matrix-eigendecomp\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-covariance-matrix-eigendecomp/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've gotten a high-level overview of the use cases for PCA and some general notes regarding the algorithm's implementation, its time to dive deeper into the theory behind PCA. In particular, you'll break down some of the primary concepts of the algorithm, including the covariance matrix and eigenvectors.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePerform a covariance matrix calculation with NumPy\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eExplain eigendecomposition and its basic characteristics \u003c/li\u003e\n\u003cli\u003eExplain the role of eigenvectors and eigenvalues in eigendecomposition \u003c/li\u003e\n\u003cli\u003eDecompose and reconstruct a matrix using eigendecomposition \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g228826ed11f4a16c8e008a66f71ae8d1"},{"id":457784,"title":"Performing Principal Component Analysis (PCA)","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-performing-principle-component-analysis\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-performing-principle-component-analysis\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-performing-principle-component-analysis/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll write the PCA algorithm from the ground up using NumPy. This should provide you with a deeper understanding of the algorithm and help you practice your linear algebra skills.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the steps required to perform PCA on a given dataset \u003c/li\u003e\n\u003cli\u003eDecompose and reconstruct a matrix using eigendecomposition \u003c/li\u003e\n\u003cli\u003ePerform a covariance matrix calculation with NumPy \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g6747449b9e6df2c0c494613e6764ddf7"},{"id":457789,"title":"Performing Principal Component Analysis (PCA) - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-numpy-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-numpy-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-numpy-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have a high-level overview of PCA, as well as some of the details of the algorithm itself, it's time to practice implementing PCA on your own using the NumPy package. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement PCA from scratch using NumPy\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g5977d47bef596d1748bef4a87eeec33a"},{"id":457794,"title":"Quiz: Principal Component Analysis","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"gcce01b97a48318c1f25d9ddc9952b337","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"g3edf2c8c948b9f818582eb3cc62d6ce0"},{"id":457808,"title":"Short Video: Solving an Eigenvalue Problem","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813281?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-solving-an-eigenvalue-problem"},{"id":457818,"title":"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab","type":"Quizzes::Quiz","indent":0,"locked":false,"assignmentExportId":"gff74a4f22f0eb7b53d1e8e7675bc604c","questionCount":1,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_submit","completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dimensionality-reduction-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dimensionality-reduction-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch3\u003eSubmission Instructions\u003c/h3\u003e\n\u003cp\u003eWhen you are finished with the lab, complete the following steps to submit your work:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSave the changes to the notebook by clicking the Save icon, shown below highlighted in red\u003cbr\u003e\u003cimg src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202021-07-28%20at%205.41.06%20PM.png\" alt=\"Screenshot of lab with save button highlighted\"\u003e\u0026nbsp;\u003c/li\u003e\n\u003cli\u003eClose the notebook browser tab(s)\u003c/li\u003e\n\u003cli\u003eShut down the notebook server by typing control-C in the terminal window where it is currently running\u003c/li\u003e\n\u003cli\u003eCommit your changes in Git by typing \u003cbr\u003e\u003ccode\u003egit commit -am \"Finished lab\"\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003ePush your changes to GitHub by typing \u003cbr\u003e\u003ccode\u003egit push origin master\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003eOpen the GitHub view of your fork of the lab in the browser. For example, if your username were \u003ccode\u003ehoffm386\u003c/code\u003e, you would go to \u003ca href=\"https://github.com/hoffm386/dsc-data-serialization-lab\" target=\"_blank\"\u003ehttps://github.com/hoffm386/dsc-data-serialization-lab\u003c/a\u003e in the browser for this particular lab. Click on \u003ccode\u003eindex.ipynb\u003c/code\u003e and double-check that your code updates are there. (The updates will not be in the README, only in the \u003ccode\u003e.ipynb\u003c/code\u003e file.)\u003c/li\u003e\n\u003cli\u003eSubmit the link to your fork of the lab in the textbox on Canvas\u003cbr\u003e\u0026nbsp;\u003cimg src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202021-08-24%20at%206.42.54%20PM.png\" alt=\"Screenshot of \u0026quot;Question 1\u0026quot; where the URL should be pasted\"\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eTroubleshooting\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"background-color: #fbeeb8;\"\u003eIf you are able to submit the URL successfully, you do not need to follow the below steps!\u003c/span\u003e\u003c/p\u003e\n\u003ch4\u003eNot a Git Repository\u003c/h4\u003e\n\u003cp\u003eIf you try to run \u003ccode\u003egit commit -am \"Finished lab\"\u003c/code\u003e and get the error message \u003ccode\u003efatal: not a git repository\u003c/code\u003e, double-check that you are running the code from the correct directory. If you type \u003ccode\u003epwd\u003c/code\u003e in the terminal and hit Enter, the path that is printed out should include the directory of the lab ‚Äî in this case, \u003ccode\u003edsc-data-serialization-lab\u003c/code\u003e. For example, a valid path would be \u003ccode\u003e/Users/myname/Development/DS/dsc-data-serialization-lab\u003c/code\u003e, since that ends with the lab directory, whereas \u003ccode\u003e/Users/myname/Development/DS/\u003c/code\u003e would not be a valid path. Use commands like \u003ccode\u003els\u003c/code\u003e and \u003ccode\u003ecd\u003c/code\u003e to navigate to the appropriate directory, then continue with the steps above, starting with step 4.\u003c/p\u003e\n\u003ch4\u003ePermission Denied\u003c/h4\u003e\n\u003cp\u003eIf you try to run \u003ccode\u003egit push origin master\u003c/code\u003e and get a \u003ccode\u003ePermission denied\u003c/code\u003e error message, you are likely trying to push to the curriculum version of the lab, not your personal fork. Follow these steps to fix this:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eIn the browser, go to the curriculum repository for this lab by clicking the \u003cimg src=\"viewer/files/Uploaded%20Media/GitHub-Mark-32px.png\" alt=\"GitHub octocat icon\"\u003e\u0026nbsp;icon above\u003c/li\u003e\n\u003cli\u003eClick the Fork button. If you already have a fork, this will take you to it. If you haven't made a fork yet, this will make the fork and take you to it\u003c/li\u003e\n\u003cli\u003eOn the page of your fork, copy the clone link. For example, \u003ca href=\"https://github.com/hoffm386/dsc-data-serialization-lab.git\" target=\"_blank\"\u003ehttps://github.com/hoffm386/dsc-data-serialization-lab.git\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eBack in the terminal where you were trying to run \u003ccode\u003egit push\u003c/code\u003e, type \u003cbr\u003e\u003ccode\u003egit remote add myfork \u0026lt;URL\u0026gt;\u003c/code\u003e \u003cbr\u003eWhere \u003ccode\u003e\u0026lt;URL\u0026gt;\u003c/code\u003e is replaced with the clone link you copied. For example, \u003ccode\u003egit remote add myfork https://github.com/hoffm386/dsc-data-serialization-lab.git\u003c/code\u003e. Then hit Enter. This means you have created a connection between your local repository and your fork\u003c/li\u003e\n\u003cli\u003eNow, push your code to your fork by typing \u003cbr\u003e\u003ccode\u003egit push myfork master\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003eProceed with the steps above, starting with step 6\u003c/li\u003e\n\u003c/ol\u003e","exportId":"gd4bb2a176d75638f44ca8a45af7b753e"},{"id":457823,"title":"PCA - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-summary\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-summary/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePCA is an \u003cem\u003eunsupervised learning technique\u003c/em\u003e which does not require labeled data \u003c/li\u003e\n\u003cli\u003eIt is also a dimensionality reduction technique which can be used to compress data and experiment with its effects on machine learning algorithms as a preprocessing step \u003c/li\u003e\n\u003cli\u003eThere are four steps to conducting PCA:\n\n\u003cul\u003e\n\u003cli\u003eCenter each feature by subtracting the feature mean\u003c/li\u003e\n\u003cli\u003eCalculate the covariance matrix for your normalized dataset\u003c/li\u003e\n\u003cli\u003eCalculate the eigenvectors/eigenvalues for the covariance matrix\n\n\u003cul\u003e\n\u003cli\u003eReorder your eigenvectors based on their accompanying eigenvalues (in descending order of the eigenvalues)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTake the dot product of the transpose of the eigenvectors with the transpose of the normalized data\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eYou can also easily implement PCA using scikit-learn \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-pca-summary\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-pca-summary\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-pca-summary/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"pca-recap"}]},{"id":47070,"name":"Topic 32: Recommendation Systems","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g0e06344ce8eccc6ff781e3cbbfbb9aa9","items":[{"id":457835,"title":"Topic 32 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan\u003eIn the Live program, there is no scheduled lecture on Singular Value Decomposition (SVD); instead there is a recorded video lecture. Take the time to watch the lecture recording if you are interested in a deeper dive into the linear algebra concepts that tie together PCA and recommendation systems.\u003c/span\u003e\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.526%; height: 127px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eSVD\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Recommendation Systems - Introduction\" href=\"pages/recommendation-systems-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/recommendation-systems-introduction\" data-api-returntype=\"Page\"\u003eRecommendation Systems - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Recommendation Systems\" href=\"pages/introduction-to-recommendation-systems\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-recommendation-systems\" data-api-returntype=\"Page\"\u003eIntroduction to Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Collaborative Filtering and Singular Value Decomposition\" href=\"assignments/g935c2c028baa43d2098a808afe5a8065\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12155\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering and Singular Value Decomposition\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Matrix Factorization with Alternating Least Squares\" href=\"assignments/g735d585333f584530e3ffdaf6d72ee19\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12158\" data-api-returntype=\"Assignment\"\u003eMatrix Factorization with Alternating Least Squares\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.713%; height: 130px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eSVD\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eRecommendation Systems\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"SVD Exit Ticket\" href=\"quizzes/ge90739ce01a620cd258817433744522a\"\u003e\u003cstrong\u003eSVD Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Collaborative Filtering with Surprise\" href=\"assignments/ga6a3b7eadae54ca83ed43d893f924a25\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12156\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering with Surprise\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Collaborative Filtering with Surprise - Lab\" href=\"assignments/g8899aaa2ef46cbed887e639d05c7181f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12157\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering with Surprise - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Recommendation Systems\" href=\"quizzes/g05d801f10914dc65584eb6465ecc0c0f\"\u003eQuiz: Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.713%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eRecommendation Systems\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Recommendation Systems Exit Ticket\" href=\"quizzes/g50cf88f4c370db6969f085cc72c98bb1\"\u003eRecommendation Systems Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Recommendation Systems - Recap\" href=\"pages/recommendation-systems-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/recommendation-systems-recap\" data-api-returntype=\"Page\"\u003eRecommendation Systems - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-32-lesson-priorities-live"},{"id":457839,"title":"Recommendation Systems - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommender-section-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommender-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommender-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about machine learning algorithms that we encounter every day in our lives:  recommendation systems! \u003c/p\u003e\n\n\u003ch2\u003eRecommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll learn about recommendation system modeling approaches and implementations.\u003c/p\u003e\n\n\u003cp\u003eA recommendation system allows predicting the future preference list for a certain customer or user, and recommends the top preference for this user. Examples include: which books would a customer prefer to buy on Amazon, which Netflix movie or series would a user watch next, etc. You'll learn about several different types of recommendation system algorithms and how they work.\u003c/p\u003e\n\n\u003ch2\u003eMatrix Factorization\u003c/h2\u003e\n\n\u003cp\u003eUnder the hood, many recommendation system algorithms use matrix factorization. This can be accomplished using techniques such as Singular Value Decomposition (SVD) and Alternating Least Squares (ALS), which you'll learn about in this section.\u003c/p\u003e\n\n\u003ch2\u003eImplementing Recommender Systems with \u003ccode\u003esurprise\u003c/code\u003e\u003c/h2\u003e\n\n\u003cp\u003e\u003ccode\u003esurprise\u003c/code\u003e is a library that is optimized to efficiently create recommendations. You'll get a chance to use this library to code up different implementations of collaborative filtering recommendation systems.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the basics of recommendation systems and how to implement them in \u003ccode\u003esurprise\u003c/code\u003e!\u003c/p\u003e","exportId":"recommendation-systems-introduction"},{"id":457842,"title":"Introduction to Recommendation Systems","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommendation-system-introduction\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-system-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-system-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson will give you a brief introduction to recommendation system modeling approaches. We will develop intuition into how these systems work and how collaborative filtering is used to make accurate recommendation systems that can harness the power of big data.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the role and rationale for recommendation systems \u003c/li\u003e\n\u003cli\u003eDescribe collaborative filtering recommender systems and their benefits/limitations \u003c/li\u003e\n\u003cli\u003eDescribe content-based recommenders and their benefits/limitations \u003c/li\u003e\n\u003cli\u003eDefine implicit and explicit rating systems \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eProblem Domain\u003c/h2\u003e\n\n\u003cp\u003eThe goal of a recommendation system is to expose people to items that they will like. In exact terms, a recommendation system predicts the future preference of a set of items for a user, and recommends the top items from this set. In today's world, due to the internet and its global reach, people have more options to choose from than ever before.\u003c/p\u003e\n\n\u003cp\u003eConsider buying an album from a traditional music store where the options are always limited and mainly depend upon size and type of the store. There is a physical limitation to how many songs, albums, and artists can be offered. An online product like Spotify, however has a much higher ceiling in terms of storage space. With this new method of selecting products, recommendation systems are a popular way for users to sort through millions of songs to find the ones that are customized exactly for them. Recommendation systems cast a direct impact on profitability and customer satisfaction for most businesses today. With the nearly limitless options consumers have for products online, they need some guidance!\u003c/p\u003e\n\n\u003cp\u003eThis idea can be represented by a concept called the \"Long Tail,\" which is a set of statistical distributions that have a very long \"tail\" of the distribution, representing many occurrences of low frequency things. In the context of consumer products, there are some products that everyone is going to buy: light bulbs, toilet paper, bread etc. There are also items that are far more obscure: specific toys, sports equipment, movies. Recommendation systems are made to help consumers tap into this long tail to assist them in picking from the endless number of options that are made available to them via the internet.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/LongTailConcept.png\" alt=\"graph showing products on the x-axis and popularity on the y-axis. a few products are very popular, labeled Head. many other products are not very popular, labeled Long Tail\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's a formal definition of recommendation systems from authors \u003ca href=\"https://misq.org/e-commerce-product-recommendation-agents-use-characteristics-and-impact.html\"\u003eBo Xiao and Izak Benbasat, 2017\u003c/a\u003e\n :\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRecommendation Systems are software agents that elicit the interests and preferences of individual consumers [‚Ä¶] and make recommendations accordingly. They have the potential to support and improve the quality of the\ndecisions consumers make while searching for and selecting products online.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch2\u003eApplications of Recommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eLet's understand what all recommendation systems can do for businesses:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eHelp in suggesting the merchants/items which a customer might be interested in after buying a product in a marketplace \u003c/li\u003e\n\u003cli\u003eEstimate profit \u0026amp; loss of many competing items and make recommendations to the customer (e.g. buying and selling stocks)\u003c/li\u003e\n\u003cli\u003eBased on the experience of the customer, recommend a customer centric or product centric offering\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eEnhance customer engagement by providing offers which can be highly appealing to the customer \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRecommendation Systems Approaches\u003c/h2\u003e\n\n\u003cp\u003eThere are two main types of recommendation systems: unpersonalized and personalized. In the majority of this section, we will focus on personalized recommendation systems because that's where data scientists can provide the most value to companies, but to start off, let's investigate some unpersonalized systems because they can be productive in their own right.\u003c/p\u003e\n\n\u003ch3\u003eUnpersonalized Recommendations\u003c/h3\u003e\n\n\u003cp\u003eUnpersonalized recommendation systems have been happening since way before machine learning was ever in the public knowledge base. An example of an unpersonalized recommendation would be on YouTube when it recommends the most viewed videos. These are videos that the most people have watched. For the most part, these recommendations aren't too bad. After all, there's a reason why things are popular. This approach, however, is not going to help more niche videos get exposure. It also won't be immensely beneficial to those who have very particular tastes. Of course, there are times when a simple approach like this might be best. An example of a simple popularity recommender working well is with the news. There's a high chance that everyone who visits a news website is going to want to see whatever is the most popular at that moment in time.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/news.png\" alt=\"home page of the New York Times\" width=\"900\"\u003e\u003c/p\u003e\n\n\u003cp\u003eBecause unpersonalized recommendations are based on the entire user pool, whatever item is the most popular at any given time would be recommended to you, even if it's something you are completely uninterested in. There are so many items that are far too obscure to be the \"most popular\" item that might make someone's day. To make more informed recommendations, personalized recommendation systems make use of big data to ensure that users are getting items tailored towards there personal interests, no matter how niche they are.\u003c/p\u003e\n\n\u003ch3\u003ePersonalized Recommendations\u003c/h3\u003e\n\n\u003cp\u003eThe general problem of personalized recommendation systems can be summarized as:\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eGiven\u003c/strong\u003e: \nThe profile of the \"active\" user and possibly some situational context, i.e. user browsing a product or making a purchase etc. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eRequired\u003c/strong\u003e:\nCreating a set of items, and a score for each recommendable item in that set\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eProfile\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cp\u003eUser profile may contain past purchases, ratings in either implicit or explicit form, demographics and interest scores for item features \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThere are two ways to gather such data. The first method is to ask for explicit ratings from a user, typically on a concrete rating scale (such as rating a movie from one to five stars). The second is to gather data implicitly as the user is in the domain of the system - that is, to log the actions of a user on the site.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cstrong\u003eProblem\u003c/strong\u003e:\nWe want to learn a function that predicts the relevance score for a given (typically unseen) item based on user user profile and context \u003c/p\u003e\n\n\u003cp\u003eWithin personalized recommendation systems there are many different possible algorithms. We're going to go over the important ones now.\u003c/p\u003e\n\n\u003cp\u003eEach of these techniques make use of different similarity metrics to determine how \"similar\" items are to one another. The most common similarity metrics are \u003ca href=\"https://en.wikipedia.org/wiki/Euclidean_distance\"\u003eEuclidean distance\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Cosine_similarity\"\u003ecosine similarity\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\"\u003ePearson correlation\u003c/a\u003e and the \u003ca href=\"https://en.wikipedia.org/wiki/Jaccard_index\"\u003eJaccard index (useful with binary data)\u003c/a\u003e. Each one of these distance metrics has its advantages and disadvantages depending on the type of ratings you are using and the characteristics of your data.\u003c/p\u003e\n\n\u003ch3\u003eContent-Based Recommenders\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eMain Idea\u003c/strong\u003e: If you like an item, you will also like \"similar\" items.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/content_based.png\" alt=\"content based filtering. user watches movies, then similar movies are recommended to the user\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThese systems are based on the characteristics of the items themselves. If you ever see a banner ad saying \"try other items like this\", it is most likely a content-based recommender system. The advantage of a content-based recommender system is that it is a recommender system that gives the user a bit more information as to why they are seeing these recommendations. If they are on a page of a book they very much like, they will be happy to see another book that is similar to it. If they are told that this book is similar to their favorite book, they're more than likely to get that book. A disadvantage of content-based recommender systems is that they often require manual or semi-manual tagging of each of products. More advanced versions of content-based recommender systems allow for the development of an average of all the items a user has liked. This allows for a more nuanced approach to incorporate more than one item when calculating which items are most similar.\u003c/p\u003e\n\n\u003ch3\u003eCollaborative Filtering Systems\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eMain Idea\u003c/strong\u003e: If user A likes items 5, 6, 7, and 8 and user B likes items 5, 6, and 7, then it is highly likely that user B will also like item 8.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/collaborative_filtering.png\" alt=\"collaborative filtering: movies watched by both users indicate that the users are similar, then movies are recommended by one user to another user\" width=\"450\"\u003e\u003c/p\u003e\n\n\u003cp\u003eCollaborative filtering systems use a collection of user rating of items to make recommendations. The issue with collaborative filtering is that you have what is called the \"cold start problem.\" The idea behind it is, how to recommend something based off of user activity if you do not have any user activity to begin with! This can be overcome through various techniques. The most important thing to realize is that there is no one best recommendation system technique. In the end, what matters most is what system actually gets people to get recommendations that they will act upon. It might be that on the aggregate, recommending the most popular items is the most cost effective way to introduce users to new products. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eThe key idea behind collaborative filtering is that similar users share similar interests and that users tend to like items that are similar to one another.\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003eWhile this may not be completely true on every occasion, if we have a large enough dataset, if there are patterns present, they will start to emerge.\nAssume there are some users who have bought certain items, we can use a matrix with size \u003cimg class=\"equation_image\" title=\"\\text{num_users} * \\text{num_items}\" src=\"/equation_images/%255Ctext{num_users}%20*%20%255Ctext{num_items}\" alt=\"{\" data-equation-content=\"\\text{num_users} * \\text{num_items}\"\u003e to denote the past behavior of users. Each cell in the matrix represents the associated opinion that a user holds. Such a matrix is called a \u003cstrong\u003eUtility Matrix\u003c/strong\u003e. For instance, \u003cimg class=\"equation_image\" title=\"M_{i, j}\" src=\"/equation_images/M_{i,%20j}\" alt=\"{\" data-equation-content=\"M_{i, j}\"\u003e denotes how user \u003cimg class=\"equation_image\" title=\"u\" src=\"https://learning.flatironschool.com/equation_images/u\" alt=\"{\" data-equation-content=\"u\"\u003e likes item \u003cimg class=\"equation_image\" title=\"i\" src=\"https://learning.flatironschool.com/equation_images/i\" alt=\"{\" data-equation-content=\"i\"\u003e. Sometimes these individual ratings are written as \u003cimg class=\"equation_image\" title=\"r_{ui}\" src=\"/equation_images/r_{ui}\" alt=\"{\" data-equation-content=\"r_{ui}\"\u003e for a rating for a given user and a given item. Using the table below as a reference point, if we replaced the \u003cimg class=\"equation_image\" title=\"u\" src=\"https://learning.flatironschool.com/equation_images/u\" alt=\"{\" data-equation-content=\"u\"\u003e and \u003cimg class=\"equation_image\" title=\"i\" src=\"https://learning.flatironschool.com/equation_images/i\" alt=\"{\" data-equation-content=\"i\"\u003e variable subscripts with actual values it would look like \u003cimg class=\"equation_image\" title=\"r_{\\text{Mike},\\text{Little Mermaid}} = 3\" src=\"/equation_images/r_{%255Ctext{Mike},%255Ctext{Little%20Mermaid}}%20=%203\" alt=\"{\" data-equation-content=\"r_{\\text{Mike},\\text{Little Mermaid}} = 3\"\u003e.\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eToy Story\u003c/th\u003e\n\u003cth\u003eCinderella\u003c/th\u003e\n\u003cth\u003eLittle Mermaid\u003c/th\u003e\n\u003cth\u003eLion King\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eMatt\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLore\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMike\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eForest\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTaylor\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eThe task of a recommendation system would be to come up with ratings for users in the spots that are currently empty. As you can imagine, most of the time, these values will be largely empty. For user 1, our recommendation system would try to predict what user 1 would rate Toy Story and the Little Mermaid and then recommend whichever product our model predicts they would rate the highest. The utility matrix above is what's known as an explicit rating. Each person has rated the movies that they've seen. Frequently, we must infer some meaning from the data and use our own judgment to determine how to use it for a recommendation system. Assume that rather than ratings, we only knew whether or not users bought a movie from a streaming website. Let's take a look at what this table would look like:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eToy Story\u003c/th\u003e\n\u003cth\u003eCinderella\u003c/th\u003e\n\u003cth\u003eLittle Mermaid\u003c/th\u003e\n\u003cth\u003eLion King\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eMatt\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLore\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMike\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eForest\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTaylor\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eThese are \u003cstrong\u003eimplicit\u003c/strong\u003e ratings because we are assuming that because a person has bought something, they would like to buy other items like it. Of course, this is not necessarily true, but it's better than nothing!\u003c/p\u003e\n\n\u003cp\u003eWithin the domain of collaborative filtering, there are both memory-based approaches and model-based approaches that you will learn about in the upcoming lessons.\u003c/p\u003e\n\n\u003ch2\u003eFurther Reading\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"http://infolab.stanford.edu/%7Eullman/mmds/ch9.pdf\"\u003eChapter 9: Mining of Massive Datasets (MMDS)\u003c/a\u003e - A must read for in-depth knowledge about how recommendation systems work, their underlying algorithms and evaluation approaches. This covers most of the topic from this lesson and also the upcoming lessons in great detail. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at an overview of recommendation systems. Focusing on collaborative filtering systems, we will move on to developing user-based engines. \u003c/p\u003e","exportId":"introduction-to-recommendation-systems"},{"id":457847,"title":"Collaborative Filtering with Singular Value Decomposition","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-collaborative-filtering-singular-value-decomposition\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-collaborative-filtering-singular-value-decomposition\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-collaborative-filtering-singular-value-decomposition/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eRecommendation Systems apply IR (Information Retrieval techniques) to select some information relevant to a given user. \u003cstrong\u003eCollaborative Filtering (CF)\u003c/strong\u003e is currently the most widely used approach to build recommendation systems and uses the users‚Äô behavior in the form of user-item ratings for predictions. CF often uses \u003cstrong\u003eMatrix Factorization (MF)\u003c/strong\u003e under the hood. In this lesson, we will look at an overview of the role of the Matrix Factorization model to address the implementation of CF with \u003cstrong\u003eSingular Value Decomposition (SVD)\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare and contrast the advantages/disadvantages of memory vs. model-based recommender systems \u003c/li\u003e\n\u003cli\u003eDescribe how memory-based collaborative filtering methods work \u003c/li\u003e\n\u003cli\u003eDescribe how model-based collaborative filtering models work \u003c/li\u003e\n\u003cli\u003eExplain how SVD is able to extract meaning with latent factors \u003c/li\u003e\n\u003cli\u003eImplement SVD using SciPy \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g935c2c028baa43d2098a808afe5a8065"},{"id":457852,"title":"Matrix Factorization with Alternating Least Squares","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-matrix-factorization-als\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-matrix-factorization-als\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-matrix-factorization-als/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we will look at another matrix factorization technique called Alternating Least Squares (ALS). This method can prove to be much more effective and robust than the SVD we saw earlier. ALS allows you to set regularization measures and minimize a loss function while optimizing the model parameter \u003ccode\u003ek\u003c/code\u003e.  We will look at the math behind this approach in this lesson. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain how bias terms can be used to create more accurate embedding matrices \u003c/li\u003e\n\u003cli\u003eDescribe how ALS is related to matrix decomposition and why it can be parallelized so well \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g735d585333f584530e3ffdaf6d72ee19"},{"id":457857,"title":"üé¨ Lecture: Singular Value Decomposition (SVD)","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding: 56.25% 0 0 0; position: relative;\"\u003e\u003ciframe style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\" title=\"Singular Value Decomposition (SVD)\" src=\"https://player.vimeo.com/video/575551378?badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\u0026amp;h=bae89cb853\" allowfullscreen=\"allowfullscreen\" allow=\"autoplay; fullscreen; picture-in-picture\"\u003e\u003c/iframe\u003e\u003c/div\u003e\n\u003cp\u003e\n\n\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eIn this lecture, Greg Damico introduces the idea of Singular Value Decomposition or SVD. Topics discussed in this lecture include: what is SVD, the relationship between SVD and Eigendecomposition, the relationship between SVD and PCA, diagonalization, dimensionality reduction, least-squares problem, and optimizing problem.\u003c/p\u003e\n\u003cp\u003eThe repository for this lecture can be found here: \u003ca class=\"inline_disabled\" style=\"color: #3598db;\" href=\"https://github.com/flatiron-school/ds-singular_value_decomposition-kvo32\"\u003eSingular Value Decomposition (SVD) Lecture Repository\u003c/a\u003e\u003c/p\u003e","exportId":"lecture-singular-value-decomposition-svd"},{"id":457862,"title":"SVD Exit Ticket","type":"Quizzes::Quiz","indent":0,"locked":false,"assignmentExportId":"g197ae5fb04bdef6077d3d41c39261a20","questionCount":7,"timeLimit":null,"attempts":1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"","exportId":"ge90739ce01a620cd258817433744522a"},{"id":457867,"title":"Implementing Recommendation Engines with Surprise","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-implementing-recommender-systems\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson will give you a brief introduction to implementing recommendation engines with a Python library called \u003ccode\u003esurprise\u003c/code\u003e. You'll get a chance to try out multiple different types of collaborative filtering engines, ranging from both basic neighborhood-based methods to matrix factorization methods. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse \u003ccode\u003esurprise\u003c/code\u003e's built-in reader class to process data to work with recommender algorithms \u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003esurprise\u003c/code\u003e to create and cross-validate different recommender algorithms \u003c/li\u003e\n\u003cli\u003eObtain a prediction for a specific user for a particular item \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga6a3b7eadae54ca83ed43d893f924a25"},{"id":457872,"title":"Implementing Recommender Systems - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-implementing-recommender-systems-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice creating a recommender system model using \u003ccode\u003esurprise\u003c/code\u003e. You'll also get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse surprise's built-in reader class to process data to work with recommender algorithms \u003c/li\u003e\n\u003cli\u003eObtain a prediction for a specific user for a particular item \u003c/li\u003e\n\u003cli\u003eIntroduce a new user with rating to a rating matrix and make recommendations for them \u003c/li\u003e\n\u003cli\u003eCreate a function that will return the top n recommendations for a user \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g8899aaa2ef46cbed887e639d05c7181f"},{"id":457875,"title":"Quiz: Recommendation Systems","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"g5565dca33fa562ec752b104aca49ab30","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"g05d801f10914dc65584eb6465ecc0c0f"},{"id":457892,"title":"Recommendation Systems - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommendation-section-recap\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecommendation approaches can consist of simply recommending popular items (without personalization), or using algorithms which takes into account past customer behavior\u003c/li\u003e\n\u003cli\u003eWhen using algorithms, the two main types are content-based algorithms (recommending new content based on similar \u003cem\u003econtent\u003c/em\u003e), or collaborative filtering based (recommending new content based on similar types of \u003cem\u003eusers\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eCollaborative Filtering (CF) is currently the most widely used approach to build recommendation systems\u003c/li\u003e\n\u003cli\u003eThe key idea behind CF is that similar users have similar interests and that a user generally likes items that are similar to other items they like\u003c/li\u003e\n\u003cli\u003eCF is filling an \"empty cell\" in the utility matrix based on the similarity between users or item. Matrix factorization or decomposition can help us solve this problem by determining what the overall \"topics\" are when a matrix is factored\u003c/li\u003e\n\u003cli\u003eMatrix decomposition can be reformulated as an optimization problem with loss functions and constraints\u003c/li\u003e\n\u003cli\u003eMatrix decomposition can be done using either Singular Value Decomposition (SVD) or Alternating Least Squares (ALS)\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003esurprise\u003c/code\u003e library allows you to build models for CF\u003c/li\u003e\n\u003c/ul\u003e","exportId":"recommendation-systems-recap"}]},{"id":47075,"name":"Topic 33: Clustering","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"gce68bd8eeb6464538bfeaabf4566602f","items":[{"id":457904,"title":"Topic 33 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 97px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eK-Means Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Short Video: Calculating a Silhouette Coefficient\" href=\"pages/short-video-calculating-a-silhouette-coefficient\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-calculating-a-silhouette-coefficient\" data-api-returntype=\"Page\"\u003eShort Video: Calculating a Silhouette Coefficient\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Clustering - Introduction\" href=\"pages/clustering-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/clustering-introduction\" data-api-returntype=\"Page\"\u003eClustering - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"K-means Clustering\" href=\"pages/k-means-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/k-means-clustering\" data-api-returntype=\"Page\"\u003eK-means Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"K-Means Clustering - Lab\" href=\"assignments/ge8a1cb59b882d6b7be9e15aeb4718b6a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187120\" data-api-returntype=\"Assignment\"\u003eK-Means Clustering - Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 168px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eK-Means Clustering\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eHierarchical Agglomerative Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.4187%;\"\u003e\u003cstrong\u003e\u003ca title=\"k-Means Clustering Exit Ticket\" href=\"quizzes/g8cb1c0407af1052fa6e18a30712ec5ec\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30671\" data-api-returntype=\"Quiz\"\u003ek-Means Clustering Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Hierarchical Agglomerative Clustering\" href=\"pages/hierarchical-agglomerative-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/hierarchical-agglomerative-clustering\" data-api-returntype=\"Page\"\u003eHierarchical Agglomerative Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Common Problems with Clustering Algorithms\" href=\"pages/common-problems-with-clustering-algorithms\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/common-problems-with-clustering-algorithms\" data-api-returntype=\"Page\"\u003eCommon Problems with Clustering Algorithms\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Semi-Supervised Learning and Look-Alike Models\" href=\"pages/semi-supervised-learning-and-look-alike-models\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/semi-supervised-learning-and-look-alike-models\" data-api-returntype=\"Page\"\u003eSemi-Supervised Learning and Look-Alike Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Clustering\" href=\"quizzes/g5dfff80ace5a749b059276ee443dd711\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30669\" data-api-returntype=\"Quiz\"\u003eQuiz: Clustering\u003c/a\u003e\u0026nbsp;\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 138px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eHierarchical Agglomerative Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.4187%;\"\u003e\u003ca title=\"Short Video: Calculating a Silhouette Coefficient\" href=\"pages/short-video-calculating-a-silhouette-coefficient\"\u003eShort Video: Calculating a Silhouette Coefficient\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Hierarchical Clustering Exit Ticket\" href=\"quizzes/g8638d28fb34d210eaaac9b6fa0ecde05\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30675\" data-api-returntype=\"Quiz\"\u003eHierarchical Clustering Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Market Segmentation with Clustering\" href=\"pages/market-segmentation-with-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/market-segmentation-with-clustering\" data-api-returntype=\"Page\"\u003eMarket Segmentation with Clustering\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Market Segmentation with Clustering - Lab\" href=\"assignments/gab7e93076acfc2552dcf83a0c4d8c33c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187124\" data-api-returntype=\"Assignment\"\u003eMarket Segmentation with Clustering - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cspan\u003e2nd*\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Clustering - Recap\" href=\"pages/clustering-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/clustering-recap\" data-api-returntype=\"Page\"\u003eClustering - Recap\u003c/a\u003e\u0026nbsp;\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e*This lab may be used for a pairing exercise and might not be published yet; contact your instructor if you have questions\u003c/p\u003e","exportId":"topic-33-lesson-priorities-live"},{"id":457909,"title":"Clustering - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-clustering-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about a useful unsupervised learning technique: clustering. This lesson summarizes the topics you'll be covering in this section.\u003c/p\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003eClustering techniques are very powerful when you want to group data with similar characteristics together, but have no pre-specified labels. The main goal of clustering is to create clusters that have a high similarity between the data belonging to one cluster while aiming for minimal similarity between clusters.  \u003c/p\u003e\n\n\u003ch3\u003eK-Means Clustering\u003c/h3\u003e\n\n\u003cp\u003eWe start by providing a basic intuition of the K-means clustering algorithm. When using the K-means clustering algorithm, the number of clusters that you want to obtain is specified upfront and the algorithm aims at the most \"optimal\" cluster centers, given that there are \u003cem\u003eK\u003c/em\u003e clusters.\u003c/p\u003e\n\n\u003ch3\u003eHierarchical Agglomerative Clustering\u003c/h3\u003e\n\n\u003cp\u003eA second branch of clustering algorithms is hierarchical agglomerative clustering. Using hierarchical clustering, unlike K-means clustering, you don't decide on the number of clusters beforehand. Instead, you start with \u003cem\u003en\u003c/em\u003e clusters, where \u003cem\u003en\u003c/em\u003e is the number of data points, and at each step you join two clusters. You stop joining clusters when a certain criterion is reached.\u003c/p\u003e\n\n\u003ch3\u003eSemi-Supervised Learning\u003c/h3\u003e\n\n\u003cp\u003eSemi-supervised learning techniques, which are increasingly popular in machine learning, combine both concepts of supervised and unsupervised learning.\u003c/p\u003e\n\n\u003ch3\u003eMarket Segmentation with Clustering\u003c/h3\u003e\n\n\u003cp\u003eA very common and useful application of clustering is market segmentation. You'll practice your clustering skills on a market segmentation dataset!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn how to use clustering techniques which are very useful for finding patterns and grouping unlabeled data together.\u003c/p\u003e","exportId":"clustering-introduction"},{"id":457914,"title":"K-means Clustering","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-k-means-clustering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about the most popular and widely-used clustering algorithm, K-means clustering. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare the different approaches to clustering networks \u003c/li\u003e\n\u003cli\u003eExplain the steps behind the K-means clustering algorithm \u003c/li\u003e\n\u003cli\u003ePerform k-means clustering in scikit-learn \u003c/li\u003e\n\u003cli\u003eExplain how clusters are evaluated \u003c/li\u003e\n\u003cli\u003eDefine an \"elbow plot\" and how to interpret it \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eClustering\u003c/em\u003e\u003c/strong\u003e techniques are among the most popular unsupervised machine learning algorithms. The main idea behind clustering is that you want to group objects into similar classes, in a way that:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eintra-class similarity is high (similarity amongst members of the same group is high)\u003c/li\u003e\n\u003cli\u003einter-class similarity is low (similarity of different groups is low)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhat does \u003cem\u003esimilarity\u003c/em\u003e mean? You should be thinking of it in terms of \u003cem\u003edistance\u003c/em\u003e, just like we did with the k-nearest-neighbors algorithm. The closer two points are, the more similar they are. It is useful to make a distinction between \u003cem\u003ehierarchical\u003c/em\u003e and \u003cem\u003enonhierarchical\u003c/em\u003e clustering algorithms:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eIn cluster analysis, an \u003cstrong\u003e\u003cem\u003eagglomerative hierarchical\u003c/em\u003e\u003c/strong\u003e algorithm starts with \u003cem\u003en\u003c/em\u003e clusters (where \u003cem\u003en\u003c/em\u003e is the number of observations, so each observation is a cluster), then combines the two most similar clusters, combines the next two most similar clusters, and so on. A \u003cstrong\u003e\u003cem\u003edivisive\u003c/em\u003e\u003c/strong\u003e hierarchical algorithm does the exact opposite, going from 1 to \u003cem\u003en\u003c/em\u003e clusters.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eA \u003cstrong\u003e\u003cem\u003enonhierarchical\u003c/em\u003e\u003c/strong\u003e algorithm chooses \u003cem\u003ek\u003c/em\u003e initial clusters and reassigns observations until no improvement can be obtained. How initial clusters and reassignments are done depends on the specific type of algorithm.\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAn essential understanding when using clustering methods is that you are basically trying to group data points together without knowing what the \u003cem\u003eactual\u003c/em\u003e cluster/classes are. This is also the main distinction between clustering and classification (which is a supervised learning method). This is why technically, you also don't know how many clusters you're looking for.\u003c/p\u003e\n\n\u003ch2\u003eNon-Hierarchical Clustering With K-Means Clustering\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eK-means clustering\u003c/em\u003e\u003c/strong\u003e is the most well-known clustering technique, and it belongs to the class of non-hierarchical clustering methods. When performing k-means clustering, you're essentially trying to find \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e cluster centers as the mean of the data points that belong to these clusters. One challenging aspect of k-means is that the number \u003cem\u003ek\u003c/em\u003e needs to be decided upon before you start running the algorithm.\u003c/p\u003e\n\n\u003cp\u003eThe k-means clustering algorithm is an iterative algorithm that reaches for a pre-determined number of clusters within an unlabeled dataset, and basically works as follows:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eSelect \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e initial seeds \u003c/li\u003e\n\u003cli\u003eAssign each observation to the cluster to which it is \"closest\"\u003c/li\u003e\n\u003cli\u003eRecompute the cluster centroids\u003c/li\u003e\n\u003cli\u003eReassign the observations to one of the clusters according to some rule\u003c/li\u003e\n\u003cli\u003eStop if there is no reallocation \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eTwo assumptions are of main importance for the k-means clustering algorithm:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eTo compute the \"cluster center\", you calculate the (arithmetic) mean of all the points belonging to the cluster.  Each cluster center is recalculated in the beginning of each new iteration\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eAfter the cluster center has been recalculated, if a given point is now closer to a different cluster center than the center of its current cluster, then that point is reassigned to the closest center \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2\u003eVisualization of K-means Clustering Algorithm\u003c/h2\u003e\n\n\u003cp\u003eIn the animation below, the green dots are the centroids. Notice how they are randomly assigned at the beginning, and shift with each iteration as they are recalculated to match the center of the points assigned to their cluster. The clustering ends when the centroids find a position in which points are no longer reassigned, meaning that the centroids no longer need to move. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/good-centroid-start.gif\" alt=\"k-means clustering animation\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eImplementing K-means Clustering in scikit-learn\u003c/h2\u003e\n\n\u003cp\u003eImplementing k-means clustering with scikit-learn is quite simple because the API mirrors the same functionality that we've seen before. The same preprocessing steps used for supervised learning methods are required -- missing values must be dealt with and all data must be in numerical format (meaning that non-numerical columns must be dropped or one-hot encoded). \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.cluster\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eKMeans\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Set number of clusters at initialization time\n\u003c/span\u003e\u003cspan class=\"n\"\u003ek_means\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eKMeans\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en_clusters\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Run the clustering algorithm\n\u003c/span\u003e\u003cspan class=\"n\"\u003ek_means\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Generate cluster index values for each row\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecluster_assignments\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ek_means\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Cluster predictions for each point are also stored in k_means.labels_\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eEvaluating Cluster Fitness\u003c/h2\u003e\n\n\u003cp\u003eRunning K-means on a dataset is easy enough, but how do we know if we have the best value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e?  The best bet is to use an accepted metric for evaluating cluster fitness such as \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html\"\u003e\u003cstrong\u003e\u003cem\u003eCalinski Harabasz Score\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e, which is more often referred to by a simpler, \u003cstrong\u003e\u003cem\u003eVariance Ratio\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eComputing Variance Ratios\u003c/h3\u003e\n\n\u003cp\u003eThe \u003cem\u003evariance ratio\u003c/em\u003e is a ratio of the variance of the points within a cluster, to the variance of a point to points in other clusters. Intuitively, we can understand that we want intra-cluster variance to be low (suggesting that the clusters are tightly knit), and inter-cluster variance to be high (suggesting that there is little to no ambiguity about which cluster the points belong to). \u003c/p\u003e\n\n\u003cp\u003eWe can easily calculate the variance ratio by importing a function from scikit-learn to calculate it for us, as shown below. To use this metric, we just need to pass in the points themselves, and the predicted labels given to each point by the clustering algorithm. The higher the score, the better the fit.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# This code builds on the previous example\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.metrics\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ecalinski_harabasz_score\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Note that we could also pass in k_means.labels_ instead of cluster_assignments\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecalinski_harabasz_score\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster_assignments\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThere are other metrics that can also be used to evaluate the fitness, such as \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score\"\u003eSilhouette Score\u003c/a\u003e. No one metric is best -- they all have slightly different strengths and weaknesses depending on the given dataset and goals. Because of this, it's generally accepted that it's best to pick one metric and stick to it. \u003c/p\u003e\n\n\u003ch3\u003eFinding the Optimal Value of K\u003c/h3\u003e\n\n\u003cp\u003eNow that we have a way to evaluate how well our clusters fit the dataset, we can use this to find the optimal value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e. The best way to do this is to create and fit different k-means clustering objects for every value of \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e that we want to try, and then compare the variance ratio scores for each. \u003c/p\u003e\n\n\u003cp\u003eWe can then visualize the scores using an \u003cstrong\u003e\u003cem\u003eElbow Plot\u003c/em\u003e\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_elbow-method.png\" alt=\"Calinski Harabaz scores for different values of k\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAn \u003cem\u003eelbow plot\u003c/em\u003e is a general term for plots like this where we can easily see where we hit a point of diminishing returns. In the plot above, we can see that performance peaks at \u003cem\u003ek=6\u003c/em\u003e, and then begins to drop off. That tells us that our data most likely has 6 naturally occurring clusters in our data. \u003c/p\u003e\n\n\u003cp\u003eElbow plots aren't exclusively used with variance ratios -- it's also quite common to calculate something like distortion (another clustering metric), which will result in a graph with a negative as opposed to a positive slope. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_elbow_2.png\" alt=\"the elbow method showing the optimal k\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003ch4\u003eUnderstanding the Elbow\u003c/h4\u003e\n\n\u003cp\u003eA note on elbow plots: higher scores aren't always better. Higher values of \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e mean introducing more overall complexity -- we will sometimes see elbow plots that look like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_dim_returns.png\" alt=\"plot with the number of clusters on the x-axis and the sum of squared distances to cluster center on the y-axis\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, although k=20 technically scores better than k=4, we choose k=4 because it is the \u003cstrong\u003e\u003cem\u003eElbow\u003c/em\u003e\u003c/strong\u003e on the graph. After the elbow, the metric we're trying to optimize for gets better at a much slower rate. Dealing with 20 clusters, when the fit is only slightly better, isn't worth it -- it's better to treat our data as having only 4 clusters, because that is the simplest overall model that provides the most value with the least complexity!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about different kinds of clustering and explored how the k-means clustering algorithm works. We also learned about how we can quantify the performance of a clustering algorithm using metrics such as variance ratios, and how we can use these metrics to find the optimal value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e by creating elbow plots!\u003c/p\u003e","exportId":"k-means-clustering"},{"id":457919,"title":"K-means Clustering - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-k-means-clustering-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll implement the k-means clustering algorithm using scikit-learn to analyze a dataset!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePerform k-means clustering in scikit-learn \u003c/li\u003e\n\u003cli\u003eDescribe the tuning parameters found in scikit-learn's implementation of k-means clustering \u003c/li\u003e\n\u003cli\u003eUse an elbow plot with various metrics to determine the optimal number of clusters \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ge8a1cb59b882d6b7be9e15aeb4718b6a"},{"id":457937,"title":"Hierarchical Agglomerative Clustering","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-hierarchical-agglomerative-clustering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about another popular class of clustering algorithms -- hierarchical agglomerative clustering!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the process behind hierarchical agglomerative clustering \u003c/li\u003e\n\u003cli\u003eDescribe the three different linkage criteria for hierarchical agglomerative clustering \u003c/li\u003e\n\u003cli\u003eDefine the purpose of a dendrogram \u003c/li\u003e\n\u003cli\u003eCompare and contrast k-means and hierarchical agglomerative clustering methodologies\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eUnderstanding Hierarchical Clustering\u003c/h2\u003e\n\n\u003cp\u003eSo far, we've worked with a non-hierarchical clustering algorithm, k-means clustering. K-means works by taking a set parameter that tells it how many clusters we think exist in the data, and then uses the Expectation-Maximization (EM) algorithm to iteratively shift each cluster centroid to the best possible position by constantly calculating and recalculating the centroid's position by assigning each point to the cluster centroid they are closest to with each new step, and then moving the centroid to the center of all the points currently assigned to that centroid. With non-hierarchical algorithms, there can be no subgroups -- that is, no clusters within clusters.\u003c/p\u003e\n\n\u003cp\u003eThis is where agglomerative clustering algorithms come in. In agglomerative clustering, the algorithm starts with \u003cimg class=\"equation_image\" title=\"n\" src=\"https://learning.flatironschool.com/equation_images/n\" alt=\"{\" data-equation-content=\"n\"\u003e clusters (where \u003cimg class=\"equation_image\" title=\"n\" src=\"https://learning.flatironschool.com/equation_images/n\" alt=\"{\" data-equation-content=\"n\"\u003e is the number of data points) and proceeds by merging the most similar clusters, until some stopping criterion. in \u003ccode\u003escikit-learn\u003c/code\u003e, the stopping criterion that is implemented is \"number of clusters\".  If left alone, the algorithm will work until it has merged every cluster into one giant cluster. We can also set the limit, if we want, to stop when there are only [x] clusters remaining. \u003c/p\u003e\n\n\u003ch3\u003eLinking Similar Clusters Together\u003c/h3\u003e\n\n\u003cp\u003eSeveral linkage criteria that have different definitions for \"most similar clusters\" can be used. The measure is always defined between two existing clusters up until that point, so the later in the algorithms, the bigger the clusters get.\u003c/p\u003e\n\n\u003cp\u003eScikit-learn provides three linkage criteria:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eward\u003c/strong\u003e (default): picks the two clusters to merge in a way that the variance within all clusters increases the least. Generally, this leads to clusters that are fairly equally sized.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eaverage\u003c/strong\u003e: merges the two clusters that have the smallest \u003cstrong\u003e\u003cem\u003eaverage\u003c/em\u003e\u003c/strong\u003e distance between all the points.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003ecomplete\u003c/strong\u003e (or maximum linkage): merges the two clusters that have the smallest \u003cstrong\u003e\u003cem\u003emaximum\u003c/em\u003e\u003c/strong\u003e distance between their points.\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs we'll see in the next lab, these linkage criteria can definitely have an effect on how the clustering algorithm performs. As always seems to be the case, no one of these is \"best\" -- which one you should use often depends on the structure of your data, and/or your own goals. \u003c/p\u003e\n\n\u003ch3\u003eA Visual Example\u003c/h3\u003e\n\n\u003cp\u003eIt's often easier to understand what the HAC algorithm is doing when we look at the decisions it makes at each given step. The following diagram demonstrates the clusters created at each step for a dataset of 16 points. Take a look at the diagram and see if you can figure out what the algorithm is doing at each step as it merges clusters together:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/hac_iterative.png\" alt=\"initialization through step 14 of HAC algorithm\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs we can see from the diagram above, in each step, the algorithm takes the two clusters that are closest together (and remember, we define \"closest together\" according to whichever linkage criteria we choose to use), and then \u003cstrong\u003e\u003cem\u003emerge\u003c/em\u003e\u003c/strong\u003e those two clusters together into a single cluster. We don't move the data points or anything like that -- we just consider them as a single unit, as opposed to two separate ones. This works at every stage because in the beginning, we treat each data point as a unique cluster. \u003c/p\u003e\n\n\u003cp\u003eThis becomes very intuitive when we look at the following gif -- pay attention to the image on the left:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/dendrogram_gif.gif\" alt=\"animation of clusters shown in x-y space on the left and a dendrogram on the right, showing which clusters correspond to which parts of the dendrogram\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs the dots disappear, the visualization is replacing them with the newly calculated center of that cluster, which will be used for linkage purposes. Now, let's end this lesson by talking about visualizations we can use to interpret results!\u003c/p\u003e\n\n\u003ch3\u003eDendrograms and Clustergrams\u003c/h3\u003e\n\n\u003cp\u003eOne advantage of HAC is that we can easily visualize the results \u003cstrong\u003e\u003cem\u003eat any given step\u003c/em\u003e\u003c/strong\u003e using visualizations such as \u003cstrong\u003e\u003cem\u003eDendrograms\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eClustergrams\u003c/em\u003e\u003c/strong\u003e. Take another look at the gif above, but this time, pay attention to the image on the right.  This is a \u003cem\u003edendrogram,\u003c/em\u003e which is used to visualize the hierarchical relationship between the various clusters that are computed throughout each step. Dendrograms are very useful to decide how clusters change depending on the euclidean distance. If you decide that your intra-cluster euclidean distance should be smaller than 3, you can draw a horizontal line at euclidean distance 3, and define which points belong to which cluster by looking at the dendrogram. For the gif above, this means that there are three clusters: cluster one contains \u003cimg class=\"equation_image\" title=\"p_0\" src=\"https://learning.flatironschool.com/equation_images/p_0\" alt=\"{\" data-equation-content=\"p_0\"\u003e, \u003cimg class=\"equation_image\" title=\"p_1\" src=\"https://learning.flatironschool.com/equation_images/p_1\" alt=\"{\" data-equation-content=\"p_1\"\u003e and \u003cimg class=\"equation_image\" title=\"p_2\" src=\"https://learning.flatironschool.com/equation_images/p_2\" alt=\"{\" data-equation-content=\"p_2\"\u003e, cluster two contains \u003cimg class=\"equation_image\" title=\"p_3\" src=\"https://learning.flatironschool.com/equation_images/p_3\" alt=\"{\" data-equation-content=\"p_3\"\u003e, cluster three contains \u003cimg class=\"equation_image\" title=\"p_4\" src=\"https://learning.flatironschool.com/equation_images/p_4\" alt=\"{\" data-equation-content=\"p_4\"\u003e, \u003cimg class=\"equation_image\" title=\"p_5\" src=\"https://learning.flatironschool.com/equation_images/p_5\" alt=\"{\" data-equation-content=\"p_5\"\u003e and \u003cimg class=\"equation_image\" title=\"p_6\" src=\"https://learning.flatironschool.com/equation_images/p_6\" alt=\"{\" data-equation-content=\"p_6\"\u003e.\u003c/p\u003e\n\n\u003cp\u003eWe can also visualize the same information by drawing lines representing each cluster at each step to create a \u003cem\u003eclustergram\u003c/em\u003e. Take a look at the following diagram below, which shows both a dendrogram and clustergram of the same HAC results:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/new_clustergram.png\" alt=\"another view of clusters on the left and dendrogram on the right\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eHow is HAC used?\u003c/h3\u003e\n\n\u003cp\u003eHAC algorithms are used in generally the same way that K-means and other clustering algorithms are used: for tasks such as market segmentation, or for gaining a deeper understanding of a dataset through cluster analysis. However, there are special cases of things that fit quite well in a hierarchical agglomerative structure -- one of the most common use cases you'll see for HAC is the way that smartphones naturally sort photos inside their photos app! Take a look at your photos app on your phone, and the albums that it creates for you -- you'll likely see that the albums are sorted in a \u003cstrong\u003e\u003cem\u003ehierarchical\u003c/em\u003e\u003c/strong\u003e fashion! Perhaps the phone chooses to group photos by date first, and then by location,  or even content! In this way, these can be viewed as natural clusters within clusters, in a way that makes intuitive sense to users. When we browse, we likely want to see photos that were taken around the same time, and then at the same place, and then narrow it down to photos about the same things, to quickly browse and find what we're looking for. This is a great example of HAC being used in the wild!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about how the HAC algorithm derives its clusters, including different linkage criteria that can be used to determine which clusters should be merged at any given point. We also examined some visualizations of HAC algorithms, in the forms of dendrograms and clustergrams!\u003c/p\u003e","exportId":"hierarchical-agglomerative-clustering"},{"id":457941,"title":"Common Problems with Clustering Algorithms","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-common-problems-with-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-common-problems-with-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we'll discuss some of the common problems often seen when attempting clustering with k-means or hierarchical agglomerative clustering.\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIdentify the problems that can arise from bad centroid initializations in k-means and bad initial groups in HAC\u003c/li\u003e\n\u003cli\u003eCompare and contrast k-means and hierarchical agglomerative clustering methodologies\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommon Problems with Clustering\u003c/h2\u003e\n\u003cp\u003eWhen working with clustering algorithms, there are certain problems that we should always be aware of in order to help us prevent situations where we unknowingly accept the results of a bad clustering. Understanding the potential problems that can arise with each clustering algorithm also tends to provide greater insight into how each algorithm works.\u003c/p\u003e\n\u003cp\u003eThe most common issue is one that is applicable to all forms of clustering -- we have no way of verifying if the results of the cluster analysis are correct or not! Always try to keep this in mind when working with clustering algorithms, and never make the mistake of treating the results of a cluster analysis as ground-truth.\u003c/p\u003e\n\u003cp\u003eTo further drive this point home, let's spend some time looking at common problems with the two kinds of clustering algorithms we've talked about so far so that we can gain insight into the situations where clustering algorithms fall short.\u003c/p\u003e\n\u003ch2\u003eAdvantages \u0026amp; Disadvantages of K-Means Clustering\u003c/h2\u003e\n\u003cp\u003eThe advantages of the k-means clustering approach are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eVery easy to implement!\u003c/li\u003e\n\u003cli\u003eWith many features, k-means is usually faster than HAC (as long as \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e is reasonably small)\u003c/li\u003e\n\u003cli\u003eObjects are locked into the cluster they are first assigned to and can change as the centroids move around\u003c/li\u003e\n\u003cli\u003eClusters are often tighter than those formed by HAC\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, this algorithm often comes with several disadvantages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQuality of results depends on picking the right value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e . This can be a problem when we don't know how many clusters to expect in our dataset\u003c/li\u003e\n\u003cli\u003eScaling our dataset will completely change the results\u003c/li\u003e\n\u003cli\u003eInitial start points of each centroid have a very strong impact on our final results. A bad start point can cause sub-optimal clusters (see example below)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-common-problems-with-clustering/master/images/bad-centroid-start.gif\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://shabal.in/visuals/kmeans/right.gif\"\u003egif courtesy of Andrey A. Shabalin\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe animation above shows what can happen when we get a bad centroid initialization. Because of the random points that the centroids were initialized at, this led to one centroid cluster containing no points, while another cluster centroid has combined two clusters by being located in between them! Even though we had the correct value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e (since we have 4 centroids, and data clearly contains 4 clusters), we ended up with incorrect results.\u003c/p\u003e\n\u003cp\u003eSince every dataset is different, and centroids are generated randomly, there is no way to make sure that we have good centroid initialization every time. One way to deal with this is to run a clustering algorithm multiple times, and keep track of how many times the same results come up. The good news here is that bad centroid initializations are typically much less likely than good centroid initializations, so the chances of getting bad results due to poor centroid initialization multiple times in a row are somewhat unlikely.\u003c/p\u003e\n\u003cp\u003eNow, let's take a look at HAC.\u003c/p\u003e\n\u003ch2\u003eAdvantages \u0026amp; Disadvantages of HAC\u003c/h2\u003e\n\u003cp\u003eHAC is useful as a clustering algorithm because:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt produces an ordered relationship between clusters, which can be useful when visualized\u003c/li\u003e\n\u003cli\u003eSmaller clusters are created. This allows us to get a very granular understanding of our dataset, and zoom in at the level where the clusters make the most sense to us (note the coloration of the lines in the example dendrogram above)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, this algorithm is also built on some assumptions which can be disadvantages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eResults are usually dependent upon the distance metric used\u003c/li\u003e\n\u003cli\u003eObjects can be grouped 'incorrectly' early on, with no way to relocate them. For instance, consider two points that belong to separate clusters, but are both nearer to each other than the center of the cluster they actually belong to (both are near the \"boundary\" between their cluster and the opposing cluster). These will be incorrectly grouped as a cluster, which will throw off the clustering of the groups they actually belong to, as well\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look at an example. Consider the circled points in the following plot:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-common-problems-with-clustering/master/images/new_bad-hac.png\" width=\"600\"\u003e\u003c/p\u003e\n\u003cp\u003eThe two points circled are from different clusters. However, they are right on the boundary between the two clusters, which has significant overlap between them. Because of this, there is a good chance that the clusters will meet the linkage criteria, and the HAC algorithm will group them together. The centroid of this new (incorrect) cluster is also close to many points on the boundary, meaning that it is quite likely that those points will be merged and the incorrect cluster will grow bigger. Early mistakes with the HAC algorithm tend to act as a bit of a slippery slope, and since HAC doesn't constantly reassign points like k-means does, this means that things can go from bad to worse if mistakes are made early on.\u003c/p\u003e\n\u003ch2\u003eA Note on Visualization\u003c/h2\u003e\n\u003cp\u003eSo far, we've checked our work by looking at visualizations of the clusters and using our eyes and our judgment to check if we agree with the results of the algorithm. However, it's worth remembering that this is highly unlikely to be an option on real-world data since we can't visualize any data with more than 3 dimensions. Because of this, it's often much harder to tell when a clustering algorithm has made a mistake, because we aren't able to use our eyes to confirm or deny the results!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we learned about some of the challenges that come with clustering, and the relative advantages and disadvantages of k-means and hierarchical agglomerative clustering.\u003c/p\u003e","exportId":"common-problems-with-clustering-algorithms"},{"id":457944,"title":"Hierarchical Agglomerative Clustering - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-hierarchical-agglomerative-clustering-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this codealong, you'll observe how hierarchical agglomerative clustering works by examining various visualizations at each step of the algorithm. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDetermine the best linkage strategy for a dataset by creating clusters and evaluating the results \u003c/li\u003e\n\u003cli\u003eCreate and interpret a dendrogram while using HAC to determine the optimal number of clusters \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g47cac2a10c36c2b793562d01cb0eebff"},{"id":457947,"title":"Semi-Supervised Learning and Look-Alike Models","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about some unsupervised learning techniques we can use to supplement our supervised learning techniques.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify appropriate use cases for semi-supervised learning \u003c/li\u003e\n\u003cli\u003eIdentify appropriate use cases for look-alike models \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCombining Supervised and Unsupervised Learning\u003c/h2\u003e\n\n\u003cp\u003eFor the majority of this section, we've focused exclusively on popular unsupervised learning techniques and their most common use cases. However, in the real world, there are also plenty of examples where it works to our advantage to bring supervised and unsupervised learning algorithms together to supplement each other. In this lesson, we'll look at two common areas combining supervised and unsupervised learning algorithms that allow us to be more effective than just using them on their own. \u003c/p\u003e\n\n\u003ch2\u003eUse Case 1: Look-Alike Models\u003c/h2\u003e\n\n\u003cp\u003eAs we've learned when working with clustering algorithms, one of their most common use cases is for market segmentation. A more advanced, but similar use case is to then use these market segments to create \u003cstrong\u003e\u003cem\u003elook-alike models\u003c/em\u003e\u003c/strong\u003e to help us identify more customers or market segments that we can plausibly assume are equally valuable, due to their similarity with valuable customers or market segments we've already identified. \u003c/p\u003e\n\n\u003cp\u003eTake a look at the following infographic that provides a visual representation of look-alike modeling:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/master/images/new_look-alike-model.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, the dark blue smiley faces represent customer segments that we already know are valuable. These are customers that we have identified in our data, and know for a fact have been good for us. Under normal circumstances, this would mean that we can divide our customers (or, more often, potential customers) into two groups: the group we know is valuable, and everyone else, who are all unknown to us. \u003c/p\u003e\n\n\u003cp\u003eThis is where \u003cem\u003elook-alike modeling\u003c/em\u003e comes in. A look-alike model uses a distance metric of our choice to rate the similarity of each customer in our group of unknowns to customers in our known, valuable group. For customers that look extremely similar to customers in own known valuable group, we can assume with a very high likelihood that these customers will also be valuable, and should direct resources at capturing them! We'll likely also see customers that are only somewhat similar to our valuable group, which tells us that they \u003cem\u003ecould possibly be valuable\u003c/em\u003e, but we aren't sure. And finally, customers that look nothing like our known valuable customers segment, should probably be left alone.  \u003c/p\u003e\n\n\u003cp\u003eIf this sounds suspiciously like clustering to you, you are absolutely correct! Although this could also be framed as a classification or regression problem, it's quite common to see clustering used to help determine similarity. After all, if we want to build a supervised learning model to predict if an unknown customer looks like our known valuable customers, then we need plenty of labeled examples, and we don't always have that luxury! \u003c/p\u003e\n\n\u003cp\u003eIn the real-world, using look-alike models to find other customers that could potentially be valuable to us is often referred to as \u003cstrong\u003e\u003cem\u003eprospecting\u003c/em\u003e\u003c/strong\u003e. Viewed in terms of the infographic above, we would choose direct resources to market to the customers that look like our valuable customers to increase our \u003cstrong\u003e\u003cem\u003etop-of-funnel\u003c/em\u003e\u003c/strong\u003e, meaning that we are trying to increase the number of potential customers that haven't shown interest in our product or company yet but are likely to, due to their similarity to customers that already have. \u003c/p\u003e\n\n\u003ch2\u003eUse Case 2: Semi-Supervised Learning\u003c/h2\u003e\n\n\u003cp\u003eThe second use case we'll talk about combines supervised and unsupervised learning to allow us access to more (pseudo) labeled data so that we can better train our supervised learning models. This technique is called \u003cstrong\u003e\u003cem\u003esemi-supervised learning\u003c/em\u003e\u003c/strong\u003e.  You may also hear it commonly referred to as \u003cstrong\u003e\u003cem\u003eweakly supervised learning\u003c/em\u003e\u003c/strong\u003e, but it means the same thing. \u003c/p\u003e\n\n\u003cp\u003ePicture the following scenario: \u003c/p\u003e\n\n\u003cp\u003eWe are trying to build a supervised learning model, and we have 100,000 observations in our dataset. However, labels are exceedingly expensive, so only 5,000 of these 100,000 observations are labeled. In traditional supervised learning, this means that in a practical sense, we really only have a dataset of 5,000 observations, because we can't do anything with the 95,000 unlabeled examples -- or can we?\u003c/p\u003e\n\n\u003cp\u003eThe main idea behind \u003cem\u003esemi-supervised learning\u003c/em\u003e is to generate \u003cstrong\u003e\u003cem\u003epseudo-labels\u003c/em\u003e\u003c/strong\u003e that are possibly correct (at least better than random chance). To do this, we don't usually use clustering algorithms -- instead, we use our supervised learning algorithms in an unsupervised way. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/master/images/new_semi-supervised.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSupervised learning typically follows a set pattern:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTrain your model on your labeled training data\u003c/em\u003e\u003c/strong\u003e. In the case of our example above, we would build the best model possible with our tiny dataset of 5,000 labeled examples. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eUse your trained model to generate pseudo-labels for your unlabeled data\u003c/em\u003e\u003c/strong\u003e. This means having our trained model make predictions on our 95,000 unlabeled examples. Since our trained model does better than random chance, this means that our generated pseudo-labels will be at least somewhat more correct than random chance. We can even put a number to this, by looking at the performance our trained model had on the test set. For example, if our trained model had an accuracy of ~70%, then we can assume that ~70% of the pseudo-labels will be correct, ~30% will be incorrect. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCombine your labeled data and your pseudo-labeled data into a single, new dataset.\u003c/em\u003e\u003c/strong\u003e. This means that we concatenate all our labeled data of 5,000 examples with the 95,000 pseudo-labeled examples. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRetrain your model on the new dataset\u003c/em\u003e\u003c/strong\u003e. Although some of the pseudo-labeled data will certainly be wrong, it's likely that the amount that is correct will be more useful, and the signal that these correctly pseudo-labeled examples provide will outweigh the incorrectly labeled ones, thereby resulting in better overall model performance. \u003c/p\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3\u003eBenefits and Drawbacks of Semi-Supervised Learning\u003c/h3\u003e\n\n\u003cp\u003eIf semi-supervised learning sounds a bit risky to you, you're not wrong. When done correctly, semi-supervised learning can increase overall model performance by opening up access to much more data than we would have access to, and more data almost always results in better performance, but without the exorbitant costs of paying to have humans generate labels for the data needed. \u003c/p\u003e\n\n\u003cp\u003eHowever, there are definitely some problems that can arise from using a semi-supervised learning approach, if we're not careful and thoughtful throughout.\u003c/p\u003e\n\n\u003ch4\u003eFeedback Loops and Self-Fulfilling Prophecies\u003c/h4\u003e\n\n\u003cp\u003eSemi-supervised learning tends to work fairly well in many use cases and has become quite a popular technique in the field of Deep Learning, which requires massive amounts of labeled data that is often very expensive to obtain. But what happens when our dataset is extremely noisy to begin with? In that case, our incorrect pseudo-labels may skew the model by introducing more \"noise\" than \"signal\". This is partially because we can end up in a feedback loop of sorts. Think about an example where the model has generated an incorrect pseudo-label. If a model trained only on the real data with no pseudo-labels got this example wrong, then what happens when you train the model on the same example, but this time provide a pseudo-label that \"confirms\" this incorrect belief? When done correctly, we can hope that the signal provided by all the correctly pseudo-labeled examples will generalize to help the model correct its mistakes on the ones it got wrong. However, if the dataset is noisy, or the original model wasn't that good to begin with (or both), then it can be quite likely that we are introducing even more incorrect information than correct information, moving the model in the wrong direction.\u003c/p\u003e\n\n\u003cp\u003eSo how do we make sure that we're not making these mistakes when using a semi-supervised approach? \u003cstrong\u003e\u003cem\u003eUse a holdout set!\u003c/em\u003e\u003c/strong\u003e You should definitely have a test set that the model has never seen before to check the performance of your semi-supervised model. Obviously, make sure that your test set only contains actual, ground-truth labeled examples, no pseudo-labels allowed! Also, the noisier your dataset or more complicated your problem, the more likely you are to run into trouble with semi-supervised learning. When possible, try to structure your tasks as binary classification tasks, rather than multi-categorical, and make sure that your dataset is as clean as possible before attempting semi-supervised learning. Although it seems risky, there's a reason companies that are heavy into deep learning and AI research such as Google, Microsoft, and Facebook make heavy use of semi-supervised learning -- when done correctly, it works wonders, without costing an arm and a leg to pay for labeling!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about two popular methodologies for using unsupervised learning in applied, focused ways to help companies generate more revenue, get more customers, or increase model performance without paying for more labeled training data!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-semi-supervised-learning-and-look-alike-models\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-semi-supervised-learning-and-look-alike-models\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"semi-supervised-learning-and-look-alike-models"},{"id":457951,"title":"Quiz: Clustering","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"gcc5993b6c22475a215c8cc6f881d46fb","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"g5dfff80ace5a749b059276ee443dd711"},{"id":457965,"title":"Short Video: Calculating a Silhouette Coefficient","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813625?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-calculating-a-silhouette-coefficient"},{"id":457974,"title":"Market Segmentation with Clustering","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we'll learn about one of the most popular use cases for clustering in the business world -- market segmentation!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain market segmentation and how clustering can be used for it\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eWhat is Market Segmentation?\u003c/h2\u003e\n\u003cp\u003ePerhaps the most common use case for clustering algorithms in the real world, \u003cstrong\u003e\u003cem\u003eMarket Segmentation\u003c/em\u003e\u003c/strong\u003e refers to using \u003cstrong\u003e\u003cem\u003eCluster Analysis\u003c/em\u003e\u003c/strong\u003e to segment a customer base into different \u003cem\u003emarket segments\u003c/em\u003e using the clustering techniques we've learned.\u003c/p\u003e\n\u003cp\u003eConsider the following scenario: You're a movie executive, and you have a new superhero film coming out. You need to decide how to best allocate your advertising budget in order to attract the most customers. This film is a sequel, so you have good demographic data on who went to see the last film. The advertising options available to you are TV, newspaper, radio, and internet. How do you best allocate your advertising budget to ensure that the movie does as well as possible?\u003c/p\u003e\n\u003cp\u003eThe answer depends on your data. A regression analysis on last year's data can give you a general idea of how much you can expect to make overall, assuming that there aren't major differences between last year and this year. However, regression just tells you what you can expect \u003cem\u003eoverall\u003c/em\u003e -- what if we're trying to optimize where we spend our money, rather than just predict what the returns will be, based on the overall amount of money we spent?\u003c/p\u003e\n\u003cp\u003eThe answer lies in knowing who your customer is. All forms of advertising are not consumed equally by every age group or demographic. By identifying \u003cstrong\u003e\u003cem\u003esegments\u003c/em\u003e\u003c/strong\u003e in our customer data, we can look for trends that identify one group or another, and create personalized regression models for each group.\u003c/p\u003e\n\u003cp\u003eIn order to understand this better, let's take a sample question that market segmentation can help us answer. For our TV advertising budget, we still have to decide what channel to run our commercials on. What effect will advertising on the Disney channel have on a person's likelihood of coming to see our superhero movie? If the person in question is 12 years old, then it's probably very likely that our commercial convinces this person to see our movie. But what about if they're 68 years old? In that case, advertising during a cartoon on the Disney channel might not be the most effective way to reach that person. If we're worried about reaching this customer, the first question we should ask is what kind of customer they are. In the case of a superhero movie, we can likely assume that all things equal, a 12-year-old child is more likely to be interested in seeing a superhero movie after seeing our commercial than a 68-year-old, so we should probably pay attention to what the data tells us about how 12-year-olds are affected by each type of media advertisement we can use!\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_old-man-little-boy-talking.png\" width=\"600\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTwo potential customers deep in conversation about what movie to see\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eYou can bet that movie studio executives have complex, well-defined models to predict their Return on Investment (RoI) for things as granular as advertising on Disney, versus advertising on the History channel. This is because different market segments of customers behave differently, and market segmentation allows us to zoom in on those groups!\u003c/p\u003e\n\u003ch3\u003eIdentifying Market Segmentation\u003c/h3\u003e\n\u003cp\u003eAt the most basic level, market segmentation allows us to look at our data and identify which customers belong to which groups. Once we have this information, we can examine each individual segment and use it to answer important questions and build individual, targeted models for each segment.\u003c/p\u003e\n\u003cp\u003eOnce we understand our market segments, then we can begin making informed decisions that are specific to each segment. So how do we find these market segments?\u003c/p\u003e\n\u003cp\u003eWith clustering, of course! By definition, market segments are groups within our dataset with substantive differences between them. A segment only matters to us if it is different from other groups -- we don't really care about identifying the segment of children with red hair versus children with brown hair in our data if they both act the same way and have the same level of interest in our movie. Before data scientists became commonplace, this sort of segmentation was usually handled by marketers using their intuition about their customer base to create \u003cem\u003ecustomer personas\u003c/em\u003e, and then seek out data to back up their assumptions. As data scientists, we know that the best option is not to seek data to confirm our beliefs -- instead, it is to pull our beliefs from evidence in the data. Clustering provides a great way for us to allow the data to tell us what is and isn't significant -- lest we get caught up chasing down market segments that aren't actually all that different -- or worse, don't actually exist at all!\u003c/p\u003e\n\u003ch2\u003eSegmentation and Targeting\u003c/h2\u003e\n\u003cp\u003eIn modern business analytics, segmentation is only the first step.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_marketing-strategy.png\" width=\"700\"\u003e\u003c/p\u003e\n\u003cp\u003eAfter we've identified the different market segments, the next step is to build individualized strategies to \u003cstrong\u003e\u003cem\u003eTarget\u003c/em\u003e\u003c/strong\u003e them! In the movie example we used above, we would first start by answering questions such as \"which market segment is most valuable to us?\" This can be answered through research or through analyzing our data, or a combination of both. Once we realized that the 12-to-18-year-old demographic is most valuable to us, we can then decide how to target them in the most effective way possible. This brings us back to our earlier question -- how do we allocate our advertising budget? If we've used regression to determine that we're most likely to get the return on investment for our advertising dollars with the 12-to-18-year-old age group, then our next step is to determine which ad channels are most effective to us. We'll likely find that TV advertisements and internet ads are very effective at reaching this particular market segment, but radio is less effective (since a solid portion of the target segment can't yet drive), and newspaper ads are unlikely to reach them at all (because when is the last time you saw a 12-year-old read a newspaper?).\u003c/p\u003e\n\u003cp\u003eThe third step in this process is a bit outside the scope of clustering. This is where the marketing team really shines -- figuring out how to position our product to make it both as desirable as possible to a given segment, while also making our product stand out from competitors.\u003c/p\u003e\n\u003cp\u003eLet's look at one more example to consider what this looks like: car advertisements!\u003c/p\u003e\n\u003cp\u003eScenario: You are the newest data scientist at Tesla Motors. Next year, you are introducing a new SUV in the $30-50k price range. The SUV is roomy, spacious, fast, and affordable, in addition to having a very high safety rating and a ton of technological bells and whistles. One day, Elon Musk asks you (presumably, on Twitter) who your valuable market segments are, and what parts of the car he should highlight in several upcoming interviews. How do you answer this question?\u003c/p\u003e\n\u003cp\u003ePresumably, the first thing you would do is to look at the results of your market segmentation and identify the most profitable market segments to target. Once you know who these segments are, you can target them with ads -- but this only brings us to the second step in our diagram above. The third step means personalizing these ads to have maximum impact on a given targeted segment. Is your target market middle-class families? Then maybe it makes sense to highlight the car's affordability, space, and safety rating. What about if your target is upper-middle-class customers between 30 and 40 years of age that enjoy luxury cars? In that case, you'd probably focus on the speed, luxury, and looks of the car, because they're more likely to care about these qualities than the others.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_market_seg.png\" width=\"70%\" height=\"70%\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eWhen you know your market segment, you can market to them in the most effective way possible!\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eStep 3 in this process is usually done with the help of survey data, under the umbrella of \u003cem\u003eUser Research\u003c/em\u003e. This is not something that data scientists typically have to worry about too much, as it is a different domain of expertise. However, the first two stages are very much something that data scientists can expect to do multiple times in their career!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we learned about how cluster analysis can be applied to determine market segmentation, and how these market segments are used in the real world to plan and execute effective business strategies!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\n\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" title=\"Thumbs up!\" alt=\"thumbs up\" data-repository=\"dsc-market-segmentation-clustering\"\u003e\u003cimg id=\"thumbs-down\" title=\"Thumbs down!\" alt=\"thumbs down\" data-repository=\"dsc-market-segmentation-clustering\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\n\u003c/footer\u003e","exportId":"market-segmentation-with-clustering"},{"id":457979,"title":"Market Segmentation with Clustering - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-market-segmentation-clustering-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll use your knowledge of clustering to perform market segmentation on a real-world dataset!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse clustering to create and interpret market segmentation on real-world data \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gab7e93076acfc2552dcf83a0c4d8c33c"},{"id":457983,"title":"Clustering - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThere are two main types of clustering algorithms: non-hierarchical clustering (k-means) and hierarchical agglomerative clustering\u003c/li\u003e\n\u003cli\u003eYou can quantify the performance of a clustering algorithm using metrics such as variance ratios\u003c/li\u003e\n\u003cli\u003eWhen working with the k-means clustering algorithm, it is useful to create elbow plots to find an optimal value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e\n\u003c/li\u003e\n\u003cli\u003eWhen using hierarchical agglomerative clustering, different linkage criteria can be used to determine which clusters should be merged and at what point\u003c/li\u003e\n\u003cli\u003eDendrograms and clustergrams are very useful visual tools in hierarchical agglomerative clustering\u003c/li\u003e\n\u003cli\u003eAdvantages of k-means clustering include easy implementation and speed, whereas the main disadvantage is that it isn't always straightforward how to pick the \"right\" value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e\n\u003c/li\u003e\n\u003cli\u003eAdvantages of hierarchical agglomerative clustering include easy visualization and intuitiveness, whereas the main disadvantage is that the result is very distance-metric-dependent\u003c/li\u003e\n\u003cli\u003eYou can use supervised and unsupervised learning together in a few different ways. Applications of this are look-alike models in market segmentation and semi-supervised learning\u003c/li\u003e\n\u003c/ul\u003e","exportId":"clustering-recap"}]},{"id":47080,"name":"Topic 34: Exploring Time Series Data","status":"completed","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g7ad5bedda4978b4fa340558c6c6d71ca","items":[{"id":457996,"title":"Topic 34 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 145px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eTime Series Data Manipulation\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Exploring Time Series Data - Introduction\" href=\"pages/exploring-time-series-data-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/exploring-time-series-data-introduction\" data-api-returntype=\"Page\"\u003eExploring Time Series Data - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Time Series\" href=\"assignments/g5e241006fa4fc3b20c656f2ced7fe4dc\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12160\" data-api-returntype=\"Assignment\"\u003eIntroduction to Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Managing Time Series Data - Lab\" href=\"assignments/g98648f0b58736379c0de5fe10e862048\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12161\" data-api-returntype=\"Assignment\"\u003eManaging Time Series Data - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Visualizing Time Series Data - Lab\" href=\"assignments/g38a7acb7ef18eec76d012e036a33d576\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12162\" data-api-returntype=\"Assignment\"\u003eVisualizing Time Series Data - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 220px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Data Manipulation\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eTime Series Trends and Stationarity\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Data Manipulation Exit Ticket\" href=\"quizzes/gf0c7c18a3e0636816c6aca490f3e1d3b\"\u003eTime Series Data Manipulation Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Types of Trends\" href=\"assignments/ga5806767e1d56323adbce5fd975ead09\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12163\" data-api-returntype=\"Assignment\"\u003eTypes of Trends\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Testing for Trends - Lab\" href=\"assignments/gba1d403ececda39a33c1783ccce4f999\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12164\" data-api-returntype=\"Assignment\"\u003eTesting for Trends - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Removing Trends\" href=\"assignments/g119393ced24c88150154a7658ec60f95\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12165\" data-api-returntype=\"Assignment\"\u003eRemoving Trends\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Removing Trends - Lab\" href=\"assignments/ga1d0e819649ad5a415863e9dd8cd00b2\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12166\" data-api-returntype=\"Assignment\"\u003eRemoving Trends - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Time Series Decomposition\" href=\"assignments/g03cc9745b85a37c968dfdc957e36819b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12167\" data-api-returntype=\"Assignment\"\u003eTime Series Decomposition\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 78px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Trends and Stationarity\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Trends and Stationarity Exit Ticket\" href=\"quizzes/ga61f46194e766cc2c8f25e2acb45d00b\"\u003eTime Series Trends and Stationarity Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Exploring Time Series Data - Recap\" href=\"pages/exploring-time-series-data-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/exploring-time-series-data-recap\" data-api-returntype=\"Page\"\u003eExploring Time Series Data - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-34-lesson-priorities-live"},{"id":458001,"title":"Exploring Time Series Data - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you will learn about working with an important and ever-present type of data: time series! Stock market prices, weather, and economic indicators like GDP are a few examples of time series data.\u003c/p\u003e\n\n\u003ch2\u003eTime Series Data\u003c/h2\u003e\n\n\u003cp\u003e\"Time series\" data refers to datasets where the progress of time is an important dimension in the dataset. For example, working with the changes in stock prices, oil flow through a pipeline or even climate data over time requires an understanding of how to work with time series data. We introduce the concept of time series data, look at how to manage and visualize time series data, introduce the types of trends and the idea of \"time series decomposition\". In the next section, we'll introduce techniques for modeling time series data.\u003c/p\u003e\n\n\u003ch3\u003eIntroduction to Time Series\u003c/h3\u003e\n\n\u003cp\u003eWe start by importing daily minimum temperatures for Melbourne, Australia and introduce the importance of using dates as index values when importing time series data into Pandas. We then go through how to downsample and upsample a dataset and show some of the built-in methods for easily selecting and slicing time series data. We also provide an introduction to some of the most common plots for time series such as a line plot and a dot plot, and approaches to grouping and visualizing time series data.\u003c/p\u003e\n\n\u003cp\u003eWe also introduce the use of time series histograms and density plots for visualizing the distribution of the values without considering the times at which the values were measured and suggest time series box and whisker plots on a per-year basis to get a sense of trends over time. Finally, we introduce time series heat maps which can be a great way of getting a sense of how time series data changes across a couple of dimensions (e.g. month to month and year to year).\u003c/p\u003e\n\n\u003ch3\u003eTypes of Trends\u003c/h3\u003e\n\n\u003cp\u003eBasic regression tests are often not capable of capturing and predicting time-dependent patterns, so we introduce the concept of trends and stationarity, and explain the Dickey-Fuller test for performing statistical testing for time series stationarity.\u003c/p\u003e\n\n\u003ch3\u003eRemoving Trends\u003c/h3\u003e\n\n\u003cp\u003eMost time series modeling techniques assume stationarity, so we look at some of the techniques available for removing (or reducing) trends and/or seasonality using techniques such as a log transformation, rolling means, and differencing.\u003c/p\u003e\n\n\u003ch3\u003eTime Series Decomposition\u003c/h3\u003e\n\n\u003cp\u003eFinally, we end the section by introducing the concept of decomposition - another approach to removing trends and seasonality from a time series dataset.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThis section will provide you with the foundational knowledge for loading and working with time series data, so you'll have the skills required to start to perform time series modeling!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-time-series-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-time-series-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"exploring-time-series-data-introduction"},{"id":458006,"title":"Introduction to Time Series","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-time-series\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-time-series\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-time-series/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFrom stock prices to climate data, time series data is found in a wide variety of domains, and being able to effectively work with such data is an increasingly important skill for data scientists. \u003c/p\u003e\n\n\u003cp\u003eIn this lecture, you will be introduced to some common techniques used to import, clean, and manipulate time series data. Additionally, you'll learn how you can effectively visualize time series data in Python.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad time series data using Pandas and perform time series indexing \u003c/li\u003e\n\u003cli\u003ePerform data cleaning operation on time series data \u003c/li\u003e\n\u003cli\u003eChange the granularity of a time series \u003c/li\u003e\n\u003cli\u003eDescribe pandas' Timestamp and Datetime datatypes \u003c/li\u003e\n\u003cli\u003eExplore the temporal structure of time series with line plots \u003c/li\u003e\n\u003cli\u003eConstruct and interpret time series histogram and density plots \u003c/li\u003e\n\u003cli\u003eCreate a time series heatmap \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g5e241006fa4fc3b20c656f2ced7fe4dc"},{"id":458011,"title":"Managing Time Series Data - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-managing-time-series-data-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-managing-time-series-data-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-managing-time-series-data-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn the previous lesson, you learned that time series data are everywhere and working with time series data is an important skill for data scientists!\u003c/p\u003e\n\n\u003cp\u003eIn this lab, you'll practice your previously learned techniques to import, clean, and manipulate time series data.\u003c/p\u003e\n\n\u003cp\u003eThe lab will cover how to perform time series analysis while working with large datasets. The dataset can be memory intensive so your computer will need at least 2GB of memory to perform some of the calculations.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad time series data using Pandas and perform time series indexing \u003c/li\u003e\n\u003cli\u003ePerform data cleaning operation on time series data \u003c/li\u003e\n\u003cli\u003eChange the granularity of a time series \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g98648f0b58736379c0de5fe10e862048"},{"id":458016,"title":"Visualizing Time Series Data - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-time-series-data-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-time-series-data-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-time-series-data-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAs mentioned in an earlier lesson, time series visualizations play an important role in the analysis of time series data. Time series are often plotted to allow data diagnostics to identify temporal structures. \u003c/p\u003e\n\n\u003cp\u003eIn this lab, we'll cover main techniques for visualizing time series data in Python using the minimum daily temperatures over 10 years (1981-1990) in the city of Melbourne, Australia. The units are in degrees Celsius and there are 3,650 observations. The \u003ca href=\"https://datamarket.com/data/set/2324/daily-minimum-temperatures-in-melbourne-australia-1981-1990\"\u003esource\u003c/a\u003e of the data is credited to the Australian Bureau of Meteorology.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplore the temporal structure of time series with line plots \u003c/li\u003e\n\u003cli\u003eConstruct and interpret time series histogram and density plots \u003c/li\u003e\n\u003cli\u003eCreate a time series heat map\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g38a7acb7ef18eec76d012e036a33d576"},{"id":458031,"title":"Types of Trends","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-types-of-trends\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-types-of-trends\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-types-of-trends/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eOften, basic regression techniques are not sufficient to grasp the more complex, time-dependent patterns that are common when dealing with time series data. Using time series analysis techniques, the purpose is to get more insight into your data on one hand and to make predictions on the other hand. First, we'll introduce the types of trends that exist in time series models and have a look at them.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what stationarity means and why it is important in time series analysis \u003c/li\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eDescribe the Dickey-Fuller test and its purpose \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga5806767e1d56323adbce5fd975ead09"},{"id":458035,"title":"Testing for Trends - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-testing-for-trends-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-testing-for-trends-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-testing-for-trends-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your knowledge of testing for stationarity.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eUse the Dickey-Fuller test and conclude whether or not a dataset is exhibiting stationarity \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gba1d403ececda39a33c1783ccce4f999"},{"id":458039,"title":"Removing Trends","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-removing-trends\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAlthough the stationarity assumption is required in several time series modeling techniques, few practical time series are stationary. In this lesson we'll discuss how you can make a time series stationary. In reality, it is almost impossible to make a series perfectly stationary, but let's try to get as close as possible!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare and contrast the different methods for removing trends and seasonality in time series data \u003c/li\u003e\n\u003cli\u003eUse differencing to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling means to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse a log transformation to minimize non-stationarity \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g119393ced24c88150154a7658ec60f95"},{"id":458044,"title":"Removing Trends - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-removing-trends-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your detrending skills!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse a log transformation to minimize non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling means to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse differencing to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eCreate visualizations of transformed time series as a visual aid to determine if stationarity has been achieved \u003c/li\u003e\n\u003cli\u003eUse the Dickey-Fuller test and conclude whether or not a dataset is exhibiting stationarity \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga1d0e819649ad5a415863e9dd8cd00b2"},{"id":458048,"title":"Time Series Decomposition","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-decomposition\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-decomposition\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-decomposition/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003ePreviously, you saw how we can combine several techniques to detrend our time series. Before we move on to our time series models, let's look at another method to remove trend and seasonality, namely \u003cstrong\u003eTime Series Decomposition\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet's once again import the passengers dataset and the \u003ccode\u003estationarity_check()\u003c/code\u003e function from the previous lab to use time series decomposition and its effect on detrending a time series.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the process and components of time series decomposition \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g03cc9745b85a37c968dfdc957e36819b"},{"id":458066,"title":"Exploring Time Series Data - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-section-recap\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you import time series data into Pandas, make sure to use the time/date information as index values using either a Pandas \u003ccode\u003etimestamp\u003c/code\u003e or Python \u003ccode\u003edatetime\u003c/code\u003e data type\u003c/li\u003e\n\u003cli\u003eThere are a range of built-in methods in Pandas for easily downsampling or upsampling time series data\u003c/li\u003e\n\u003cli\u003eLine plots and dot plots can be useful for getting a sense of how a time series dataset changes over time\u003c/li\u003e\n\u003cli\u003eHistograms and density plots can be useful for getting a sense of the time-independent distribution of a time series\u003c/li\u003e\n\u003cli\u003eBox and whisker plots per year (or other seasonality period - day, week, month, etc) can be a great way to easily see trends in the distribution of time series data over time\u003c/li\u003e\n\u003cli\u003eHeat maps can also be useful for comparing changes of time series data across a couple of dimensions. For example, with months on one axis and years on another, they can be a great way to see both seasonality and year on year trends\u003c/li\u003e\n\u003cli\u003eA time series is said to be stationary if its statistical properties such as mean and variance remain constant over time\u003c/li\u003e\n\u003cli\u003eMost time series models work on the assumption that the time series are stationary (assumption of homoscedasticity)\u003c/li\u003e\n\u003cli\u003eMany time series datasets \u003cem\u003edo\u003c/em\u003e have trends, violating the assumption of homoscedasticity\u003c/li\u003e\n\u003cli\u003eCommon examples are trends that include linear (straight line over time), exponential, and periodic. Some datasets also have increasing (or decreasing) variance over time\u003c/li\u003e\n\u003cli\u003eAny given dataset may exhibit multiple trends (e.g. linear, periodic, and reduction of variance)\u003c/li\u003e\n\u003cli\u003eRolling statistics can be used to test for trends to see whether the centrality and/or dispersion of time series changes over time\u003c/li\u003e\n\u003cli\u003eThe Dickey-Fuller test is a common test for determining whether a time series contains trends\u003c/li\u003e\n\u003cli\u003eCommon approaches for removing trends and seasonality include taking a log-transform, subtracting the rolling mean, and differencing\u003c/li\u003e\n\u003cli\u003eDecomposing allows you to separately view \u003cem\u003eseasonality\u003c/em\u003e (which could be daily, weekly, annual, etc), \u003cem\u003etrend\u003c/em\u003e, and \u003cem\u003erandom\u003c/em\u003e, which is the variability in time series after removing the effects of the seasonality and trend\u003c/li\u003e\n\u003c/ul\u003e","exportId":"exploring-time-series-data-recap"}]},{"id":47085,"name":"Topic 35: Modeling Time Series Data","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"ge5695df63ab9b4a0c363f3024c5a3cc9","items":[{"id":458080,"title":"Topic 35 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 284px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eTime Series Modeling\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Modeling Time Series Data - Introduction\" href=\"pages/modeling-time-series-data-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/modeling-time-series-data-introduction\" data-api-returntype=\"Page\"\u003eModeling Time Series Data - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Basic Time Series Models\" href=\"assignments/g93c55fdf39a2cc133da1d60ed47dc1d4\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187090\" data-api-returntype=\"Assignment\"\u003eBasic Time Series Models\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Basic Time Series Models - Lab\" href=\"assignments/g1d58818d312c4d5f9f62f3dc6c1b782b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187091\" data-api-returntype=\"Assignment\"\u003eBasic Time Series Models - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Correlation and Autocorrelation in Time Series\" href=\"assignments/g707994093d5da85ab8ed839b66896e84\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187101\" data-api-returntype=\"Assignment\"\u003eCorrelation and Autocorrelation in Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Correlation and Autocorrelation in Time Series - Lab\" href=\"assignments/gff5be975b62dc44dd62d3c3e18377bd7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187102\" data-api-returntype=\"Assignment\"\u003eCorrelation and Autocorrelation in Time Series - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"ARMA Models\" href=\"pages/arma-models\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/arma-models\" data-api-returntype=\"Page\"\u003eARMA Models\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"ARMA Models in statsmodels\" href=\"assignments/gf868208900f3e52add61497dd6c38a20\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187088\" data-api-returntype=\"Assignment\"\u003eARMA Models in statsmodels\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"ARMA Models in statsmodels - Lab\" href=\"assignments/gc3248cd9dd99557b6439eb760221ba01\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187089\" data-api-returntype=\"Assignment\"\u003eARMA Models in statsmodels - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 41.6686%;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Time Series\" href=\"quizzes/g6f491f0e0c0297c3b56e2a98b1f7ec9a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30674\" data-api-returntype=\"Quiz\"\u003eQuiz: Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.4856%; height: 36px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Modeling\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eTime Series Modeling Walkthrough\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Time Series Modeling Exit Ticket\" href=\"quizzes/gfc62258e0fcd6a6f69716d3621e26746\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30682\" data-api-returntype=\"Quiz\"\u003e\u003cstrong\u003eTime Series Modeling Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.5794%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Modeling Walkthrough\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Modeling Walkthrough Exit Ticket\" href=\"quizzes/g1312f4631ddd87855c7283a1939eb895\"\u003eTime Series Modeling Walkthrough Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Modeling Time Series Data - Recap\" href=\"pages/modeling-time-series-data-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/modeling-time-series-data-recap\" data-api-returntype=\"Page\"\u003eModeling Time Series Data - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-35-lesson-priorities-live"},{"id":458085,"title":"Modeling Time Series Data - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about modeling for time series data. \u003c/p\u003e\n\n\u003ch2\u003eTime Series Modeling\u003c/h2\u003e\n\n\u003cp\u003eIn the previous section, we introduced the idea of time series data and provided some best practices for importing, managing, and visualizing time series data along with a number of techniques for removing trends and/or seasonality from a time series dataset. In this section, we're going to look at various types of models for time series data.\u003c/p\u003e\n\n\u003ch3\u003eBasic Time Series Models\u003c/h3\u003e\n\n\u003cp\u003eWe start off by introducing two basic time series models -- the white noise and random walk models.\u003c/p\u003e\n\n\u003ch3\u003eCorrelation, Autocorrelation, and Partial Autocorrelation\u003c/h3\u003e\n\n\u003cp\u003eWe will then move on to the concept of correlation as it relates to time series datasets, and plot the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) for a time series. \u003c/p\u003e\n\n\u003ch3\u003eARMA Models\u003c/h3\u003e\n\n\u003cp\u003eWe then move on to introduce two other key time series models that are widely used for predicting future values for time series data - the auto regressive (AR) and moving average (MA) models.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eLet's get started! This section wraps up our introduction to time series analysis, giving you the modeling tools required to effectively forecast time series data.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-time-series-models-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-time-series-models-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"modeling-time-series-data-introduction"},{"id":458090,"title":"Basic Time Series Models","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-basic-time-series-models\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eWe've looked at time series and what they might look like. Now why do we need to model time series? Essentially, you're trying to find patterns and understand the data in a way that you \ncan use this information to (hopefully) make accurate predictions about the future.\u003c/p\u003e\n\n\u003cp\u003eIn this lesson you'll learn about two basic time series models: the white noise and random walk models.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the properties of a white noise model \u003c/li\u003e\n\u003cli\u003eExplain the properties of a random walk model \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g93c55fdf39a2cc133da1d60ed47dc1d4"},{"id":458096,"title":"Basic Time Series Models - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-basic-time-series-models-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have some basic understanding of the white noise and random walk models, its time for you to implement them! \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerate and analyze a white noise model \u003c/li\u003e\n\u003cli\u003eGenerate and analyze a random walk model \u003c/li\u003e\n\u003cli\u003eImplement differencing in a random walk model \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g1d58818d312c4d5f9f62f3dc6c1b782b"},{"id":458101,"title":"Correlation and Autocorrelation in Time Series","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corr-autocorr-in-time-series\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll talk about correlation, autocorrelation, and partial autocorrelation in time series. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe what role correlation plays in time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the autocorrelation function (ACF) for a time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the partial autocorrelation function (PACF) for a time series \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g707994093d5da85ab8ed839b66896e84"},{"id":458106,"title":"Correlation and Autocorrelation in Time Series - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corr-autocorr-in-time-series-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your knowledge of correlation, autocorrelation, and partial autocorrelation by working on three different datasets. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePlot and discuss the autocorrelation function (ACF) for a time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the partial autocorrelation function (PACF) for a time series \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gff5be975b62dc44dd62d3c3e18377bd7"},{"id":458110,"title":"ARMA Models","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eYou've seen two basic time series models now, the random walk and white noise models. In this lesson, you'll learn about two other very important time series models that are widely used to understand and predict future values in stochastic processes: the Autoregressive (AR) and Moving Average (MA) models.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\n- Explain what autoregressive means in an autoregressive model \n- Explain what a moving average model means \n- Describe how AR and MA can be combined to form an ARMA model \u003c/p\u003e\n\n\u003ch2\u003eThe Autoregressive Model\u003c/h2\u003e\n\n\u003cp\u003eAn autoregressive (AR) model is when a value from a time series is regressed on previous values from the same time series.\u003c/p\u003e\n\n\u003cp\u003eIn words, the mathematical idea is the following:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\text{Today = constant + slope} \\times \\text{yesterday + noise} \" src=\"/equation_images/%20%255Ctext{Today%20=%20constant%20+%20slope}%20%255Ctimes%20%255Ctext{yesterday%20+%20noise}\" alt=\"{\" data-equation-content=\" \\text{Today = constant + slope} \\times \\text{yesterday + noise} \"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eOr, mathematically:\n\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\" src=\"/equation_images/%255Clarge%20Y_t%20=%20%255Cmu%20+%20%255Cphi%20*%20Y_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eSome notes based on this formula:\n- If the slope is 0, the time series is a white noise model with mean \u003cimg class=\"equation_image\" title=\"\\mu\" src=\"https://learning.flatironschool.com/equation_images/%255Cmu\" alt=\"{\" data-equation-content=\"\\mu\"\u003e\n- If the slope is not 0, the time series is autocorrelated\n- Bigger slope means bigger autocorrelation\n- When there is a negative slope, the time series follows an oscillatory process\u003c/p\u003e\n\n\u003cp\u003eWe simulated some time series below. Have a look at them, and make sure this follows your intuition looking at the formula.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_model.png\" alt=\"autoregressive model\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNote that simply having a value for \u003cem\u003ephi\u003c/em\u003e ( \u003cimg class=\"equation_image\" title=\"\\phi\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi\" alt=\"{\" data-equation-content=\"\\phi\"\u003e ) slightly bigger than 1, the time series clearly goes in one direction. Note the scale of the y-axis, where the y-axis scale for all the other processes is between -10 and 10, the last time series goes down to values of -100.\u003c/p\u003e\n\n\u003cp\u003eLet's look at the autocorrelation plots as well.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_ACF.png\" alt=\"autoregressive autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThe oscillatory process of the time series with \u003cimg class=\"equation_image\" title=\"\\phi=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.9\" alt=\"{\" data-equation-content=\"\\phi=0.9\"\u003e is reflected in the autocorrelation function, returning an oscillatory autocorrelation function as well. \u003cimg class=\"equation_image\" title=\"\\phi=0.2\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.2\" alt=\"{\" data-equation-content=\"\\phi=0.2\"\u003e leads to a very low, insignificant,  autocorrelation. \u003cimg class=\"equation_image\" title=\"\\phi=0.8\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.8\" alt=\"{\" data-equation-content=\"\\phi=0.8\"\u003e leads to a strong autocorrelation for the first few lags and then incurs a steep decline. Having a \u003cimg class=\"equation_image\" title=\"\\phi=1.02\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=1.02\" alt=\"{\" data-equation-content=\"\\phi=1.02\"\u003e (just slightly bigger than 1) leads to strong and long-lasting autocorrelation.\u003c/p\u003e\n\n\u003cp\u003eNext, let's look at the partial autocorrelation plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_PACF.png\" alt=\"autogregressive partial autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFor each of these PACFs, we notice a high value for 1 lag, then autocorrelations of 0, except for the second one. This is no big surprise, as the slope parameter is fairly small, so the relationship between a value and the next one is fairly limited.\u003c/p\u003e\n\n\u003ch2\u003eThe  Moving Average Model\u003c/h2\u003e\n\n\u003cp\u003eThe Moving Average model can be described as the weighted sum of today's and yesterday's noise.\u003c/p\u003e\n\n\u003cp\u003eIn words, the mathematical idea is the following:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} \" src=\"/equation_images/%20%255Ctext{Today%20=%20Mean%20+%20Noise%20+%20Slope}%20%255Ctimes%20%255Ctext{yesterday's%20noise}\" alt=\"{\" data-equation-content=\" \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} \"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eOr, mathematically:\n\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\" src=\"/equation_images/%255Clarge%20Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta%20*%20%255Cepsilon_{t-1}\" alt=\"{\" data-equation-content=\"\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eSome notes based on this formula:\n- If the slope is 0, the time series is a white noise model with mean \u003cimg class=\"equation_image\" title=\"\\mu\" src=\"https://learning.flatironschool.com/equation_images/%255Cmu\" alt=\"{\" data-equation-content=\"\\mu\"\u003e\n- If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n- Bigger slope means bigger autocorrelation\n- When there is a negative slope, the time series follow an oscillatory process\u003c/p\u003e\n\n\u003cp\u003eFor the Moving Average Model we also simulated some time series with varying parameters below.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_model.png\" alt=\"moving average model\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen there is a positive \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e there is a certain persistence in level, meaning that each observation is generally close to its neighbors. This is more pronounced for higher values of \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e. MA series with negative coefficients, however, show oscillatory patterns. Recall that when \u003cimg class=\"equation_image\" title=\"\\theta=0\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=0\" alt=\"{\" data-equation-content=\"\\theta=0\"\u003e, the process is a true white noise process! \u003c/p\u003e\n\n\u003cp\u003eLet's look at the ACF plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_ACF.png\" alt=\"moving average autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRemember that MA processes have autocorrelations, but because of the structure of the MA formula (regressing it on the noise term of the previous observation) there is only a dependence for one period, and the autocorrelation is zero for lags 2 and higher.\u003c/p\u003e\n\n\u003cp\u003eIf \u003cimg class=\"equation_image\" title=\"\\theta \u003e0\" src=\"/equation_images/%255Ctheta%20\u003e0\" alt=\"{\" data-equation-content=\"\\theta \u003e0\"\u003e the lag one autocorrelation is positive, if \u003cimg class=\"equation_image\" title=\"\\theta \u003c0\" src=\"/equation_images/%255Ctheta%20\u003c0\" alt=\"{\" data-equation-content=\"\\theta \u003c0\"\u003e the lag one autocorrelation is negative.\u003c/p\u003e\n\n\u003cp\u003eNext, let's look at the partial autocorrelation plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_PACF.png\" alt=\"moving average partial autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFor PACFs, a typical structure is that  there is a strong correlation with the 1-period lag (strength depending on \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e), and then the PACF gradually tails off. You can particularly observe this for \u003cimg class=\"equation_image\" title=\"\\theta=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=0.9\" alt=\"{\" data-equation-content=\"\\theta=0.9\"\u003e and \u003cimg class=\"equation_image\" title=\"\\theta=-0.95\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=-0.95\" alt=\"{\" data-equation-content=\"\\theta=-0.95\"\u003e.\u003c/p\u003e\n\n\u003ch2\u003eHigher-order AR and MA models\u003c/h2\u003e\n\n\u003cp\u003eLet's look at the formulas of AR and MA again:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAR: \u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi%20*%20Y_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\"\u003e\u003c/li\u003e\n\u003cli\u003eMA: \u003cimg class=\"equation_image\" title=\"Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta%20*%20%255Cepsilon_{t-1}\" alt=\"{\" data-equation-content=\"Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNote that these models are constructed in a way that processes only depend directly on the previous observation in the process. These are known as \"1st order models\", and denoted by AR(1) and MA(1) processes respectively. Let's look at AR(2) and MA(2).\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAR(2): \u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi_1%20*%20Y_{t-1}+%255Cphi_2%20*%20Y_{t-2}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t\"\u003e\u003c/li\u003e\n\u003cli\u003eMA(2): \u003cimg class=\"equation_image\" title=\"Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta_1%20*%20%255Cepsilon_{t-1}+%20%255Ctheta_2%20*%20%255Cepsilon_{t-2}\" alt=\"{\" data-equation-content=\"Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNeedless to say, this can be extended to higher-orders as well! Generally, the order of an AR model is denoted \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e, and the order of an MA model is denoted \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e.\u003c/p\u003e\n\n\u003ch2\u003eACF and PACF intuition for AR(p) and MA(q)\u003c/h2\u003e\n\n\u003cp\u003eA quick overview of how higher order models affect the ACF and PACF: \u003c/p\u003e\n\n\u003ch3\u003eAR(p)\u003c/h3\u003e\n\n\u003cp\u003eConsidering a time series that was generated by an autoregression (AR) process with an order of \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e, we would expect the ACF plot for the AR(p) time series to be strong to a lag of \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e and remain stagnant for subsequent lag values, trailing off at some point as the effect is weakened. The PACF, on the other hand, describes the direct relationship between an observation and its lag. This generally leads to no correlation for lag values beyond \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e.\u003c/p\u003e\n\n\u003ch3\u003eMA(q)\u003c/h3\u003e\n\n\u003cp\u003eWith a time series generated by a moving average (MA) process with an order \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e, we would expect the ACF for the MA(q) process to show a strong correlation with recent values up to the lag of \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e, then an immediate decline to minimal or no correlation. For the PACF, we would expect the plot to show a strong relationship to the lag and then a tailing off to no correlation from the lag onwards.\u003c/p\u003e\n\n\u003ch2\u003eARMA models\u003c/h2\u003e\n\n\u003cp\u003eNow that we've seen AR and MA models, it is important to note that \u003cstrong\u003ethere is no reason why AR and MA models would not coexist\u003c/strong\u003e. That's where ARMA models come in, which basically means that in this model, a regression on past values takes place (AR part) and also that the error term is modeled as a linear combination of error terms of the recent past (MA part). Generally, one denotes ARMA as ARMA(p, q).\u003c/p\u003e\n\n\u003cp\u003eAn ARMA(2,1) model is given by:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi_1%20Y_{t-1}+%255Cphi_2%20Y_{t-2}+%20%255Ctheta%20%255Cepsilon_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eA short table to summarize ACF and PACF for AR(p), MA(q), and ARMA(p, q):\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eAR(p)\u003c/th\u003e\n\u003cth\u003eMA(q)\u003c/th\u003e\n\u003cth\u003eARMA(p, q)\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eACF\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003ctd\u003eCuts off after lag q\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePACF\u003c/td\u003e\n\u003ctd\u003eCuts off after lag p\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003ch2\u003eNote on modeling\u003c/h2\u003e\n\n\u003cp\u003eSeeing the table above, you might get an idea of why ACF and PACF are so useful when modeling! What you generally will try to do for any time series analysis is:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDetrend your time series using differencing. ARMA models represent stationary processes, so we have to make sure there are no trends in our time series\u003c/li\u003e\n\u003cli\u003eLook at ACF and PACF of the time series\u003c/li\u003e\n\u003cli\u003eDecide on the AR, MA, and order of these models\u003c/li\u003e\n\u003cli\u003eFit the model to get the correct parameters and use for prediction\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eAdditional resources\u003c/h2\u003e\n\n\u003cp\u003eTo learn more about AR, MA, and ARMA, have a look at lessons 1 and 2 \u003ca href=\"https://online.stat.psu.edu/stat510/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eGreat! Now that you have learned the basics of AR, MA, and ARMA models, let's look at some time series and how to model them in the next lesson!\u003c/p\u003e","exportId":"arma-models"},{"id":458114,"title":"ARMA Models in StatsModels","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models-statsmodels\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll use your knowledge of the autoregressive (AR) and moving average (MA) models, along with the \u003ccode\u003estatsmodels\u003c/code\u003e library to model time series data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eFit an AR model using \u003ccode\u003estatsmodels\u003c/code\u003e \u003c/li\u003e\n\u003cli\u003eFit an MA model using \u003ccode\u003estatsmodels\u003c/code\u003e \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gf868208900f3e52add61497dd6c38a20"},{"id":458119,"title":"ARMA Models in StatsModels - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models-statsmodels-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll fit an ARMA model using \u003ccode\u003estatsmodels\u003c/code\u003e to a real-world dataset. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDecide the optimal parameters for an ARMA model by plotting ACF and PACF and interpreting them \u003c/li\u003e\n\u003cli\u003eFit an ARMA model using StatsModels \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gc3248cd9dd99557b6439eb760221ba01"},{"id":458123,"title":"Quiz: Time Series","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"gd5cf3ed3933765abc49d5ce14be53715","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"g6f491f0e0c0297c3b56e2a98b1f7ec9a"},{"id":458154,"title":"Modeling Time Series Data - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-models-section-recap\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA white noise model has a fixed and constant mean and variance, and no correlation over time\u003c/li\u003e\n\u003cli\u003eA random walk model has no specified mean or variance, but has a strong dependence over time\u003c/li\u003e\n\u003cli\u003eThe Pandas \u003ccode\u003e.corr()\u003c/code\u003e method can be used to return the correlation between various time series in the DataFrame\u003c/li\u003e\n\u003cli\u003eAutocorrelation allows us to identify how strongly each time series observation is related to previous observations\u003c/li\u003e\n\u003cli\u003eThe Autocorrelation Function (ACF) is a function that represents autocorrelation of a time series as a function of the time lag\u003c/li\u003e\n\u003cli\u003eThe Partial Autocorrelation Function (or PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags\u003c/li\u003e\n\u003cli\u003eARMA (Autoregressive and Moving Average) modeling is a tool for forecasting time series values by regressing the variable on its own lagged (past) values\u003c/li\u003e\n\u003cli\u003eARMA models assume that you've already detrended your data and that there is no seasonality\u003c/li\u003e\n\u003c/ul\u003e","exportId":"modeling-time-series-data-recap"}]},{"id":47091,"name":"Topic 36: Big Data and (Py)Spark","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"ga5e985716089f35d6154990b88b1513f","items":[{"id":458168,"title":"Topic 36 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8857%; height: 95px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete Before \u003cem\u003eBig Data Introduction\u003c/em\u003e Lecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Big Data and (Py)Spark - Introduction\" href=\"pages/big-data-and-py-spark-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/big-data-and-py-spark-introduction\" data-api-returntype=\"Page\"\u003eBig Data and (Py)Spark - Introduction\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Big Data\" href=\"pages/introduction-to-big-data\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-big-data\" data-api-returntype=\"Page\"\u003eIntroduction to Big Data\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 53px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 10px;\"\u003e\u003ca title=\"Parallel and Distributed Computing with MapReduce\" href=\"pages/parallel-and-distributed-computing-with-mapreduce\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/parallel-and-distributed-computing-with-mapreduce\" data-api-returntype=\"Page\"\u003eParallel and Distributed Computing with MapReduce\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 10px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd style=\"width: 35.11%;\"\u003e\u003cstrong\u003e\u003ca title=\"(Py)Spark Basics\" href=\"pages/py-spark-basics\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/py-spark-basics\" data-api-returntype=\"Page\"\u003e(Py)Spark Basics\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.229%; height: 242px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete After \u003cem\u003eBig Data Introduction\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eSpark\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd style=\"width: 35.11%;\"\u003e\u003cstrong\u003e\u003ca title=\"Big Data 1 Exit Ticket\" href=\"quizzes/g188723d464955f60bb59d6ca8d4ecbe7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30679\" data-api-returntype=\"Quiz\"\u003eBig Data 1 Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Installing and Configuring PySpark with Docker\" href=\"pages/installing-and-configuring-pyspark-with-docker\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/installing-and-configuring-pyspark-with-docker\" data-api-returntype=\"Page\"\u003eInstalling and Configuring PySpark with Docker\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e2nd*\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Understanding SparkContext - Codealong\" href=\"assignments/g294b94461ee6e9572f786a2e6bb0659b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187165\" data-api-returntype=\"Assignment\"\u003eUnderstanding SparkContext - Codealong\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 53px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 10px;\"\u003e\u003ca title=\"Resilient Distributed Datasets (RDDs) - Lab\" href=\"assignments/g2f77863d15f7cdaae1efb4cd6c8dd382\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187149\" data-api-returntype=\"Assignment\"\u003eResilient Distributed Datasets (RDDs) - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 10px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Word Count with MapReduce - Lab\" href=\"assignments/gda1b3b7f840139ea7429bdb7e29b0a3f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187173\" data-api-returntype=\"Assignment\"\u003eWord Count with MapReduce - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Spark DataFrames\" href=\"assignments/gbb401e4ed8174cf280ef12f218168b8b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187152\" data-api-returntype=\"Assignment\"\u003eSpark DataFrames\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Machine Learning with Spark\" href=\"assignments/geb081d1079ab27f821ff41228da6e22b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187121\" data-api-returntype=\"Assignment\"\u003eMachine Learning with Spark\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Machine Learning with Spark -  Lab\" href=\"assignments/ga40052b34f7e3efc7a91e89bac792750\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187122\" data-api-returntype=\"Assignment\"\u003eMachine Learning with Spark - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Big Data in PySpark\" href=\"quizzes/g9c577f9088ef666a272048004754cb3c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30673\" data-api-returntype=\"Quiz\"\u003eQuiz: Big Data in PySpark\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e*Installing PySpark is important if you want to use it for your project, or to follow along with lecture content on your local machine. If you just want to go through the lessons and labs, you can do so on IllumiDesk without any additional installation steps.\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.229%; height: 84px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete After \u003cem\u003eSpark\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Short Video: sklearn to pyspark\" href=\"pages/short-video-sklearn-to-pyspark\" data-api-endpoint=\"pages/short-video-sklearn-to-pyspark?module_item_id=mastercourse_15802_382_11deed98de38e4b0d2396caeee891876\" data-api-returntype=\"Page\"\u003eShort Video: sklearn to pyspark\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n      \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Spark Exit Ticket\" href=\"quizzes/g7eef4fe2befd6ecccfbf8cdd086abbaa\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30684\" data-api-returntype=\"Quiz\"\u003eSpark Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Building a Recommendation System in PySpark - Lab\" href=\"assignments/g45c3dc138b3452c222b28c9ae7968aea\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187093\" data-api-returntype=\"Assignment\"\u003eBuilding a Recommendation System in PySpark - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Big Data and (Py)Spark - Recap\" href=\"pages/big-data-and-py-spark-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/big-data-and-py-spark-recap\" data-api-returntype=\"Page\"\u003eBig Data and (Py)Spark - Recap\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-36-lesson-priorities-live"},{"id":458172,"title":"Big Data and (Py)Spark - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-pyspark-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you will be introduced to the idea of big data and the tools data scientists use to manage it.\u003c/p\u003e\n\n\u003ch2\u003eBig Data\u003c/h2\u003e\n\n\u003cp\u003eBig data is undoubtedly one of the most hyped terms in data science these days. Big data analytics involves dealing with data that is large in volume and high in variety and velocity, making it challenging for data scientists to run their routine analysis activities. In this section, you'll learn the basics of dealing with big data through parallel and distributed computing.\u003c/p\u003e\n\n\u003ch3\u003eParallel and Distributed Computing with MapReduce\u003c/h3\u003e\n\n\u003cp\u003eWe start this section by providing more context on the ideas of parallel and distributed computing and \u003cstrong\u003eMapReduce\u003c/strong\u003e. When talking about distributed and parallel computing, we refer to the fact that complex (and big) data science tasks can be executed over a cluster of interconnected computers instead of on just one machine. You'll learn that MapReduce allows us to convert these big datasets into sets of tuples as key:value pairs, as we'll cover in more detail in this section.\u003c/p\u003e\n\n\u003ch2\u003eApache Spark and PySpark\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003eApache Spark\u003c/strong\u003e is an open-source distributed cluster-computing framework that makes it easier (and feasible) to use huge amounts of data! It was developed in response to limitations of MapReduce and written using the Scala programming language. Fortunately for Python developers, there is also a Python interface for Spark called \u003cstrong\u003ePySpark\u003c/strong\u003e. Throughout these lessons we will use the terms \"Spark\" and \"PySpark\" fairly interchangeably, though technically \"Spark\" is the underlying framework and \"PySpark\" is the Python library we'll be using.\u003c/p\u003e\n\n\u003ch3\u003eInstalling and Configuring PySpark with Docker\u003c/h3\u003e\n\n\u003cp\u003ePySpark was not part of the original environment setup you completed. While the interface is in Python, Spark relies on an underlying Java virtual machine (JVM) that can be challenging to install. Therefore we will provide instructions for installing PySpark with and without \u003cstrong\u003eDocker\u003c/strong\u003e, a container system that uses an \"image\" to handle a lot of the configuration for you.\u003c/p\u003e\n\n\u003ch2\u003eSpark Unstructured API\u003c/h2\u003e\n\n\u003cp\u003eFirst we'll look at the fundamental low-level data structures used by Spark: SparkContext and RDDs.\u003c/p\u003e\n\n\u003ch3\u003eRDDs (Resilient Distributed Datasets)\u003c/h3\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDDs) are the core concept in PySpark. RDDs are immutable distributed collections of data objects. Each dataset in RDD is divided into logical partitions, which may be computed on different computers (so-called \"nodes\") in the Spark cluster. In this section, you'll learn how RDDs in Spark work. Additionally, you'll learn that RDD operations can be split into actions and transformations. \u003c/p\u003e\n\n\u003ch3\u003eWord Count with MapReduce\u003c/h3\u003e\n\n\u003cp\u003eYou'll use MapReduce with Spark RDDs to solve a basic NLP task where you compare the attributes of different authors of various texts.\u003c/p\u003e\n\n\u003ch2\u003eSpark Structured API\u003c/h2\u003e\n\n\u003cp\u003eThen we'll look at the modern use of Spark: SparkSession, Spark DataFrames, and MLlib.\u003c/p\u003e\n\n\u003ch3\u003eSpark DataFrames\u003c/h3\u003e\n\n\u003cp\u003eSpark DataFrames are built on top of RDDs, but have a more intuitive and performant data structure. They are also what we'll use for machine learning with Spark.\u003c/p\u003e\n\n\u003ch3\u003eMachine Learning with Spark\u003c/h3\u003e\n\n\u003cp\u003eAfter you've solved a basic MapReduce problem, you will learn about employing the machine learning modules of PySpark. You will perform both a regression and classification problem and get the chance to build a full parallelizable data science pipeline that can scale to work with big data.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the foundations of Big Data and how to manage it with Apache Spark!\u003c/p\u003e","exportId":"big-data-and-py-spark-introduction"},{"id":458177,"title":"Introduction to Big Data","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-introduction\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn the information age, data in huge quantities has become available to analysts and decision-makers. Due to a vast increase in the amount of such data in recent times, a number of specialized platforms and development paradigms have been developed that can handle big data. Using such specialist approaches allows data scientists to gain valuable insights from complex data, ranging from daily transactions to customer interactions and social network data.\u003c/p\u003e\n\n\u003cp\u003eThis section aims to focus on some of the different analytical approaches and tools data scientists apply to big data in order to gain valuable insights that aid business decision making. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the domain areas where big data is particularly useful \u003c/li\u003e\n\u003cli\u003eList the technologies associated with big data \u003c/li\u003e\n\u003cli\u003eDescribe the 3 V's of big data and how they differentiate big data from routine data \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Big Data\u003c/h2\u003e\n\n\u003cp\u003eThe topic of \"big data\" has received a lot of hype lately, accompanied by a huge amount of interest from big businesses as it can potentially provide them data-driven decision-making abilities. Big data is one of the most discussed topics in business today across industry sectors, although it was barely known a few years ago. This lesson will focus on what big data is, why it is important, and the benefits it brings. \u003c/p\u003e\n\n\u003cp\u003eBig data is no different than normal data that we have seen so far; it's only \"bigger.\" This changes the analytical landscape that must be used as the huge size increase of the data requires specialized tools, techniques, and platforms. It helps us solve new problems and find improved ways to find answers to old problems. \u003c/p\u003e\n\n\u003ch3\u003eDefining Big Data\u003c/h3\u003e\n\n\u003cp\u003eDespite all the hype around this topic, there is no clear consensus on how to define  \u003cstrong\u003ebig data\u003c/strong\u003e. The term often gets related to business analytics and data mining for identifying relationships and associations present in huge amounts of transaction data.  \u003c/p\u003e\n\n\u003cp\u003eIn the data science domain, big data usually refers to datasets that grow so large that they become awkward to work with using traditional database management systems and analytical approaches. They are datasets whose size is beyond the ability of commonly used software tools and storage systems to capture, store, manage, as well as process the data within a tolerable elapsed time.\u003c/p\u003e\n\n\u003ch4\u003eHow Big is \"Big\" Data?\u003c/h4\u003e\n\n\u003cp\u003eBig data sizes are constantly increasing, currently ranging from a few terabytes (TB) to many petabytes (PB) of data in a single dataset. Consequently, some of the difficulties related to big data include capturing, storing, searching, sharing, analyzing, and visualizing. Today, enterprises are exploring large volumes of highly detailed data to discover trends and pieces of information considered incapable of being captured before. \u003c/p\u003e\n\n\u003cp\u003eHere are some of the examples of big data:  \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eWeb traffic data: Data points such as number of page views, previous web page, user information, advertisement click-through rate, pages per visit, average visit duration  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eText data: Emails, tweets, news reports, voice recordings, and text gathered from crawling the web can make massive datasets that are valuable to data scientists  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eLocation and time data: GPS data helps Google determine which roads have higher traffic and which businesses will be busier at certain hours  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eSocial network data: Using the information of relationships between users on Facebook, LinkedIn, Twitter, Reddit, and countless other websites and apps  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eSmart grid and sensor data: With the advent of the Internet of Things (IoT), more and more devices are able to record data at all times, making it possible to gather lots of data instantaneously  \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003e3 V's of Big Data\u003c/h2\u003e\n\n\u003cp\u003eDoug Laney published a \u003ca href=\"https://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf\"\u003epaper\u003c/a\u003e on three defining characteristics of big data. Three main features characterize big data: volume, variety, and velocity, or the three V‚Äôs. The volume of the data is its size, and how enormous it is. Velocity refers to the rate with which data is changing, or how often it is created. Finally, variety includes the different formats and types of data, as well as the different kinds of uses and ways of analyzing the data:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/3_components.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's look a bit deeper into what these 3 V's refer to:\u003c/p\u003e\n\n\u003ch3\u003eVOLUME\u003c/h3\u003e\n\n\u003cp\u003eVolume refers to the \u003cstrong\u003eamount of data\u003c/strong\u003e generated through websites, portals, and online applications in a data-driven business. Especially for online retailers, volume encompasses the available data that are out there and need to be assessed for relevance. \u003c/p\u003e\n\n\u003cp\u003eConsider the following:\u003c/p\u003e\n\n\u003cp\u003eAs of 2019, Facebook has 2.32 billion users, Youtube: 1.9 billion users, WhatsApp: 1.6 billion users and Instagram: 1 billion users. Every day, these users contribute to billions of images, posts, videos, tweets, etc. You can now imagine the insanely large amount (or \u003cstrong\u003ev\u003c/strong\u003eolume) of data that is generated every minute around the world.\nData volume is the primary attribute of big data. Big data can be quantified by size in Terabytes (TBs) or Petabytes (PBs), as well as even the number of records, transactions, tables, or files. Additionally, one of the things that makes big data really big is that it‚Äôs coming from a greater variety of sources than ever before, including logs, clickstreams, and social media as we will see below. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/rank_users.png\" width=\"650\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eVELOCITY\u003c/h3\u003e\n\n\u003cp\u003eVelocity refers to the speed with which data is generated, and as internet speeds have increased and the number of users has increased, the velocity has also increased substantially.\u003c/p\u003e\n\n\u003cp\u003eThe following image created by \u003ca href=\"https://www.allaccess.com/merge/archive/29580/2019-this-is-what-happens-in-an-internet-minute\"\u003eLori Lewis and Chadd Callahan\u003c/a\u003e shows what happens on major social media platforms in one minute. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/internet_minute.jpg\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eVelocity is basically the frequency of data generation or the frequency of data delivery. The leading edge of\nbig data is streaming data, which is collected in real-time from the websites. \u003c/p\u003e\n\n\u003cp\u003eTools within the big data stack help companies hold this explosion in velocity, accept the incoming flow of data, and at the same time process it quickly enough so that it does not create bottlenecks.\u003c/p\u003e\n\n\u003ch3\u003eVARIETY\u003c/h3\u003e\n\n\u003cp\u003eVariety in big data refers to all the structured and unstructured data that has the possibility of getting generated either by humans or by machines. Structured data is whatever data you could store in a spreadsheet. It can easily be cataloged and summary statistics can be calculated for it. Unstructured data are raw things like texts, tweets, pictures, videos, emails, voice mails, hand-written text, ECG readings, and audio recordings. Humans can only make sense of data that is structured, and it is usually up to data scientists to create some organization and structure to unstructured data.\u003c/p\u003e\n\n\u003cp\u003eVariety is all about the ability to classify the incoming data into various categories and turn unstructured data into something with more structure.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/unstructured_data.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis leads us to the most widely used definition in the industry by Gartner: \u003c/p\u003e\n\n\u003ch3\u003e\u003cem\u003eBig data is high-volume, high-velocity and/or high-variety information assets that demand cost-effective, innovative forms of information processing that enable enhanced insight, decision making, and process automation\u003c/em\u003e.\u003c/h3\u003e\n\n\u003cp\u003eAny data sources that fall under those 3 Vs are sources of big data, no matter how you define it.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eNOTE\u003c/strong\u003e: \u003cem\u003eSome researchers have discussed the addition of a fourth V, or \u003cstrong\u003eVeracity\u003c/strong\u003e. Veracity focuses on the quality of the data. This characterizes big data quality as good, bad, or undefined due to data inconsistency, incompleteness, ambiguity, latency, deception, and approximations\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eThe important thing to remember from this three-pronged definition of Big Data is that there is not a single component that makes data \"big\" or not. It is also a futile effort to try and make a definition of what the threshold is to make something \"big data\" rather than normal data. As technologies evolve and new distributed algorithms are created, what was once big data will no longer be big, and we will raise the bar.\u003c/p\u003e\n\n\u003ch2\u003eBig Data Analytics\u003c/h2\u003e\n\n\u003cp\u003eWith the evolution of technology and the increased amounts of data, as discussed above, the need for faster and more efficient ways of analyzing such data has also grown exponentially. Having big data \u003cstrong\u003ealone\u003c/strong\u003e is no longer enough to make efficient decisions at the right time. As we mentioned above, Big Data cannot be easily analyzed with traditional data management and analysis techniques and infrastructures. Therefore, there arises a need for new\ntools and methods specialized for big data analytics, as well as the required architectures for storing and managing such data. Accordingly, the emergence of big data has an effect on everything from the data itself to its collection, analysis, and visualization, as well as the final extracted decisions.\u003c/p\u003e\n\n\u003cp\u003eThe image below shows the technology stack, or the key tools and platforms being heavily employed in big data analytics today. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/tech_stack.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eExplaining each one of these tools/platforms etc. is outside the scope of this lesson. You are, however, encouraged to look up these technologies and see their role in big data analytics. Such a stack maps the different big data storage, management, analytics tools/methods, visualization, and evaluation tools to the different phases of the decision-making process. \u003c/p\u003e\n\n\u003cp\u003eThe key activities associated with big data analytics are reflected in four main areas: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBig data warehousing and distribution\u003c/li\u003e\n\u003cli\u003eBig data storage\u003c/li\u003e\n\u003cli\u003eBig data computational platforms\u003c/li\u003e\n\u003cli\u003eBig data analyses, visualization, and evaluation\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSuch a framework can be applied for knowledge discovery and informed decision-making in big data-driven organizations.\u003c/p\u003e\n\n\u003ch3\u003eExample Business Applications of Big Data Analytics\u003c/h3\u003e\n\n\u003cp\u003eAlong with some of the most common advanced data analytics methods such as regression analysis, association rules, clustering, and classification, some additional analyses have become common with big data.\u003c/p\u003e\n\n\u003cp\u003eFor example, social media has recently become important for social networking and content sharing. Yet, the content that is generated from social media websites is enormous and remains largely unexploited. However, social media analytics can be used to analyze such data and extract useful information and predictions.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/social_media.png\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSocial media analytics\u003c/strong\u003e is based on developing and evaluating informatics frameworks and tools in order to collect, monitor, summarize, analyze, as well as visualize social media data. \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSocial media analytics facilitates understanding the reactions and conversations between people in online communities, as well as extracting useful patterns and intelligence from their interactions and what they share on social media websites.\u003c/p\u003e\n\n\u003cp\u003eOn the other hand, \u003cstrong\u003etext mining\u003c/strong\u003e and \u003cstrong\u003eNLP\u003c/strong\u003e techniques are used to analyze a document or set of documents in order to understand the content within and the meaning of the information contained. Text mining has become very important nowadays since much of the information stored consists of text - in the form of emails, SMS texts, social media feeds, blogs, etc. While data mining deals with structured data, text presents special characteristics which basically follow a non-relational form and require wisely thought-out schemas to grant it more structure.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/nlp.png\" width=\"200\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eSentiment analysis/opinion mining\u003c/strong\u003e is also becoming more and more important as online opinion data, such as blogs, product reviews, forums, and social data from social media sites, like Twitter and Facebook, grow tremendously. \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSentiment Analysis\u003c/strong\u003e focuses on analyzing and understanding emotions from subjective text patterns and is enabled through text mining. It identifies the opinions and attitudes of individuals towards certain topics, and it is useful in classifying viewpoints as positive or negative. \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/sentiment_2.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSentiment analysis uses NLP and text analytics in order to identify and extract information by finding words that are indicative of certain sentiments, as well as relationships between words so that sentiments can be accurately identified.\u003c/p\u003e\n\n\u003cp\u003eAnd finally, one of the leading applications in big data analytics is \u003cstrong\u003erecommendation systems\u003c/strong\u003e. Powerful recommendation engines can be built for anything from movies and videos to music, books, and products as offered by Netflix, Pandora, or Amazon. As customers of an online retailer browse through products, the Recommendation system offers recommendations of products they might be interested in. In our daily online browsing and shopping routine, most of us often come across messages like the one shown below. This is a recommendation system doing its job. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/rec.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRecommendation systems have been immensely beneficial for both businesses and consumers. Big data is the driving force behind recommendation systems. A typical recommendation system cannot do its job without sufficient data and big data supplies plenty of user data such as past purchases, browsing history, and feedback for the recommendation systems to provide relevant and effective recommendations. In a nutshell, even the most advanced recommendations cannot be effective without big data.\u003c/p\u003e\n\n\u003ch3\u003eSo what's next?\u003c/h3\u003e\n\n\u003cp\u003eAfter this quick introduction, we will look at MapReduce, a distributed computation platform designed to incorporate big data analytics and how it is used by Hadoop/Apache Spark development environments to analyze big data. \u003c/p\u003e\n\n\u003ch2\u003eAdditional Reading\u003c/h2\u003e\n\n\u003cp\u003eBig data is a huge subject and incorporates a lot of underlying technologies and principles. You are advised to visit the following resources and read up on big data to develop a sound and holistic understanding of the domain. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=0cizsKDn3TI\"\u003eYoutube: Big Data Trap\u003c/a\u003e - Highly recommended, an excellent lecture on the social dimension of big data.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.educba.com/big-data-vs-data-science/\"\u003eBig Data vs Data Science\u003c/a\u003e - How to relate big data analytics to routine analytics that we have so far!\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://pdfs.semanticscholar.org/d392/0f02dbb15da19b04d782fc0546ef113e0bf7.pdf\"\u003eBig Data Analytics\u003c/a\u003e - A great paper summarizing big-data-related terms, ideas, etc. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://web.archive.org/web/20200214174508/https://www.ntnu.no/iie/fag/big/lessons/lesson2.pdf\"\u003eIntroduction to Big Data\u003c/a\u003e - A paper discussing the basics of big data\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this introductory lesson on big data, we looked at what data qualifies as \"big data\". We looked at how it is hard to come up with a standard definition of big data due to the variety of its applications and use cases. Up next, we will get into how we actually make parallelizable applications that are efficient with big data. \u003c/p\u003e","exportId":"introduction-to-big-data"},{"id":458182,"title":"Parallel and Distributed Computing with MapReduce","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-parallel-and-distributed-computing-with-mapreduce\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eMapReduce is a programming paradigm that enables the ability to scale across hundreds or thousands of servers for big data analytics. The underlying concept can be somewhat difficult to grasp, because this paradigm differs from the traditional programming practices. This lesson aims to present a simple yet intuitive account of MapReduce that we shall put into practice in upcoming labs. \u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eIn a nutshell, the term \"MapReduce\" refers to two distinct tasks. The first is the \u003cstrong\u003eMap\u003c/strong\u003e job, which takes one set of data and transforms it into another set of data, where individual elements are broken down into tuples \u003cstrong\u003e(key/value pairs)\u003c/strong\u003e, while the \u003cstrong\u003eReduce\u003c/strong\u003e job takes the output from a map as input and combines those data tuples into a smaller set of tuples.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eWe'll see this with help of some simple examples in this lesson.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain how the MapReduce paradigm works and how it differs from traditional programming approaches \u003c/li\u003e\n\u003cli\u003eExplain what is meant by distributed and parallel processing \u003c/li\u003e\n\u003cli\u003eUse MapReduce with a simple word count example \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eParallel and Distributed Processing\u003c/h2\u003e\n\n\u003cp\u003eThe MapReduce programming paradigm is designed to allow \u003cstrong\u003eparallel and distributed processing\u003c/strong\u003e  of large sets of data (also known as big data). MapReduce allows us to convert such big datasets into sets of \u003cstrong\u003etuples\u003c/strong\u003e as \u003cstrong\u003ekey:value\u003c/strong\u003e pairs, as we'll see shortly. These pairs are analogous to the data structures we saw with dictionaries and JSON files etc. These tuples are \u003cstrong\u003emapped\u003c/strong\u003e and \u003cstrong\u003ereduced\u003c/strong\u003e in a computational environment to allow distributed execution of complex tasks on a group (cluster) of interconnected computers. \u003c/p\u003e\n\n\u003cp\u003eSo in simpler terms, \u003cem\u003eMapReduce uses parallel distributed computing to turn big data into regular data.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's first see what we mean by parallel and distributed processing below. \u003c/p\u003e\n\n\u003ch3\u003eDistributed Processing Systems\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eA distributed processing system is a group of computers in a network working in tandem to accomplish a task\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhen computers are in a distributed system, they do not share hard drive memory or processing memory; they communicate with one other through messages, which are transferred over a network. The individual computers in this network are referred to as \u003cstrong\u003enodes\u003c/strong\u003e. As you've seen before, computers can send requests as well as packets of data to one another.\u003c/p\u003e\n\n\u003cp\u003eThe two most common ways of organizing computers into a distributed system are the client-server system and peer-to-peer system.\u003c/p\u003e\n\n\u003cp\u003eThe client-server architecture has nodes that make requests to a central server. The server will then decide to accept or reject these requests and send additional methods out to the outer nodes.\u003c/p\u003e\n\n\u003cp\u003ePeer-to-peer systems allow nodes to communicate with one another directly without requiring approval from a server.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/types_of_network.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eParallel Processing Systems\u003c/h3\u003e\n\n\u003cp\u003eThese networks are useful for many applications all over the web, but they are generally ill-suited for dealing with the processing power required for very large sets of data and complex problems.\u003c/p\u003e\n\n\u003cp\u003eJust like in the workplace, whenever there is an extremely complex task, it is best to divide and conquer. In the world of big data, if the data is \"big\" enough, it is generally better to take the approach of splitting up the larger task into smaller pieces.\u003c/p\u003e\n\n\u003cp\u003eEven though individual processors are getting faster (remember \u003ca href=\"https://en.wikipedia.org/wiki/Moore%27s_law\"\u003eMoore's Law\u003c/a\u003e), they will never have the ability to keep up with the amount of data we are able to produce. The best solution computer scientists have developed has been to use the power of \u003cstrong\u003emultiple processors\u003c/strong\u003e to put them to the same task. When using a well-developed distributed system, multiple processors can accomplish tasks at a fraction of the time it would take for a single processor to accomplish. As noted in the picture below, if you can divide the work between multiple processors, everything will be more efficient. \u003c/p\u003e\n\n\u003cp\u003eWith parallel computing:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ea larger problem is broken up into smaller pieces\u003c/li\u003e\n\u003cli\u003eevery part of the problem follows a series of instructions\u003c/li\u003e\n\u003cli\u003eeach one of the instructions is executed simultaneously on different processors\u003c/li\u003e\n\u003cli\u003eall of the answers are collected from the small problems and combined into one final answer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn the image below, you can see a simple example of a process being broken up and completed both sequentially and in parallel.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/parallel.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eOf course, not all problems can be parallelized, but there are some that are formally called \u003ca href=\"https://en.wikipedia.org/wiki/Embarrassingly_parallel\"\u003eembarrassingly parallel\u003c/a\u003e problems that require hardly any effort to ensure that a certain task is able to easily parallelizable. One example of something that would be embarrassingly parallelizable would be password cracking. Another example would be a movie production company trying to calculate the total profit they made from all of the movies they released in a given year. Let's think about all of the components that go into determining whether or not a movie is profitable.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003estory rights\u003c/li\u003e\n\u003cli\u003eproducer\u003c/li\u003e\n\u003cli\u003edirector\u003c/li\u003e\n\u003cli\u003ecast\u003c/li\u003e\n\u003cli\u003eproduction costs\u003c/li\u003e\n\u003cli\u003evisual effects\u003c/li\u003e\n\u003cli\u003emusic\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eand of course\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ebox office revenue\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHere is what this would look like if it was calculated sequentially.\u003c/p\u003e\n\n\u003cp\u003eIf a movie studio was to compute each one it's movie's profits sequentially, it would take far more time than if it calculated each movie's profit and combined them in parallel.\u003c/p\u003e\n\n\u003cp\u003eHere is a diagram of what parallel processing looks like in action: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/parallel_movies_.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSo how can we make all these nodes communicate with one another? By using a programming paradigm called MapReduce!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eMapReduce\u003c/strong\u003e is a software framework developed for processing datasets that qualify as \"Big Data\", in a \u003cstrong\u003edistributed and parallel\u003c/strong\u003e processing environment over several computers/nodes connected to each other as part of a \u003cstrong\u003ecluster\u003c/strong\u003e. It is a specific instance of the generalized split-apply-combine technique used to perform different data analyses.\u003c/p\u003e\n\n\u003cp\u003eWe will soon look into a simple example that is shown to introduce MapReduce,  \u003cstrong\u003eThe Word Count Problem\u003c/strong\u003e. The overall concept of MapReduce is very simple yet very powerful as:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSomehow, all data can be mapped to \u003cstrong\u003ekey:value\u003c/strong\u003e pairs \u003c/li\u003e\n\u003cli\u003eKeys and values themselves can be of ANY data type \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor our example, let's say a national association of zoos wants to determine the total number of species of animals in the country. After receiving responses from every zoo in the country, a data scientist receives a large file that has a different zoo located on each line with the species at that location. \u003c/p\u003e\n\n\u003cp\u003eHere are the first five zoos the data scientist reads over in the data document they receive:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eAnimals\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003elion tiger bear\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003elion giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egiraffe penguin\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epenguin lion giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekoala giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eLet's now look at how you would use the MapReduce framework in this simple word count example that could be generalized to much more data.\u003c/p\u003e\n\n\u003cp\u003eWe'll take a look at an image of this process in action and determine what's actually going on.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/word_count.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003e1. MAP Task (Splitting \u0026amp; Mapping)\u003c/h3\u003e\n\n\u003cp\u003eThe dataset that needs processing must first be transformed into \u003cstrong\u003ekey:value\u003c/strong\u003e pairs and split into fragments, which are then assigned to map tasks. Each computing cluster is assigned a number of map tasks, which are subsequently distributed among its nodes. In this example, let's assume that we are using 5 nodes (a server with 5 different workers).\u003c/p\u003e\n\n\u003cp\u003eFirst, split the data from one file or files into however many nodes are being used.\u003c/p\u003e\n\n\u003cp\u003eWe will then use the map function to create key:value pairs represented by:\u003cbr\u003e\n\u003cem\u003e{animal}\u003c/em\u003e , \u003cem\u003e{# of animals per zoo}\u003c/em\u003e \u003c/p\u003e\n\n\u003cp\u003eAfter processing of the original key:value pairs, some \u003cstrong\u003eintermediate\u003c/strong\u003e key:value pairs are generated. The intermediate key:value pairs are \u003cstrong\u003esorted by their key values\u003c/strong\u003e to create a new list of key:value pairs.\u003c/p\u003e\n\n\u003ch3\u003e2. Shuffling\u003c/h3\u003e\n\n\u003cp\u003eThis list from the map task is divided into a new set of fragments that sorts and shuffles the mapped objects into an order or grouping that will make it easier to reduce them. \u003cstrong\u003eThe number of these new fragments will be the same as the number of the reduce tasks\u003c/strong\u003e. \u003c/p\u003e\n\n\u003ch3\u003e3. REDUCE Task (Reducing)\u003c/h3\u003e\n\n\u003cp\u003eNow, every properly shuffled segment will have a reduce task applied to it. After the task is completed, the final output is written onto a file system. The underlying file system is usually HDFS (Hadoop Distributed File System). \u003c/p\u003e\n\n\u003cp\u003eIt's important to note that MapReduce will generally only be powerful when dealing with large amounts of data. When working with a small dataset, it will be faster not to perform operations in the MapReduce framework.\u003c/p\u003e\n\n\u003cp\u003eThere are two groups of entities in this process to ensuring that the MapReduce task gets done properly:\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eJob Tracker\u003c/strong\u003e: a \"master\" node that informs the other nodes which map and reduce jobs to complete\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eTask Tracker\u003c/strong\u003e: the \"worker\" nodes that complete the map and reduce operations\u003c/p\u003e\n\n\u003cp\u003eThere are different names for these components depending on the technology used, but there will always be a master node that informs worker nodes what tasks to perform.\u003c/p\u003e\n\n\u003cp\u003eA general pseudocode for a word count map and reduce tasks would look like \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Count word frequency\n\u003c/span\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003edoc\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eword\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edoc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"s\"\u003e' '\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eemit\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003eword\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ereduce\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ekey\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eemit\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ekey\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003esum\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSimilarly, we can discuss combining several MapReduce jobs in order to complete a given task. This means that once the first MapReduce job is finished, the output will become an input for the second MapReduce job and that output could be the final result (or fed into another MapReduce job). \u003c/p\u003e\n\n\u003cp\u003eLet's assume that we would like to extend the word count program and we would like to count all words in a given Twitter dataset. The first MapReduce will read our twitter data and extract the tweets' text. The second MapReduce is the word count Map-Reduce which will analyze the Twitter dataset and produce the statistics about it. So it is simply chaining together multiple jobs. \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eInputFile -\u0026gt; Map-1 -\u0026gt; Reduce-1 -\u0026gt; output-1 -\u0026gt; Map-2 - \u0026gt; Reduce-2 -\u0026gt; output-2 -\u0026gt; ... Map-x -\u0026gt; Reduce-x\u003c/strong\u003e  \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLater we are going to look at Apache Spark, which adds extra features of security and fault tolerance to its MapReduce offering, making it an industry standard. We will also look at programming for the aforementioned word count problem.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cp\u003eVisit following external links to read about the previous descriptions and examples in more detail. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.tutorialspoint.com/map_reduce/map_reduce_introduction.htm\"\u003eMapReduce Introduction\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.guru99.com/introduction-to-mapreduce.html\"\u003eWhat is MapReduce? How it Works\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at how MapReduce allows a programming paradigm quite different than traditional programming practices, yet very powerful and effective towards processing large amounts of data.\u003c/p\u003e","exportId":"parallel-and-distributed-computing-with-mapreduce"},{"id":458188,"title":"(Py)Spark Basics","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-basics\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-basics\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-basics/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eBefore we begin writing PySpark code, let's go over some more of the concepts that underpin Apache Spark.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the high-level architecture of Apache Spark\u003c/li\u003e\n\u003cli\u003eDescribe the driver, worker, and executor in the context of Spark's parallelism\u003c/li\u003e\n\u003cli\u003eDescribe the data structures used by Apache Spark and PySpark in particular\u003c/li\u003e\n\u003cli\u003eList use cases for Spark\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSpark Architecture\u003c/h2\u003e\n\n\u003cp\u003eThe high-level architecture of the Apache Spark stack looks like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1007%2Fs41060-016-0027-9/MediaObjects/41060_2016_27_Fig1_HTML.gif?as=webp\" alt=\"Spark Architecture\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Figure from \u003cem\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e\u003c/em\u003e)\u003c/p\u003e\n\n\u003cp\u003eWe'll start at the bottom and work our way up.\u003c/p\u003e\n\n\u003ch3\u003eStorage\u003c/h3\u003e\n\n\u003cp\u003eWe won't focus too much on the specifics here, since they are applicable to all sorts of distributed computing systems. The main thing to be aware of is that production-grade Big Data stacks require specialized file systems.\u003c/p\u003e\n\n\u003cp\u003eSome storage options that are compatible with Spark are:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\"\u003eHDFS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cassandra.apache.org/_/index.html\"\u003eCassandra\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hbase.apache.org/\"\u003eHBase\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.alluxio.io/\"\u003eAlluxio\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eCluster Manager\u003c/h3\u003e\n\n\u003cp\u003e\u003cimg src=\"https://spark.apache.org/docs/latest/img/cluster-overview.png\" alt=\"Cluster manager diagram\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Figure from \u003ca href=\"https://spark.apache.org/docs/latest/cluster-overview.html\"\u003eCluster Mode Overview\u003c/a\u003e)\u003c/p\u003e\n\n\u003cp\u003eAs mentioned previously, Big Data tools typically rely on distributed and parallel computing. This is implemented in the Apache Spark stack using a cluster manager.\u003c/p\u003e\n\n\u003cp\u003eThe main takeaway here should be a basic familiarity with the terminology.\u003c/p\u003e\n\n\u003cp\u003eA \u003cstrong\u003e\u003cem\u003ecluster\u003c/em\u003e\u003c/strong\u003e is a group of interconnected computers used for distributed and parallel computing. A \u003cstrong\u003e\u003cem\u003ecluster manager\u003c/em\u003e\u003c/strong\u003e manages those machines by allocating resources and connecting the driver program and worker nodes. A \u003cstrong\u003e\u003cem\u003edriver\u003c/em\u003e\u003c/strong\u003e program maintains information about your application, responds to external programs, and analyzes, distributes, and schedules work across worker nodes. \u003cstrong\u003e\u003cem\u003eWorker\u003c/em\u003e\u003c/strong\u003e nodes contain \u003cstrong\u003e\u003cem\u003eexecutor\u003c/em\u003e\u003c/strong\u003e processes that execute the code assigned by the driver.\u003c/p\u003e\n\n\u003cp\u003eHere are links to some cluster manager options:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\"\u003eHadoop YARN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mesos.apache.org/\"\u003eApache Mesos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/ec2/\"\u003eAmazon EC2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\"\u003eKubernetes\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eA Note About The Spark Curriculum\u003c/h3\u003e\n\n\u003cp\u003eBecause the curriculum lessons and labs are smaller, proof-of-concept applications of Spark, we will \u003cstrong\u003enot\u003c/strong\u003e be using a special distributed file storage system like HDFS or a full-fledged cluster manager like YARN. Instead, we will use \u003ca href=\"https://spark.apache.org/docs/latest/spark-standalone.html\"\u003eSpark Standalone\u003c/a\u003e with a local cluster.\u003c/p\u003e\n\n\u003cp\u003eTypically a data scientist or data engineer would not be responsible for managing a cluster. In fact, you can refer to the \u003ca href=\"https://spark.apache.org/docs/latest/api/python/\"\u003ePySpark documentation\u003c/a\u003e, which contains a version of the Spark architecture diagram that doesn't even include the storage and cluster manager layers. Instead it just focuses on the Spark Core and upper-level libraries:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://spark.apache.org/docs/latest/api/python/_images/pyspark-components.png\" alt=\"Simplified Spark Architecture\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eSpark Core (Unstructured API)\u003c/h3\u003e\n\n\u003ch4\u003eAdvantages Over MapReduce\u003c/h4\u003e\n\n\u003cp\u003eThe Spark Core is where Spark's advantages over MapReduce appear. To quote from \u003cem\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e\u003c/em\u003e (emphasis added):\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eApache Spark has emerged as the de facto standard for big data analytics after Hadoop‚Äôs MapReduce. As a framework, it combines a core engine for distributed computing with an advanced programming model for in-memory processing. Although it has the same linear scalability and fault tolerance capabilities as those of MapReduce, it comes with a multistage in-memory programming model comparing to the rigid map-then-reduce disk-based model. With such an advanced model, Apache Spark is much faster and easier to use.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eApache Spark leverages the memory of a computing cluster to reduce the dependency on the underlying distributed file system, leading to dramatic performance gains in comparison with Hadoop‚Äôs MapReduce.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eRecall the difference between data or models \u003cem\u003ein memory\u003c/em\u003e (e.g. data stored in a Python variable) vs. \u003cem\u003eon disk\u003c/em\u003e (e.g. a CSV or pickled model file). Almost all of the data work we do in this curriculum is in memory, since this is much faster and more flexible than performing all of the IO operations needed to save everything to disk. Spark uses this same approach.\u003c/p\u003e\n\n\u003cp\u003eYou can read more about the specific performance gains made by Spark compared to MapReduce \u003ca href=\"https://research.ijcaonline.org/volume113/number1/pxc3900531.pdf\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eUnstructured API\u003c/h4\u003e\n\n\u003cp\u003eFunctionality within the Spark Core is also referred to as the \"Unstructured API\".\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eNote: \"API\" doesn't necessarily mean an HTTP API accessed over the internet -- in this case it just means the interface of classes and functions that your code can invoke.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe Unstructured API is the older, lower-level interface.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eNote: \"lower-level\" is literally true in the case of the figure shown at the top of this lesson, but it also generally means that a tool is closer to the underlying machine code executing on a computer. That means that it is usually more configurable than a higher-level tool, but also that it tends to be more difficult to use and is possibly not optimized for specific use cases.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIt includes some constructs that resemble MapReduce constructs, such as Accumulators and Broadcast variables, as well as SparkContext and Resilient Distributed Datasets (RDDs). You can find the full PySpark Unstructured API documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eSparkContext\u003c/h4\u003e\n\n\u003cp\u003eSparkContext is the entry point for using the Unstructured API. You'll notice it is inside the \"Driver Program\" rectangle in the cluster manager figure above. We will cover more details of how SparkContext is used with PySpark in a future lesson. You can also read more from the PySpark documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eResilient Distributed Datasets (RDDs)\u003c/h4\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDDs) are the fundamental data structure used by the Spark Core and accessible via the Unstructured API. Once again, we will cover more details in a future lesson, and you can read more from the PySpark documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.html#rdd-apis\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3\u003eUpper-Level Libraries (Structured API)\u003c/h3\u003e\n\n\u003cp\u003eThe upper-level libraries, also known as the Structured API, is where Spark gets really exciting. They are higher-level, easier to use, and optimized for particular tasks.\u003c/p\u003e\n\n\u003cp\u003eFor data analysis and manipulation, the Structured API offers Spark SQL, a \u003ccode\u003epandas\u003c/code\u003e API, and Spark Streaming. For machine learning the Structured API offers MLlib.\u003c/p\u003e\n\n\u003ch4\u003eSpark SQL\u003c/h4\u003e\n\n\u003cp\u003eSpark SQL has data structures called DataFrame and Dataset.\u003c/p\u003e\n\n\u003cp\u003eA Spark SQL \u003cstrong\u003e\u003cem\u003eDataFrame\u003c/em\u003e\u003c/strong\u003e is similar to a \u003ccode\u003epandas\u003c/code\u003e DataFrame in that it keeps track of column names and types, which improves efficiency and makes the data easier to work with. It is not the same as the DataFrame used in the \u003ccode\u003epandas\u003c/code\u003e API, although it is possible to convert between them if necessary. You can find more documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eA Spark SQL \u003cstrong\u003e\u003cem\u003eDataset\u003c/em\u003e\u003c/strong\u003e works similar to a DataFrame except it has an additional Row construct. Datasets are not usable in PySpark (only in Scala and Java) at this time, although you may see references to them in the main Spark documentation.\u003c/p\u003e\n\n\u003cp\u003eRather than a SparkContext like is used for the Unstructured API, the entry point to Spark SQL is a \u003cstrong\u003e\u003cem\u003eSparkSession\u003c/em\u003e\u003c/strong\u003e. You can find more documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003ePandas API\u003c/h4\u003e\n\n\u003cp\u003eThe \u003ccode\u003epandas\u003c/code\u003e API allows you to use familiar \u003ccode\u003epandas\u003c/code\u003e class and function names, with the power of Spark! \u003ca href=\"https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/faq.html#should-i-use-pyspark-s-dataframe-api-or-pandas-api-on-spark\"\u003eThe PySpark maintainers recommend\u003c/a\u003e that anyone who already knows how to use \u003ccode\u003epandas\u003c/code\u003e uses this API. You can find the API reference \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html\"\u003ehere\u003c/a\u003e and user guide \u003ca href=\"https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eSpark Streaming\u003c/h4\u003e\n\n\u003cp\u003eStreaming data is outside the scope of this curriculum, but it's useful to know that Spark has functionality for it. You can find the PySpark documentation for Spark Streaming \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.streaming.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eMLlib\u003c/h4\u003e\n\n\u003cp\u003eMLlib allows you to perform many of the same machine learning tasks as scikit-learn, including transforming data, building and evaluating supervised and unsupervised machine learning models, and even building pipelines. There is also an Alternating Least Squares (ALS) implementation, which we will apply to a recommender system!\u003c/p\u003e\n\n\u003cp\u003eYou can find the PySpark documentation for MLlib \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e (2016) is an excellent review article. It should take 90-120 minutes to read, and we highly encourage you to take the time if you're interested in using Spark.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://stanford.edu/%7Erezab/sparkclass/slides/itas_workshop.pdf\"\u003eIntro to Apache Spark\u003c/a\u003e (2014) is a 194-slide presentation that goes into more detail about Spark with many code examples. Note: it appears that links in the slide deck starting with \u003ccode\u003ecdn.liber118.com\u003c/code\u003e are no longer working, but the GitHub links are still functional.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eAt a high level, Spark's architecture consists of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStorage\u003c/li\u003e\n\u003cli\u003eCluster Manager\u003c/li\u003e\n\u003cli\u003eSpark Core (Unstructured API)\u003c/li\u003e\n\u003cli\u003eUpper-Level Libraries (Structured API)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe Cluster Manager divides and shares the physical resources of a cluster of machines, utilizing a driver program that specifies tasks for executors within worker nodes.\u003c/p\u003e\n\n\u003cp\u003eThe Spark Core (Unstructured API) is accessed using SparkContext, and utilizes the RDD data structure.\u003c/p\u003e\n\n\u003cp\u003eThe upper-level libraries (Structured API) include code for specific use cases, including data analysis and manipulation (Spark SQL, \u003ccode\u003epandas\u003c/code\u003e API, Spark Streaming) and machine learning (MLlib). Spark SQL is accessed using SparkSession and introduces two additional data structures (DataFrame and Dataset).\u003c/p\u003e\n\n\u003cp\u003eNow that we've covered the concepts, let's dive into some specific implementations!\u003c/p\u003e","exportId":"py-spark-basics"},{"id":458207,"title":"Installing and Configuring PySpark with Docker","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-docker-installation\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn a large-scale enterprise environment, you would typically run (Py)Spark on a distributed cloud system or possibly a dedicated hardware in a datacenter. However it is also possible to run it on your local computer as a standalone cluster. In this lesson we'll walk through how to do just that!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUnderstand how to install PySpark on your local computer\u003c/li\u003e\n\u003cli\u003eExplain the utility of Docker when dealing with package management \u003c/li\u003e\n\u003cli\u003eInstall a Docker container that comes packaged with Spark \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eInstalling PySpark without Docker\u003c/h2\u003e\n\n\u003cp\u003eIt is possible to install PySpark without Docker, but it will require more-advanced systems administration skills. Follow these instructions if you want to get the best possible Spark performance from your personal computer, but be aware that \u003cstrong\u003eyou can feel free to skip this\u003c/strong\u003e because there are a lot of little places that things can go wrong, and it can be difficult to troubleshoot.\u003c/p\u003e\n\n\u003ch3\u003eCreating a New \u003ccode\u003econda\u003c/code\u003e Environment\u003c/h3\u003e\n\n\u003cp\u003eIf you want to work on a project using PySpark, we recommend that you make a new \u003ccode\u003econda\u003c/code\u003e environment. Execute the following commands in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate base\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate spark-env\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eChecking for Successful Environment Creation\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich python\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure that the path displayed includes \u003ccode\u003espark-env\u003c/code\u003e before proceeding to the next step. If it doesn't, try \u003ccode\u003econda deactivate\u003c/code\u003e repeatedly until no environment is shown, then \u003ccode\u003econda activate spark-env\u003c/code\u003e again.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Java\u003c/h3\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, execute this line in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge \u003cspan class=\"nv\"\u003eopenjdk\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e11\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis installs OpenJDK, an open-source version of Java, within your \u003ccode\u003econda\u003c/code\u003e environment.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful Java Installation\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich java\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure the path displayed includes \u003ccode\u003espark-env\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eLaunch an interactive \u003cstrong\u003eJava shell\u003c/strong\u003e by running:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ejshell\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003ejshell\u0026gt;\u003c/code\u003e prompt.\u003c/p\u003e\n\n\u003cp\u003eIf you want to write some Java code here, you can! Or you can just quit the Java shell by typing \u003ccode\u003e/exit\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch3\u003eInstalling PySpark\u003c/h3\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, execute this line in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epyspark\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e3\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis installs a setup for a standalone Spark cluster as well as the PySpark library to interact with that cluster.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Installation: Spark\u003c/h4\u003e\n\n\u003cp\u003eFirst, check that Spark installed successfully by launching an interactive \u003cstrong\u003eSpark shell\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003espark-shell\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003escala\u0026gt;\u003c/code\u003e prompt. It's normal for this to take several seconds, and also to print out several lines of warnings, such as \u003ccode\u003eWARNING: Illegal reflective access\u003c/code\u003e, as well as some fun ASCII art:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\\n      /_/\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry typing \u003ccode\u003esc\u003c/code\u003e and hitting Enter to see the string representation of the SparkContext in Scala. Then quit the Scala shell by typing \u003ccode\u003e:quit\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Installation: PySpark\u003c/h4\u003e\n\n\u003cp\u003eThen, check that PySpark installed successfully by launching an interactive \u003cstrong\u003ePySpark shell\u003c/strong\u003e. Run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epyspark\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003e\u0026gt;\u0026gt;\u0026gt;\u003c/code\u003e prompt, as well as the same warnings and ASCII art as the \u003ccode\u003espark-shell\u003c/code\u003e did. Try typing \u003ccode\u003esc\u003c/code\u003e and hitting Enter to see the string representation of the SparkContext in Python (and you can test out any other random Python commands). Then quit the PySpark shell by typing \u003ccode\u003equit()\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Jupyter Notebook and Other Useful Libraries\u003c/h3\u003e\n\n\u003cp\u003eIn theory \u003ccode\u003espark-env\u003c/code\u003e already has everything you need to start developing PySpark code! But there are a couple more tools that we typically use for data science that you probably want to install as well.\u003c/p\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, run these commands in the terminal to install Jupyter Notebook and Matplotlib. Afterwards you can install any other libraries you like to use as well.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epython \u003cspan class=\"nt\"\u003e-m\u003c/span\u003e ipykernel \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e--user\u003c/span\u003e \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nt\"\u003e--display-name\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"Python (spark-env)\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ematplotlib\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eRunning a PySpark Notebook Locally\u003c/h3\u003e\n\n\u003cp\u003eNow you can clone this notebook and run \u003ccode\u003ejupyter notebook\u003c/code\u003e to start it in your \u003ccode\u003espark-env\u003c/code\u003e. The three cells below should run with no errors (although there may be warnings):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003esc\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epyspark\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSparkContext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'local[*]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e22/03/07 20:38:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003erdd\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparallelize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etakeSample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e[597, 803, 304, 458, 603]\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\n\u003chr\u003e\n\n\u003ch2\u003eInstalling PySpark with Docker\u003c/h2\u003e\n\n\u003cp\u003eIf you're lucky, all of the commands above ran smoothly and you are now able to use PySpark directly on your machine using \u003ccode\u003econda\u003c/code\u003e. However we recognize that this process frequently goes wrong, and troubleshooting often involves some tricky systems administration tasks, configuring environment variables such as \u003ccode\u003e$PATH\u003c/code\u003e, \u003ccode\u003e$JAVA_PATH\u003c/code\u003e, etc.\u003c/p\u003e\n\n\u003cp\u003eIn the rest of this lesson, we'll describe an alternative way to install PySpark using \u003cstrong\u003eDocker\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eWhy Docker?\u003c/h3\u003e\n\n\u003cp\u003eDocker is a container technology that allows \u003cstrong\u003epackaging\u003c/strong\u003e and \u003cstrong\u003edistribution\u003c/strong\u003e of software  so that it takes away the headache of things like setting up an environment, configuring logging, configuring options, etc. Docker basically removes the excuse of \u003cem\u003eIt doesn't work on my machine\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.zdnet.com/article/what-is-docker-and-why-is-it-so-darn-popular/\"\u003eVisit this link learn more about docker and containers\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003eHow Does Docker Work?\u003c/h3\u003e\n\n\u003cp\u003eWithout getting too much into the details of virtualization and underlying operating systems, a Docker \u003cstrong\u003eimage\u003c/strong\u003e is deployed in a \u003cstrong\u003econtainer\u003c/strong\u003e where it essentially operates as a self-contained computer wherever it is run. It can be running on a Windows desktop, a Mac laptop, or an AWS cloud server, and the dependencies and environment should work exactly the same.\u003c/p\u003e\n\n\u003cp\u003eKind of like the \u003ccode\u003e.yml\u003c/code\u003e file we used to create \u003ccode\u003elearn-env\u003c/code\u003e, Docker containers have a static specification that tells the software what to install. Only instead of just Python packages, the \u003cstrong\u003eDockerfile\u003c/strong\u003e (as it's called) specifies the operating system, shell language, permissions, environment variables, etc.\u003c/p\u003e\n\n\u003cp\u003eThe Dockerfile we'll be using is for an image maintained by Jupyter called \u003ccode\u003epyspark-notebook\u003c/code\u003e. You can view the full Dockerfile \u003ca href=\"https://github.com/jupyter/docker-stacks/blob/master/pyspark-notebook/Dockerfile\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eIn order to turn that file into a functioning container, we need to install Docker.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Docker\u003c/h3\u003e\n\n\u003cp\u003eGo to the \u003ca href=\"https://docs.docker.com/get-docker/\"\u003eGet Docker\u003c/a\u003e page, click on your operating system, and follow the instructions. Note that there is a graphical user interface called \"Docker Desktop\" available for Mac and Windows users, whereas at the time of this writing there is not an equivalent tool for Linux users. Linux users can install the \"server\" version.\u003c/p\u003e\n\n\u003ch3\u003ePulling the PySpark Stack from DockerHub\u003c/h3\u003e\n\n\u003cp\u003eIf you were developing your own Dockerfiles, you could just work locally, similarly to how you could write Python code locally without connecting to any remote repositories. But we want to run an image created by someone else, so we want to use the \u003ccode\u003edocker pull\u003c/code\u003e command from \u003ca href=\"https://hub.docker.com/r/jupyter/pyspark-notebook\"\u003eDockerHub\u003c/a\u003e. This is roughly equivalent to running \u003ccode\u003egit pull\u003c/code\u003e from GitHub, except you're downloading a pre-built computer image.\u003c/p\u003e\n\n\u003cp\u003eSpecifically, run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will initiate a download that will likely take a while, then finally you should see a message like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eStatus: Downloaded newer image for jupyter/pyspark-notebook:latest\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou have now pulled down the PySpark stack!\u003c/p\u003e\n\n\u003ch3\u003eRunning Jupyter Notebook with Docker\u003c/h3\u003e\n\n\u003cp\u003eNow that you have pulled down \u003ccode\u003epyspark-notebook\u003c/code\u003e, run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(The \u003ccode\u003e-p\u003c/code\u003e flag is setting the ports on your computer as well as the container to be connected.)\u003c/p\u003e\n\n\u003cp\u003eThis will launch a notebook server that should look fairly similar to when you run a regular \u003ccode\u003ejupyter notebook\u003c/code\u003e command!\u003c/p\u003e\n\n\u003cp\u003eHowever you will most likely need to copy the URL displayed in the terminal and paste it into a browser window, rather than having it automatically open like \u003ccode\u003ejupyter notebook\u003c/code\u003e usually does. The URL will look something like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:8888/lab?token=\u0026lt;token\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen once you paste it into the browser address bar, you'll be redirected to just \u003ccode\u003ehttp://127.0.0.1:8888/lab\u003c/code\u003e, which is a Jupyter Lab interface:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation/raw/master/images/jupyter_lab.png\" alt=\"jupyter lab screenshot\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIf you want to navigate back to the classic \u003ccode\u003ejupyter notebook\u003c/code\u003e file window, simply enter \u003ccode\u003ehttp://127.0.0.1:8888/tree\u003c/code\u003e in the address bar (replacing \u003ccode\u003elab\u003c/code\u003e with \u003ccode\u003etree\u003c/code\u003e).\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Image Installation\u003c/h4\u003e\n\n\u003cp\u003eFrom here, you can create a new notebook and run these lines of code, which should not produce an error:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark\u003c/span\u003e\n\u003cspan class=\"n\"\u003esc\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epyspark\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSparkContext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'local[*]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparallelize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etakeSample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eConnecting Docker Container to Your File System\u003c/h3\u003e\n\n\u003cp\u003eYou might have noticed something strange when you were creating that notebook: there was only a directory called \u003ccode\u003ework\u003c/code\u003e, nothing related to the directory on your computer where you launched \u003ccode\u003edocker run\u003c/code\u003e!\u003c/p\u003e\n\n\u003cp\u003eThis is because even though the notebook server looked very similar to one being run directly on your computer, this one only had access to the container's file system.\u003c/p\u003e\n\n\u003cp\u003eIf you want to be able to use notebooks from the curriculum or files on disk (e.g. CSV files), it's useful to be able to connect your computer's file system to the container.\u003c/p\u003e\n\n\u003ch4\u003eShutting Down Previous Docker Container\u003c/h4\u003e\n\n\u003cp\u003eShut down the currently-running container by typing \u003ccode\u003econtrol-C\u003c/code\u003e in the terminal window where it is currently running. If you accidentally closed that terminal window, you can:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eUse a command-line approach:\n\n\u003cul\u003e\n\u003cli\u003eRun \u003ccode\u003edocker ps\u003c/code\u003e to see a list of all currently-running docker containers\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003edocker stop \u0026lt;container id\u0026gt;\u003c/code\u003e where \u003ccode\u003e\u0026lt;container id\u0026gt;\u003c/code\u003e is from the \u003ccode\u003edocker ps\u003c/code\u003e print-out. For example, \u003ccode\u003edocker stop efb990e0e054\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eOr, use Docker Desktop:\n\n\u003cul\u003e\n\u003cli\u003eOpen Docker Desktop and locate the currently-running container in the \"Containers / Apps\" list\u003c/li\u003e\n\u003cli\u003eClick the square stop button\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4\u003eStarting Docker Again, Connected to Your File System\u003c/h4\u003e\n\n\u003cp\u003eThe formal language of this is called \"mounting a volume\", so it uses the \u003ccode\u003e-v\u003c/code\u003e command-line option.\u003c/p\u003e\n\n\u003cp\u003eThe general structure looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003eabsolute file path of current directory\u003cspan class=\"o\"\u003e}\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe are mapping \u003ccode\u003e{absolute file path of current directory}\u003c/code\u003e on your computer onto \u003ccode\u003e/home/jovyan/work\u003c/code\u003e in the container.\u003c/p\u003e\n\n\u003cp\u003e(Fun fact: the username \u003ccode\u003ejovyan\u003c/code\u003e is a \u003ca href=\"https://docs.jupyter.org/en/latest/community/content-community.html#what-is-a-jovyan\"\u003eplay on the name Jupyter\u003c/a\u003e. \u003cem\u003eJovyan\u003c/em\u003e is to \u003ca href=\"https://en.wiktionary.org/wiki/Jovian\"\u003e\u003cem\u003eJovian\u003c/em\u003e\u003c/a\u003e as \u003cem\u003eJupyter\u003c/em\u003e is to \u003cem\u003eJupiter\u003c/em\u003e.)\u003c/p\u003e\n\n\u003cp\u003eFor \u003cstrong\u003eMac\u003c/strong\u003e or \u003cstrong\u003eLinux\u003c/strong\u003e, the actual command looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor \u003cstrong\u003eWindows\u003c/strong\u003e, the actual command looks like this (executed in Command Prompt, not Git Bash):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker run -p 8888:8888 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow you should be able to navigate to the \u003ccode\u003ework\u003c/code\u003e directory and find this notebook there!\u003c/p\u003e\n\n\u003ch4\u003eA Couple More Command-Line Options\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e-it\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis starts the container in \"interactive mode\" and allows you to access the Bash shell inside the container.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e--rm\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis removes the container from your list of images as soon as you shut it down. Since you are storing your data on your computer's file system, this is a good option to avoid creating a lot of extra unnecessary files.\u003c/p\u003e\n\n\u003cp\u003eTherefore we recommend that you run this complete command:\u003c/p\u003e\n\n\u003cp\u003eOn \u003cstrong\u003eMac/Linux\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work \u003cspan class=\"nt\"\u003e-it\u003c/span\u003e \u003cspan class=\"nt\"\u003e--rm\u003c/span\u003e jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOn \u003cstrong\u003eWindows\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker run -p 8888:8888 -v %cd%:/home/jovyan/work -it --rm jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at installing Spark with and without a Docker container.\u003c/p\u003e\n\n\u003cp\u003eTo recap the steps:\u003c/p\u003e\n\n\u003ch3\u003eWithout Docker\u003c/h3\u003e\n\n\u003cp\u003eRun all of these commands, following the instructions above to ensure that each step worked as expected:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate base\nconda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8\nconda activate spark-env\nconda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge \u003cspan class=\"nv\"\u003eopenjdk\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e11\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epyspark\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e3\nconda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge notebook\npython \u003cspan class=\"nt\"\u003e-m\u003c/span\u003e ipykernel \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e--user\u003c/span\u003e \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nt\"\u003e--display-name\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"Python (spark-env)\"\u003c/span\u003e\nconda \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ematplotlib\njupyter notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eWith Docker\u003c/h3\u003e\n\n\u003cp\u003eGo to the \u003ca href=\"https://docs.docker.com/get-docker/\"\u003eGet Docker\u003c/a\u003e page, click on your operating system, and follow the instructions.\u003c/p\u003e\n\n\u003cp\u003eFor Mac/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\ndocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor Windows:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\ndocker run -p 8888:8888 -v %cd%:/home/jovyan/work -it --rm jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","exportId":"installing-and-configuring-pyspark-with-docker"},{"id":458211,"title":"Understanding SparkContext - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-sparkcontext\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sparkcontext\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sparkcontext/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eSparkContext is the entry point for using the Unstructured API of Spark. In this lesson we'll go over how SparkContext works in PySpark, create a SparkContext called \u003ccode\u003esc\u003c/code\u003e, and explore \u003ccode\u003esc\u003c/code\u003e's properties.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine a SparkContext and why it is important to a Spark application\u003c/li\u003e\n\u003cli\u003eCreate a SparkContext with PySpark\u003c/li\u003e\n\u003cli\u003eList the major properties and methods of SparkContext\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g294b94461ee6e9572f786a2e6bb0659b"},{"id":458214,"title":"Resilient Distributed Datasets (RDDs) - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-resilient-distributed-datasets-rdd-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-resilient-distributed-datasets-rdd-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-resilient-distributed-datasets-rdd-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDD) are fundamental data structures of Spark. An RDD is essentially the Spark representation of a set of data, spread across multiple machines, with APIs to let you act on it. An RDD can come from any data source, e.g. text files, a database, a JSON file, etc.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply the map(func) transformation to a given function on all elements of an RDD in different partitions \u003c/li\u003e\n\u003cli\u003eApply a map transformation for all elements of an RDD \u003c/li\u003e\n\u003cli\u003eCompare the difference between a transformation and an action within RDDs \u003c/li\u003e\n\u003cli\u003eUse collect(), count(), and take() actions to trigger spark transformations\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eUse filter to select data that meets certain specifications within an RDD \u003c/li\u003e\n\u003cli\u003eSet number of partitions for parallelizing RDDs \u003c/li\u003e\n\u003cli\u003eCreate RDDs from Python collections \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g2f77863d15f7cdaae1efb4cd6c8dd382"},{"id":458218,"title":"Word Count with MapReduce - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-word-count-with-map-reduce-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-count-with-map-reduce-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-count-with-map-reduce-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we have seen the key map and reduce operators in Spark, and also know when to use transformation and action operators, we can revisit the word count problem we introduced earlier in the section. In this lab, we will read a text corpus into the Spark environment, perform a word count, and try basic NLP ideas to get a good grip on how MapReduce performs. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply the map(func) transformation to a given function on all elements of an RDD in different partitions \u003c/li\u003e\n\u003cli\u003eApply a map transformation for all elements of an RDD \u003c/li\u003e\n\u003cli\u003eCompare the difference between a transformation and an action within RDDs \u003c/li\u003e\n\u003cli\u003eUse collect(), count(), and take() actions to trigger spark transformations \u003c/li\u003e\n\u003cli\u003eUse filter to select data that meets certain specifications within an RDD \u003c/li\u003e\n\u003cli\u003eUse Spark and the MapReduce framework to complete a full parallelized word count problem \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gda1b3b7f840139ea7429bdb7e29b0a3f"},{"id":458221,"title":"Spark DataFrames","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-dataframes\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-dataframes\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-dataframes/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eYou've now explored how to perform operations on Spark RDDs for simple MapReduce tasks. This is useful for contexts where the low-level Unstructured API is most appropriate, but now we're going to move on to using a more intuitive and powerful interface: Spark DataFrames!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad and manipulate data using Spark SQL DataFrames\u003c/li\u003e\n\u003cli\u003eDescribe the similarities and differences between RDDs, Spark SQL DataFrames, and pandas DataFrames\u003c/li\u003e\n\u003c/ul\u003e","exportId":"gbb401e4ed8174cf280ef12f218168b8b"},{"id":458226,"title":"Machine Learning with Spark","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-machine-learning-with-spark-v2-4\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we've performed some data manipulation and aggregation with Spark SQL DataFrames, let's get to the really cool stuff: machine learning!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine estimators and transformers in Spark ML \u003c/li\u003e\n\u003cli\u003eCreate a Spark ML pipeline that transforms data and runs over a grid of hyperparameters \u003c/li\u003e\n\u003c/ul\u003e","exportId":"geb081d1079ab27f821ff41228da6e22b"},{"id":458231,"title":"Machine Learning with Spark - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-machine-learning-with-spark-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003ePreviously you saw how to manipulate data with Spark DataFrames as well as create machine learning models. In this lab, you're going to practice loading data, manipulating it, preparing visualizations, and fitting it in the Spark MLlib framework. Let's get started!\u003c/p\u003e\n\n\u003ch3\u003eObjectives\u003c/h3\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad and manipulate data using Spark DataFrames \u003c/li\u003e\n\u003cli\u003eCreate a Spark ML pipeline that transforms data and runs over a grid of hyperparameters \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga40052b34f7e3efc7a91e89bac792750"},{"id":458237,"title":"Quiz: Big Data in PySpark","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"ge5f816d782a9139758688bf12fe92fc7","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"g9c577f9088ef666a272048004754cb3c"},{"id":458248,"title":"Short Video: sklearn to pyspark","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713814441?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-sklearn-to-pyspark"},{"id":458258,"title":"Building a Recommendation System in PySpark - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"als-recommender-system-pyspark-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/als-recommender-system-pyspark-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/als-recommender-system-pyspark-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we will implement a movie recommendation system using ALS in Spark programming environment. Spark's machine learning library \u003ccode\u003eml\u003c/code\u003e comes packaged with a very efficient implementation of the ALS algorithm that we looked at in the previous lesson. The lab will require you to put into practice your Spark programming skills for creating and manipulating PySpark DataFrames. We will go through a step-by-step process into developing a movie recommendation system using ALS and PySpark using the \u003ccode\u003eMovieLens\u003c/code\u003e dataset that we used in a previous lab.\u003c/p\u003e\n\n\u003cp\u003eNote: You are advised to refer to \u003ca href=\"http://spark.apache.org/docs/2.2.0/api/python/index.html\"\u003ePySpark documentation\u003c/a\u003e heavily for completing this lab as it will introduce a few new methods. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse Spark to train and cross-validate an ALS model \u003c/li\u003e\n\u003cli\u003eIntroduce a new user with rating to a rating matrix and make recommendations for them \u003c/li\u003e\n\u003cli\u003eCreate a function that will return the top n recommendations for a user \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g45c3dc138b3452c222b28c9ae7968aea"},{"id":458263,"title":"Big Data and (Py)Spark - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-pyspark-recap\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBig Data usually refers to datasets that grow so large that they become awkward to work with using traditional database management systems and analytical approaches\u003c/li\u003e\n\u003cli\u003eBig data refers to data that is terabytes (TB) to petabytes (PB) in size\u003c/li\u003e\n\u003cli\u003eMapReduce can be used to split big datasets up in smaller sets to be distributed over several machines to deal with Big Data Analytics \u003c/li\u003e\n\u003cli\u003ePySpark can be installed directly on your computer using \u003ccode\u003econda\u003c/code\u003e or in a Docker container\u003c/li\u003e\n\u003cli\u003eWhen you start working with PySpark, you have to create a \u003ccode\u003eSparkContext\u003c/code\u003e or \u003ccode\u003eSparkSession\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eThe creation or RDDs is essential when working with PySpark\u003c/li\u003e\n\u003cli\u003eExamples of actions and transformations include \u003ccode\u003ecollect()\u003c/code\u003e, \u003ccode\u003ecount()\u003c/code\u003e, \u003ccode\u003efilter()\u003c/code\u003e, \u003ccode\u003efirst()\u003c/code\u003e, \u003ccode\u003etake()\u003c/code\u003e, and \u003ccode\u003ereduce()\u003c/code\u003e \u003c/li\u003e\n\u003cli\u003eMachine Learning on the scale of big data can be done with Spark using the \u003ccode\u003eml\u003c/code\u003e library\u003c/li\u003e\n\u003c/ul\u003e","exportId":"big-data-and-py-spark-recap"}]},{"id":47097,"name":"Topic 37: Natural Language Processing","status":"started","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g42079c4ff48ac0dfe3c3fa1b40ffe628","items":[{"id":458282,"title":"Topic 37 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.7191%; height: 188px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNLP Pre-Processing\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Natural Language Processing - Introduction\" href=\"pages/natural-language-processing-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/natural-language-processing-introduction\" data-api-returntype=\"Page\"\u003eNatural Language Processing - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP and Word Vectorization\" href=\"pages/nlp-and-word-vectorization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/nlp-and-word-vectorization\" data-api-returntype=\"Page\"\u003eNLP and Word Vectorization\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Word Vectorization - Lab\" href=\"assignments/ga30aa82d071d72e9a33e2fe1c8b59f4a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187174\" data-api-returntype=\"Assignment\"\u003eWord Vectorization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to NLP with NLTK\" href=\"pages/introduction-to-nlp-with-nltk\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-nlp-with-nltk\" data-api-returntype=\"Page\"\u003eIntroduction to NLP with NLTK\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Introduction to Regular Expressions\" href=\"pages/introduction-to-regular-expressions\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-regular-expressions\" data-api-returntype=\"Page\"\u003eIntroduction to Regular Expressions\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Regular Expressions - Codealong\" href=\"assignments/g311caf2ef8d1c4fae0d9dd5602a56818\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187146\" data-api-returntype=\"Assignment\"\u003eRegular Expressions - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8934%; height: 160px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Pre-Processing\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eNLP Vectorization\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Short Video: The Bag of Words Model\" href=\"pages/short-video-the-bag-of-words-model\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-the-bag-of-words-model\" data-api-returntype=\"Page\"\u003eShort Video: The Bag of Words Model\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 37.9688%;\"\u003e\u003cstrong\u003e\u003ca title=\" NL Pre-Processing Exit Ticket\" href=\"quizzes/g00c1d4e4c62cb2f4bcc9a48df38ab1df\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30660\" data-api-returntype=\"Quiz\"\u003e NL Pre-Processing Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Feature Engineering for Text Data\" href=\"pages/feature-engineering-for-text-data\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/feature-engineering-for-text-data\" data-api-returntype=\"Page\"\u003e\u003cstrong\u003eFeature Engineering for Text Data\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Corpus Statistics - Lab\" href=\"assignments/g884dfd7a7c655abeb9864d3e0f37cb7a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187100\" data-api-returntype=\"Assignment\"\u003eCorpus Statistics - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Context-Free Grammars and POS Tagging\" href=\"pages/context-free-grammars-and-pos-tagging\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/context-free-grammars-and-pos-tagging\" data-api-returntype=\"Page\"\u003eContext-Free Grammars and POS Tagging\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Context-Free Grammars - Codealong\" href=\"assignments/g533c9d870df05d068e79cd3996c70b47\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187098\" data-api-returntype=\"Assignment\"\u003eContext-Free Grammars - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 105px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Vectorization\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eNLP Modeling\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Short Video: TF-IDF Vectorization\" href=\"pages/short-video-tf-idf-vectorization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-tf-idf-vectorization\" data-api-returntype=\"Page\"\u003eShort Video: TF-IDF Vectorization\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP Vectorization Exit Ticket\" href=\"quizzes/gc87c99b3ff83367c87ec87311d640eca\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30668\" data-api-returntype=\"Quiz\"\u003eNLP Vectorization Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Text Classification\" href=\"pages/text-classification\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/text-classification\" data-api-returntype=\"Page\"\u003eText Classification\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Natural Language Processing\" href=\"quizzes/ge4eb3dd722fcfcc80f1f9aa87b632443\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30666\" data-api-returntype=\"Quiz\"\u003eQuiz: Natural Language Processing\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 105px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Modeling\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP Modeling Exit Ticket\" href=\"quizzes/g272d6ccbdae72e63883d6986cb4fd1fa\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30680\" data-api-returntype=\"Quiz\"\u003eNLP Modeling Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"‚≠êÔ∏è Text Classification - Cumulative Lab\" href=\"quizzes/g11ad01bbe6f79a0e7287e5eb4163a824\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30667\" data-api-returntype=\"Quiz\"\u003e‚≠êÔ∏è Text Classification - Cumulative Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st*\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Natural Language Processing - Recap\" href=\"pages/natural-language-processing-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/natural-language-processing-recap\" data-api-returntype=\"Page\"\u003eNatural Language Processing - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e*Cumulative labs may be used for pairing exercises and might not be published yet; contact your instructor if you have questions\u003c/strong\u003e\u003c/p\u003e","exportId":"topic-37-lesson-priorities-live"},{"id":458288,"title":"Natural Language Processing - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson summarizes the topics we'll be covering in this section and why they'll be important to you as a data scientist.\u003c/p\u003e\n\n\u003ch2\u003eFoundations of Natural Language Processing (NLP)\u003c/h2\u003e\n\n\u003cp\u003eIn this section we will be covering Natural Language Processing (NLP), which refers to analytics tasks that deal with natural human language, in the form of text or speech.\u003c/p\u003e\n\n\u003ch3\u003eNatural Language Tool Kit (NLTK)\u003c/h3\u003e\n\n\u003cp\u003eWe'll start by providing more context on the Natural Language Tool Kit (NLTK), one of the most popular NLP libraries used in Python.  This library was developed by researchers at the University of Pennsylvania, and it has quickly become one of the most powerful and complete library of NLP tools available. \u003c/p\u003e\n\n\u003ch3\u003eRegular Expressions\u003c/h3\u003e\n\n\u003cp\u003eData preprocessing is an essential part of NLP, and that's why being very familiar with \u003cstrong\u003eregular expressions\u003c/strong\u003e is extremely important. Regular expressions, or \"Regex\" is extremely useful for NLP. We can use regex to quickly pattern match and filter through text documents. \u003c/p\u003e\n\n\u003ch3\u003eFeature Engineering for Text Data\u003c/h3\u003e\n\n\u003cp\u003eWorking with text data comes with a lot of ambiguity. Feature engineering for NLP is pretty specific, and in this section you'll learn some feature engineering techniques that are essential when working with text data. You'll learn how to remove stop words from your text, as well as how to create frequency distributions, representing histograms that give us an overview of the total number of times each word occurs in a given text corpus. \u003c/p\u003e\n\n\u003cp\u003eAdditionally, you'll learn about stemming and lemmatization, which is the technique of removing suffixes from our words (and can enhance our text insight by creating frequency histograms \u003cem\u003eafter\u003c/em\u003e having performed stemming or lemmatization!). You'll also learn how to create bigrams, which creates an insight on how often two words occur together!\u003c/p\u003e\n\n\u003ch3\u003eContext-Free Grammars and Part-of-Speech (POS) Tagging\u003c/h3\u003e\n\n\u003cp\u003eIn NLP, it is important to understand what context-free grammars and part-of-speech tagging are. Context-free grammars refer to bits of text that are grammatically correct, but feel like complete nonsense when considering the same bit of text on the semantic level. POS tagging refers to the act of helping a computer understand how to interpret a sentence. The context-free grammars (CFG) defines the rules of how sentences can exist. You'll see multiple examples on how to use both CFG and POS tagging, and why they are important!\u003c/p\u003e\n\n\u003ch3\u003eText Classification\u003c/h3\u003e\n\n\u003cp\u003eWe will finish off this section by explaining the general process to set text data up for classification problems.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the foundations of NLP and different techniques to make a computer understand text!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-nlp-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-nlp-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"natural-language-processing-introduction"},{"id":458292,"title":"NLP and Word Vectorization","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-nlp-and-word-vectorization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-and-word-vectorization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-and-word-vectorization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about some foundational concepts in Natural Language Processing such as stemming and lemmatization, as well as various strategies for converting text data into word vectors!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain stemming and lemmatization\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eExplain what stop words are and why they are frequently removed \u003c/li\u003e\n\u003cli\u003eDefine tokenization in the context of NLP \u003c/li\u003e\n\u003cli\u003eDefine TF-IDF vectorization and its components \u003c/li\u003e\n\u003cli\u003eDefine count vectorization and its relationship to bag of words \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Natural Language Processing?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eNatural Language Processing\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eNLP\u003c/em\u003e\u003c/strong\u003e, is the study of how computers can interact with humans through the use of human language.  Although this is a field that is quite important to Data Scientists, it does not belong to Data Science alone.  NLP has been around for quite a while, and sits at the intersection of \u003cem\u003eComputer Science\u003c/em\u003e, \u003cem\u003eArtificial Intelligence\u003c/em\u003e, \u003cem\u003eLinguistics\u003c/em\u003e, and \u003cem\u003eInformation Theory\u003c/em\u003e. In the early days of NLP, it mainly consisted of trying to program algorithms that contained many rules borrowed from the field of linguistics. However, in the 1980s, machine learning started to show great success with many NLP tasks, and many of these rule-based methods took a back seat to approaches involving machine learning and AI. Fast forward to now, and NLP has become an area of applied machine learning that Data Scientists all around the globe work in every day. \u003c/p\u003e\n\n\u003ch2\u003eNLP and Bayesian Statistics\u003c/h2\u003e\n\n\u003cp\u003eAs machine learning has come into its own, we've seen NLP products get better and better.  For instance, in just a few decades, we've gone from rule-based chat bots with preprogrammed responses to things like Siri and \u003ca href=\"https://www.youtube.com/watch?v=D5VN56jQMWM\"\u003eGoogle Duplex\u003c/a\u003e (if you aren't familiar with Duplex, take a few minutes to follow that link and watch the demo on YouTube -- you won't be disappointed!). Much of the most exciting advancements currently happening in the field of NLP are due to Deep Learning.  However, we can still do amazing things with machine learning and text data by making use of Bayesian methods. For instance, you may remember a time in the early 2000s when the problem of email spam was bad, and getting worse.  This problem was eventually solved through the application of machine learning -- specifically, \u003cstrong\u003e\u003cem\u003eNaive Bayesian Classification\u003c/em\u003e\u003c/strong\u003e!  For the remainder of this section, we'll focus on how we can apply our newfound knowledge of Bayesian methods to solve real-world NLP tasks such as \u003ca href=\"http://www.paulgraham.com/spam.html\"\u003espam filtering\u003c/a\u003e and text classification. \u003c/p\u003e\n\n\u003ch2\u003eWorking With Text Data\u003c/h2\u003e\n\n\u003cp\u003eWorking with text data comes with a unique set of problems and solutions that other types of datasets don't have.  Often, text data requires more cleaning and preprocessing than normal data, in order to get it into a format where we can use statistical methods or machine learning to work with it. Let's explore some of the things we generally need to do to get text data into a form where we can work with it. \u003c/p\u003e\n\n\u003ch2\u003eCreating a  Bag of Words\u003c/h2\u003e\n\n\u003cp\u003eThe most common approach to working with text is to vectorize it by creating a \u003cstrong\u003e\u003cem\u003eBag of Words\u003c/em\u003e\u003c/strong\u003e.  In this case, the name \"Bag of Words\" is quite descriptive of the final product -- the bag contains information about all the important words in the text individually, but not in any particular order. It's as if we take every word in a \u003cstrong\u003e\u003cem\u003eCorpus\u003c/em\u003e\u003c/strong\u003e and throw them into a bag. With a large enough corpus, we'll often see certain patterns start to emerge -- for instance, a bag of words made out of Shakespeare's \u003cem\u003eHamlet\u003c/em\u003e is probably more similar to a bag of words made out of \u003cem\u003eMacbeth\u003c/em\u003e than it is to something like \u003cem\u003eThe Hunger Games\u003c/em\u003e. The simplest way to create a bag of words is to just count how many times each unique word is used in a given corpus. If we have a number for every word, then we have a way to treat each bag as a \u003cstrong\u003e\u003cem\u003evector\u003c/em\u003e\u003c/strong\u003e, which opens up all kinds of machine learning tools for use.  \u003c/p\u003e\n\n\u003cp\u003eLet's explore some of the steps that must occur before we can fully vectorize a text and work with it.\u003c/p\u003e\n\n\u003ch3\u003eBasic Cleaning and Tokenization\u003c/h3\u003e\n\n\u003cp\u003eOne of the most basic problems seen when working with text data is things like punctuation and capitalization.  Although counting how many times a word appears in a text sounds straightforward at first, it can actually be quite complicated at times, and will almost always require some decisions on our part. For instance, consider the following sentence:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"Apple shareholders have had a great year. Apple's stock price has gone steadily upwards -- Apple even broke a trillion-dollar valuation, continuing the dominance of this tech stock.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIf we were to count how many times each word appears in this sentence, we would likely say that \"Apple\" has a count of three.  However, if we wrote a basic Python script to do this, our algorithm would tell us that the word \"Apple\" only appears twice! To a computer, \"Apple\" and \"Apple's\" are different words.  Capitalization is also a problem -- \"apple\" would also be counted as a different word. Similarly, punctuation is also a problem.  A basic counting algorithm would see \"stock\" and \"stock.\" as two completely different words. \u003c/p\u003e\n\n\u003cp\u003eFirst and foremost, cleaning a text dataset usually means removing punctuation, and lowercasing everything. However, this can be tricky, and require decisions on your part based on the text you're working with and your goals -- for instance, whether or not apostrophes should be removed. \u003c/p\u003e\n\n\u003cp\u003eThe goal of this step is to create word \u003cstrong\u003e\u003cem\u003etokens\u003c/em\u003e\u003c/strong\u003e. The sentence \"Where did you get those coconuts?\", when cleaned and tokenized, would probably look more like \u003ccode\u003e['where', 'did', 'you, 'get', 'those', 'coconuts']\u003c/code\u003e. \u003c/p\u003e\n\n\u003cp\u003eHowever, there are still other important decisions to make during the tokenization stage. For instance, should \"run\" and \"runs\" be counted as the same token, or as different tokens? How about \"ran\", or \"running\"?  \u003c/p\u003e\n\n\u003ch3\u003eStemming, Lemmatization, and Stop Words\u003c/h3\u003e\n\n\u003cp\u003eSometimes, depending on the task, it may be best to leave \"run\" and \"runs\" as different tokens.  However, this often is not the case -- especially with smaller datasets.  NLP methods such as \u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e help us deal with this problem, where we reduce each word token down to its root word.  For cases such as \"run\", \"runs\", \"running\" and \"ran\", they are more similar than different -- we may want our algorithm to treat these as the same word, \"run\".  \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e accomplishes this by removing the ends of words where the end signals some sort of derivational change to the word. For instance, we know that adding an 's' to the end of a word makes it plural -- a stemming algorithm given the word \"cats\" would return \"cat\".  Note that stems do not have to make sense as actual English words. For example, \"ponies\" would be reduced to \"poni\", not \"pony\". Stemming is a more crude, heuristic process that contains rule sets that tells the algorithm how to stem each word, and what it should be stemmed to. The process is more crude than lemmatization, but it's also easier to implement. For instance, take a look at this example subset of stemming rules from the \u003ca href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\"\u003eStanford NLP Group\u003c/a\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-nlp-and-word-vectorization/master/images/new_stemming.png\" alt=\"stemming rules and examples\" width=\"400\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e accomplishes pretty much the same thing as stemming, but does it in a more complex way, by examining the \u003cstrong\u003e\u003cem\u003emorphology\u003c/em\u003e\u003c/strong\u003e of words and attempting to reduce each word to its most basic form, or \u003cstrong\u003e\u003cem\u003elemma\u003c/em\u003e\u003c/strong\u003e.  Note that the results here often end up a bit different than stemming.  See the following table for an example of the differences in results:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: center\"\u003eWord\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eStem\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eLemma\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003eStudies\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudi\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003eStudying\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eFinally, you may have intuited that many words in a text are pretty much useless and contain little to no actual information. For instance, words such as \"the\" and \"of\".  These are called \u003cstrong\u003e\u003cem\u003eStop Words\u003c/em\u003e\u003c/strong\u003e, and are often removed after tokenization is complete in order to reduce the dimensionality of each corpus down to only the words that contain important information. Popular NLP frameworks and toolkits such as NLTK contain a list of stop words for most languages, which allow us to easily loop through our tokenized corpus and remove any stop words we find. \u003c/p\u003e\n\n\u003ch2\u003eVectorization Strategies\u003c/h2\u003e\n\n\u003cp\u003eOnce we cleaned and tokenized our text data, we can convert it to vectors. However, there are a few different ways we can do this. Depending on our goals and our dataset, some may be more useful than others. \u003c/p\u003e\n\n\u003ch3\u003eCount Vectorization\u003c/h3\u003e\n\n\u003cp\u003eOne of the most basic, but useful ways of vectorizing text data is to simply count the number of times each word appears in the corpus. If working with a single document, we just create a single vector, where each element in the vector corresponds to the count of a unique word in the document. If working with multiple documents, we would store everything in a DataFrame, with each column representing a unique word, while each row represents the count vector for a given document. \u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: center\"\u003eDocument\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eAardvark\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eApple\u003c/th\u003e\n\u003cth\u003e...\u003c/th\u003e\n\u003cth\u003eZebra\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e3\u003c/td\u003e\n\u003ctd\u003e...\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003e2\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e2\u003c/td\u003e\n\u003ctd\u003e...\u003c/td\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eNote that we do not need to have a column for every word in the English language -- just a column for each word that shows up in the total vocabulary of our document or documents. If we have multiple documents, we just combine the unique words from each document to get the total dimensionality that allows us to represent each. If a word doesn't show up in a given document, that's fine -- that just means the count is 0 for that row and column. \u003c/p\u003e\n\n\u003ch3\u003eTF-IDF Vectorization\u003c/h3\u003e\n\n\u003cp\u003eTF-IDF stands for \u003cstrong\u003e\u003cem\u003eTerm Frequency-Inverse Document Frequency\u003c/em\u003e\u003c/strong\u003e. It is a combination of two individual metrics, which are the TF and IDF, respectively. TF-IDF is used when we have multiple documents. It is based on the idea that rare words contain more information about the content of a document than words that are used many times throughout all the documents. For instance, if we treated every article in a newspaper as a separate document, looking at the amount of times the word \"he\" or \"she\" is used probably doesn't tell us much about what that given article is about -- however, the amount of times \"touchdown\" is used can provide good signal that the article is probably about sports.  \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTerm Frequency\u003c/em\u003e\u003c/strong\u003e is calculated with the following formula:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Term\\ Frequency(t) = \\frac{number\\ of\\ times\\ t\\ appears\\ in\\ a\\ document} {total\\ number\\ of\\ terms\\ in\\ the\\ document} \" src=\"/equation_images/%255Clarge%20Term%255C%20Frequency(t)%20=%20%255Cfrac{number%255C%20of%255C%20times%255C%20t%255C%20appears%255C%20in%255C%20a%255C%20document}%20{total%255C%20number%255C%20of%255C%20terms%255C%20in%255C%20the%255C%20document}\" alt=\"{\" data-equation-content=\"\\large Term\\ Frequency(t) = \\frac{number\\ of\\ times\\ t\\ appears\\ in\\ a\\ document} {total\\ number\\ of\\ terms\\ in\\ the\\ document} \"\u003e\u003c/p\u003e \u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eInverse Document Frequency\u003c/em\u003e\u003c/strong\u003e is calculated with the following formula:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large IDF(t) = log_e(\\frac{Total\\ Number\\ of\\ Documents}{Number\\ of\\ Documents\\ with\\ t\\ in\\ it})\" src=\"/equation_images/%255Clarge%20IDF(t)%20=%20log_e(%255Cfrac{Total%255C%20Number%255C%20of%255C%20Documents}{Number%255C%20of%255C%20Documents%255C%20with%255C%20t%255C%20in%255C%20it})\" alt=\"{\" data-equation-content=\"\\large IDF(t) = log_e(\\frac{Total\\ Number\\ of\\ Documents}{Number\\ of\\ Documents\\ with\\ t\\ in\\ it})\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThe \u003cstrong\u003e\u003cem\u003eTF-IDF\u003c/em\u003e\u003c/strong\u003e value for a given word in a given document is just found by multiplying the two!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about some foundational concepts in Natural Language Processing such as stemming and lemmatization, as well as various strategies for converting text data into word vectors.\u003c/p\u003e","exportId":"nlp-and-word-vectorization"},{"id":458296,"title":"Word Vectorization - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-word-vectorization-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-vectorization-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-vectorization-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll tokenize and vectorize text documents, create and use a bag of words, and identify words unique to individual documents using TF-IDF vectorization. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:  \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement tokenization and count vectorization from scratch \u003c/li\u003e\n\u003cli\u003eImplement TF-IDF from scratch \u003c/li\u003e\n\u003cli\u003eUse dimensionality reduction on vectorized text data to create and interpret visualizations \u003c/li\u003e\n\u003c/ul\u003e","exportId":"ga30aa82d071d72e9a33e2fe1c8b59f4a"},{"id":458300,"title":"Introduction to NLP with NLTK","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll discuss a general overview of Natural Language Processing, and the popular Python library for NLP, \u003cstrong\u003e\u003cem\u003eNatural Language Tool Kit\u003c/em\u003e\u003c/strong\u003e (NLTK).\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify ways we can use NLTK to simplify and accelerate common preprocessing tasks for text data\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Natural Language Processing?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eNatural Language Processing\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eNLP\u003c/em\u003e\u003c/strong\u003e, refers to analytics tasks that deal with natural human language, in the form of text or speech. These tasks usually involve some sort of machine learning, whether for text classification or for feature generation, but NLP isn't just machine learning. Tasks such as text preprocessing and cleaning also fall under the NLP umbrella. \u003c/p\u003e\n\n\u003cp\u003eThe most common Python library used for NLP tasks is \u003cstrong\u003e\u003cem\u003eNatural Language Tool Kit\u003c/em\u003e\u003c/strong\u003e, or NLTK for short. This library was developed by researchers at the University of Pennsylvania, and quickly became the most powerful and complete library of NLP tools available. \u003c/p\u003e\n\n\u003ch2\u003eUsing NLTK\u003c/h2\u003e\n\n\u003cp\u003eNLTK is a sort of \"one-stop shop\" for all things NLP. It contains many sample corpora, with everything from full texts from Project Gutenberg to transcripts of State of the Union speeches from US Presidents. This library contains functions and tools for everything from data cleaning and preprocessing, to linguistic analysis, to feature generation and extraction. NLTK even contains its own Bayesian classifiers for quick testing (although realistically, you'll likely want to continue using scikit-learn for these sorts of tasks). \u003c/p\u003e\n\n\u003cp\u003eNLP is unique in that in addition to statistics and math, it also relies heavily on the field of \u003cstrong\u003e\u003cem\u003eLingustics\u003c/em\u003e\u003c/strong\u003e. Many of the concepts you'll run into will be grounded in linguistics. Some of them will seem a bit foreign to you if you haven't studied languages or grammar yet, but don't worry! The reality of it all is that you don't need deep expertise in linguistics to work with text data, because NLTK was built by professionals to make it easier for everyone to access the linguistic tools and methods needed for working with text data. Although a linguist knows how to manually generate something like a \u003cstrong\u003e\u003cem\u003eParse Tree\u003c/em\u003e\u003c/strong\u003e for a sentence, NLTK provides this functionality for you in just a few lines of code. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eA sample Parse Tree created with NLTK\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-nltk/master/images/new_parse_tree.png\" width=\"750\"\u003e \n\n\u003ch2\u003eWorking With Text, Simplified\u003c/h2\u003e\n\n\u003cp\u003eGenerally, projects that work with text data follow the same overall pattern as any other projects. The main difference is that text projects usually require a bit more cleaning and preprocessing than regular data, in order to get the text into a format that's usable for modeling. \u003c/p\u003e\n\n\u003cp\u003eHere are some of the ways that NLTK can make our lives easier when working with text data:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStop Word Removal\u003c/em\u003e\u003c/strong\u003e: NLTK contains a full library of stop words, making it easy to remove the words that don't matter from our data.    \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eFiltering and Cleaning\u003c/em\u003e\u003c/strong\u003e: NLTK provides simple, easy ways to create and filter frequency distributions, as well providing multiple ways to clean, stem, lemmatize, or tokenize datasets.   \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eFeature Selection and Feature Engineering\u003c/em\u003e\u003c/strong\u003e: NLTK contains tools to quickly generate features such as bigrams and n-grams. It also contains major libraries such as the \u003cstrong\u003e\u003cem\u003ePenn Tree Bank\u003c/em\u003e\u003c/strong\u003e to allow quick feature engineering, such as generating part-of-speech tags, or sentence polarity. \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAgain, don't worry if you're not sure what things like 'lemmatize' mean yet -- we'll cover all of that soon! With effective use of NLTK, we can quickly process and work with text data, allowing us to quickly get our data into the shape needed for tasks we're familiar with, such as classification!\u003c/p\u003e\n\n\u003cp\u003eFor the remainder of this section, we're going to spend some time getting comfortable with NLTK, while also learning about foundational concepts of linguistics that underpin many of the tasks in NLP. We'll learn to effectively use NLTK to clean and preprocess data in a variety of ways. We'll gain some practice filtering data with regular expressions, generate text statistics to compare text documents, and quickly engineer features to help us better train classifiers for text classification!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about what NLP is, and how the NLTK package can save us time and make us more effective when working with text data. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-introduction-to-nltk\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-introduction-to-nltk\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"introduction-to-nlp-with-nltk"},{"id":458304,"title":"Introduction to Regular Expressions","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-regular-expressions\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-regular-expressions\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-regular-expressions/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about how we can use \u003cstrong\u003e\u003cem\u003eRegular Expressions\u003c/em\u003e\u003c/strong\u003e for pattern matching and filtering when working with text data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify common use cases where regular expressions are useful \u003c/li\u003e\n\u003cli\u003eCreate regex code to capture meaningful patterns found in text \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat Are Regular Expressions?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRegular Expressions\u003c/em\u003e\u003c/strong\u003e are a type of pattern that describe some text. We can use these regular expressions to quickly match patterns and filter through text documents. Regular Expressions (or regex, for short) are an important tool anytime we need to pull information from a larger text document without manually reading the entire thing. For data scientists, regex is extremely useful for data gathering. With regex, we can quickly scrape webpages by using regex to search through the html and find the info needed. \u003c/p\u003e\n\n\u003ch3\u003eUse Cases for NLP\u003c/h3\u003e\n\n\u003cp\u003eRegex is especially useful for Natural Language Processing. By definition, just about any text document you work with on an NLP task is going to be one that contains a large amount of text. One of the more common NLP-specific use cases for regex is to use regex during the tokenization stage to define the rules for where we should split strings into separate tokens. As an example, NLTK's basic \u003ccode\u003eword_tokenize()\u003c/code\u003e function would split a word that contains an apostrophe into 3 separate tokens -- \u003ccode\u003e'they're'\u003c/code\u003e gets broken into \u003ccode\u003e[\"they\", \"'\", \"re\"]\u003c/code\u003e. This is because the word tokenizer has instructions to just grab sequences of letters as the basic tokens, and an apostrophe isn't a letter. When preprocessing text data, it's quite common to use some small regex patterns to create a more intelligent tokenization scheme to avoid problems like this, so that our tokenizer treats words like \u003ccode\u003e'they're'\u003c/code\u003e as a single token. \u003c/p\u003e\n\n\u003ch2\u003eCreating Basic Patterns\u003c/h2\u003e\n\n\u003cp\u003eRegex is only as good as the \u003cstrong\u003e\u003cem\u003ePatterns\u003c/em\u003e\u003c/strong\u003e we create. We can use these patterns to find, or to replace text. There are many, many things we can do with regex, and covering them all is outside the scope of this lesson. Instead, we'll just focus on some of the more useful, basic patterns that allow us to begin using regex to work with text data. \u003c/p\u003e\n\n\u003cp\u003eLet's take a look at a basic regex pattern, to get a feel for what they look like. \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ere\u003c/span\u003e\n\u003cspan class=\"n\"\u003esentence\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'he said that she said \"hello\".'\u003c/span\u003e\n\u003cspan class=\"n\"\u003epattern\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'he'\u003c/span\u003e\n\u003cspan class=\"n\"\u003ep\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ere\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nb\"\u003ecompile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esentence\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ep\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efindall\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"c1\"\u003e# Output will be ['he', 'he, 'he']\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe define a pattern by a Python string. We can then use the regular expressions library, \u003ccode\u003ere\u003c/code\u003e, to compile this pattern. Once we have a compiled pattern, we just need to pass in a string and the pattern will find every instance of that pattern in the string. \u003c/p\u003e\n\n\u003cp\u003eFor people new to regex, the results from the pattern above might be surprising at first. The pattern successfully matches the word 'he', but it also matches the letters 'he' that are found inside of the words 'she' and 'hello'.  Subsequences inside of larger sequences are fair game to regex. If we just wanted to match the word 'he', we would need to specify that the pattern needs to start and end with a space, or use of \u003cstrong\u003e\u003cem\u003eanchors\u003c/em\u003e\u003c/strong\u003e for things like word boundaries. \u003c/p\u003e\n\n\u003ch2\u003eRanges, Groups, and Quantifiers\u003c/h2\u003e\n\n\u003cp\u003eObviously, we don't want to have to explicitly type every valid match for any search into our pattern. That would defeat the purpose. Luckily, we don't have to type every possible uppercase letter to match on uppercase letters. Instead, we can use a \u003cstrong\u003e\u003cem\u003eRange\u003c/em\u003e\u003c/strong\u003e such as \u003ccode\u003e[A-Z]\u003c/code\u003e. This will match any uppercase letter. Ranges are always inside of square brackets. We can put many things inside of ranges at the same time, and regex will match on any of them. For instance, if we wanted to find any uppercase letter, lowercase letter, or digit, we could use \u003ccode\u003e[A-Za-z0-9]\u003c/code\u003e. \u003c/p\u003e\n\n\u003ch3\u003eCharacter Classes\u003c/h3\u003e\n\n\u003cp\u003eCharacter classes are a special case of ranges. Since it's quite a common task to use ranges to do things like match on words or numbers, regex actually includes character classes as a shortcut. For instance, we could use \u003ccode\u003e\\d\u003c/code\u003e to match any digit -- this is equivalent to using \u003ccode\u003e[0-9]\u003c/code\u003e. We could also use \u003ccode\u003e\\w\u003c/code\u003e to match on any word. In the same vein, we can use \u003ccode\u003e\\D\u003c/code\u003e to get anything that \u003cem\u003eisn't\u003c/em\u003e a digit, or \u003ccode\u003e\\W\u003c/code\u003e to match on everything that isn't a word. There are a few other types of character classes as well. For a full list, check out the cheat sheet below!\u003c/p\u003e\n\n\u003ch3\u003eGroups and Quantifiers\u003c/h3\u003e\n\n\u003cp\u003eGroups are kind of like ranges, but they specify an exact pattern to match on. Groups are denoted by parentheses. Whereas \u003ccode\u003e[A-Z0-9]\u003c/code\u003e matches on any uppercase letter or any digit, \u003ccode\u003e(A-Z0-9)\u003c/code\u003e will only match on the sequence \u003ccode\u003e'A-Z0-9'\u003c/code\u003e exactly. This becomes much more useful when paired with \u003cstrong\u003e\u003cem\u003eQuantifiers\u003c/em\u003e\u003c/strong\u003e, which allows us to specify how many times a group should happen in a row. If we want to specify an exact number of times, we can use curly braces. For instance, a group followed by \u003ccode\u003e{3}\u003c/code\u003e will only match on patterns that have that group repeated exactly 3 times. The most common quantifiers are usually:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e*\u003c/code\u003e (0 or more times)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e+\u003c/code\u003e (1 or more times)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e?\u003c/code\u003e (0 or 1 times)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn this way, we can fill a grouping with any pattern, tell and specify the number of times we can expect to see that pattern. When we include things like ranges, groupings, and quantifiers together, it becomes easy to write a pattern that can match complex things, like email addresses -- take a look at the example provided below, and see if you can figure out how it works!\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e'([A-Za-z]+)@([A-Za-z]+)\\.com'\u003c/code\u003e \u003c/p\u003e\n\n\u003cp\u003eThis pattern matches basic email addresses like '\u003ca href=\"mailto:joe@gmail.com\"\u003ejoe@gmail.com\u003c/a\u003e', but not '\u003ca href=\"mailto:john.doe@gmail.com\"\u003ejohn.doe@gmail.com\u003c/a\u003e', or '\u003ca href=\"mailto:joe@stanford.edu\"\u003ejoe@stanford.edu\u003c/a\u003e'. Take a look at the pattern again -- how would you need to modify the pattern in order for it to match either of those, as well?\u003c/p\u003e\n\n\u003ch2\u003eAlways Keep A Cheat Sheet Handy\u003c/h2\u003e\n\n\u003cp\u003eRegex is confusing, but it gets easier. With that being said, don't worry about trying to memorize all of the different symbols and metacharacters. Instead, focus on how patterns work, and just look up the symbols when you need them. The internet is filled with great regex cheatsheets. Here's an easy one to keep on hand for future reference:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-regular-expressions/master/images/regex_cheat_sheet.png\" alt=\"regex cheat sheet\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about what regular expressions are, how they are used in NLP for specific tasks, and some common patterns and tools in regex. \u003c/p\u003e","exportId":"introduction-to-regular-expressions"},{"id":458309,"title":"Regular Expressions - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-regular-expressions-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-regular-expressions-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-regular-expressions-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll make use of some common regex patterns to search through text. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCreate regex code to capture meaningful patterns found in text \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g311caf2ef8d1c4fae0d9dd5602a56818"},{"id":458319,"title":"Short Video: The Bag of Words Model","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713814376?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-the-bag-of-words-model"},{"id":458326,"title":"Feature Engineering for Text Data","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-feature-engineering-for-text-data\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-feature-engineering-for-text-data\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-feature-engineering-for-text-data/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll examine some common approaches to feature engineering for text data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what stop words are and why they are frequently removed \u003c/li\u003e\n\u003cli\u003eExplain stemming and lemmatization\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eDefine bigrams and n-grams \u003c/li\u003e\n\u003cli\u003eDefine mutual information in the context of NLP \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCommon Approaches to NLP Feature Engineering\u003c/h2\u003e\n\n\u003cp\u003eAs you've likely noticed by now, working with text data comes with \u003cstrong\u003e\u003cem\u003ea lot\u003c/em\u003e\u003c/strong\u003e of ambiguity. When all we start with is an arbitrarily-sized string of words, there's no clear answer as to what sorts of features we should engineer, or even where we should start! The goal of this lesson is to provide a framework for working with text data, and help us figure out exactly what sorts of features we should create when working with text data. \u003c/p\u003e\n\n\u003cp\u003eIn this lesson, we'll focus on the following topics:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStopword Removal\u003c/li\u003e\n\u003cli\u003eFrequency Distributions\u003c/li\u003e\n\u003cli\u003eStemming and Lemmatization\u003c/li\u003e\n\u003cli\u003eBigrams, N-grams, and Mutual Information Score\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRemoving Stop Words\u003c/h2\u003e\n\n\u003cp\u003eWhen working with text data, one of the first steps to try is to remove the \u003cstrong\u003e\u003cem\u003eStop Words\u003c/em\u003e\u003c/strong\u003e from the text. One common feature of text data (regardless of language!) is the inclusion of stop words for grammatical structure. Words such as \"a\", \"and\", \"but\", and \"or\" are examples of stop words. While a sentence would be both grammatically incorrect and hard to understand without them, from a modeling standpoint, stop words provide little to no actual value. If we create a \u003cstrong\u003e\u003cem\u003eFrequency Distribution\u003c/em\u003e\u003c/strong\u003e to see the number of times each word is used in a corpus, we'll almost always find that the top spots are dominated by stop words, which tell us nothing about the actual content of the corpus. Removing stop words allows us to reduce the overall dimensionality of our dataset (which is always a good thing), while also distilling the overall vocabulary of our bag-of-words down only to the words that really matter. \u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eNLTK\u003c/em\u003e makes it extremely easy to remove stopwords. The library includes a full corpus of all stopwords for all the languages NLTK supports. Since we usually only want the stopwords relevant to the language our text data is in, NLTK even makes it easy to filter out the unneeded stop words and grab only the ones that pertain to our problem. \u003c/p\u003e\n\n\u003cp\u003eThe following example shows how we can get all the stopwords for English from NLTK:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk.corpus\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003estring\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Get all the stop words in the English language\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewords\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'english'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# It is generally a good idea to also remove punctuation\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Now we have a list that includes all english stopwords, as well as all punctuation\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epunctuation\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce we have a list of stopwords, we can easily remove them from our text data after we've tokenized our data. Recall that we can easily tokenize text data using NLTK's \u003ccode\u003eword_tokenize()\u003c/code\u003e function. Once we have a list of word tokens, all we need to do is use a list comprehension, and omit any tokens that can be found in our stopwords list.  For example:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eword_tokenize\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eword_tokenize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_text_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# It is usually a good idea to lowercase all tokens during this step, as well\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopped_tokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ew\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elower\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ew\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003etokens\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ew\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eFrequency Distributions\u003c/h2\u003e\n\n\u003cp\u003eOnce we have tokenized our data and removed all the stop words, the next step is usually to explore our text data through a \u003cstrong\u003e\u003cem\u003eFrequency Distribution\u003c/em\u003e\u003c/strong\u003e. This is just a fancy way of saying that we create a histogram that tells us the total number of times each word is used in a given corpus. \u003c/p\u003e\n\n\u003cp\u003eOnce we have tokenized our text data, we can use NLTK to easily create a frequency distribution using \u003ccode\u003enltk.FreqDist()\u003c/code\u003e. A frequency distribution is analogous to a Python dictionary, with a few more bells and whistles attached to make it easier to use for NLP tasks. Each key is a word token, and each value is the corresponding number of times that token appeared in the tokenized corpus given to the \u003ccode\u003eFreqDist\u003c/code\u003e object at instantiation. \u003c/p\u003e\n\n\u003cp\u003eWe can easily filter a \u003ccode\u003eFreqDist()\u003c/code\u003e object to see the most common words by using the \u003ccode\u003e.most_common()\u003c/code\u003e built-in method, as seen below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e  \u003cspan class=\"nn\"\u003enltk\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFreqDist\u003c/span\u003e\n\u003cspan class=\"n\"\u003efreqdist\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFreqDist\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etokens\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# get the 200 most common words \n\u003c/span\u003e\u003cspan class=\"n\"\u003emost_common\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efreqdist\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emost_common\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce we have the most common words, we can easily use this to filter out the text and reduce the dimensionality of particularly large datasets, as needed. \u003c/p\u003e\n\n\u003ch2\u003eStemming and Lemmatization\u003c/h2\u003e\n\n\u003cp\u003eConsider the words 'run', 'running', 'ran', and 'runs'. If we create a basic frequency distribution, each of these words will be treated as a separate token. After all, they are different words. However, we know that they pretty much mean the same thing. Counting these words as individual separate tokens can sometimes hurt our model by needlessly increasing dimensionality, and hiding important information from our model. Although we instinctively know that those four words are all talking about the same action, our model will default to thinking that they are four completely different concepts. The way we deal with this is to remove suffixes through techniques such as \u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003ePeople often get stemming and lemmatization confused, because they are extremely similar. They generally accomplish the same task, but they use different means to do so. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e follows a predetermined set of rules to reduce a word to its \u003cem\u003estem\u003c/em\u003e.  Words like 'running' and 'runs' will be reduced down to 'run', because the stemmer contains rules that understands how to deal with suffixes such as '-ing' and '-s'. The best stemmer currently available is the \u003cstrong\u003e\u003cem\u003ePorter Stemmer\u003c/em\u003e\u003c/strong\u003e. For code samples demonstrating how to use it, check out NLTK's documentation for the \u003ca href=\"http://www.nltk.org/howto/stem.html\"\u003ePorter Stemmer\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e differs from stemming in that it reduces each word down to a linguistically valid \u003cstrong\u003e\u003cem\u003elemma\u003c/em\u003e\u003c/strong\u003e, or root word. It does this through stored linguistic mappings. Lemmatization is generally more complex, but also more accurate. This is because the rules that guide things like the Porter Stemmer are good, but far from perfect. For example, stemmers commonly deal with the suffix \u003ccode\u003e-ed\u003c/code\u003e by just  dropping it from the word. This usually works, until it runs into an edge case like the word 'agreed'. When stemmed, 'agreed' becomes 'agre'. Lemmatization does not make this mistake, because it contains a mapping for the word that tells it what 'agreed' should be reduced down to. Generally, most lemmatizers make use of the famous \u003cstrong\u003e\u003cem\u003eWordNet\u003c/em\u003e\u003c/strong\u003e lexical database. \u003c/p\u003e\n\n\u003cp\u003eNLTK makes it quite easy to make use of lemmatization, as demonstrated below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk.stem.wordnet\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eWordNetLemmatizer\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eWordNetLemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'feet'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# foot\n\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'running'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# run\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eBigrams and Mutual Information Score\u003c/h2\u003e\n\n\u003cp\u003eAnother alternative to tokenization is to instead create \u003cstrong\u003e\u003cem\u003eBigrams\u003c/em\u003e\u003c/strong\u003e out of the text. A bigram is just a pair of adjacent words, treated as a single unit. \u003c/p\u003e\n\n\u003cp\u003eConsider the sentence \"the dog played outside\". If we created bigrams out of this sentence, we would get \u003ccode\u003e('the', 'dog'), ('dog', 'played'), ('played', 'outside')\u003c/code\u003e. From a modeling perspective, this can be quite useful, because sometimes pairs of words are greater than the sum of their parts. Note that bigrams are just a special case of \u003cstrong\u003e\u003cem\u003en-grams\u003c/em\u003e\u003c/strong\u003e -- we can choose any number of words for a sequence. Alternatively, it's quite common to create n-grams at the character level, rather than the word level. \u003c/p\u003e\n\n\u003cp\u003eOne handy feature of bigrams is that we can apply a frequency filter to only keep bigrams that show up more than a set number of times. In this way, we can get rid of all bigrams that only occur because of random chance, and keep the bigrams that must mean something, because they occur together multiple times. How strict your frequency filter should be depends on a number of factors, and generally, it's something you'll have to experiment with to get right. However, most experts tend to apply a minimum frequency filter of 5. \u003c/p\u003e\n\n\u003cp\u003eAnother way we can make use of bigrams is to calculate their \u003cstrong\u003e\u003cem\u003ePointwise Mutual Information Score\u003c/em\u003e\u003c/strong\u003e. This is a statistical measure from information theory that generally measures the mutual dependence between two words. In plain english, this measures how much information the bigram itself contains by computing the dependence between the two words in the bigram. For instance, the bigram \u003ccode\u003e('San', 'Francisco')\u003c/code\u003e would likely have a high mutual information score, because when these tokens appear in the text, it is highly likely that they appear together, and unlikely that they appear next other words. \u003c/p\u003e\n\n\u003cp\u003eIn practice, you don't need to worry too much about how to calculate mutual information, because NLTK provides an easy way to do this for us. We'll explore this in detail in the next lab. Instead, your main takeaway on this topic should be that mutual information scores are a type of feature that you can engineer for text data that may provide good information for you when it comes to exploring the text data or fitting a model to it. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about various types of feature engineering we can perform on text data, and what each one means!\u003c/p\u003e","exportId":"feature-engineering-for-text-data"},{"id":458330,"title":"Corpus Statistics - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corpus-statistics-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corpus-statistics-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corpus-statistics-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll learn how to use various NLP techniques to generate descriptive statistics to explore a text corpus!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerate common corpus statistics using NLTK \u003c/li\u003e\n\u003cli\u003eUse a count vectorization strategy to create a bag of words \u003c/li\u003e\n\u003cli\u003eCompare two different text corpora using corpus statistics generated by NLTK \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g884dfd7a7c655abeb9864d3e0f37cb7a"},{"id":458333,"title":"Context-Free Grammars and POS Tagging","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll explore the concept of context-free grammars, and the role they play in linguistics and NLP, particularly in relation to part-of-speech tagging.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe how you might manually create rules related to context-free grammar \u003c/li\u003e\n\u003cli\u003eDefine context-free grammars \u003c/li\u003e\n\u003cli\u003eExplain parts of speech (POS) tagging, and why it is important in NLP \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is a Context-Free Grammar?\u003c/h2\u003e\n\n\u003cp\u003eConsider the following sentence: \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"Colorless green ideas sleep furiously.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis is a sentence dreamed up by the famous linguist \u003ca href=\"https://en.wikipedia.org/wiki/Noam_Chomsky\"\u003eNoam Chomsky\u003c/a\u003e. This sentence, while correct at the \u003cstrong\u003e\u003cem\u003egrammatical\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003esyntactic\u003c/em\u003e\u003c/strong\u003e level, is just a bunch of nonsense when we consider it at the \u003cstrong\u003e\u003cem\u003esemantic\u003c/em\u003e\u003c/strong\u003e level. The sentence follows all the proper rules for a sentence in English, although in reality, it's complete nonsense. This was one of Chomsky's big ideas -- that speech contains an underlying \"deep structure\" that we recognize, regardless of the actual content of the sentence. We don't need any context about what the sentence is actually about to determine if the grammar is correct -- hence the name, \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e, which we'll refer to as 'CFG' for short, for the remainder of this lesson. \u003c/p\u003e\n\n\u003cp\u003eIn order to understand CFGs, we first need to back up and gain a little background knowledge about linguistics. According to linguistics, there are five different levels of language:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/new_LevelsOfLanguage-Graph.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen talking about CFGs, we're focusing on the \u003cstrong\u003e\u003cem\u003esyntactic level\u003c/em\u003e\u003c/strong\u003e. This level worries only about the structure of the sentence, not the informational content. \u003c/p\u003e\n\n\u003cp\u003eSo why do CFGs matter to us? For starters, they are an important part of computer science as a whole, as any code we write gets fed through a parser to determine what we want the computer to actually do. For NLP specifically, they are important because they describe a way that we can write a grammar to interpret sentences at the syntactic level. This is an approach that can be used when we want to generate \u003cstrong\u003e\u003cem\u003ePart-Of-Speech (POS) Tags\u003c/em\u003e\u003c/strong\u003e. Consider the word \"run\". This word can be interpreted as either a noun or a verb. As a noun, we may be talking about the concept of going for a jog, or a run scored in a baseball game. As a verb, we may be talking about the action of running. On its own, we don't know this. Part of the way we know which meaning to interpret for the word is our understanding of where the word fits into the sentence, and the part of speech it occupies in that sentence -- we implicitly recognize that the sentence \"I run in the mornings\" uses run as a verb, while the sentence \"The Yankees scored a run\" uses it as a noun, all based on it's placement in the sentence. \u003c/p\u003e\n\n\u003cp\u003eThis brings us to the concept of \u003cstrong\u003e\u003cem\u003eParse Trees\u003c/em\u003e\u003c/strong\u003e. \u003c/p\u003e\n\n\u003ch2\u003eParse Trees and Sentence Structure\u003c/h2\u003e\n\n\u003cp\u003eIn English, sentences consist of a \u003cstrong\u003e\u003cem\u003eNoun Phrase\u003c/em\u003e\u003c/strong\u003e followed by a \u003cstrong\u003e\u003cem\u003eVerb Phrase\u003c/em\u003e\u003c/strong\u003e, which may optionally be followed by a \u003cstrong\u003e\u003cem\u003ePrepositional Phrase\u003c/em\u003e\u003c/strong\u003e. This seems simple, but it gets more tricky when we realize that there is a recursive structure to these phrases. A noun phrase may consist of multiple smaller noun phrases, and in some cases, even a verb phrase. Similarly, a verb phrase can consist of multiple smaller verb phrases and noun phrases, which can themselves be made up of smaller noun phrases and verb phrases. \u003c/p\u003e\n\n\u003cp\u003eThis leads levels of \u003cstrong\u003e\u003cem\u003eambiguity\u003c/em\u003e\u003c/strong\u003e that can be troublesome for computers. NLTK's documentation explains this by examining the classic Groucho Marx joke:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThere are two different ways that we can interpret the first sentence. The common way that we interpret it is that a person shot an elephant while wearing pajamas. However, the alternative interpretation that is still correct (and the source of Marx's timeless punchline) is that Marx shot an elephant that was actually \u003cem\u003ein\u003c/em\u003e his pajamas. While we humans immediately understand the correct interpretation of the sentence (and hopefully get the joke), a computer has no way of knowing which of the two is the correct interpretation. \u003c/p\u003e\n\n\u003cp\u003eThe difference between the two interpretations can be most easily understood by comparing the \u003cstrong\u003e\u003cem\u003eParse Tree\u003c/em\u003e\u003c/strong\u003e for each. Take a look at this diagram from the \u003ca href=\"https://www.nltk.org/book/ch08.html\"\u003eNLTK Book's chapter on analyzing sentence structure\u003c/a\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/parse_tree.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's break these diagrams down piece by piece. The first, most natural interpretation of the phrase \"I shot an elephant in my pajamas\" breaks down the sentence as such:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNoun phrase: \u003ccode\u003e['I']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eVerb phrase: \u003ccode\u003e['shot', 'an', 'elephant']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ePrepositional phrase: \u003ccode\u003e['in', 'my', 'pajamas']\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis is the basic sentence structure that we are used to hearing. The noun phrase tells us the subject of the sentence, the verb phrase tells us what the subject did, and the prepositional phrase offers more information about the circumstances of the action, e.g. where, when, how, etc. Note that the verb phrase here is made up of a verb ('shot'), followed by a noun phrase ('an elephant'), much in the same way that the prepositional phrase consists of a preposition ('in'), followed by a noun phrase ('my pajamas'). This nested structure is \u003cstrong\u003e\u003cem\u003erecursive\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eHowever, the ambiguity that Marx plays off of uses the second parse tree's structure:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNoun phrase: \u003ccode\u003e['I']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eVerb phrase: \u003ccode\u003e['shot', 'an', 'elephant', 'in', 'my', 'pajamas']\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIf we compare the two parse trees visually, the difference becomes clear. Whereas in the first interpretation, the verb phrase consists of a verb phrase and a prepositional phrase, the second interpretation is different, treating the prepositional phrase as part of a noun phrase, which is, in turn, part of the noun phrase contained within that verb phrase. If all the grammar terms are making your head spin a little, don't worry, that's normal! The simple explanation here is that the first interpretation treats 'elephant' and 'in my pajamas' as belonging to different things, while the second treats 'elephant in my pajamas' as a single phrase. \u003c/p\u003e\n\n\u003ch2\u003eWhy Does This Matter?\u003c/h2\u003e\n\n\u003cp\u003eYou may be wondering why any of this actually matters to a Data Scientist. At a glance, it mostly just seems like a rehashing of a bunch of grade-school grammar rules. The answer is that using parse trees to understand sentence structure can help us determine meaning when working with human speech. It also helps highlight why this is such a complicated task -- computers do not have the ability to judge the meaning of a sentence based on things like semantic context like we do. Put simply, we know what an elephant is, what pajamas are, and understand that it's highly unlikely that an elephant could fit in pajamas. This helps us determine how we understand that sentence on the fly -- computers don't have this luxury, so they don't know which to choose!\u003c/p\u003e\n\n\u003ch2\u003ePOS Tagging and CFGs\u003c/h2\u003e\n\n\u003cp\u003eThis brings us to part of speech tagging. One way that we can help a computer understand how to interpret a sentence is to create a CFG for it to use when parsing. The CFG defines the rules of how sentences can exist. We do this by labeling different word tokens as their grammatical types, and then defining which combinations of grammatical types are valid examples of verb phrases, noun phrases, etc. \u003c/p\u003e\n\n\u003cp\u003eLet's take a look at the example CFG from the NLTK link provided above:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/cfg.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's break down this CFG, and see if we can understand it a bit better. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eS -\u0026gt; NP VP\u003c/code\u003e A sentence (S) consists of a Noun Phrase (NP) followed by a Verb Phrase (VP).\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ePP -\u0026gt; P NP\u003c/code\u003e A Prepositional Phrase (PP) consists of a Preposition (P) followed by a Noun Phrase (NP)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eNP -\u0026gt; Det N | Det N PP | 'I'\u003c/code\u003e A Noun Phrase (NP) can consist of:\n\n\u003cul\u003e\n\u003cli\u003ea Determiner (Det) followed by a Noun (N), or (as denoted by \u003ccode\u003e|\u003c/code\u003e) \u003c/li\u003e\n\u003cli\u003ea Determiner (Det) followed by a Noun (N), followed by a Prepositional Phrase (PP), or\u003c/li\u003e\n\u003cli\u003eThe token \u003ccode\u003e'I'\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eVP -\u0026gt; V NP | VP PP\u003c/code\u003e A Verb Phrase can consist of:\n\n\u003cul\u003e\n\u003cli\u003ea Verb (V) followed by a Noun Phrase (NP) or\u003c/li\u003e\n\u003cli\u003ea Verb Phrase (VP) followed by a Prepositional Phrase (PP)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eDet -\u0026gt; 'an' | 'my'\u003c/code\u003e Determiners are the tokens 'an' or 'my'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eN -\u0026gt; 'elephant' | 'pajamas'\u003c/code\u003e Nouns are the tokens 'elephant' or 'pajamas'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eV -\u0026gt; 'shot'\u003c/code\u003e Verbs are the token 'shot'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eP -\u0026gt; 'in'\u003c/code\u003e Prepositions are the token 'in'\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs we can see, the CFG provides explicit rules as to both:\n1. How sentences, noun phrases, verb phrases, and prepositional phrases may be structured\n2. What parts of speech each token belongs to \u003c/p\u003e\n\n\u003cp\u003eThis defines a very small CFG that allows the parser to successfully generate parse trees for the Groucho Marx's sentence. Note that both the parse trees seen above are valid, according to the rules defined in this grammar. Even though this grammar is quite explicit, both of them work. \u003c/p\u003e\n\n\u003cp\u003eSo what happens if this CFG runs across a sentence structure it doesn't understand, or a token that it doesn't have a POS label for? It fails! True CFGs are quite complex. This was a toy example. \u003c/p\u003e\n\n\u003cp\u003eIn the next lab, we'll gain some practice writing some toy CFGs for a few target sentences. We'll also learn how we can skip all this fun stuff and get existing POS tags for our tokens straight from NLTK whenever we need them, thanks to databases such as the \u003cstrong\u003e\u003cem\u003ePenn Tree Bank\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we dove into linguistics to understand the concept of a \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e, and explored how they can be used to create parse trees for sentences.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-context-free-grammars-and-POS-tagging\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-context-free-grammars-and-POS-tagging\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"context-free-grammars-and-pos-tagging"},{"id":458337,"title":"Context-Free Grammars - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-context-free-grammars-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll write our own \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e (CFG) to provide a parser with rules for how sentences can be parsed. We'll also explore how we can easily obtain \u003cstrong\u003e\u003cem\u003ePart-of-Speech (POS) Tags\u003c/em\u003e\u003c/strong\u003e using NLTK!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse NLTK to create context-free grammar and part-of-speech (POS) tags\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g533c9d870df05d068e79cd3996c70b47"},{"id":458346,"title":"Short Video: TF-IDF Vectorization","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713724950?h=6c82571832\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"Untitled\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-tf-idf-vectorization"},{"id":458354,"title":"Text Classification","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-text-classification\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-text-classification/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll discuss the general process for setting up text datasets for classification problems.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the steps for classifying text data \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClassification for Text Data\u003c/h2\u003e\n\n\u003cp\u003eFor the final lab of this section, we'll use everything we've learned so far to build a classifier that works well with text data. As you've probably guessed, text data is significantly harder to work with than most traditional datasets, because of the sheer amount of preprocessing needed to get the data into a format acceptable to a machine learning algorithm. \u003c/p\u003e\n\n\u003cp\u003eThe main challenge in working with text data isn't just the preprocessing -- its the number of decisions you have to make about how you'll clean and structure the data. In a traditional dataset full of numerical and categorical features, the preprocessing steps are fairly straightforward. Generally, we normalize the numeric data, check for and deal with multicollinearity, convert categorical data to numerical format through one-hot encoding, and so forth. Although the steps themselves may not be easy, there's generally little ambiguity about \u003cem\u003ewhat needs to be done\u003c/em\u003e. Text data is a bit more ambiguous. Let's examine some of the decisions we generally need to make when working with text data.\u003c/p\u003e\n\n\u003ch2\u003eCleaning and Preprocessing Text Data\u003c/h2\u003e\n\n\u003cp\u003eOnce we have our data, the fun part begins. We'll need to begin by preprocessing and cleaning our text data. As you've seen throughout this section, preprocessing text data is a bit more challenging than working with more traditional data types because there's no clear-cut answer for exactly what sort of preprocessing and cleaning we need to do. When working with traditional datasets, our goals are generally pretty clear for this stage -- normalize and clean our numerical data, convert categorical data to a numeric format, check for and deal with multicollinearity, etc. The steps we take are largely dependent on what the data already looks like when we get a hold of it. Text data is different -- if we inspect a raw text dataset, we'll generally see that it only has one dimension -- the actual text, in the form of a string. This could be anything from a tweet to a full novel. This means that we need to make some decisions about how to preprocess our data. Before we can begin cleaning and preprocessing our text data, we need to make some decisions about things such as:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDo we remove stop words or not?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we stem or lemmatize our text data, or leave the words as is?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eIs basic tokenization enough, or do we need to support special edge cases through the use of regex?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we use the entire vocabulary, or just limit the model to a subset of the most frequently used words? If so, how many?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we engineer other features, such as bigrams, or POS tags, or Mutual Information Scores?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat sort of vectorization should we use in our model? Boolean Vectorization? Count Vectorization? TF-IDF? More advanced vectorization strategies such as Word2Vec?\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThese are all questions that we'll need to think about pretty much anytime we begin working with text data.\u003c/p\u003e\n\n\u003ch2\u003eFeature Engineering\u003c/h2\u003e\n\n\u003cp\u003eAnother common decision point when working with text data is exactly what features to include in the dataset. As we saw in a previous lab, NLTK makes it quite easy to do things like generate part-of-speech tags for words, or create word or character-level n-grams. In general, there's no great answer for exactly which features will improve the performance of your model, and which won't. This means that your best bet is to experiment, and treat the entire project as an iterative process! When working with text data, don't be afraid to try modeling on alternative forms of the text data, such as bigrams or n-grams. Similarly, we encourage you to explore how adding in additional features such as POS tags or mutual information scores affect the overall model performance. Sometimes, it has a great effect on performance. Other times, not much. Either way, you won't know until you try!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we discussed the challenges that come with working with text data for classification, and the types of decisions we should be ready to make when cleaning and preprocessing a dataset!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-text-classification\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-text-classification\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-text-classification/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"text-classification"},{"id":458356,"title":"Quiz: Natural Language Processing","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"g0405b9cee60106c07d13b4ef06cf59f8","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"min_score","requiredPoints":3.0,"completed":false,"content":"","exportId":"ge4eb3dd722fcfcc80f1f9aa87b632443"},{"id":458373,"title":"‚≠êÔ∏è Text Classification - Cumulative Lab","type":"Quizzes::Quiz","indent":0,"locked":false,"assignmentExportId":"gcc72941e26479db2c74fd6ea6a876426","questionCount":1,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_submit","completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eWork on this lab on your local computer. If you're not sure what to do, refer to the instructions in \u003ca title=\"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\" href=\"quizzes/gd4bb2a176d75638f44ca8a45af7b753e\"\u003e‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\u003c/a\u003e\u003c/p\u003e","exportId":"g11ad01bbe6f79a0e7287e5eb4163a824"},{"id":458378,"title":"Natural Language Processing - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNLP has become increasingly popular over the past few years, and NLP researchers have achieved very insightful insights\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eThe Natural Language Tool Kit (NLTK) is one of the most popular Python libraries for NLP\u003c/li\u003e\n\u003cli\u003eRegular Expressions are an important part of NLP, which can be used for pattern matching and filtering\u003c/li\u003e\n\u003cli\u003eRegular Expressions can become confusing, so make sure to use our provided cheat sheet the first few times you work with regex\u003c/li\u003e\n\u003cli\u003eIt is strongly recommended you take some time to use regex tester websites to ensure you understand how changing your regex pattern affects your results when working towards a correct answer!\u003c/li\u003e\n\u003cli\u003eFeature Engineering is essential when working with text data, and to understand the dynamics of your text\u003c/li\u003e\n\u003cli\u003eCommon feature engineering techniques are removing stop words, stemming, lemmatization, and n-grams\u003c/li\u003e\n\u003cli\u003eWhen diving deeper into grammar and linguistics, context-free grammars and part-of-speech tagging is important\u003c/li\u003e\n\u003cli\u003eIn this context, parse trees can help computers when dealing with ambiguous words \u003c/li\u003e\n\u003cli\u003e\n\u003cem\u003eHow\u003c/em\u003e you clean and preprocess your data will have a major effect on the conclusions you'll be able to draw in your NLP classification problems \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-nlp-section-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-nlp-section-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"natural-language-processing-recap"}]},{"id":47101,"name":"Topic 38: Neural Networks","status":"completed","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g23a6d31a68ba26c6d7b06ca5047ca55a","items":[{"id":458388,"title":"Topic 38 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.251%; height: 98px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNeural Networks Architecture\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Neural Networks - Introduction\" href=\"pages/neural-networks-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/neural-networks-introduction\" data-api-returntype=\"Page\"\u003eNeural Networks - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Neural Networks \" href=\"assignments/g5cfd415b6c16b8a663492df51792ab17\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187116\" data-api-returntype=\"Assignment\"\u003eIntroduction to Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Introduction to Neural Networks - Lab\" href=\"assignments/gf2f068c1f54bb20d5b59fed69c0b026d\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187117\" data-api-returntype=\"Assignment\"\u003eIntroduction to Neural Networks - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.6255%; height: 261px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNeural Networks Architecture\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eIntro to Keras and TensorFlow\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Neural Network Architecture Exit Ticket\" href=\"quizzes/g019828bafb8113a73d23e631cda07bd3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30661\" data-api-returntype=\"Quiz\"\u003eNeural Network Architecture Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Keras\" href=\"assignments/g0eb3977117857e24bafa2973c6d41fd6\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187113\" data-api-returntype=\"Assignment\"\u003eIntroduction to Keras\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Keras - Lab\" href=\"assignments/gf64a29e6ba56e3918fe4a29949d8110b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187119\" data-api-returntype=\"Assignment\"\u003eKeras - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Deeper Neural Networks\" href=\"assignments/g5593261c5fe164b30874c26e98026d4c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187104\" data-api-returntype=\"Assignment\"\u003eDeeper Neural Networks\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Deeper Neural Networks - Lab\" href=\"assignments/g435e4887d3bebaf536db883d19cdf707\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187105\" data-api-returntype=\"Assignment\"\u003eDeeper Neural Networks - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Image Classification with Multi-Layer Perceptrons\" href=\"pages/image-classification-with-multi-layer-perceptrons\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/image-classification-with-multi-layer-perceptrons\" data-api-returntype=\"Page\"\u003eImage Classification with Multi-Layer Perceptrons\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Image Classification with MLPs - Lab\" href=\"assignments/g41f7a6a6dd480b27090ed07c9767da64\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187110\" data-api-returntype=\"Assignment\"\u003eImage Classification with MLPs - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.626%;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Neural Networks\" href=\"quizzes/ga45ae0602eaec10912652ed52580feb0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30664\" data-api-returntype=\"Quiz\"\u003eQuiz: Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\"\u003e\u003cstrong\u003e\u003cspan style=\"color: #000000;\"\u003e1st\u003c/span\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.5188%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eIntro to Keras and TensorFlow\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Short Video: Regression with a Neural Network\" href=\"pages/short-video-regression-with-a-neural-network\" data-api-endpoint=\"pages/short-video-regression-with-a-neural-network?module_item_id=mastercourse_15802_382_27525315d1cfc0d6bf5ed83471c2f0af\" data-api-returntype=\"Page\"\u003eShort Video: Regression with a Neural Network\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e2nd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Intro to Keras and Tensorflow Exit Ticket\" href=\"quizzes/g0e314f849741298b050a433febfe8e80\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30686\" data-api-returntype=\"Quiz\"\u003eIntro to Keras and Tensorflow Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Neural Networks - Recap\" href=\"pages/neural-networks-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/neural-networks-recap\" data-api-returntype=\"Page\"\u003eNeural Networks - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-38-lesson-priorities-live"},{"id":458394,"title":"Neural Networks - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-neural-nets-intro-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-intro-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-intro-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll be introduced to one of the most advanced machine learning algorithms currently in the world -- neural networks! \u003c/p\u003e\n\n\u003ch2\u003eDeep Learning\u003c/h2\u003e\n\n\u003cp\u003eThe time has come to learn about one of the most exciting and fast-growing areas of data science: Deep Learning! When we talk about deep learning, we are talking about (deep) neural networks. You'll learn all about them in this section. You'll also use Python to build (basic) neural networks from scratch.\u003c/p\u003e\n\n\u003ch3\u003eNeural Networks\u003c/h3\u003e\n\n\u003cp\u003eIn this section, you'll learn what it means when we talk about neural networks. You'll learn about the essential building blocks like \"layers\", \"nodes\", \"arrows\", \"weights\", \"loss\", \"cost function\", etc. You'll learn that a neural network generally consists of several layers, and how a logistic regression model can be represented as a neural network with just one layer. You'll be able to explain what the advantages and disadvantages of using neural networks are, and get an insight of how forward and backward propagation are used in neural networks to minimize the loss and \"optimize\" your neural network.\u003c/p\u003e\n\n\u003ch3\u003eKeras and TensorFlow\u003c/h3\u003e\n\n\u003cp\u003eYou'll be introduced to Keras, a leading open source neural network library in Python, which is now a part of TensorFlow. Keras makes building neural networks surprisingly easy. Before building your first neural network model in Keras, you'll learn about tensors and why they are important when building deep learning models.\u003c/p\u003e\n\n\u003ch3\u003eDeeper Neural Networks\u003c/h3\u003e\n\n\u003cp\u003eYou'll learn why deeper networks sometimes lead to better results, and we'll generalize what you have learned before to get your matrix dimensions right for deep networks. You'll build deeper neural networks from scratch, and also learn how to build these using Keras.\u003c/p\u003e\n\n\u003cp\u003eYou'll learn that deep representations are really good at automating what used to be a tedious and time-consuming process of feature engineering. In this section, you'll see that you can actually build a smaller but deeper neural network with exponentially less hidden units which performs even better than a network with more hidden units. The reason for this is that learning happens in each layer, and adding more layers (even with fewer limits) can lead to very powerful predictions! You'll learn about matrix notation for these deep networks and how to build a network like that from scratch.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the basics of neural networks and how to implement them in Keras!\u003c/p\u003e","exportId":"neural-networks-introduction"},{"id":458398,"title":"Introduction to Neural Networks","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNeural networks are becoming increasingly more popular and are responsible for some of the most cutting edge advancements in data science including image and speech recognition. They have also been transformative in reducing the need for intensive and often time intensive feature engineering needed for traditional supervised learning tasks. In this lesson, we'll investigate the architecture of neural networks.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what neural networks are and what they can achieve \u003c/li\u003e\n\u003cli\u003eList the components of a neural network \u003c/li\u003e\n\u003cli\u003eExplain forward propagation in a neural network \u003c/li\u003e\n\u003cli\u003eExplain backward propagation and discuss how it is related to forward propagation \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g5cfd415b6c16b8a663492df51792ab17"},{"id":458402,"title":"Introduction to Neural Networks - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-neural-networks-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice everything you have learned during the lecture. We know there is quite a bit of math involved, but don't worry! Using Python and trying things out yourself will actually make a lot of things much more clear! Before we start, let's load some necessary libraries so we can import our data.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImport images using Keras \u003c/li\u003e\n\u003cli\u003eBuild a \"shallow\" neural network from scratch \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gf2f068c1f54bb20d5b59fed69c0b026d"},{"id":458415,"title":"Introduction to Keras","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-keras\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThus far we have a solid basic conceptual understanding of neural networks and their basic architecture. We've seen neural networks for classification including a neural network with no hidden layers (logistic regression), one hidden layer, and several hidden layers. From here, we'll begin to use Keras, a package that has prebuilt many of the building blocks of neural networks which we investigated in previous lessons.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine a tensor \u003c/li\u003e\n\u003cli\u003ePerform tensor slicing \u003c/li\u003e\n\u003cli\u003eExplain the different tensor operations (element-wise, broadcast, and dot product) \u003c/li\u003e\n\u003cli\u003eExplain how an epoch and batch relate to one another \u003c/li\u003e\n\u003cli\u003eExplain the steps to build a neural network in Keras \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g0eb3977117857e24bafa2973c6d41fd6"},{"id":458418,"title":"Keras - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-keras-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you'll once again build a neural network, but this time you will be using Keras to do a lot of the heavy lifting.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a neural network using Keras \u003c/li\u003e\n\u003cli\u003eEvaluate performance of a neural network using Keras \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gf64a29e6ba56e3918fe4a29949d8110b"},{"id":458422,"title":"Deeper Neural Networks","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-deeper-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eSome of the most powerful neural networks use many dozens of layers of activation functions in order to model complex relationships. Let's see how we can extend neural networks even further with deeper neural networks!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the mechanics of a deep neural network \u003c/li\u003e\n\u003cli\u003eExplain the purpose of an activation function in a neural network \u003c/li\u003e\n\u003cli\u003eList the different activation functions\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eCompare and contrast the different activation functions \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g5593261c5fe164b30874c26e98026d4c"},{"id":458425,"title":"Deeper Neural Networks - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-deeper-neural-networks-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll dig deeper into the work horse of deep learning, \u003cstrong\u003e\u003cem\u003eMulti-Layer Perceptrons\u003c/em\u003e\u003c/strong\u003e! We'll build and train a couple of different MLPs with Keras and explore the tradeoffs that come with adding extra hidden layers. We'll also try switching between some of the activation functions we learned about in the previous lesson to see how they affect training and performance. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a deep neural network using Keras \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g435e4887d3bebaf536db883d19cdf707"},{"id":458429,"title":"Image Classification with Multi-Layer Perceptrons","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-image-classification-with-mlps\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll learn why deeper networks sometimes lead to better results, and we'll generalize what you have learned before to get your matrix dimensions right in deep networks.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what is meant by \"deep representations\" of images \u003c/li\u003e\n\u003cli\u003eMathematically represent forward and back propagation in a deep neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhy deep representations?\u003c/h2\u003e\n\n\u003cp\u003eDeep representations are really good at automating what used to be a tedious process of feature engineering. Not only would modelers need to have complex programming and analytical skills, they would also often require domain knowledge in order to manually build features that would then be passed on to a regression or classification algorithm. With deep representations, this time consuming process is often severely diminished. \u003c/p\u003e\n\n\u003cp\u003eFor example, the deep layers of a neural network for computer might look like this:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efirst layer detects edges in pictures\u003c/li\u003e\n\u003cli\u003esecond layer groups edges together and starts to detect different parts\u003c/li\u003e\n\u003cli\u003emore layers: group even bigger parts together, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eor in the case of audio:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efirst layer: low lever wave features\u003c/li\u003e\n\u003cli\u003esecond layer: basic units of sounds, \"phonemes\" \u003c/li\u003e\n\u003cli\u003ethird: word recognition\u003c/li\u003e\n\u003cli\u003efourth: sentence recognition\n-...\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe general idea is shallow networks detect \"simple\" things, and the deeper you go, the more complex things can be detected. \u003c/p\u003e\n\n\u003cp\u003eYou can build a smaller but deeper neural network that needs exponentially less hidden units but performs better, because learning happens in each layer!\u003c/p\u003e\n\n\u003ch2\u003eDeep Network Architecture and Notation\u003c/h2\u003e\n\n\u003cp\u003eLet's try to generalize all the notation to get things straight and know the dimensions of all matrices we'll be working with. Let's have a look at this 3-layer network:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-image-classification-with-mlps/master/images/new_classwmips.png\" alt=\"neural network with input layer, first hidden layer, second hidden layer, output layer\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eImagine that there are 300 cases, or observations (m = 300). What do our matrices look like? \u003c/p\u003e\n\n\u003cp\u003eLet's start with \u003cimg class=\"equation_image\" title=\" Z^{[1]} = W^{[1]} X +b^{[1]}\" src=\"/equation_images/%20Z^{[1]}%20=%20W^{[1]}%20X%20+b^{[1]}\" alt=\"{\" data-equation-content=\" Z^{[1]} = W^{[1]} X +b^{[1]}\"\u003e.  \u003c/p\u003e\n\n\u003cp\u003eWhile not shown above in the diagram, Z is the output of the linear part of one of our hidden layers.  \u003c/p\u003e\n\n\u003cp\u003eBreaking this down, we have:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"W^{[1]}\" src=\"/equation_images/W^{[1]}\" alt=\"{\" data-equation-content=\"W^{[1]}\"\u003e is the weights matrix with dimensions (4 x 2)\u003c/li\u003e\n\u003cli\u003eIf we look at all our samples, \u003cimg class=\"equation_image\" title=\"x\" src=\"https://learning.flatironschool.com/equation_images/x\" alt=\"{\" data-equation-content=\"x\"\u003e is a (2 x 300)-matrix \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"Z^{[1]}\" src=\"/equation_images/Z^{[1]}\" alt=\"{\" data-equation-content=\"Z^{[1]}\"\u003e is a (4 x 300)-matrix \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"b^{[1]}\" src=\"/equation_images/b^{[1]}\" alt=\"{\" data-equation-content=\"b^{[1]}\"\u003e is a (4 x 1)-matrix. Due to broadcasting in Python, this matrix will be duplicated into a (4 x 300)-matrix \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSimilarly, the second hidden layer also has a linear function attached.\u003c/p\u003e\n\n\u003cp\u003eIn \u003cimg class=\"equation_image\" title=\" Z^{[2]} = W^{[2]} A^{[1]} +b^{[2]}\" src=\"/equation_images/%20Z^{[2]}%20=%20W^{[2]}%20A^{[1]}%20+b^{[2]}\" alt=\"{\" data-equation-content=\" Z^{[2]} = W^{[2]} A^{[1]} +b^{[2]}\"\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe dimension of \u003cimg class=\"equation_image\" title=\"A^{[1]}\" src=\"/equation_images/A^{[1]}\" alt=\"{\" data-equation-content=\"A^{[1]}\"\u003e is the same as the dimension of \u003cimg class=\"equation_image\" title=\"Z^{[1]}\" src=\"/equation_images/Z^{[1]}\" alt=\"{\" data-equation-content=\"Z^{[1]}\"\u003e: (4 x 300)\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"W^{[2]}\" src=\"/equation_images/W^{[2]}\" alt=\"{\" data-equation-content=\"W^{[2]}\"\u003e is the weights matrix with dimensions (3 x 4)\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"Z^{[2]}\" src=\"/equation_images/Z^{[2]}\" alt=\"{\" data-equation-content=\"Z^{[2]}\"\u003e is a (3 x 300)-matrices \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"b^{[2]}\" src=\"/equation_images/b^{[2]}\" alt=\"{\" data-equation-content=\"b^{[2]}\"\u003e is a (3 x 1)-matrix. Due to broadcasting in Python, this matrix will be duplicated into a (3 x 300)-matrix \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGeneralizing Notation\u003c/h2\u003e\n\n\u003cp\u003eFrom here, we wish to generalize our notation to a deep network with \u003cimg class=\"equation_image\" title=\"L\" src=\"https://learning.flatironschool.com/equation_images/L\" alt=\"{\" data-equation-content=\"L\"\u003e layers as opposed to 2. For each of these layers, we have parameters associated with the linear transformation of the layer, and parameters associated with the activation function applied to the output of this linear transformation.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eParameters for the linear transformation:\u003c/strong\u003e  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W^{[l]}: (n^{[l]}, n^{[l-1]})\" src=\"/equation_images/W^{[l]}:%20(n^{[l]},%20n^{[l-1]})\" alt=\"{\" data-equation-content=\"W^{[l]}: (n^{[l]}, n^{[l-1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/b^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\"b^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"dW^{[l]}: (n^{[l]}, n^{[l-1]})\" src=\"/equation_images/dW^{[l]}:%20(n^{[l]},%20n^{[l-1]})\" alt=\"{\" data-equation-content=\"dW^{[l]}: (n^{[l]}, n^{[l-1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"db^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/db^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\"db^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eParameters for the activation function:\u003c/strong\u003e  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" a^{[l]}, z^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/%20a^{[l]},%20z^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\" a^{[l]}, z^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" Z^{[l]}, A^{[l]}: (n^{[l]}, m)\" src=\"/equation_images/%20Z^{[l]},%20A^{[l]}:%20(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\" Z^{[l]}, A^{[l]}: (n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)\" src=\"/equation_images/%20dZ^{[l]},%20dA^{[l]}:%20(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\" dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eForward Propagation\u003c/h2\u003e\n\n\u003cp\u003eRecall that deep networks work by performing forward propagation; evaluating a cost function associated with the output of the neural network by successively calculating the output of each layer given initial parameter values, and passing this output on to the next layer until a finalized output has been calculated and the cost function can then be evaluated.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eInput is \u003cimg class=\"equation_image\" title=\"a^{[l-1]}\" src=\"/equation_images/a^{[l-1]}\" alt=\"{\" data-equation-content=\"a^{[l-1]}\"\u003e\u003c/li\u003e\n\u003cli\u003eOutput \u003cimg class=\"equation_image\" title=\"a^{[l]}\" src=\"/equation_images/a^{[l]}\" alt=\"{\" data-equation-content=\"a^{[l]}\"\u003e, save \u003cimg class=\"equation_image\" title=\"z^{[l]}, w^{[l]}, b^{[l]}, a^{[l-1]} \" src=\"/equation_images/z^{[l]},%20w^{[l]},%20b^{[l]},%20a^{[l-1]}\" alt=\"{\" data-equation-content=\"z^{[l]}, w^{[l]}, b^{[l]}, a^{[l-1]} \"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHere's some more details about how the forward propagation calculation is performed:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Z^1\" src=\"/equation_images/Z^1\" alt=\"{\" data-equation-content=\"Z^1\"\u003e is the output of the linear transformation of the initial input \u003cimg class=\"equation_image\" title=\"A^1\" src=\"/equation_images/A^1\" alt=\"{\" data-equation-content=\"A^1\"\u003e (the observations). In successive layers, \u003cimg class=\"equation_image\" title=\"A^l\" src=\"/equation_images/A^l\" alt=\"{\" data-equation-content=\"A^l\"\u003e is the output from the previous hidden layer. In all of these cases, \u003cimg class=\"equation_image\" title=\"W^l\" src=\"/equation_images/W^l\" alt=\"{\" data-equation-content=\"W^l\"\u003e is a matrix of weights to be optimized to minimize the cost function. \u003cimg class=\"equation_image\" title=\"b^l\" src=\"/equation_images/b^l\" alt=\"{\" data-equation-content=\"b^l\"\u003e is also optimized but is a vector as opposed to a matrix.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"g^l\" src=\"/equation_images/g^l\" alt=\"{\" data-equation-content=\"g^l\"\u003e is the activation function which takes the output of this linear transformation and yields the input to the next hidden layer.  \u003c/p\u003e\n\n\u003cp\u003eMathematically we have:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}\" src=\"/equation_images/%20Z^{[l]}=%20W^{[l]}%20A^{[l-1]}%20+%20b^{[l]}\" alt=\"{\" data-equation-content=\" Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" A^{[l]}= g^{[l]} ( Z^{[l]})\" src=\"/equation_images/%20A^{[l]}=%20g^{[l]}%20(%20Z^{[l]})\" alt=\"{\" data-equation-content=\" A^{[l]}= g^{[l]} ( Z^{[l]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003ehere, \u003cimg class=\"equation_image\" title=\" Z^{[l]}, A^{[l]}\" src=\"/equation_images/%20Z^{[l]},%20A^{[l]}\" alt=\"{\" data-equation-content=\" Z^{[l]}, A^{[l]}\"\u003e both have a shape of \u003cimg class=\"equation_image\" title=\"(n^{[l]}, m)\" src=\"/equation_images/(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\"(n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eBackward Propagation\u003c/h2\u003e\n\n\u003cp\u003eOnce an output for the neural network given the current parameter weights has been calculated, we must back propagate to calculate the gradients of layer parameters with respect to the cost function. This will allow us to apply an optimization algorithm such as gradient descent in order to make small adjustments to the parameters in order to minimize our cost (and improve our predictions).\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eInput: \u003cimg class=\"equation_image\" title=\"da ^{[l]}\" src=\"/equation_images/da%20^{[l]}\" alt=\"{\" data-equation-content=\"da ^{[l]}\"\u003e\u003c/li\u003e\n\u003cli\u003eOutput:  \u003cimg class=\"equation_image\" title=\"da^{[l-1]}\" src=\"/equation_images/da^{[l-1]}\" alt=\"{\" data-equation-content=\"da^{[l-1]}\"\u003e, \u003cimg class=\"equation_image\" title=\"dW^{[l]}, db^{[l]}\" src=\"/equation_images/dW^{[l]},%20db^{[l]}\" alt=\"{\" data-equation-content=\"dW^{[l]}, db^{[l]}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn terms of formulas, the gradients for our respective parameters in each activation layer are given by:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})\" src=\"/equation_images/%20dZ^{[l]}=%20dA%20^{[l]}%20*%20g^{[l]'}%20(Z^{[l]})\" alt=\"{\" data-equation-content=\" dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}\" src=\"/equation_images/%20dW^{[l]}%20=%20%255Cdfrac{1}{m}%20dZ^{[l]}*%20A^{[l-1]T}\" alt=\"{\" data-equation-content=\" dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)\" src=\"/equation_images/%20db^{[l]}%20=%20%255Cdfrac{1}{m}%20np.sum(dZ^{[l]},%20axis=1,%20keepdims=True)\" alt=\"{\" data-equation-content=\" db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dA^{[l-1]} = W^{[l]T}*dZ^{[l]}\" src=\"/equation_images/%20dA^{[l-1]}%20=%20W^{[l]T}*dZ^{[l]}\" alt=\"{\" data-equation-content=\" dA^{[l-1]} = W^{[l]T}*dZ^{[l]}\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eProcess Overview\u003c/h2\u003e\n\n\u003cp\u003eTo summarize the process once more, we begin by defining a model architecture which includes the number of hidden layers, activation functions, and the number of units in each of these.   \u003c/p\u003e\n\n\u003cp\u003eWe then initialize parameters for each of these layers (typically randomly). After the initial parameters are set, forward propagation evaluates the model giving a prediction, which is then used to evaluate a cost function. Forward propagation involves evaluating each layer and then piping this output into the next layer. \u003c/p\u003e\n\n\u003cp\u003eEach layer consists of a linear transformation and an activation function. The parameters for the linear transformation in \u003cstrong\u003eeach\u003c/strong\u003e layer include \u003cimg class=\"equation_image\" title=\"W^l\" src=\"/equation_images/W^l\" alt=\"{\" data-equation-content=\"W^l\"\u003e and \u003cimg class=\"equation_image\" title=\"b^l\" src=\"/equation_images/b^l\" alt=\"{\" data-equation-content=\"b^l\"\u003e. The output of this linear transformation is represented by \u003cimg class=\"equation_image\" title=\"Z^l\" src=\"/equation_images/Z^l\" alt=\"{\" data-equation-content=\"Z^l\"\u003e. This is then fed through the activation function (again, for each layer) giving us an output \u003cimg class=\"equation_image\" title=\"A^l\" src=\"/equation_images/A^l\" alt=\"{\" data-equation-content=\"A^l\"\u003e which is the input for the next layer of the model.  \u003c/p\u003e\n\n\u003cp\u003eAfter forward propagation is completed and the cost function is evaluated, back propogation is used to calculate gradients of the initial parameters with respect to this cost function. Finally, these gradients are then used in an optimization algorithm, such as gradient descent, to make small adjustments to the parameters and the entire process of forward propagation, back propagation, and parameter adjustments is repeated until the modeller is satisfied with the results.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations\"\u003ehttps://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this brief lesson, we gave an intuitive justification behind using deep network structures and reviewed the architecture for neural nets in general. In upcoming lessons, we will begin to extend our previous work in creating a single layer neural network in order to build a deeper more powerful model.\u003c/p\u003e","exportId":"image-classification-with-multi-layer-perceptrons"},{"id":458432,"title":"Image Classification with MLPs - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-image-classification-with-mlps-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFor the final lab in this section, we'll build a more advanced \u003cstrong\u003e\u003cem\u003eMulti-Layer Perceptron\u003c/em\u003e\u003c/strong\u003e to solve image classification for a classic dataset, MNIST!  This dataset consists of thousands of labeled images of handwritten digits, and it has a special place in the history of Deep Learning. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a multi-layer neural network image classifier using Keras \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g41f7a6a6dd480b27090ed07c9767da64"},{"id":458435,"title":"Quiz: Neural Networks","type":"Quizzes::Quiz","indent":2,"locked":false,"assignmentExportId":"gd62c4039c560ef223ef6a6245bb3dcd0","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"","exportId":"ga45ae0602eaec10912652ed52580feb0"},{"id":458446,"title":"Short Video: Regression with a Neural Network","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813950?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","exportId":"short-video-regression-with-a-neural-network"},{"id":458453,"title":"Neural Networks - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-neural-nets-recap-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-recap-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-recap-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003ch3\u003eNeural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eNeural networks are powerful models that can be customized and tweaked using various amounts of nodes, layers, etc.\u003c/li\u003e\n\u003cli\u003eThe most basic neural networks are single-layer densely connected neural networks, which have very similar properties as logistic regression models\u003c/li\u003e\n\u003cli\u003eCompared to more traditional statistics and ML techniques, neural networks perform particularly well when using unstructured data\u003c/li\u003e\n\u003cli\u003eApart from densely connected networks, other types of neural networks include convolutional neural networks, recurrent neural networks, and generative adversarial neural networks \u003c/li\u003e\n\u003cli\u003eWhen working with image data, it's important to understand how image data is stored when working with them in Python\u003c/li\u003e\n\u003cli\u003eLogistic regression can be seen as a single-layer neural network with a sigmoid activation function\u003c/li\u003e\n\u003cli\u003eNeural networks use loss and cost functions to minimize the \"loss\", which is a function that summarizes the difference between the actual outcome (eg. pictures contain Santa or not) and the model prediction (whether the model correctly identifies pictures with Santa)\u003c/li\u003e\n\u003cli\u003eBackward and forward propagation are used to estimate the so-called \"model weights\"\u003c/li\u003e\n\u003cli\u003eAdding more layers to neural networks can substantially increase model performance\u003c/li\u003e\n\u003cli\u003eSeveral activations can be used in model nodes, you can explore with different types and evaluate how it affects performance\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eDeep Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eDeep neural network representations can lighten the burden and automate certain tasks of heavy data preprocessing\u003c/li\u003e\n\u003cli\u003eDeep representations need exponentially fewer hidden units than shallow networks, to obtain the same performance\u003c/li\u003e\n\u003cli\u003eParameter initialization, forward propagation, cost function evaluation, and backward propagation are again the cornerstones of deep networks\u003c/li\u003e\n\u003cli\u003eTensors are the building blocks of neural networks and a good understanding of them and how to use them in Python is crucial\u003c/li\u003e\n\u003cli\u003eScalars can be seen as 0-D tensors. Vectors can be seen as 1-D tensors, and matrices as 2-D tensors\u003c/li\u003e\n\u003cli\u003eThe usage of tensors reaches beyond matrices: tensors can have N dimensions\u003c/li\u003e\n\u003cli\u003eTensors can be created and manipulated using NumPy\u003c/li\u003e\n\u003cli\u003eKeras makes building neural networks in Python easy, and you learned how to do that in this section\u003c/li\u003e\n\u003cli\u003eYou can use Keras to do some NLP as well, e.g. for tokenization \u003c/li\u003e\n\u003c/ul\u003e","exportId":"neural-networks-recap"}]},{"id":47105,"name":"Topic 39: Tuning Neural Networks","status":"completed","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g36962a75f13484bc512e7f84c95d4708","items":[{"id":458462,"title":"Topic 39 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 186px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNetwork Evaluation and Regularization\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Tuning Neural Networks - Introduction\" href=\"pages/tuning-neural-networks-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-introduction\" data-api-returntype=\"Page\"\u003eTuning Neural Networks - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Regularization\" href=\"pages/tuning-neural-networks-with-regularization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-with-regularization\" data-api-returntype=\"Page\"\u003e\u003cstrong\u003eTuning Neural Networks with Regularization\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Regularization - Lab\" href=\"assignments/g44969ffff4b33b816b9daba862417b65\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12382\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks with Regularization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Normalization\" href=\"pages/tuning-neural-networks-with-normalization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-with-normalization\" data-api-returntype=\"Page\"\u003eTuning Neural Networks with Normalization\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Normalization - Lab\" href=\"assignments/g3f1caffeac6631bd5eec966c32c523dd\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12384\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks with Normalization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks from Start to Finish - Lab\" href=\"assignments/g499e8e49f89e304b98ba1a620123f8a3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12385\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks from Start to Finish - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 203px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNetwork Evaluation and Regularization\u003c/em\u003e Lecture, Before \u003cem\u003eConvolutional Neural Networks\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Network Regularization and Evaluation Exit Ticket\" href=\"quizzes/g4298ef63270d7a1a95ee2a490732081d\"\u003eNetwork Regularization and Evaluation Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Convolutional Neural Networks\" href=\"pages/convolutional-neural-networks\"\u003eConvolutional Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Convolutional Neural Networks - Codealong\" href=\"assignments/g546a70919f77202cb729711ea35833d7\"\u003eConvolutional Neural Networks - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Building a CNN from Scratch\" href=\"assignments/gc0c371179354c474eb62d3e35ada83d6\"\u003eBuilding a CNN from Scratch\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Visualizing Intermediate Activations\" href=\"assignments/g133398f3cf3addbcc4503103ffaa1031\"\u003eVisualizing Intermediate Activations\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Visualizing Activation Functions - Lab\" href=\"assignments/gcd231132357b7197c79a1dd8aa04b47c\"\u003eVisualizing Activation Functions - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 80px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eConvolutional Neural Networks\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"CNNs Exit Ticket\" href=\"quizzes/g8714088b2a6bd1ad813141f7a91f909c\"\u003e\u003cstrong\u003eCNNs Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks - Recap\" href=\"pages/tuning-neural-networks-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-recap\" data-api-returntype=\"Page\"\u003eTuning Neural Networks - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-39-lesson-priorities-live"},{"id":458466,"title":"Tuning Neural Networks - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-intro-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-intro-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-intro-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have a general sense of the architecture of neural networks and some of their underlying concepts, its time to further investigate how to properly tune a model for optimal performance.\u003c/p\u003e\n\n\u003ch2\u003eRegularization\u003c/h2\u003e\n\n\u003cp\u003eYou've seen regularization before in many other models including linear regression. For example, recall the L1 and L2 penalties which modify ordinary linear regression. These updated loss functions can help tune models so they do not overfit to the training data. For neural networks, you'll use a surprisingly similar process in order to achieve well trained models that are neither overfit nor underfit.\u003c/p\u003e\n\n\u003ch2\u003eNormalization\u003c/h2\u003e\n\n\u003cp\u003eAnother modeling problem occurs when one gets trapped into a local minimum when searching for an optimal solution using an iterative approach such as gradient descent. One technique for counteracting this scenario is normalizing features. Normalization in deep learning models can drastically decrease computation time, mitigate common issues such as vanishing or exploding gradients, and increase model performance.\u003c/p\u003e\n\n\u003ch3\u003eOptimization\u003c/h3\u003e\n\n\u003cp\u003eYou'll also look at alternative optimization algorithms. These are of primary interest when one encounters local minimum. Knowing when one has hit such a pitfall can be challenging and typically requires experimenting with different optimization approaches and learning rates.\u003c/p\u003e\n\n\u003ch2\u003eConvolutional Neural Networks\u003c/h2\u003e\n\n\u003cp\u003eThere are several issues when using densely connected neural networks on image data. Firstly, dense layers learn global patterns rather than local patterns, and densely connected networks can really grow very big if we have high resolution images. In this section, you'll see why Convolutional Neural Networks are often preferred over densely connected networks for image processing. Additionally, you'll learn what a convolution operation is, the different building blocks of convolutional neural networks (including filters, padding schemes, strided convolutions, etc.), and the types of network layers that are part of your convolutional neural networks.\u003c/p\u003e\n\n\u003ch3\u003eBuilding a CNN from Scratch\u003c/h3\u003e\n\n\u003cp\u003eOnce you understand how CNNs work, you'll practice building one from scratch. You'll learn how to preprocess your image data so your model can be trained using Keras. Just like with densely connected networks, Keras provides an extremely user-friendly tool to build CNNs.\u003c/p\u003e\n\n\u003ch3\u003eVisualizing Intermediate Activations\u003c/h3\u003e\n\n\u003cp\u003eAs with densely connected networks, CNNs are complicated networks that are considered a \"black box\" tool with little insight in what's happening in the network layers. However, when using CNNs, you're essentially changing your image through filters in every layer. You'll learn to get some insight in your black box models by visualizing the intermediate layers in your CNNs!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll extend your deep learning knowledge by learning about regularization, normalization, and convolutional neural networks.\u003c/p\u003e","exportId":"tuning-neural-networks-introduction"},{"id":458469,"title":"Tuning Neural Networks with Regularization","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-regularization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've learned about neural networks and some streamlined methods for building such models, it's time to further explore how to tune and optimize the performance of these networks. One important aspect is reducing the time and resources needed to train these models. In previous lessons, when importing the Santa images, you immediately reduced each image to an extremely pixelated 64x64 representation. On top of that, you further down-sampled the dataset to reduce the number of observations. This was because training neural networks is resource intensive and is often a time consuming process as a result. Typically you also want to improve the accuracy and performance of these models. In this lesson, you will begin to examine various techniques related to these goals, beginning with the discussion of validation sets.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the relationship between bias and variance in neural networks\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eExplain how regularization affects the nodes of a neural network \u003c/li\u003e\n\u003cli\u003eExplain L1, L2, and dropout regularization in a neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eHyperparameters and iterative deep learning\u003c/h2\u003e\n\n\u003cp\u003eFirst, there are many hyperparameters you can tune. These include: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003enumber of hidden units\u003c/li\u003e\n\u003cli\u003enumber of layers\u003c/li\u003e\n\u003cli\u003elearning rate ( \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e )\u003c/li\u003e\n\u003cli\u003eactivation function\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe question then becomes, how do you choose these parameters? One primary method is to develop validation sets to strike a balance between specificity and generalization. \u003c/p\u003e\n\n\u003ch2\u003eTraining, Validation, and Test Sets\u003c/h2\u003e\n\n\u003cp\u003eWhen tuning neural networks it typically helps to split the data into three distinct partitions as follows:\n- You train algorithms on the training set\n- You'll use a validation set to decide which one will be your final model after parameter tuning\n- After having chosen the final model (and having evaluated long enough), you'll use the test set to get an unbiased estimate of the classification performance (or whatever your evaluation metric will be)  \u003c/p\u003e\n\n\u003cp\u003eRemember that it is \u003cstrong\u003eVERY IMPORTANT\u003c/strong\u003e to make sure that the holdout (validation) and test samples come from the same distribution: e.g. same resolution of Santa pictures. \u003c/p\u003e\n\n\u003ch2\u003eBias and Variance in Deep Learning\u003c/h2\u003e\n\n\u003cp\u003eFinding a balance between generalization and specificity is at the heart of the bias-variance trade off. To further examine this process for tuning neural networks, let's return to a simple example you've seen before. \u003c/p\u003e\n\n\u003ch3\u003eThe Circles Example\u003c/h3\u003e\n\n\u003cp\u003eIn classical machine learning, you often need to consider \"bias-variance trade-off\". You'll investigate these concepts here, and see how deep learning is slightly different and a trade-off isn't always present!\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eBias = underfitting\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eHigh variance = overfitting\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eGood fit --\u0026gt; somewhere in between \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTo start, take another look at the two circles data, the data looked like this: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/example.png\" alt=\"scatter plot showing two concentric circles\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRecall that you fit a logistic regression model to the data here. You got something that looked like the picture below. The model didn't do a particularly good job at discriminating between the yellow and purple dots. You could say this is a model with a \u003cstrong\u003ehigh bias\u003c/strong\u003e, the model is \u003cstrong\u003eunderfitting\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/underfitting.png\" alt=\"graph with concentric circles, this time partitioned in two by a single diagonal line\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen using a neural network, what you reached in the end was a pretty good decision boundary, a circle discriminating between the yellow and purple dots: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/good.png\" alt=\"the same graph, this time with an inner circle and outer area partition\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAt the other end of the spectrum, you might experience \u003cstrong\u003eoverfitting\u003c/strong\u003e, where you create a circle which is super sensitive to small deviations of the colored dots, like the example below. You can also call this a model with \u003cstrong\u003ehigh variance\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/overfitting.png\" alt=\"the same graph, this time with an inner and outer circle with more wiggly lines\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eThe Santa Example\u003c/h2\u003e\n\n\u003cp\u003e\n \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/S_4.jpg\" alt=\"Santa image\" style=\"height: 220px;\"\u003e \n \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/NS_1.jpg\" alt=\"Not Santa image\" style=\"height: 220px;\"\u003e \n \u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eHigh variance\u003c/th\u003e\n\u003cth\u003eHigh bias\u003c/th\u003e\n\u003cth\u003eHigh variance \u0026amp; bias\u003c/th\u003e\n\u003cth\u003eLow variance and bias\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003etrain set error\u003c/td\u003e\n\u003ctd\u003e12%\u003c/td\u003e\n\u003ctd\u003e26%\u003c/td\u003e\n\u003ctd\u003e26%\u003c/td\u003e\n\u003ctd\u003e12%\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003evalidation set error\u003c/td\u003e\n\u003ctd\u003e25%\u003c/td\u003e\n\u003ctd\u003e28%\u003c/td\u003e\n\u003ctd\u003e40%\u003c/td\u003e\n\u003ctd\u003e13%\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eAssume that our best model can get to a validation set accuracy of 87%. Note that \"high\" and \"low\" are relative! Also, in deep learning there is less of a bias variance trade-off! \u003c/p\u003e\n\n\u003ch2\u003eRules of Thumb Regarding Bias / Variance\u003c/h2\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eHigh Bias? (training performance)\u003c/th\u003e\n\u003cth\u003eHigh variance? (validation performance)\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eUse a bigger network\u003c/td\u003e\n\u003ctd\u003eMore data\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTrain longer\u003c/td\u003e\n\u003ctd\u003eRegularization\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLook for other existing NN architectures\u003c/td\u003e\n\u003ctd\u003eLook for other existing NN architectures\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003ch2\u003eRegularization\u003c/h2\u003e\n\n\u003cp\u003eUse regularization when the model overfits to the data. \u003c/p\u003e\n\n\u003ch3\u003eL1 and L2 regularization\u003c/h3\u003e\n\n\u003ch4\u003eIn logistic regression\u003c/h4\u003e\n\n\u003cp\u003eLet's look back at the logistic regression example with lambda, a regularization parameter (another hyperparameter you have to tune).\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" J (w,b) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}||w||_2^2\" src=\"/equation_images/%20J%20(w,b)%20=%20%255Cdfrac{1}{m}%20%255Csum^m_{i=1}%255Cmathcal{L}(%255Chat%20y^{(i)},%20y^{(i)})+%20%255Cdfrac{%255Clambda}{2m}||w||_2^2\" alt=\"{\" data-equation-content=\" J (w,b) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}||w||_2^2\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"||w||\u003cem\u003e2^2 = \\sum^{n_x}\u003c/em\u003e{j=1}w_j^2= w^Tw\" src=\"/equation_images/||w||\u003cem\u003e2^2%20=%20%255Csum^{n_x}\u003c/em\u003e{j=1}w_j^2=%20w^Tw\" alt=\"{\"\u003e2^2 = \\sum^{n_x}{j=1}w_j^2= w^Tw}' data-equation-content='||w||\u003cem\u003e2^2 = \\sum^{n_x}\u003c/em\u003e{j=1}w_j^2= w^Tw' /\u0026gt;\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is called L2-regularization. You can also add a regularization term for \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e, but \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e is just one parameter. L2-regularization is the most common type of regularization.\u003c/p\u003e\n\n\u003cp\u003eL1-regularization is where you just add a term:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\dfrac{\\lambda}{m}||w||_1\" src=\"/equation_images/%20%255Cdfrac{%255Clambda}{m}||w||_1\" alt=\"{\" data-equation-content=\" \\dfrac{\\lambda}{m}||w||_1\"\u003e\u003c/p\u003e (could also be 2 in the denominator)\u003cp\u003e\u003c/p\u003e\n\n\u003ch4\u003eIn a neural network\u003c/h4\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" J (w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}\\sum^L_{l=1}||w^{[l]}||^2\" src=\"/equation_images/%20J%20(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]})%20=%20%255Cdfrac{1}{m}%20%255Csum^m_{i=1}%255Cmathcal{L}(%255Chat%20y^{(i)},%20y^{(i)})+%20%255Cdfrac{%255Clambda}{2m}%255Csum^L_{l=1}||w^{[l]}||^2\" alt=\"{\" data-equation-content=\" J (w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}\\sum^L_{l=1}||w^{[l]}||^2\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"||w^{[l]}||^2 = \\sum^{n^{[l-1]}}\u003cem\u003e{i=1} \\sum^{n^{[l]}}\u003c/em\u003e{j=1} (w_{ij}^{[l]})^2\" src=\"/equation_images/||w^{[l]}||^2%20=%20%255Csum^{n^{[l-1]}}\u003cem\u003e{i=1}%20%255Csum^{n^{[l]}}\u003c/em\u003e{j=1}%20(w_{ij}^{[l]})^2\" alt=\"{\"\u003e{i=1} \\sum^{n^{[l]}}{j=1} (w_{ij}^{[l]})^2}' data-equation-content='||w^{[l]}||^2 = \\sum^{n^{[l-1]}}\u003cem\u003e{i=1} \\sum^{n^{[l]}}\u003c/em\u003e{j=1} (w_{ij}^{[l]})^2' /\u0026gt;\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThis matrix norm is called the \"Frobenius norm\", also referred to as \u003cimg class=\"equation_image\" title=\"||w^{[l]}||^2 _F\" src=\"/equation_images/||w^{[l]}||^2%20_F\" alt=\"{\" data-equation-content=\"||w^{[l]}||^2 _F\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHow does backpropagation change now?\u003c/p\u003e\n\n\u003cp\u003eWhichever expression you have from the backpropagation, and add \u003cimg class=\"equation_image\" title=\"\\dfrac{\\lambda}{m} w^{[l]}\" src=\"/equation_images/%255Cdfrac{%255Clambda}{m}%20w^{[l]}\" alt=\"{\" data-equation-content=\"\\dfrac{\\lambda}{m} w^{[l]}\"\u003e.\nSo,\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"dw^{[l]} = \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\" src=\"/equation_images/dw^{[l]}%20=%20%255Ctext{[backpropagation%20derivatives]%20}+%20%255Cdfrac{%255Clambda}{m}%20w^{[l]}\" alt=\"{\" data-equation-content=\"dw^{[l]} = \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\"\u003e\u003c/p\u003e \u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eAfterwards, \u003cimg class=\"equation_image\" title=\"w^{[l]}\" src=\"/equation_images/w^{[l]}\" alt=\"{\" data-equation-content=\"w^{[l]}\"\u003e is updated again as \u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\alpha dw^{[l]} \" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Calpha%20dw^{[l]}\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\alpha dw^{[l]} \"\u003e\u003c/p\u003e\n\n\u003cp\u003eL2-regularization is called weight decay, because regularization will make your load smaller:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\alpha \\bigr( \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\\bigr)\" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Calpha%20%255Cbigr(%20%255Ctext{[backpropagation%20derivatives]%20}+%20%255Cdfrac{%255Clambda}{m}%20w^{[l]}%255Cbigr)\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\alpha \\bigr( \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\\bigr)\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\dfrac{\\alpha\\lambda}{m}w^{[l]} - \\alpha \\text{[backpropagation derivatives]}\" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Cdfrac{%255Calpha%255Clambda}{m}w^{[l]}%20-%20%255Calpha%20%255Ctext{[backpropagation%20derivatives]}\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\dfrac{\\alpha\\lambda}{m}w^{[l]} - \\alpha \\text{[backpropagation derivatives]}\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eHence your weights will become smaller by a factor \u003cimg class=\"equation_image\" title=\"\\bigr(1- \\dfrac{\\alpha\\lambda}{m}\\bigr)\" src=\"/equation_images/%255Cbigr(1-%20%255Cdfrac{%255Calpha%255Clambda}{m}%255Cbigr)\" alt=\"{\" data-equation-content=\"\\bigr(1- \\dfrac{\\alpha\\lambda}{m}\\bigr)\"\u003e.\u003c/p\u003e\n\n\u003cp\u003eIntuition for regularization: the weight matrices will be penalized from being too large. Actually, the network will be forced to almost be simplified.\u003c/p\u003e\n\n\u003cp\u003eAlso: e.g., \u003cem\u003etanh\u003c/em\u003e function, if \u003cimg class=\"equation_image\" title=\"w\" src=\"https://learning.flatironschool.com/equation_images/w\" alt=\"{\" data-equation-content=\"w\"\u003e is small, the activation function will be mostly operating in the linear region and not \"explode\" as easily.\u003c/p\u003e\n\n\u003ch2\u003eDropout Regularization\u003c/h2\u003e\n\n\u003cp\u003eWhen you apply the Dropout technique, a random subset of nodes (also called the units) in a layer are ignored (their weights set to zero) during each phase of training. Below is an image from the \u003ca href=\"http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\"\u003eoriginal paper\u003c/a\u003e that introduced this technique. \u003c/p\u003e\n\n\u003cp\u003eOn the left you can see a standard neural network with four layers (one input layer, two hidden layers, and an output layer). On the right, you can see the network after Dropout is applied during one step of training. This technique is very effective because it allows us to train neural networks on different parts of the data, thus ensuring that our model is not overly sensitive noise in the data. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/dropout.png\" alt=\"Left: a standard neural net with 2 hidden layers. Right: An example of a thinned net produced by applying dropout to the network on the left.\"\u003e \u003c/p\u003e\n\n\u003cp\u003eIn Keras, you specify \u003cem\u003eDropout\u003c/em\u003e using the \u003ccode\u003eDropout\u003c/code\u003e layer, which is applied to input and hidden layers. The \u003ccode\u003eDropout\u003c/code\u003e layers requires one argument, \u003ccode\u003erate\u003c/code\u003e, which specifies the fraction of units to drop, usually between 0.2 and 0.5. \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodels\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSequential\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'relu'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einput_shape\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,)))\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Dropout applied to the input layer\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDropout\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'relu'\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Dropout applied to the hidden layer\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDropout\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'sigmoid'\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn different iterations through the training set, different nodes will be zeroed out!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you began to explore how to further tune and optimize out of the box neural networks built with Keras. This included regularization analogous to previous machine learning work you've seen, as well dropout regularization, which can be used to further prune your networks. In the upcoming lab you'll get a chance to experiment with these concepts in practice and observe their effect on your models outputs. \u003c/p\u003e","exportId":"tuning-neural-networks-with-regularization"},{"id":458473,"title":"Tuning Neural Networks with Regularization - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-regularization-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply early stopping criteria with a neural network \u003c/li\u003e\n\u003cli\u003eApply L1, L2, and dropout regularization on a neural network\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eExamine the effects of training with more data on a neural network\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g44969ffff4b33b816b9daba862417b65"},{"id":458477,"title":"Tuning Neural Networks with Normalization","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-normalization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we've investigated some methods for tuning our networks, we will investigate some further methods and concepts regarding reducing training time. These concepts will begin to form a more cohesive framework for choices along the modeling process.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what normalization does to training time with neural networks and why \u003c/li\u003e\n\u003cli\u003eExplain what a vanishing or exploding gradient is, and how it is related to model convergence \u003c/li\u003e\n\u003cli\u003eCompare the different optimizer strategies for neural networks \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eNormalized Inputs: Speed up Training\u003c/h2\u003e\n\n\u003cp\u003eOne way to speed up training of your neural networks is to normalize the input. In fact, even if training time were not a concern, normalization to a consistent scale (typically 0 to 1) across features should be used to ensure that the process converges to a stable solution. Similar to some of our previous work in training models, one general process for standardizing our data is subtracting the mean and dividing by the standard deviation. \u003c/p\u003e\n\n\u003ch2\u003eVanishing or Exploding Gradients\u003c/h2\u003e\n\n\u003cp\u003eNot only will normalizing your inputs speed up training, it can also mitigate other risks inherent in training neural networks. For example, in a neural network, having input of various ranges can lead to difficult numerical problems when the algorithm goes to compute gradients during forward and back propagation. This can lead to untenable solutions and will prevent the algorithm from converging to a solution. In short, make sure you normalize your data! Here's a little more mathematical background: \u003c/p\u003e\n\n\u003cp\u003eTo demonstrate, imagine a very deep neural network. Assume \u003cimg class=\"equation_image\" title=\"g(z)=z\" src=\"https://learning.flatironschool.com/equation_images/g(z)=z\" alt=\"{\" data-equation-content=\"g(z)=z\"\u003e (so no transformation, just a linear activation function), and biases equal to 0. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\hat y = w^{[L]}w^{[L-1]}w^{[L-2]}... w^{[3]}w^{[2]}w^{[1]}x\" src=\"/equation_images/%255Chat%20y%20=%20w^{[L]}w^{[L-1]}w^{[L-2]}...%20w^{[3]}w^{[2]}w^{[1]}x\" alt=\"{\" data-equation-content=\"\\hat y = w^{[L]}w^{[L-1]}w^{[L-2]}... w^{[3]}w^{[2]}w^{[1]}x\"\u003e \u003c/p\u003e\n\n\u003cp\u003erecall that \u003cimg class=\"equation_image\" title=\"z^{[1]} =w^{[1]}x \" src=\"/equation_images/z^{[1]}%20=w^{[1]}x\" alt=\"{\" data-equation-content=\"z^{[1]} =w^{[1]}x \"\u003e, and that \u003cimg class=\"equation_image\" title=\"a^{[1]}=g(z^{[1]})=z^{[1]}\" src=\"/equation_images/a^{[1]}=g(z^{[1]})=z^{[1]}\" alt=\"{\" data-equation-content=\"a^{[1]}=g(z^{[1]})=z^{[1]}\"\u003e\u003c/p\u003e\n\n\u003cp\u003esimilarly, \u003cimg class=\"equation_image\" title=\"a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\" src=\"/equation_images/a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\" alt=\"{\" data-equation-content=\"a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003eImagine two nodes in each layer, and w =  \u003cimg class=\"equation_image\" title=\"\\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}\" src=\"/equation_images/%255Cbegin{bmatrix}%201.3%20\u0026amp;%200%20%255C%200%20\u0026amp;%201.3%20%255Cend{bmatrix}\" alt=\"{\" data-equation-content=\"\\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}\"\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\hat y = w^{[L]} \\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}^{L-1}   x\" src=\"/equation_images/%255Chat%20y%20=%20w^{[L]}%20%255Cbegin{bmatrix}%201.3%20\u0026amp;%200%20%255C%200%20\u0026amp;%201.3%20%255Cend{bmatrix}^{L-1}%20%20%20x\" alt=\"{\" data-equation-content=\"\\hat y = w^{[L]} \\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}^{L-1}   x\"\u003e\u003c/p\u003e\n\n\u003cp\u003eEven if the \u003cimg class=\"equation_image\" title=\"w\" src=\"https://learning.flatironschool.com/equation_images/w\" alt=\"{\" data-equation-content=\"w\"\u003e's are slightly smaller than 1 or slightly larger, the activations will explode when there are many layers in the network!   \u003c/p\u003e\n\n\u003ch2\u003eOther Solutions to Vanishing and Exploding Gradients\u003c/h2\u003e\n\n\u003cp\u003eAside from normalizing the data, you can also investigate the impact of changing the initialization parameters when you first launch the gradient descent algorithm. \u003c/p\u003e\n\n\u003cp\u003eFor initialization, the more input features feeding into layer l, the smaller you want each \u003cimg class=\"equation_image\" title=\"w_i\" src=\"https://learning.flatironschool.com/equation_images/w_i\" alt=\"{\" data-equation-content=\"w_i\"\u003e to be.   \u003c/p\u003e\n\n\u003cp\u003eA common rule of thumb is:   \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Var(w_i) = 1/n \" src=\"https://learning.flatironschool.com/equation_images/Var(w_i)%20=%201/n\" alt=\"{\" data-equation-content=\"Var(w_i) = 1/n \"\u003e  \u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Var(w_i) = 2/n\" src=\"https://learning.flatironschool.com/equation_images/Var(w_i)%20=%202/n\" alt=\"{\" data-equation-content=\"Var(w_i) = 2/n\"\u003e  \u003c/p\u003e\n\n\u003cp\u003eOne common initialization strategy for the relu activation function is:  \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ew^{[l]} = np.random.randn(shape)*np.sqrt(2/n_(l-1)) \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eLater, we'll discuss other initialization strategies pertinent to other activation functions.\u003c/p\u003e\n\n\u003ch2\u003eOptimization\u003c/h2\u003e\n\n\u003cp\u003eIn addition, you could even use an alternative convergence algorithm instead of gradient descent. One issue with gradient descent is that it oscillates to a fairly big extent, because the derivative is bigger in the vertical direction.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization/master/images/new_optimizer.png\" alt=\"oscillating gradient descent\" width=\"600\"\u003e  \u003c/p\u003e\n\n\u003cp\u003eWith that, here are some optimization algorithms that work faster than gradient descent:\u003c/p\u003e\n\n\u003ch3\u003eGradient Descent with Momentum\u003c/h3\u003e\n\n\u003cp\u003eCompute an exponentially weighted average of the gradients and use that gradient instead. The intuitive interpretation is that this will successively dampen oscillations, improving convergence.\u003c/p\u003e\n\n\u003cp\u003eMomentum: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"dW\" src=\"https://learning.flatironschool.com/equation_images/dW\" alt=\"{\" data-equation-content=\"dW\"\u003e and \u003cimg class=\"equation_image\" title=\"db\" src=\"https://learning.flatironschool.com/equation_images/db\" alt=\"{\" data-equation-content=\"db\"\u003e on the current minibatch \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"V_{dw} = \\beta V_{dw} + (1-\\beta)dW\" src=\"/equation_images/V_{dw}%20=%20%255Cbeta%20V_{dw}%20+%20(1-%255Cbeta)dW\" alt=\"{\" data-equation-content=\"V_{dw} = \\beta V_{dw} + (1-\\beta)dW\"\u003e and\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"V_{db} = \\beta V_{db} + (1-\\beta)db\" src=\"/equation_images/V_{db}%20=%20%255Cbeta%20V_{db}%20+%20(1-%255Cbeta)db\" alt=\"{\" data-equation-content=\"V_{db} = \\beta V_{db} + (1-\\beta)db\"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cem\u003eThese are the moving averages for the derivatives of \u003cimg class=\"equation_image\" title=\"W\" src=\"https://learning.flatironschool.com/equation_images/W\" alt=\"{\" data-equation-content=\"W\"\u003e and \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha Vdw\" src=\"https://learning.flatironschool.com/equation_images/W:=%20W-%20%255Calpha%20Vdw\" alt=\"{\" data-equation-content=\"W:= W- \\alpha Vdw\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha Vdb\" src=\"https://learning.flatironschool.com/equation_images/b:=%20b-%20%255Calpha%20Vdb\" alt=\"{\" data-equation-content=\"b:= b- \\alpha Vdb\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThis averages out gradient descent, and will \"dampen\" oscillations. Generally, \u003cimg class=\"equation_image\" title=\"\\beta=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta=0.9\" alt=\"{\" data-equation-content=\"\\beta=0.9\"\u003e is a good hyperparameter value.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch3\u003eRMSprop\u003c/h3\u003e\n\n\u003cp\u003eRMSprop stands for \"root mean square\" prop. It slows down learning in one direction and speed up in another one. On each iteration, it uses exponentially weighted average of the squares of the derivatives. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{dw} = \\beta S_{dw} + (1-\\beta)dW^2\" src=\"/equation_images/S_{dw}%20=%20%255Cbeta%20S_{dw}%20+%20(1-%255Cbeta)dW^2\" alt=\"{\" data-equation-content=\"S_{dw} = \\beta S_{dw} + (1-\\beta)dW^2\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{db} = \\beta S_{dw} + (1-\\beta)db^2\" src=\"/equation_images/S_{db}%20=%20%255Cbeta%20S_{dw}%20+%20(1-%255Cbeta)db^2\" alt=\"{\" data-equation-content=\"S_{db} = \\beta S_{dw} + (1-\\beta)db^2\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}\" src=\"/equation_images/W:=%20W-%20%255Calpha%20%255Cdfrac{dw}{%255Csqrt{S_{dw}}}\" alt=\"{\" data-equation-content=\"W:= W- \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}\"\u003e and\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha \\dfrac{db}{\\sqrt{S_{db}}}\" src=\"/equation_images/b:=%20b-%20%255Calpha%20%255Cdfrac{db}{%255Csqrt{S_{db}}}\" alt=\"{\" data-equation-content=\"b:= b- \\alpha \\dfrac{db}{\\sqrt{S_{db}}}\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the direction where we want to learn fast, the corresponding \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e will be small, so dividing by a small number. On the other hand, in the direction where we will want to learn slow, the corresponding \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e will be relatively large, and updates will be smaller. \u003c/p\u003e\n\n\u003cp\u003eOften, add small \u003cimg class=\"equation_image\" title=\"\\epsilon\" src=\"https://learning.flatironschool.com/equation_images/%255Cepsilon\" alt=\"{\" data-equation-content=\"\\epsilon\"\u003e in the denominator to make sure that you don't end up dividing by 0.\u003c/p\u003e\n\n\u003ch3\u003eAdam Optimization Algorithm\u003c/h3\u003e\n\n\u003cp\u003e\"Adaptive Moment Estimation\", basically using the first and second moment estimations. Works very well in many situations! It takes momentum and RMSprop to put it together!\u003c/p\u003e\n\n\u003cp\u003eInitialize:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0\" src=\"/equation_images/V_{dw}=0,%20S_{dw}=0,%20V_{db}=0,%20S_{db}=0\" alt=\"{\" data-equation-content=\"V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0\"\u003e \u003c/p\u003e\n\n\u003cp\u003eFor each iteration:\u003c/p\u003e\n\n\u003cp\u003eCompute \u003cimg class=\"equation_image\" title=\"dW, db\" src=\"https://learning.flatironschool.com/equation_images/dW,%20db\" alt=\"{\" data-equation-content=\"dW, db\"\u003e using the current mini-batch: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dW\" src=\"/equation_images/V_{dw}%20=%20%255Cbeta_1%20V_{dw}%20+%20(1-%255Cbeta_1)dW\" alt=\"{\" data-equation-content=\"V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dW\"\u003e, \u003cimg class=\"equation_image\" title=\"V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db\" src=\"/equation_images/V_{db}%20=%20%255Cbeta_1%20V_{db}%20+%20(1-%255Cbeta_1)db\" alt=\"{\" data-equation-content=\"V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db\"\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dW^2\" src=\"/equation_images/S_{dw}%20=%20%255Cbeta_2%20S_{dw}%20+%20(1-%255Cbeta_2)dW^2\" alt=\"{\" data-equation-content=\"S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dW^2\"\u003e, \u003cimg class=\"equation_image\" title=\"S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2\" src=\"/equation_images/S_{db}%20=%20%255Cbeta_2%20S_{db}%20+%20(1-%255Cbeta_2)db^2\" alt=\"{\" data-equation-content=\"S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2\"\u003e \u003c/p\u003e\n\n\u003cp\u003eIt's like momentum and then RMSprop. We need to perform a correction! This is sometimes also done in RSMprop, but definitely here too.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V^{corr}\u003cem\u003e{dw}= \\dfrac{V\u003c/em\u003e{dw}}{1-\\beta_1^t}\" src=\"/equation_images/V^{corr}\u003cem\u003e{dw}=%20%255Cdfrac{V\u003c/em\u003e{dw}}{1-%255Cbeta_1^t}\" alt=\"{\"\u003e{dw}= \\dfrac{V{dw}}{1-\\beta_1^t}}' data-equation-content='V^{corr}\u003cem\u003e{dw}= \\dfrac{V\u003c/em\u003e{dw}}{1-\\beta_1^t}' /\u0026gt;, \u003cimg class=\"equation_image\" title=\"V^{corr}\u003cem\u003e{db}= \\dfrac{V\u003c/em\u003e{db}}{1-\\beta_1^t}\" src=\"/equation_images/V^{corr}\u003cem\u003e{db}=%20%255Cdfrac{V\u003c/em\u003e{db}}{1-%255Cbeta_1^t}\" alt=\"{\"\u003e{db}= \\dfrac{V{db}}{1-\\beta_1^t}}' data-equation-content='V^{corr}\u003cem\u003e{db}= \\dfrac{V\u003c/em\u003e{db}}{1-\\beta_1^t}' /\u0026gt;\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S^{corr}\u003cem\u003e{dw}= \\dfrac{S\u003c/em\u003e{dw}}{1-\\beta_2^t}\" src=\"/equation_images/S^{corr}\u003cem\u003e{dw}=%20%255Cdfrac{S\u003c/em\u003e{dw}}{1-%255Cbeta_2^t}\" alt=\"{\"\u003e{dw}= \\dfrac{S{dw}}{1-\\beta_2^t}}' data-equation-content='S^{corr}\u003cem\u003e{dw}= \\dfrac{S\u003c/em\u003e{dw}}{1-\\beta_2^t}' /\u0026gt;, \u003cimg class=\"equation_image\" title=\"S^{corr}\u003cem\u003e{db}= \\dfrac{S\u003c/em\u003e{db}}{1-\\beta_2^t}\" src=\"/equation_images/S^{corr}\u003cem\u003e{db}=%20%255Cdfrac{S\u003c/em\u003e{db}}{1-%255Cbeta_2^t}\" alt=\"{\"\u003e{db}= \\dfrac{S{db}}{1-\\beta_2^t}}' data-equation-content='S^{corr}\u003cem\u003e{db}= \\dfrac{S\u003c/em\u003e{db}}{1-\\beta_2^t}' /\u0026gt;\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha \\dfrac{V^{corr}\u003cem\u003e{dw}}{\\sqrt{S^{corr}\u003c/em\u003e{dw}+\\epsilon}}\" src=\"/equation_images/W:=%20W-%20%255Calpha%20%255Cdfrac{V^{corr}\u003cem\u003e{dw}}{%255Csqrt{S^{corr}\u003c/em\u003e{dw}+%255Cepsilon}}\" alt=\"{\"\u003e{dw}}{\\sqrt{S^{corr}{dw}+\\epsilon}}}' data-equation-content='W:= W- \\alpha \\dfrac{V^{corr}\u003cem\u003e{dw}}{\\sqrt{S^{corr}\u003c/em\u003e{dw}+\\epsilon}}' /\u0026gt; and\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha \\dfrac{V^{corr}\u003cem\u003e{db}}{\\sqrt{S^{corr}\u003c/em\u003e{db}+\\epsilon}}\" src=\"/equation_images/b:=%20b-%20%255Calpha%20%255Cdfrac{V^{corr}\u003cem\u003e{db}}{%255Csqrt{S^{corr}\u003c/em\u003e{db}+%255Cepsilon}}\" alt=\"{\"\u003e{db}}{\\sqrt{S^{corr}{db}+\\epsilon}}}' data-equation-content='b:= b- \\alpha \\dfrac{V^{corr}\u003cem\u003e{db}}{\\sqrt{S^{corr}\u003c/em\u003e{db}+\\epsilon}}' /\u0026gt;  \u003c/p\u003e\n\n\u003cp\u003eHyperparameters: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\beta_1 = 0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_1%20=%200.9\" alt=\"{\" data-equation-content=\"\\beta_1 = 0.9\"\u003e\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\beta_2 = 0.999\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_2%20=%200.999\" alt=\"{\" data-equation-content=\"\\beta_2 = 0.999\"\u003e\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\epsilon = 10^{-8}\" src=\"/equation_images/%255Cepsilon%20=%2010^{-8}\" alt=\"{\" data-equation-content=\"\\epsilon = 10^{-8}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eGenerally, only \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e gets tuned.\u003c/p\u003e\n\n\u003ch3\u003eLearning Rate Decay\u003c/h3\u003e\n\n\u003cp\u003eLearning rate decreases across epochs.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = \\dfrac{1}{1+\\text{decay_rate * epoch_nb}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%20%255Cdfrac{1}{1+%255Ctext{decay_rate%20*%20epoch_nb}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = \\dfrac{1}{1+\\text{decay_rate * epoch_nb}}* \\alpha_0\"\u003e\u003c/p\u003e\n\n\u003cp\u003eother methods:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = 0.97 ^{\\text{epoch_nb}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%200.97%20^{%255Ctext{epoch_nb}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = 0.97 ^{\\text{epoch_nb}}* \\alpha_0\"\u003e (or exponential decay)\u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = \\dfrac{k}{\\sqrt{\\text{epoch_nb}}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%20%255Cdfrac{k}{%255Csqrt{%255Ctext{epoch_nb}}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = \\dfrac{k}{\\sqrt{\\text{epoch_nb}}}* \\alpha_0\"\u003e\u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003eManual decay!\u003c/p\u003e\n\n\u003ch2\u003eHyperparameter Tuning\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen some optimization algorithms, take another look at all the hyperparameters that need tuning: \u003c/p\u003e\n\n\u003cp\u003eMost important:\n- \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNext:\n- \u003cimg class=\"equation_image\" title=\"\\beta\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta\" alt=\"{\" data-equation-content=\"\\beta\"\u003e (momentum)\n- Number of hidden units\n- mini-batch-size\u003c/p\u003e\n\n\u003cp\u003eFinally:\n- Number of layers\n- Learning rate decay\u003c/p\u003e\n\n\u003cp\u003eAlmost never tuned:\n- \u003cimg class=\"equation_image\" title=\"\\beta_1\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_1\" alt=\"{\" data-equation-content=\"\\beta_1\"\u003e, \u003cimg class=\"equation_image\" title=\"\\beta_2\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_2\" alt=\"{\" data-equation-content=\"\\beta_2\"\u003e, \u003cimg class=\"equation_image\" title=\"\\epsilon\" src=\"https://learning.flatironschool.com/equation_images/%255Cepsilon\" alt=\"{\" data-equation-content=\"\\epsilon\"\u003e (Adam)\u003c/p\u003e\n\n\u003cp\u003eThings to do:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDon't use a grid, because hard to say in advance which hyperparameters will be important\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.coursera.org/learn/deep-neural-network/lecture/lXv6U/normalizing-inputs\"\u003ehttps://www.coursera.org/learn/deep-neural-network/lecture/lXv6U/normalizing-inputs\u003c/a\u003e \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum\"\u003ehttps://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum\u003c/a\u003e \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you began learning about issues regarding the convergence of neural networks training. This included the need for normalization as well as initialization parameters and some optimization algorithms. In the upcoming lab, you'll further investigate these ideas in practice and observe their impacts from various perspectives.\u003c/p\u003e","exportId":"tuning-neural-networks-with-normalization"},{"id":458481,"title":"Tuning Neural Networks with Normalization - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-normalization-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you'll build a neural network to perform a regression task.\u003c/p\u003e\n\n\u003cp\u003eIt is worth noting that getting regression to work with neural networks can be comparatively difficult because the output is unbounded (\u003cimg class=\"equation_image\" title=\"\\hat y\" src=\"https://learning.flatironschool.com/equation_images/%255Chat%20y\" alt=\"{\" data-equation-content=\"\\hat y\"\u003e can technically range from \u003cimg class=\"equation_image\" title=\"-\\infty\" src=\"https://learning.flatironschool.com/equation_images/-%255Cinfty\" alt=\"{\" data-equation-content=\"-\\infty\"\u003e to \u003cimg class=\"equation_image\" title=\"+\\infty\" src=\"https://learning.flatironschool.com/equation_images/+%255Cinfty\" alt=\"{\" data-equation-content=\"+\\infty\"\u003e), and the models are especially prone to exploding gradients. This issue makes a regression exercise the perfect learning case for tinkering with normalization and optimization strategies to ensure proper convergence!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eFit a neural network to normalized data \u003c/li\u003e\n\u003cli\u003eImplement and observe the impact of various initialization techniques \u003c/li\u003e\n\u003cli\u003eImplement and observe the impact of various optimization techniques \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g3f1caffeac6631bd5eec966c32c523dd"},{"id":458484,"title":"Tuning and Optimizing Neural Networks - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've practiced regularization, initialization, and optimization techniques, its time to synthesize these concepts into a cohesive modeling pipeline.  \u003c/p\u003e\n\n\u003cp\u003eWith this pipeline, you will not only fit an initial model but also attempt to improve it. Your final model selection will pertain to the test metrics across these models. This will more naturally simulate a problem you might be faced with in practice, and the various modeling decisions you are apt to encounter along the way.  \u003c/p\u003e\n\n\u003cp\u003eRecall that our end objective is to achieve a balance between overfitting and underfitting. You've seen the bias variance trade-off, and the role of regularization in order to reduce overfitting on training data and improving generalization to new cases. Common frameworks for such a procedure include train/validate/test methodology when data is plentiful, and K-folds cross-validation for smaller, more limited datasets. In this lab, you'll perform the latter, as the dataset in question is fairly limited. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply normalization as a preprocessing technique \u003c/li\u003e\n\u003cli\u003eImplement a K-folds cross validation modeling pipeline for deep learning models \u003c/li\u003e\n\u003cli\u003eApply regularization techniques to improve your model's performance \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g499e8e49f89e304b98ba1a620123f8a3"},{"id":458498,"title":"Convolutional Neural Networks","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-convolutional-neural-networks\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eConvolutional Neural Networks (CNNs), build upon the fully connected neural networks you've seen to date. Since detailed images can have incredibly high dimensions based on the number of pixels, CNNs provide an alternative formulation for analyzing groups of pixels. Without the convolutional operation, fitting neural networks to medium to large images would be infeasible for all but the most powerful computers. For example, given a color image with 500 x 500 pixels, you would have 500 x 500 x 3 = 750,000 input features, \u003cimg class=\"equation_image\" title=\"(x_1,...,x_{750,000})\" src=\"/equation_images/(x_1,...,x_{750,000})\" alt=\"{\" data-equation-content=\"(x_1,...,x_{750,000})\"\u003e. \nFrom there, even having 2000 hidden units (3% of the input), in the first hidden layer, would result in roughly 1.5 billion parameters!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine what a convolution is, as it relates to CNNs \u003c/li\u003e\n\u003cli\u003eExplain how convolutions work using RGB images \u003c/li\u003e\n\u003cli\u003eDescribe what a pooling layer is in a neural network \u003c/li\u003e\n\u003cli\u003eExplain how padding works with convolution layers of a neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCNNs\u003c/h2\u003e\n\n\u003cp\u003eCNNs have certain features that identify patterns in images because of \"convolution operation\" including:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eDense layers learn global patterns in their input feature space\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eConvolution layers learn local patterns, and this leads to the following interesting features:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUnlike with densely connected networks, when a convolutional neural network recognizes a pattern in one region, these insights can be shared and applied to other regions.\u003c/li\u003e\n\u003cli\u003eDeeper convolutional neural networks can learn spatial hierarchies. A first layer will learn small local patterns, a second layer will learn larger patterns using features of the first layer patterns, etc. \u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBecause of these properties, CNNs are great for tasks like: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImage classification\u003c/li\u003e\n\u003cli\u003eObject detection in images\u003c/li\u003e\n\u003cli\u003ePicture neural style transfer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eBuilding CNNs in Keras\u003c/h2\u003e\n\n\u003cp\u003eBuilding a CNN in Keras is very similar to the previous neural networks that you've built to date. To start, you will initialize a sequential model as before and go on adding layers. However, rather then simply adding additional dense layers or dropouts between them, we will now start to investigate other potential layer architectures including convolutional layers.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/Image_158CNN.png\" alt=\"input image, convolutions, pooling, fully connected\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eThe Convolution Operation\u003c/h2\u003e\n\n\u003cp\u003eThe idea behind the convolutional operation is to detect complex building blocks, or features, that can aid in the larger task such as image recognition. For example, we'll detect vertical or horizontal edges present in the image. Let's look at what horizontal edge detection would look like: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/conv.png\" alt=\"one 5 by 5 grid, one 3 by 3 grid containing 1 1 1 0 0 0 -1 -1 -1\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is a simplified 5 x 5 pixel image (grayscale!). You use a so-called \"filter\" (denoted on the right) to perform a convolution operation. This particular filter operation will detect horizontal edges. The matrix in the left should have number in it (from 1-255, or let's assume we rescaled it to number 1-10). The output is a 3 x 3 matrix. (\u003cem\u003eThis example is for computational clarity, no clear edges\u003c/em\u003e)\u003c/p\u003e\n\n\u003cp\u003eIn Keras, function for the convolution step is \u003ccode\u003eConv2D\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe convolutional operation applies this filter (typically 3x3 or 5x5) to each possible 3x3 or 5x5 region of the original image. The graphic below demonstrates this process.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/convolution-layer-a.png\" alt=\"animation of filter operation across an image to create a smaller matrix output\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://stanford.edu/%7Eshervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\"\u003egif courtesy of Stanford University\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003ePadding\u003c/h2\u003e\n\n\u003cp\u003eThere are some issues with using filters on images including: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eThe image shrinks with each convolution layer: you're throwing away information in each layer! For example:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStarting from a 5 x 5 matrix, and using a 3 x 3 matrix, you end up with a 3 x 3 image\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eStarting from a 10 x 10 matrix, and using a 3 x 3 matrix, you end up with a 8 x 8 image, etc. \u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe pixels around the edges are used much less in the outputs due to the filter   \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor example, if you apply 3x3 filters to a 5x5 image, the original 5x5 image contains 25 pixels, but tiling the 3x3 filter only has 9 possible locations. Here's the 4 of the 9 possible locations for the 3x3 filter on a 5x5 image:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_1.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_2.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_3.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_4.jpeg\" width=\"200\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFortunately, padding solves both of these problems! Just one layer of pixels around the edges preserves the image size when having a 3 x 3 filter. We can also use bigger filters, but generally the dimensions are odd!\u003c/p\u003e\n\n\u003cp\u003eSome further terminology regarding padding that you should be aware of includes:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\"Valid\" - no padding\u003c/li\u003e\n\u003cli\u003e\"Same\" - padding such that output is same as the input size\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBy adding padding to our 5x5 image, (now a 6x6 image by adding a border of pixels) we can add padding so that each pixel of our original 5x5 image can be the center of a 3x3 convolution window filter.\u003c/p\u003e\n\n\u003ch2\u003eStrided convolutions\u003c/h2\u003e\n\n\u003cp\u003eAnother method to change the output of your convolutions is to change the stride. The stride is how the convolution filter is moved over the original image. In our above example, we moved the filter one pixel to the right starting from the upper left hand corner, and then began to do this again after moving the filter one pixel down. Alternatively, by changing the stride, we could move our filter by 2 pixels each time, resulting in a smaller number of possible locations for the filter.  \u003c/p\u003e\n\n\u003cp\u003eStrided convolutions are rarely used in practice but a good feature to be aware of for some models.\u003c/p\u003e\n\n\u003ch2\u003eConvolutions on RGB images\u003c/h2\u003e\n\n\u003cp\u003eInstead of 5 x 5 grayscale, imagine a 7 x 7 RGB image, which boils down to having a 7 x 7 x 3 tensor. (The image itself is compromised by a 7 by 7 matrix of pixels, each with 3 numerical values for the RGB values.) From there, you will need to use a filter that has the third dimension equal to 3 as well, let's say, 3 x 3 x 3 (a 3D \"cube\"). \u003c/p\u003e\n\n\u003cp\u003eThis allows you to detect horizontal edges in the blue channel.\u003c/p\u003e\n\n\u003cp\u003eThen, in each layer, you can convolve with several 3D filters. Afterwards, you stack every output of the result together, giving you a matrix of shape 5 x 5 x \u003ccode\u003enumber_of_filters\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eIf you think of it, the filter plays the same role as the w^{[1]} in our densely connected networks.\u003c/p\u003e\n\n\u003cp\u003eThe advantage is, while your image may be huge, the amount of parameters you have still only depends on how many filters you're using!\u003c/p\u003e\n\n\u003cp\u003eImagine 20 (3 x 3 x 3) --\u0026gt; 20 * 27 + a bias for each filter (1* 20) = 560 parameters.\u003c/p\u003e\n\n\u003cp\u003eNotation:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e = size of the filter\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"p^{[l]}\" src=\"/equation_images/p^{[l]}\" alt=\"{\" data-equation-content=\"p^{[l]}\"\u003e = padding\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"s^{[l]}\" src=\"/equation_images/s^{[l]}\" alt=\"{\" data-equation-content=\"s^{[l]}\"\u003e = amount of stride\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\" n_c^{[l]}\" src=\"/equation_images/%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_c^{[l]}\"\u003e = number of filters\u003c/li\u003e\n\u003cli\u003e\u003cp\u003efilter: \u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e x \u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e x \u003cimg class=\"equation_image\" title=\" n_c^{[l-1]}\" src=\"/equation_images/%20n_c^{[l-1]}\" alt=\"{\" data-equation-content=\" n_c^{[l-1]}\"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eInput = \u003cimg class=\"equation_image\" title=\" n_h^{[l-1]} * n_w^{[l-1]} * n_c^{[l-1]} \" src=\"/equation_images/%20n_h^{[l-1]}%20*%20n_w^{[l-1]}%20*%20n_c^{[l-1]}\" alt=\"{\" data-equation-content=\" n_h^{[l-1]} * n_w^{[l-1]} * n_c^{[l-1]} \"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eOutput = \u003cimg class=\"equation_image\" title=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \" src=\"/equation_images/%20n_h^{[l]}%20*%20n_w^{[l]}%20*%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHeight and width are given by:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"n_h^{[l]}= \\Bigr\\lfloor\\dfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\" src=\"/equation_images/n_h^{[l]}=%20%255CBigr%255Clfloor%255Cdfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1%255CBigr%255Crfloor\" alt=\"{\" data-equation-content=\"n_h^{[l]}= \\Bigr\\lfloor\\dfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"n_w^{[l]}= \\Bigr\\lfloor\\dfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\" src=\"/equation_images/n_w^{[l]}=%20%255CBigr%255Clfloor%255Cdfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1%255CBigr%255Crfloor\" alt=\"{\" data-equation-content=\"n_w^{[l]}= \\Bigr\\lfloor\\dfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\"\u003e\u003c/p\u003e\n\n\u003cp\u003eActivations: \u003cimg class=\"equation_image\" title=\"a^{[l]}\" src=\"/equation_images/a^{[l]}\" alt=\"{\" data-equation-content=\"a^{[l]}\"\u003e is of dimension \u003cimg class=\"equation_image\" title=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \" src=\"/equation_images/%20n_h^{[l]}%20*%20n_w^{[l]}%20*%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \"\u003e\u003c/p\u003e\n\n\u003ch2\u003ePooling layer\u003c/h2\u003e\n\n\u003cp\u003eThe last element in a CNN architecture (before fully connected layers as we have previously discussed in other neural networks) is the pooling layer. This layer is meant to substantially downsample the previous convolutional layers. The idea behind this is that the previous convolutional layers will find patterns such as edges or other basic shapes present in the pictures. From there, pooling layers such as Max pooling (the most common) will take a summary of the convolutions from a larger section. In practice, Max pooling (taking the max of all convolutions from a larger area of the original image) works better than average pooling as we are typically looking to detect whether a feature is present in that region. Downsampling is essential in order to produce viable execution times in the model training.\u003c/p\u003e\n\n\u003cp\u003eMax pooling has some important hyperparameters:\n- \u003cimg class=\"equation_image\" title=\"f\" src=\"https://learning.flatironschool.com/equation_images/f\" alt=\"{\" data-equation-content=\"f\"\u003e (filter size)\n- \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e (stride)\u003c/p\u003e\n\n\u003cp\u003eCommon hyperparameters include: \u003ccode\u003ef=2\u003c/code\u003e, \u003ccode\u003es=2\u003c/code\u003e and \u003ccode\u003ef=3\u003c/code\u003e, \u003ccode\u003es=2\u003c/code\u003e, this shrinks the size of the representations.\u003c/p\u003e\n\n\u003cp\u003eIf a feature is detected anywhere in the quadrants, a high number will appear, so max pooling preserves this feature.\u003c/p\u003e\n\n\u003ch2\u003eFully Connected Layers in CNN\u003c/h2\u003e\n\n\u003cp\u003eOnce you have added a number of convolutional layers and pooling layers, you then will add fully connected (dense) layers as we did before in previous neural network models. This now allows the network to learn a final decision function based on these transformed informative inputs generating from the convolutional and pooling layers.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about the basic concepts behind CNNs including their use cases and general architecture. In the upcoming lab, you'll begin to look at how you can build these models in Python using Keras.\u003c/p\u003e","exportId":"convolutional-neural-networks"},{"id":458502,"title":"Convolutional Neural Networks - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-convolutional-neural-networks-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this codealong, we will reinvestigate our previous Santa image classification example. To do this, we will review loading a dataset from a nested directory structure and building a baseline model. From there, we'll build a CNN and demonstrate its improved performance on image recognition tasks. It is recommended you run the cells in order to further explore variables and investigate the code snippets themselves. However, please note that some cells (particularly training cells later on) may take several minutes to run. (On a Macbook pro the entire notebook took ~15 minutes to run.)\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad images from a hierarchical file structure using an image datagenerator \u003c/li\u003e\n\u003cli\u003eExplain why one might augment image data when training a neural network \u003c/li\u003e\n\u003cli\u003eApply data augmentation to image files before training a neural network \u003c/li\u003e\n\u003cli\u003eBuild a CNN using Keras \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g546a70919f77202cb729711ea35833d7"},{"id":458504,"title":"Building a CNN from Scratch - Lab","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-building-a-cnn-from-scratch\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-building-a-cnn-from-scratch\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-building-a-cnn-from-scratch/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have background knowledge regarding how CNNs work and how to build them using Keras, its time to practice those skills a little more independently in order to build a CNN on your own to solve a image recognition problem. In this lab, you'll practice building an image classifier from start to finish using a CNN.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad images from a hierarchical file structure using an image datagenerator \u003c/li\u003e\n\u003cli\u003eApply data augmentation to image files before training a neural network \u003c/li\u003e\n\u003cli\u003eBuild a CNN using Keras \u003c/li\u003e\n\u003cli\u003eVisualize and evaluate the performance of CNN models \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gc0c371179354c474eb62d3e35ada83d6"},{"id":458506,"title":"Visualizing Intermediate Activations","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-intermediate-activations\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-intermediate-activations\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-intermediate-activations/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eDeep learning is extremely powerful and is helping to lead the advancement of many AI tasks. That said, deep learning is often criticized for having a lot of \u003cem\u003eblack box\u003c/em\u003e algorithms in that the components of the model itself are difficult to interpret. In the case of CNNs and image recognition, this is actually not true at all! In this lesson, you will explore how you can visualize the intermediate hidden layers within your CNN to uncover what sorts of features your deep network is uncovering through some of the various filters. With that, you'll gain interesting insights and knowledge as to how your CNN is \u003cem\u003eseeing\u003c/em\u003e the world.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad a saved Keras model \u003c/li\u003e\n\u003cli\u003eUse Keras methods to visualize the activation functions in CNNs \u003c/li\u003e\n\u003c/ul\u003e","exportId":"g133398f3cf3addbcc4503103ffaa1031"},{"id":458509,"title":"Visualizing Activation Functions - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-activation-functions-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-activation-functions-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-activation-functions-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've built your own CNN and seen how to visualize feature maps, its time to practice loading a pretrained model from file and visualize the learned features systematically. In this lab, you'll expand upon the code from the previous lesson in order to succinctly visualize all the channels from each layer in a CNN.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad a saved Keras model \u003c/li\u003e\n\u003cli\u003eUse Keras methods to visualize the activation functions in CNNs \u003c/li\u003e\n\u003c/ul\u003e","exportId":"gcd231132357b7197c79a1dd8aa04b47c"},{"id":458525,"title":"Tuning Neural Networks - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-recap-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-recap-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-recap-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003ch3\u003eTuning Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eValidation and test sets are used when iteratively building deep neural networks\u003c/li\u003e\n\u003cli\u003eLike traditional machine learning models, we need to watch out for the bias variance trade-off when building deep learning models\u003c/li\u003e\n\u003cli\u003eExamples of alternatives for gradient descent are: RMSprop, Adam, Gradient Descent with Momentum, etc.\u003c/li\u003e\n\u003cli\u003eHyperparameter tuning is of crucial importance when working with deep learning models, as setting the parameters right can lead to great improvements in model performance\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eRegularization\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eSeveral regularization techniques can help us limit overfitting: L1 Regularization, L2 Regularization, Dropout Regularization, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eNormalization\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eTraining of deep neural networks can be sped up by using normalized inputs\u003c/li\u003e\n\u003cli\u003eNormalized inputs can also help mitigate a common issue of vanishing or exploding gradients\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eConvolutional Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eCNNs are a useful model for image recognition due to their ability to recognize visual patterns at varying scales\u003c/li\u003e\n\u003cli\u003eThe essence of a CNN is a convolutional operation, where a window is slid across the image based on a stride size\u003c/li\u003e\n\u003cli\u003ePadding can be used to prevent shrinkage and make sure pixels at the edge of an image receive the necessary attention\u003c/li\u003e\n\u003cli\u003eMax pooling is typically used between convolutional layers to reduce the dimensionality\u003c/li\u003e\n\u003cli\u003eAfter developing the convolutional and pooling layers to form a base, the end of the network architecture still connects back to a densely connected network to perform classification\u003c/li\u003e\n\u003c/ul\u003e","exportId":"tuning-neural-networks-recap"}]},{"id":47109,"name":"Topic 40: Amazon Web Services","status":"completed","unlockDate":null,"prereqs":[],"requirement":"all","sequential":false,"exportId":"g0e7370999d9fba80091511a7fa02df15","items":[{"id":458537,"title":"Topic 40 Lesson Priorities (Live)","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 196px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eCloud Services\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 36.7893%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.3512%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Amazon Web Services - Introduction\" href=\"pages/amazon-web-services-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-web-services-introduction\" data-api-returntype=\"Page\"\u003eAmazon Web Services - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003cstrong\u003e\u003ca title=\"Cloud Computing\" href=\"pages/cloud-computing\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/cloud-computing\" data-api-returntype=\"Page\"\u003eCloud Computing\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"The AWS Ecosystem\" href=\"pages/the-aws-ecosystem\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/the-aws-ecosystem\" data-api-returntype=\"Page\"\u003eThe AWS Ecosystem\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Amazon Simple Storage Service (S3)\" href=\"pages/amazon-simple-storage-service-s3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-simple-storage-service-s3\" data-api-returntype=\"Page\"\u003eAmazon Simple Storage Service (S3)\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 22px;\"\u003e\u003ca title=\"Introduction to Amazon SageMaker\" href=\"pages/introduction-to-amazon-sagemaker\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-amazon-sagemaker\" data-api-returntype=\"Page\"\u003eIntroduction to Amazon SageMaker\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 22px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Data Science and Machine Learning Engineering\" href=\"pages/data-science-and-machine-learning-engineering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/data-science-and-machine-learning-engineering\" data-api-returntype=\"Page\"\u003eData Science and Machine Learning Engineering\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Introduction to Flask\" href=\"pages/introduction-to-flask\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-flask\" data-api-returntype=\"Page\"\u003eIntroduction to Flask\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Deploying a Model with Flask\" href=\"pages/deploying-a-model-with-flask\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/deploying-a-model-with-flask\" data-api-returntype=\"Page\"\u003eDeploying a Model with Flask\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Introduction to Dash\" href=\"pages/introduction-to-dash\"\u003eIntroduction to Dash\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Deploying a Model with Dash\" href=\"pages/deploying-a-model-with-dash\"\u003eDeploying a Model with Dash\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Productionizing a Model with Docker and SageMaker\" href=\"assignments/ge49973b1f11da2d1d2ab006198d397c0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12386\" data-api-returntype=\"Assignment\"\u003eProductionizing a Model with Docker and SageMaker\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8934%; height: 80px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eCloud Services\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 36.7893%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.3512%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Cloud Services Exit Ticket\" href=\"quizzes/ge4dfe6dffe72ccc8d79792139640e029\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/quizzes/11295\" data-api-returntype=\"Quiz\"\u003eCloud Services Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Amazon Web Services - Recap\" href=\"pages/amazon-web-services-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-web-services-recap\" data-api-returntype=\"Page\"\u003eAmazon Web Services - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","exportId":"topic-40-lesson-priorities-live"},{"id":458541,"title":"Amazon Web Services - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll be introduced to Amazon Web Services (AWS) - the most popular cloud service. \u003c/p\u003e\n\n\u003ch2\u003eMachine Learning and the Cloud\u003c/h2\u003e\n\n\u003cp\u003eWe'll begin this section by learning about all the ways that cloud computing services such as \u003cstrong\u003e\u003cem\u003eAmazon Web Services (AWS)\u003c/em\u003e\u003c/strong\u003e have made things better and easier for data scientists. We'll also explore why being able to productionize the machine learning models you create so that other people can use them is one of the most valuable skills you can have as a data scientist. \u003c/p\u003e\n\n\u003ch2\u003eAmazon Web Services (AWS)\u003c/h2\u003e\n\n\u003cp\u003eOne we understand the importance of cloud services and how they fit into the picture for data scientists, we'll jump right in to the most popular cloud service, AWS. We'll learn about what AWS ecosystem contains and how we can use it. We'll also create an account and learn our way around the AWS dashboard. \u003c/p\u003e\n\n\u003ch2\u003eAWS SageMaker\u003c/h2\u003e\n\n\u003cp\u003eOnce we know the basics of AWS, we'll learn how we can make use of the most important tool for Data Scientists, \u003cstrong\u003e\u003cem\u003eAWS SageMaker\u003c/em\u003e\u003c/strong\u003e! We'll see how we can incorporate AWS SageMaker into our workflow to simplify things like distributed training or model productionization! \u003c/p\u003e\n\n\u003ch2\u003eHands-On Practice Shipping Models\u003c/h2\u003e\n\n\u003cp\u003eFinally, we will train and ship real-world models using AWS SageMaker. We'll start by training and productionizing some classical machine learning models with scikit-learn and then set up endpoints with AWS SageMaker so that we can make them available for inference. Then, we'll move onto training a Deep Learning model with SageMaker, so that we can make use of distributed training to speed things up, and then ship the model to production. Finally, we'll use SageMaker to train and productionize a more advanced Convolutional Neural Network for image classification. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eBy the end of this section, you'll know the basics of how to use AWS for Data Science projects, and you'll have hands-on experience training and productionizing three different machine learning models. This will set you up for success with your capstone project!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-productionizing-machine-learning-models-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-productionizing-machine-learning-models-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"amazon-web-services-introduction"},{"id":458543,"title":"Cloud Computing","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-cloud-computing\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-cloud-computing\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-cloud-computing/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFor most of this curriculum, we have focused on techniques that you can apply on your own computer. In a production setting, you will likely need to go beyond your computer and utilize cloud services! This lesson gives an overview of what that means and what your options are.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the general concept of \"the cloud\"\u003c/li\u003e\n\u003cli\u003eIdentify some of the most popular cloud platforms\u003c/li\u003e\n\u003cli\u003eIdentify the key use cases of cloud platforms\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eThe Cloud\u003c/h2\u003e\n\n\u003cp\u003e\u003ca title=\"ÁôæÊ•ΩÂÖé, CC BY-SA 3.0 \u003chttps://creativecommons.org/licenses/by-sa/3.0\u003e, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Cloud_computing_icon.svg\"\u003e\u003cimg width=\"256\" alt=\"Cloud computing icon\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Cloud_computing_icon.svg/256px-Cloud_computing_icon.svg.png\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCloud computing\u003c/em\u003e\u003c/strong\u003e is originally an IT infrastructure term, which is contrasted with \u003cem\u003eon-premises\u003c/em\u003e computing. In traditional IT infrastructure, specialized computers (servers) would be purchased and set up at the company to do things like store customer data in a database, or serve the company's website. The problem with this setup is that it's less flexible (leaving resources unused at low-traffic times, running the risk of servers being overloaded at high-traffic times) and requires on-site server maintenance expertise. Some small or niche organizations still use 100% on-premises computing (e.g. because of special security needs), but nowadays most have moved to using some kind of cloud platform.\u003c/p\u003e\n\n\u003cp\u003eOn a cloud platform, server resources are typically available \"on-demand\", meaning that the amount of storage space or CPU time scales based on user needs, and the user pays accordingly. This allows for better agility, performance, and monitoring than traditional on-premises setups.\u003c/p\u003e\n\n\u003ch3\u003ePopular Cloud Platforms\u003c/h3\u003e\n\n\u003cp\u003e\u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e emerged in the early 21st Century as the first modern cloud platform. Previously there had been time-sharing approaches and virtual private network (VPN) services, but AWS also introduced the concept of virtual private servers. Two early AWS products, Simple Storage Service (S3) and Elastic Compute Cloud (EC2), were released in 2006 and are still very popular today.\u003c/p\u003e\n\n\u003cp\u003eOther major tech companies soon followed with their own cloud platforms, to compete with AWS and also offer novel products and services. The two major competitors to AWS are Microsoft's \u003cstrong\u003eAzure\u003c/strong\u003e and \u003cstrong\u003eGoogle Cloud\u003c/strong\u003e. For most typical cloud computing use cases, all three of these companies offer comparable services, although one particular offering might be best for your company's needs in terms of pricing or specifications.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://www.flexera.com/blog/wp-content/uploads/2021/03/Picture9.png\" alt=\"public cloud adoption for enterprises\"\u003e\nFrom \u003ca href=\"https://www.flexera.com/blog/cloud/cloud-computing-trends-2021-state-of-the-cloud-report/\"\u003e\u003cem\u003eCloud Computing Trends: 2021 State of the Cloud Report\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eBecause AWS is the most popular cloud platform, we'll take some time later to discuss the AWS ecosystem and specific AWS services that you may find useful in your projects or future career.\u003c/p\u003e\n\n\u003ch2\u003eHardware Acceleration\u003c/h2\u003e\n\n\u003cp\u003eYou're already familiar with software libraries like NumPy and Spark that can help your computer perform at its best, but ultimately your personal computer (laptop or desktop) was probably not designed specifically for high-powered machine learning tasks.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eHardware acceleration\u003c/strong\u003e is useful when you need to train models or make predictions more quickly. As a general concept, \u003ca href=\"https://www.omnisci.com/learn/resources/technical-glossary/hardware-acceleration\"\u003ehardware acceleration\u003c/a\u003e means using purpose-built hardware rather than general-purpose hardware.\u003c/p\u003e\n\n\u003cp\u003eIn the case of machine learning, this typically means running your code on a \u003cstrong\u003eGPU\u003c/strong\u003e, rather than a CPU.  A CPU \u003cem\u003ecan\u003c/em\u003e do everything that a GPU can do, but it is not optimized for it, so it will likely take more time.  \u003ca href=\"https://towardsdatascience.com/maximize-your-gpu-dollars-a9133f4e546a\"\u003eThis blog\u003c/a\u003e argues that a CPU is to a GPU as a horse and buggy is to a car.\u003c/p\u003e\n\n\u003cp\u003eThe easiest way to get started with utilizing a GPU is by using a \u003cstrong\u003ecloud notebook\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCloud Notebooks\u003c/h3\u003e\n\n\u003cp\u003eA cloud notebook means that you can work in a familiar notebook interface, while at the same time using more-powerful computational resources. You usually don't have to install or configure anything -- you can just start coding in a super-powerful cloud environment. Sometimes these cloud environments even have built-in GitHub integration, so you can complete the entire development process in the cloud! Some past Flatiron students have found cloud notebooks to be extremely helpful for building the kinds of models they wanted to build in the time they had.\u003c/p\u003e\n\n\u003cp\u003eThere are also some downsides to cloud notebooks to be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSometimes you don't have precise control over the available \u003cstrong\u003ePython packages\u003c/strong\u003e and their versions. So, for example, you might want to use the latest version of TensorFlow, but the service you're using might not support it yet.\u003c/li\u003e\n\u003cli\u003ePaid tools (including the AWS and Google Cloud Platform tools listed below) can quickly get very \u003cstrong\u003eexpensive\u003c/strong\u003e. In particular be very careful about completing tutorials or running other people's projects, because it's easy to use up a lot of compute resources. You will typically get some free credits when signing up for these services, and we recommend that you save them for your own portfolio projects. Also make sure you always shut down your notebook instance when you're not using it.\u003c/li\u003e\n\u003cli\u003eSome of these notebooks don't work with a straightforward \u003cstrong\u003efile system\u003c/strong\u003e like you do on your everyday DS setup. Instead of simply being able to call \u003ccode\u003epd.read_csv\u003c/code\u003e to open a file, you'll likely need to interact with a web API to pull in your data from a storage bucket or other virtual storage location.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSome popular cloud notebooks include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html\"\u003eAWS SageMaker\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eProfessional-grade cloud JupyterLab instances (paid service, some free credits may be available)\u003c/li\u003e\n\u003cli\u003eWe'll also have more lessons on this later in the curriculum\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/vertex-ai/docs/workbench/user-managed?hl=en_US\"\u003eGoogle Cloud Notebooks\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eProfessional-grade cloud JupyterLab instances (paid service, some free credits may be available)\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://research.google.com/colaboratory/\"\u003eGoogle Colab\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eMore like the \"Google Docs\" of notebooks: not quite the same as a Jupyter notebook, and doesn't have access to a file system, but very fast to get started and 100% free\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.kaggle.com/code\"\u003eKaggle Kernels\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eNot exactly a Jupyter notebook, but a similar interface from Kaggle. Great if you're using a dataset from Kaggle\u003c/li\u003e\n\u003cli\u003eFree, although you're limited to \u003ca href=\"https://www.kaggle.com/page/GPU-tips-and-tricks\"\u003e30 hours per week\u003c/a\u003e of GPU time\u003c/li\u003e\n\u003cli\u003eGo \u003ca href=\"https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu\"\u003ehere\u003c/a\u003e for instructions on how to set up a GPU, \u003ca href=\"https://www.kaggle.com/docs/notebooks\"\u003ehere\u003c/a\u003e for full documentation\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://databricks.com/product/faq/community-edition\"\u003eDatabricks Community Edition\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eNot exactly a Jupyter notebook, but a similar interface from Databricks\u003c/li\u003e\n\u003cli\u003eFree cloud Spark cluster functionality\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eCloud Instances/Containers\u003c/h3\u003e\n\n\u003cp\u003eSometimes you want to be able to run a full-fledged cloud computer, not just a notebook. With cloud instances, you can provision the necessary compute resources for completing essentially any task! You get root access to the file system and can run long-running scripts without overheating your personal computer. With Docker, you can even develop the code locally then deploy it online to speed up processing times.\u003c/p\u003e\n\n\u003cp\u003eThere are also some downsides of cloud instances to be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSimilar to cloud notebooks, paid cloud instances can get very \u003cstrong\u003eexpensive\u003c/strong\u003e. Pay particular attention to the amount of storage you are using, since a storage-specific solution might be a lot cheaper than a general-purpose cloud instance.\u003c/li\u003e\n\u003cli\u003eCloud instances require some \u003cstrong\u003esystems administration\u003c/strong\u003e skills. You'll likely need to configure access permissions and ports. Most containers are Linux-based so you'll need to be comfortable navigating and installing things using the terminal.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSome popular cloud instances include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/ec2/\"\u003eAWS EC2\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGo \u003ca href=\"https://aws.amazon.com/blogs/machine-learning/train-deep-learning-models-on-gpus-using-amazon-ec2-spot-instances/\"\u003ehere\u003c/a\u003e for instructions on training deep learning models with GPUs on EC2\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/compute/docs\"\u003eGoogle Cloud Compute Engine\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGo \u003ca href=\"https://cloud.google.com/ai-platform/training/docs/using-gpus\"\u003ehere\u003c/a\u003e for instructions on using GPUs for training models with Google Cloud Platform\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/en-us/azure/virtual-machines/\"\u003eAzure Virtual Machines\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eBecause this is made by Microsoft, they're one of the few places that offers Windows virtual machines\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oracle.com/cloud/\"\u003eOracle Cloud Infrastructure\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerous free tier\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCloud Storage\u003c/h2\u003e\n\n\u003cp\u003eIt's annoying to have huge data files taking up space on your laptop, and if you want to train your model in the cloud, your data also needs to be in the cloud. But for reasons related to hardware acceleration, it can get pretty expensive to store large datasets in general-purpose cloud services like an EC2 instance or a cloud VM. That's when cloud storage services become useful.\u003c/p\u003e\n\n\u003cp\u003eThere are many different kinds of cloud storage tools, but they fall roughly into three categories: \u003cstrong\u003efile storage\u003c/strong\u003e systems, cloud storage \u003cstrong\u003ebuckets\u003c/strong\u003e, and cloud \u003cstrong\u003edatabases\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCloud File Storage\u003c/h3\u003e\n\n\u003cp\u003eThis type of cloud storage is probably most familiar to you already. Cloud file storage includes something like Dropbox or Google Drive, where files are stored in directories that can be navigated in a way that is similar to the file system on your local computer.\u003c/p\u003e\n\n\u003cp\u003eWhile there are professional-grade cloud tools for this such as \u003ca href=\"https://aws.amazon.com/efs/\"\u003eAWS Elastic File System (EFS)\u003c/a\u003e, \u003ca href=\"https://azure.microsoft.com/en-us/services/storage/files/\"\u003eAzure Files\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/filestore\"\u003eGoogle Cloud Filestore\u003c/a\u003e, the main takeaway you should have is the contrast between file storage and the storage approaches described below.\u003c/p\u003e\n\n\u003ch3\u003eCloud Storage Buckets\u003c/h3\u003e\n\n\u003cp\u003eAlso known as \u003cstrong\u003eobject storage\u003c/strong\u003e services, cloud storage buckets are great for storing raw files, e.g. folders full of images, CSVs, or JSONs. Unlike cloud file storage, files are not stored in directories. Instead, all data is stored in a \"flat\" system where it can be retrieved by name. This lack of hierarchy makes cloud storage buckets faster to use and more cost efficient than traditional file storage.\u003c/p\u003e\n\n\u003cp\u003eTypically these services are not free, although they are fairly cheap (2-5 cents per GB per month) and typically come with some free credits.\u003c/p\u003e\n\n\u003cp\u003eSome major providers of cloud storage buckets include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/s3/getting-started/\"\u003eAWS S3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/storage/\"\u003eGoogle Cloud Storage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/en-us/azure/storage/common/storage-introduction\"\u003eAzure Storage\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAWS S3 is the oldest and tends to have the most integration support with other platforms, although you may need to use Google storage if you're using other Google products or Azure storage if you're using other Azure products. Google Cloud Functions, for example, rely on source code being stored in Google Cloud Storage.\u003c/p\u003e\n\n\u003ch3\u003eCloud Databases\u003c/h3\u003e\n\n\u003cp\u003eDatabases are a familiar concept, but thus far we have mainly practiced using SQLite. If you're working with production-scale SQL data, it's best not to save it in a SQLite file but rather to store it on a database server.\u003c/p\u003e\n\n\u003cp\u003eMost likely your projects in this program will not require you to use a production-scale database, but this is an opportunity to practice if you want to prepare for on-the-job tasks.\u003c/p\u003e\n\n\u003cp\u003eSome major providers of cloud databases include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.heroku.com/postgres\"\u003eHeroku Postgres\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.mongodb.com/cloud/atlas\"\u003eMongoDB Atlas\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/rds/aurora/\"\u003eAWS Aurora\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/rds/\"\u003eAWS RDS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we discussed the definition of \"cloud services\" and walked through several use cases. In summary, most cloud services can be described as either being used for \u003cem\u003ehardware acceleration\u003c/em\u003e, including cloud notebooks and cloud instances, and \u003cem\u003ecloud storage\u003c/em\u003e, including cloud file storage, cloud storage buckets, and cloud databases.\u003c/p\u003e","exportId":"cloud-computing"},{"id":458546,"title":"The AWS Ecosystem","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-the-aws-ecosystem\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll get set up to use \u003cstrong\u003e\u003cem\u003eAmazon Web Services\u003c/em\u003e\u003c/strong\u003e, and then get to know our way around the platform. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/awscloud.svg\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eSet up an AWS account and explore the Amazon Resource Center \u003c/li\u003e\n\u003cli\u003eExplain what the \"regions\" are in AWS and why it is important to choose the right one\u003c/li\u003e\n\u003cli\u003eExplain the purpose of AWS IAM\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\n\u003cp\u003eBefore we can begin exploring everything AWS has to offer, we'll need to create an account on the platform. To do this, start by following this link to \u003ca href=\"https://aws.amazon.com/\"\u003eAmazon Web Services\u003c/a\u003e. While you're there, you may want to take the time to bookmark it -- chances are this is a website you'll use frequently in your career as a data scientist!\u003c/p\u003e\n\n\u003ch3\u003eWill This Cost Money?\u003c/h3\u003e\n\n\u003cp\u003eAlthough you will need a credit card to register for AWS, working through this section will not cost any money. AWS provides a free tier for learning and prototyping on the platform -- this is the tier we'll use for everything going forward. As long as you correctly register for the free tier, this will not cost you any money. \u003c/p\u003e\n\n\u003ch3\u003eRegister Your Email\u003c/h3\u003e\n\n\u003cp\u003eBegin by clicking the \"Sign Up\" button in the top right-hand corner of the page. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-1.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNext, create an account by adding your email and password. You'll also need to set an \u003cstrong\u003e\u003cem\u003eAWS Account Name\u003c/em\u003e\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-2.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eOn the next screen, enter your contact information. \u003cstrong\u003e\u003cem\u003eMake sure you set your account type to 'Personal'!\u003c/em\u003e\u003c/strong\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-3.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis next page is especially important -- be sure to select the \u003cstrong\u003e\u003cem\u003eBasic Plan\u003c/em\u003e\u003c/strong\u003e! As a reminder, you will be asked to enter a credit card number during the next few steps. Although we will only be making use of the free tier of services for AWS, be aware that you will still need to enter a credit card number in order to complete the registration process. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-4.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNow that you're all signed up, click the \"Sign in to the Console\" button to actually enter the AWS Console. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-5.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eGreat, you've now created an AWS Account! Let's take a look around. \u003c/p\u003e\n\n\u003ch2\u003eThe AWS Console\u003c/h2\u003e\n\n\u003cp\u003eNow that you're signed in, you'll see the \u003cstrong\u003e\u003cem\u003eAWS Console\u003c/em\u003e\u003c/strong\u003e. This is your \"home screen\" for AWS -- it allows you to quickly navigate through the thousands of services offered on AWS to find what you need. The easiest way to find what you need is the \"Find Services\" search bar at the top of the body of the page. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-6.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eYou can also click the \"See All Services\" dropdown to see a full list of services you can use in AWS. There are \u003cstrong\u003ea ton\u003c/strong\u003e of services, but don't let yourself get overwhelmed -- you'll probably never end up using the vast majority of these, as only a few apply to the work of a data scientist.\u003c/p\u003e\n\n\u003ch2\u003eA Note on Regions\u003c/h2\u003e\n\n\u003ch3\u003eAWS Regions\u003c/h3\u003e\n\n\u003cp\u003eAWS has data centers all over the world, and they are \u003cstrong\u003enot\u003c/strong\u003e interchangeable when it comes to your projects. Check out \u003ca href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\"\u003ethis link\u003c/a\u003e to see a list of all of the current AWS regions across the globe. While it typically won't matter for your projects in this program, the different AWS regions vary in terms of latency, cost, legal compliance, and features.\u003c/p\u003e\n\n\u003cp\u003eEach AWS region is a separate geographic area and is designed to be completely isolated from the other regions. This helps achieve the greatest possible fault-tolerance and stability. Communication between regions is possible, but often costs money and/or requires additional security configuration.\u003c/p\u003e\n\n\u003ch3\u003eImplications for Your Projects\u003c/h3\u003e\n\n\u003cp\u003eIt is \u003cstrong\u003e\u003cem\u003every important\u003c/em\u003e\u003c/strong\u003e that you always choose the same region to connect to with your projects. Resources are not automatically replicated across regions! One of the most common mistakes newcomers to AWS make is thinking they've lost their project because they are connected to a different data center and don't realize it. We'll remind you of this again later, but it can't hurt to say it twice: always make sure you're connected to the correct data center! This goes doubly for when you're creating a new project. \u003c/p\u003e\n\n\u003ch2\u003eAWS IAM\u003c/h2\u003e\n\n\u003cp\u003eIAM stands for \u003ca href=\"https://aws.amazon.com/iam/\"\u003eIdentity and Access Management\u003c/a\u003e. AWS allows IT administrators to configure access to different services at a very granular level, which can get intimidating pretty quickly!\u003c/p\u003e\n\n\u003cp\u003eEssentially all you need to know is that access to services requires you to create a \u003cstrong\u003erole\u003c/strong\u003e in IAM, and then set a \u003cstrong\u003epolicy\u003c/strong\u003e for that role's access permissions. In some cases, e.g. you want to run a cloud notebook in \u003ca href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/security-iam.html\"\u003eAWS SageMaker\u003c/a\u003e, that role should be restricted to just you, and you should have permission to take any action. In other cases, e.g. you want to store data in an \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-overview.html\"\u003eS3 bucket\u003c/a\u003e, you might want to allow anyone to download the data, but only allow yourself to upload.\u003c/p\u003e\n\n\u003cp\u003eIn our curriculum examples we'll advise on IAM settings, but you'll likely need to do your own research as you explore beyond these for your own projects. Luckily these are public projects so the risk of leaking data or models is low. In a job setting, make sure you consult with your IT team to make sure that you are not revealing private data.\u003c/p\u003e\n\n\u003ch2\u003eUsing the Amazon Resource Center\u003c/h2\u003e\n\n\u003cp\u003eAs platforms go, you won't find many with more options than AWS. It has an amazing amount of offerings, with more getting added all the time. While AWS is great for basic use cases like hosting a server or a website, it also has all kinds of different offerings in areas such as Databases, Machine Learning, Data Analytics and other areas useful to Data Scientists.\u003c/p\u003e\n\n\u003cp\u003eIt's not possible for us to cover how to use every service in AWS in this section -- but luckily, we don't need to, because Amazon already has! The \u003ca href=\"https://aws.amazon.com/getting-started/\"\u003eGetting Started Resource Center\u003c/a\u003e contains a ton of awesome tutorials, demonstrations, and sample projects for just about everything you would ever want to know about any service on AWS. We \u003cstrong\u003e\u003cem\u003estrongly recommend\u003c/em\u003e\u003c/strong\u003e bookmarking this page, as the tutorials they offer are very high quality, and free!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-7.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we signed up for Amazon Web Services and explored some of the different options on the platform. \u003c/p\u003e","exportId":"the-aws-ecosystem"},{"id":458550,"title":"Amazon Simple Storage Service (S3)","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-aws-s3\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-aws-s3\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-aws-s3/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAmazon Simple Storage Service (S3) is one of the flagship services from AWS. In this lesson we'll discuss how you might use it as a data scientist!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe use cases for S3 buckets in data science\u003c/li\u003e\n\u003cli\u003eCreate S3 buckets and upload data\u003c/li\u003e\n\u003cli\u003eAccess data in S3 buckets with Python code\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eS3 Buckets in Data Science\u003c/h2\u003e\n\n\u003ch3\u003eLimitations of GitHub\u003c/h3\u003e\n\n\u003cp\u003eAt this point in the program, you might have encountered an error message like this more than once:\u003c/p\u003e\n\n\u003cpre style=\"color:red\"\u003eremote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com\nremote: error: Trace: 08740bd2fb02f980041be67b73e715a9\nremote: error: See http://git.io/iEPt8g for more information.\nremote: error: File is 218.83 MB; this exceeds GitHub's file size limit of 100.00 MB\n! [remote rejected] master -\u0026gt; master (pre-receive hook declined)\nerror: failed to push some refs\n\u003c/pre\u003e\n\n\u003cp\u003eThis happens when you try to push a file that exceeds GitHub's \u003ca href=\"https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github\"\u003efile size limits\u003c/a\u003e. The file might contain data in CSV or JSON format, or maybe a pickled ML model.\u003c/p\u003e\n\n\u003cp\u003eThe short-term workaround is to use \u003ccode\u003e.gitignore\u003c/code\u003e so that the file or files just stay on your computer and are not pushed to GitHub. But that has some limitations:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you want someone else to be able to \u003cstrong\u003ereproduce\u003c/strong\u003e your project and one or more files are too big for GitHub, how do they get the file(s)? You would need to provide very detailed instructions to make this possible\u003c/li\u003e\n\u003cli\u003eIf you want to \u003cstrong\u003etrain your model in the cloud\u003c/strong\u003e and your data is too big for GitHub, how will your code access the data?\u003c/li\u003e\n\u003cli\u003eIf you want to \u003cstrong\u003eproductionize your model\u003c/strong\u003e and your pickled model is too big for GitHub, how will your code access the model?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis problem is also not limited to GitHub. Some cloud notebooks do not support standard file systems at all, and some deployment approaches have file size limitations that are much more restrictive than GitHub's!\u003c/p\u003e\n\n\u003cp\u003eFortunately, while these tools might not be optimized for larger files, S3 buckets are a great alternative.\u003c/p\u003e\n\n\u003ch3\u003eRecommended S3 Setup for Data Science\u003c/h3\u003e\n\n\u003cp\u003eFor your projects, let's assume you are:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eWorking from a Jupyter notebook locally\u003c/li\u003e\n\u003cli\u003eNot concerned about access or keeping data private\u003c/li\u003e\n\u003cli\u003eNot needing to dynamically upload data (e.g. allow users to upload photos)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTherefore we recommend that you follow this S3 setup:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eSet up an S3 bucket where objects are all publicly readable\u003c/li\u003e\n\u003cli\u003eWhen you encounter or create a file that is too big for GitHub, \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html\"\u003eupload files to S3\u003c/a\u003e\n\n\u003col\u003e\n\u003cli\u003eFor files below 160 GB, use the AWS Console (web browser interface)\u003c/li\u003e\n\u003cli\u003eFor files between 160 GB and 5 TB, use \u003ccode\u003eboto3\u003c/code\u003e (the AWS Python SDK)\u003c/li\u003e\n\u003c/ol\u003e\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003eboto3\u003c/code\u003e in your Python code to access data in your bucket\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eNow we will go over all of these steps!\u003c/p\u003e\n\n\u003ch2\u003eCreating and Configuring S3 Buckets\u003c/h2\u003e\n\n\u003cp\u003eIn some software applications, S3 buckets are created dynamically based on application context. For data science, projects don't typically need to be quite so dynamic, so we can create our S3 buckets using the more-intuitive AWS console interface rather than using code.\u003c/p\u003e\n\n\u003cp\u003eGo to the \u003cstrong\u003eS3 management console\u003c/strong\u003e. This can be accessed by searching for \"s3\" in the \u003ca href=\"https://aws.amazon.com/console/\"\u003eAWS Management Console\u003c/a\u003e or by going directly to \u003ca href=\"https://s3.console.aws.amazon.com/s3/home\"\u003ethis link\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eClick on \u003cstrong\u003e\"Create Bucket\"\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eGive your bucket a \u003cstrong\u003eunique name\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you're working on a specific project, try giving the bucket a name that relates to the project\u003c/li\u003e\n\u003cli\u003eDO NOT include any private/secret information in the bucket name\u003c/li\u003e\n\u003cli\u003eIf someone else has already used a bucket name, you will not be able to use it\n\n\u003cul\u003e\n\u003cli\u003eIf you're feeling stuck brainstorming a name, try adding today's date to it. That will be less likely to already be in use\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eScroll down and \u003cstrong\u003eun-check \"Block all public access\"\u003c/strong\u003e. AWS assumes that you want your data to be private, but we are moving forward with the assumption that public data access is not a problem. You will also need to check the box next to \u003cstrong\u003eI acknowledge that the current settings might result in this bucket and the objects within becoming public\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eScroll the rest of the way down and click \u003cstrong\u003eCreate Bucket\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eNow you should have a bucket set up where objects can be public!\u003c/p\u003e\n\n\u003ch2\u003eUploading Data to S3 Buckets\u003c/h2\u003e\n\n\u003ch3\u003eAWS Console Approach\u003c/h3\u003e\n\n\u003cp\u003eFor files below 160 GB, you can use the AWS Management Console. Go to the \u003cstrong\u003eS3 management console\u003c/strong\u003e and click on the name of your bucket.\u003c/p\u003e\n\n\u003cp\u003eBy default, you should see the \"Objects\" tab. Click on \u003cstrong\u003eUpload\u003c/strong\u003e. Click \u003cstrong\u003eAdd Files\u003c/strong\u003e and use the file picker to select a file or multiple files on your computer.\u003c/p\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003ePermissions\u003c/strong\u003e and click to expand. Under \"Predefined ACLs\", click \u003cstrong\u003eGrant public-read access\u003c/strong\u003e and then check the box next to \u003cstrong\u003eI understand the risk of granting public-read access to the specified objects\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eScroll to the bottom and click \u003cstrong\u003eUpload\u003c/strong\u003e. You will be taken to an upload status page while the file is being uploaded, then you can click \u003cstrong\u003eClose\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eChecking for Successful Upload and Configuration\u003c/h3\u003e\n\n\u003cp\u003eNow your data should be publicly hosted on S3! Try clicking on the file name in the \"Objects\" tab to see all of the information about it.\u003c/p\u003e\n\n\u003cp\u003eTo test whether the file permissions were successfully set to be public, you can click on either the \"Open\" button in the upper right, or the \"Object URL\" link inside the \"Object Overview\" panel.\u003c/p\u003e\n\n\u003ch4\u003eSuccessful Upload\u003c/h4\u003e\n\n\u003cp\u003eIf your file is downloaded, that means the settings are correct. (If it is a very large file, feel free to stop the download to save time and space -- you already have the file on your computer!)\u003c/p\u003e\n\n\u003ch4\u003eUnsuccessful Upload\u003c/h4\u003e\n\n\u003cp\u003eIf you see a message like this:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThis XML file does not appear to have any style information associated with it. The document tree is shown below.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e\u0026lt;Error\u0026gt;\n\u0026lt;Code\u0026gt;AccessDenied\u0026lt;/Code\u0026gt;\n\u0026lt;Message\u0026gt;Access Denied\u0026lt;/Message\u0026gt;\n\u0026lt;RequestId\u0026gt;XXXXXXXXXXXXXXXX\u0026lt;/RequestId\u0026gt;\n\u0026lt;HostId\u0026gt;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\u0026lt;/HostId\u0026gt;\n\u0026lt;/Error\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat means that you did not configure the permissions correctly. Go back through and make sure that:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe bucket settings are configured so that objects can be public\n\n\u003cul\u003e\n\u003cli\u003eIf you look at the bucket from the \u003ca href=\"https://s3.console.aws.amazon.com/s3/home\"\u003eS3 management console\u003c/a\u003e, you should see the text \"Objects can be public\" in the \"Access\" column\u003c/li\u003e\n\u003cli\u003eIf you do not see that, click on the bucket, go to the \u003cstrong\u003ePermissions\u003c/strong\u003e tab, scroll down to \u003cstrong\u003eBlock public access (bucket settings)\u003c/strong\u003e, and click \u003cstrong\u003eEdit\u003c/strong\u003e. Un-check \u003cstrong\u003eBlock all public access\u003c/strong\u003e, check \u003cstrong\u003eI acknowledge that the current settings might result in this bucket and the objects within becoming public\u003c/strong\u003e, and click \u003cstrong\u003eSave Changes\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eThe object settings are configured so that the public can access them\n\n\u003cul\u003e\n\u003cli\u003eIf you click on the bucket name, then click on the name of the file (e.g. \u003ccode\u003etest.csv\u003c/code\u003e), then go to the \u003cstrong\u003ePermissions\u003c/strong\u003e tab, you should see \"Read\" in the \"Object\" column next to \"Everyone (public access)\"\u003c/li\u003e\n\u003cli\u003eIf you do not see that, click on \u003cstrong\u003eEdit\u003c/strong\u003e next to \"Access control list (ACL)\". Locate the row that says \"Everyone (public access)\" and the column that says \"Objects\", and click the checkbox next to \u003cstrong\u003eRead\u003c/strong\u003e. Scroll down and click the checkbox next to \u003cstrong\u003eI understand the effects of these changes on this object\u003c/strong\u003e, then click \u003cstrong\u003eSave changes\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003ePython Approach\u003c/h3\u003e\n\n\u003cp\u003eFor files from 160 GB to 5 TB, you'll need a more sophisticated approach. Check out \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\"\u003ethis documentation\u003c/a\u003e for an overview of the multi-part upload process.\u003c/p\u003e\n\n\u003cp\u003eFortunately you can use \u003ccode\u003eboto3\u003c/code\u003e, the same package we'll use in the later examples in this lesson, in order to achieve this. First, use \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html#configuration\"\u003ethis documentation\u003c/a\u003e to configure a file on your computer to give \u003ccode\u003eboto3\u003c/code\u003e the credentials it needs to upload. Then follow the documentation \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_multipart_upload\"\u003ehere\u003c/a\u003e to create the actual upload.\u003c/p\u003e\n\n\u003ch2\u003eAccessing Data in S3 Buckets\u003c/h2\u003e\n\n\u003cp\u003eAs demonstrated above, one way to access the data in your S3 bucket is simply to navigate the the relevant web address and download the file. However, our main goal is to make the data accessible in \u003cstrong\u003ePython code\u003c/strong\u003e, not using a web browser. To achieve that, we'll use the \u003ccode\u003eboto3\u003c/code\u003e library!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/boto3.png\" alt=\"boto3\"\u003e\u003c/p\u003e\n\n\u003cp\u003eBoto 3 is a library that allows Python developers to access many different Amazon web services, not just S3. You can find the full list \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/index.html\"\u003ehere\u003c/a\u003e. But we'll focus on using S3 with \u003ccode\u003eboto3\u003c/code\u003e because that is one of the most common use cases for data scientists.\u003c/p\u003e\n\n\u003cp\u003e(The name \"boto\" is a type of dolphin that is native to the Amazon river. \u003ca href=\"https://github.com/boto/boto3/issues/1023#issuecomment-287127647\"\u003eAccording to its developer\u003c/a\u003e, \"I wanted something short, unusual, and with at least some kind of connection to Amazon\".)\u003c/p\u003e\n\n\u003ch3\u003eInstalling \u003ccode\u003eboto3\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis library is not part of \u003ccode\u003elearn-env\u003c/code\u003e as of this writing. If you are working on a project, we recommend activating that project \u003ccode\u003econda\u003c/code\u003e environment. Or if you're just wanting to learn about \u003ccode\u003eboto3\u003c/code\u003e, you can un-comment this line of code to install it in your current environment:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install boto3 -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure this cell runs successfully before proceeding:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eboto3\u003c/span\u003e\n\u003cspan class=\"n\"\u003es3\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboto3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eresource\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"s3\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eConnecting to an Example S3 Bucket\u003c/h3\u003e\n\n\u003cp\u003eFor the purposes of this curriculum, we have loaded some example files into an S3 bucket for you! Let's go through those examples, starting with a text file.\u003c/p\u003e\n\n\u003ch4\u003eText File\u003c/h4\u003e\n\n\u003cp\u003eWe'll instantiate an instance of the \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html?highlight=s3.object#S3.Object\"\u003e\u003ccode\u003eObject\u003c/code\u003e class\u003c/a\u003e by passing in those string values. The first one, \u003ccode\u003ebucket_name\u003c/code\u003e, is the name of the bucket. The second, \u003ccode\u003ekey\u003c/code\u003e, is the name of the object (file) inside that bucket.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/data/zen_of_python.txt\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003es3.Object(bucket_name='curriculum-content', key='data-science/data/zen_of_python.txt')\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis object is used kind of like a request in the \u003ccode\u003erequests\u003c/code\u003e library. You call the \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html?highlight=s3.object#S3.Object.get\"\u003e\u003ccode\u003eget\u003c/code\u003e method\u003c/a\u003e to initiate an HTTP \u003ccode\u003eGET\u003c/code\u003e request.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'ResponseMetadata': {'RequestId': 'JR1N0QAM82W3ETVW',\n  'HostId': 'J2J6MiFzynwLLLlOXBSTgYyFOPcDpoofyc165VnBbB+nNEH2cbovo7p4+MGMYXiT0mfD8acVZ2o=',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amz-id-2': 'J2J6MiFzynwLLLlOXBSTgYyFOPcDpoofyc165VnBbB+nNEH2cbovo7p4+MGMYXiT0mfD8acVZ2o=',\n   'x-amz-request-id': 'JR1N0QAM82W3ETVW',\n   'date': 'Thu, 10 Mar 2022 20:58:09 GMT',\n   'last-modified': 'Thu, 10 Mar 2022 19:17:44 GMT',\n   'etag': '\"760dcb2a44c5b0553ee12ea8cca057b8\"',\n   'x-amz-server-side-encryption': 'AES256',\n   'accept-ranges': 'bytes',\n   'content-type': 'binary/octet-stream',\n   'server': 'AmazonS3',\n   'content-length': '858'},\n  'RetryAttempts': 0},\n 'AcceptRanges': 'bytes',\n 'LastModified': datetime.datetime(2022, 3, 10, 19, 17, 44, tzinfo=tzutc()),\n 'ContentLength': 858,\n 'ETag': '\"760dcb2a44c5b0553ee12ea8cca057b8\"',\n 'ContentType': 'binary/octet-stream',\n 'ServerSideEncryption': 'AES256',\n 'Metadata': {},\n 'Body': \u0026lt;botocore.response.StreamingBody at 0x10ad09128\u0026gt;}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe actual data for the object is contained in the \"Body\" of the response. Let's extract that key and read out the data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"n\"\u003edecode\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etxt_body\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eMore-Complex Files: \u003ccode\u003eBytesIO\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eIf we have a file type where we want to do something other than just print out its contents (e.g. images, pickled models, CSVs), we need to add one more step: creating a virtual file with \u003ccode\u003eBytesIO\u003c/code\u003e (a class in the built-in \u003ca href=\"https://docs.python.org/3/library/io.html\"\u003ePython \u003ccode\u003eio\u003c/code\u003e module\u003c/a\u003e). Then we can send that virtual file to a library like Pillow, \u003ccode\u003ejoblib\u003c/code\u003e, or \u003ccode\u003epandas\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch4\u003eImage File\u003c/h4\u003e\n\n\u003cp\u003e\u003ccode\u003elearn-env\u003c/code\u003e already has Pillow, but un-comment the following line if you need to install it in the environment you're currently using to look at this example. Or you can feel free to skip this example and go down to the next one!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install pillow -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ePIL\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eImage\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Getting the same boto3 image that appears earlier in this lesson\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/images/boto3.png\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eimg_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into a BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Display the image using Pillow\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimage\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eImage\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edisplay\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimage\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"index_files/index_18_0.png\" alt=\"png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is a bit silly example (displaying image data in a Jupyter notebook) but the same approach could be used for loading data into an image classification tool! Check out \u003ca href=\"https://medium.com/analytics-vidhya/custom-keras-generator-fetching-images-from-s3-to-train-neural-network-4e98694de8ee\"\u003ethis blog post\u003c/a\u003e for an example.\u003c/p\u003e\n\n\u003ch4\u003ePickled Model\u003c/h4\u003e\n\n\u003cp\u003eSome model algorithms (e.g. Random Forest, Neural Networks) produce very large pickled models that don't easily fit into GitHub. And in some cases, your deployment approach will not have a file system available, so you'll need to use a cloud storage technique regardless of the model size. Below we show an example of a fairly simple linear regression model that has been stored in S3, but the same concept can easily apply to larger, more-complex models:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.linear_model\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Initialize S3 object\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/models/regression_model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epkl_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Load the data using joblib\n\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Loaded model is y = \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecoef_\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003ex + \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eintercept_\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e12\u003c/span\u003e\u003cspan class=\"p\"\u003e]])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eLoaded model is y = 1.0x + 1.0\n\n\n\n\n\narray([11., 12., 13.])\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eCSV File\u003c/h4\u003e\n\n\u003cp\u003eCSV data is a more realistic file type you might be working with. The below example reads a CSV file from an S3 bucket, then loads it into \u003ccode\u003epandas\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Initialize S3 object\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/data/test.csv\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecsv_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into a BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Load the data with pandas\n\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread_csv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv\u003e\n\u003cstyle\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eid\u003c/th\u003e\n      \u003cth\u003ebattery_power\u003c/th\u003e\n      \u003cth\u003eblue\u003c/th\u003e\n      \u003cth\u003eclock_speed\u003c/th\u003e\n      \u003cth\u003edual_sim\u003c/th\u003e\n      \u003cth\u003efc\u003c/th\u003e\n      \u003cth\u003efour_g\u003c/th\u003e\n      \u003cth\u003eint_memory\u003c/th\u003e\n      \u003cth\u003em_dep\u003c/th\u003e\n      \u003cth\u003emobile_wt\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003epc\u003c/th\u003e\n      \u003cth\u003epx_height\u003c/th\u003e\n      \u003cth\u003epx_width\u003c/th\u003e\n      \u003cth\u003eram\u003c/th\u003e\n      \u003cth\u003esc_h\u003c/th\u003e\n      \u003cth\u003esc_w\u003c/th\u003e\n      \u003cth\u003etalk_time\u003c/th\u003e\n      \u003cth\u003ethree_g\u003c/th\u003e\n      \u003cth\u003etouch_screen\u003c/th\u003e\n      \u003cth\u003ewifi\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1043\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e193\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e16\u003c/td\u003e\n      \u003ctd\u003e226\u003c/td\u003e\n      \u003ctd\u003e1412\u003c/td\u003e\n      \u003ctd\u003e3476\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e841\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e61\u003c/td\u003e\n      \u003ctd\u003e0.8\u003c/td\u003e\n      \u003ctd\u003e191\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e746\u003c/td\u003e\n      \u003ctd\u003e857\u003c/td\u003e\n      \u003ctd\u003e3895\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1807\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e2.8\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1366\u003c/td\u003e\n      \u003ctd\u003e2396\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1546\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e96\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e20\u003c/td\u003e\n      \u003ctd\u003e295\u003c/td\u003e\n      \u003ctd\u003e1752\u003c/td\u003e\n      \u003ctd\u003e3893\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e1434\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e49\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e108\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e749\u003c/td\u003e\n      \u003ctd\u003e810\u003c/td\u003e\n      \u003ctd\u003e1773\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e995\u003c/th\u003e\n      \u003ctd\u003e996\u003c/td\u003e\n      \u003ctd\u003e1700\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e54\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e170\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e644\u003c/td\u003e\n      \u003ctd\u003e913\u003c/td\u003e\n      \u003ctd\u003e2121\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e996\u003c/th\u003e\n      \u003ctd\u003e997\u003c/td\u003e\n      \u003ctd\u003e609\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e13\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e1152\u003c/td\u003e\n      \u003ctd\u003e1632\u003c/td\u003e\n      \u003ctd\u003e1933\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e997\u003c/th\u003e\n      \u003ctd\u003e998\u003c/td\u003e\n      \u003ctd\u003e1185\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e80\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e477\u003c/td\u003e\n      \u003ctd\u003e825\u003c/td\u003e\n      \u003ctd\u003e1223\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e998\u003c/th\u003e\n      \u003ctd\u003e999\u003c/td\u003e\n      \u003ctd\u003e1533\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e50\u003c/td\u003e\n      \u003ctd\u003e0.4\u003c/td\u003e\n      \u003ctd\u003e171\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e38\u003c/td\u003e\n      \u003ctd\u003e832\u003c/td\u003e\n      \u003ctd\u003e2509\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e999\u003c/th\u003e\n      \u003ctd\u003e1000\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e35\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e140\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e457\u003c/td\u003e\n      \u003ctd\u003e608\u003c/td\u003e\n      \u003ctd\u003e2828\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e1000 rows √ó 21 columns\u003c/p\u003e\n\u003c/div\u003e\n\n\u003ch4\u003eAvoiding \u003ccode\u003eBytesIO\u003c/code\u003e by Installing S3Fs\u003c/h4\u003e\n\n\u003cp\u003eIf you are using \u003ccode\u003epandas\u003c/code\u003e and you want to avoid having to use \u003ccode\u003eBytesIO\u003c/code\u003e, there is a library called \u003ca href=\"https://s3fs.readthedocs.io/en/latest/\"\u003eS3Fs (S3 Filesystem)\u003c/a\u003e that can help you shorten the above code by treating S3 URLs as regular file system URLs. You just need to start the file path with \u003ccode\u003e\"s3://\"\u003c/code\u003e!\u003c/p\u003e\n\n\u003cp\u003e(S3Fs is used \"under the hood\" by \u003ccode\u003epandas\u003c/code\u003e and does not require a separate import for this type of use.)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install s3fs -c conda-forge -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eHere is the same example as above, using S3Fs to shorten the code:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread_csv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"s3://curriculum-content/data-science/data/test.csv\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv\u003e\n\u003cstyle\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eid\u003c/th\u003e\n      \u003cth\u003ebattery_power\u003c/th\u003e\n      \u003cth\u003eblue\u003c/th\u003e\n      \u003cth\u003eclock_speed\u003c/th\u003e\n      \u003cth\u003edual_sim\u003c/th\u003e\n      \u003cth\u003efc\u003c/th\u003e\n      \u003cth\u003efour_g\u003c/th\u003e\n      \u003cth\u003eint_memory\u003c/th\u003e\n      \u003cth\u003em_dep\u003c/th\u003e\n      \u003cth\u003emobile_wt\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003epc\u003c/th\u003e\n      \u003cth\u003epx_height\u003c/th\u003e\n      \u003cth\u003epx_width\u003c/th\u003e\n      \u003cth\u003eram\u003c/th\u003e\n      \u003cth\u003esc_h\u003c/th\u003e\n      \u003cth\u003esc_w\u003c/th\u003e\n      \u003cth\u003etalk_time\u003c/th\u003e\n      \u003cth\u003ethree_g\u003c/th\u003e\n      \u003cth\u003etouch_screen\u003c/th\u003e\n      \u003cth\u003ewifi\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1043\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e193\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e16\u003c/td\u003e\n      \u003ctd\u003e226\u003c/td\u003e\n      \u003ctd\u003e1412\u003c/td\u003e\n      \u003ctd\u003e3476\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e841\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e61\u003c/td\u003e\n      \u003ctd\u003e0.8\u003c/td\u003e\n      \u003ctd\u003e191\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e746\u003c/td\u003e\n      \u003ctd\u003e857\u003c/td\u003e\n      \u003ctd\u003e3895\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1807\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e2.8\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1366\u003c/td\u003e\n      \u003ctd\u003e2396\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1546\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e96\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e20\u003c/td\u003e\n      \u003ctd\u003e295\u003c/td\u003e\n      \u003ctd\u003e1752\u003c/td\u003e\n      \u003ctd\u003e3893\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e1434\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e49\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e108\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e749\u003c/td\u003e\n      \u003ctd\u003e810\u003c/td\u003e\n      \u003ctd\u003e1773\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e995\u003c/th\u003e\n      \u003ctd\u003e996\u003c/td\u003e\n      \u003ctd\u003e1700\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e54\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e170\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e644\u003c/td\u003e\n      \u003ctd\u003e913\u003c/td\u003e\n      \u003ctd\u003e2121\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e996\u003c/th\u003e\n      \u003ctd\u003e997\u003c/td\u003e\n      \u003ctd\u003e609\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e13\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e1152\u003c/td\u003e\n      \u003ctd\u003e1632\u003c/td\u003e\n      \u003ctd\u003e1933\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e997\u003c/th\u003e\n      \u003ctd\u003e998\u003c/td\u003e\n      \u003ctd\u003e1185\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e80\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e477\u003c/td\u003e\n      \u003ctd\u003e825\u003c/td\u003e\n      \u003ctd\u003e1223\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e998\u003c/th\u003e\n      \u003ctd\u003e999\u003c/td\u003e\n      \u003ctd\u003e1533\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e50\u003c/td\u003e\n      \u003ctd\u003e0.4\u003c/td\u003e\n      \u003ctd\u003e171\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e38\u003c/td\u003e\n      \u003ctd\u003e832\u003c/td\u003e\n      \u003ctd\u003e2509\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e999\u003c/th\u003e\n      \u003ctd\u003e1000\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e35\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e140\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e457\u003c/td\u003e\n      \u003ctd\u003e608\u003c/td\u003e\n      \u003ctd\u003e2828\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e1000 rows √ó 21 columns\u003c/p\u003e\n\u003c/div\u003e\n\n\u003ch3\u003eConnecting to Your S3 Bucket\u003c/h3\u003e\n\n\u003cp\u003eIn the cell below, replace the string values with the names of your S3 bucket and the file you want to read:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003ebucket_name\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eobject_name\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we'll attempt to load your object using \u003ccode\u003eboto3\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebucket_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eobject_name\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(If you get a \u003ccode\u003eNoCredentialError\u003c/code\u003e here, that means that you either have the wrong bucket or object name, or you did not set the permissions on the bucket or object correctly. Double-check that the steps above are working as expected.)\u003c/p\u003e\n\n\u003cp\u003eNow you can continue with whatever next steps are appropriate for your use case!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we introduced the use cases for S3 in data science: typically data scientists use S3 for storing files that are too big for GitHub, but still need to be accessible from Python code for the purposes of reproducibility, using certain cloud services, or deployment. These can include many types of files, including text, images, pickled models, and data files such as CSV.\u003c/p\u003e\n\n\u003cp\u003eWe recommend that you use the AWS console to upload content to a bucket and configure the access permissions, then use the \u003ccode\u003eboto3\u003c/code\u003e Python library to access this content from the context of Python code.\u003c/p\u003e","exportId":"amazon-simple-storage-service-s3"},{"id":458554,"title":"Introduction to Amazon SageMaker","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about \u003cstrong\u003e\u003cem\u003eAmazon SageMaker\u003c/em\u003e\u003c/strong\u003e, and explore some of the common use cases it covers for data scientists. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the use cases of Amazon SageMaker \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is SageMaker?\u003c/h2\u003e\n\n\u003cp\u003eSageMaker is a platform created by Amazon to centralize all the various services related to Data Science and Machine Learning. If you're a data scientist working on AWS, chances are that you'll be spending most (if not all) of your time in SageMaker getting things done. You can get to SageMaker by just searching for \"SageMaker\" inside the spotlight search bar in the AWS Console. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/sagemaker.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSageMaker Use Cases\u003c/h2\u003e\n\n\u003cp\u003eWhen you visit the page for SageMaker, you'll notice that the following graphic highlighting the various use cases SageMaker can help with:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/use_cases.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eYou'll also notice these same categories on the sidebar on the left side of the screen, with more detailed links to services that fall under each category:\n\u003cbr\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/sidebar.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's a brief explanation of what each of these service areas are used for in a professional data science setting.\u003c/p\u003e\n\n\u003ch3\u003eGround Truth\u003c/h3\u003e\n\n\u003cp\u003eOne of the hardest, most expensive, and most tedious parts of data science is getting the labels needed for supervised learning projects. For projects inside companies, it's quite common to start by gathering the proprietary data needed in order to train a model that can answer the business question and/or provide the service your company needs. One of the major use cases SageMaker provides is a well-structured way to manage data labeling projects. \u003cstrong\u003e\u003cem\u003eSageMaker GroundTruth\u003c/em\u003e\u003c/strong\u003e allows you to manage private teams, in case your information is sensitive, or to manage public teams by leveraging \u003cstrong\u003e\u003cem\u003eAWS Mechanical Turk\u003c/em\u003e\u003c/strong\u003e, which crowdsources labels from an army of public contractors that have signed up and are paid by the label. \u003c/p\u003e\n\n\u003cp\u003eRecently, Amazon launched an automated labeling service that makes use of machine learning models to generate labels in a human-in-the-loop format, where only labels that are above a particular confidence threshold (which you set yourself) are auto-generated by the model. This allows your contractors to focus only on the tough examples, and saves you from having to pay as much for labels for the easy examples which a model can handle. \u003c/p\u003e\n\n\u003ch3\u003eNotebooks\u003c/h3\u003e\n\n\u003cp\u003eThese are exactly what they sound like -- cloud-based jupyter notebooks, a data scientist's 'bread and butter'!  SageMaker notebooks are just like regular jupyter notebooks, with a bit more added functionality. For instance, it's quite easy to choose from a bunch of pre-configured kernels to select which version of Python/TensorFlow/etc. you want to use. You can start a notebook from scratch inside SageMaker and do all of your work in the cloud, or you can upload preexisting notebooks into SageMaker, allowing you to do you work on a local machine and move it over to the cloud when you're ready for training!\u003c/p\u003e\n\n\u003cp\u003eWe strongly recommend you take a minute to poke around inside a SageMaker notebook to get a feel for what it looks like and what it can do. They're pretty amazing!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/notebook.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eTraining\u003c/h3\u003e\n\n\u003cp\u003eSageMaker's training services allow you to easily leverage cloud computing with AWS's specialized GPU and TPU servers, allowing you to train massive models that simply wouldn't be possible on a local machine. There are a ton of configuration options, and you can easily set budgets, limits, training times, and even auto-tune your hyperparameters! Although this is outside the scope of our lessons on AWS, Amazon provides some pretty amazing (and fast!) tutorials about how to use more specific services like cloud training or \u003ca href=\"https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/\"\u003emodel tuning\u003c/a\u003e once you've completed this section! \u003c/p\u003e\n\n\u003ch3\u003eInference\u003c/h3\u003e\n\n\u003cp\u003eArguably the most important part of the data science pipeline, \u003cstrong\u003e\u003cem\u003eInference\u003c/em\u003e\u003c/strong\u003e services focus on allowing you to create endpoints so that people can consume your models over the internet! One of the most handy parts of SageMaker's approach to inference is the fact that you can productionize your own model, or just use one of theirs! While there are certainly times where you'll need to create, train, and host your own model, AWS has made things simple by allowing you to use their own models and charging you on a per-use basis. For instance, let's say that you needed to make some time series forecasts. While you could go down the very complicated route of training your own model, you could also just make use of AWS SageMaker's \u003cem\u003eDeepAR\u003c/em\u003e model, which uses the most cutting-edge time series model available to make forecasts on your data. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about Amazon SageMaker, and explored some of the common use cases it covers for data scientists!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-introduction-to-aws-sagemaker\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-introduction-to-aws-sagemaker\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"introduction-to-amazon-sagemaker"},{"id":458558,"title":"Data Science and Machine Learning Engineering","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-data-science-and-machine-learning-engineering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-data-science-and-machine-learning-engineering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-data-science-and-machine-learning-engineering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about how the role of Machine Learning Engineer fits into the broader data science job market.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the difference between a Data Scientist and a Machine Learning Engineer\u003c/li\u003e\n\u003cli\u003eExplain the difference between deploying models and productionizing models\u003c/li\u003e\n\u003cli\u003eThink about how your skillset fits into the data science job market\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eData Scientist vs. Machine Learning Engineer\u003c/h2\u003e\n\n\u003cp\u003eAt large, established tech companies, data-related roles have specialized into separate Data Scientist and Machine Learning Engineer categories.\u003c/p\u003e\n\n\u003cp\u003eData Scientists typically run experiments and train models until they have found a solution that works. Once they have trained and validated the model, they typically then hand off productionization of the model to \u003cstrong\u003e\u003cem\u003eMachine Learning Engineers\u003c/em\u003e\u003c/strong\u003e. Whereas the Data Scientist creates the basic prototype, the Machine Learning Engineer's job is to put that model into a production system in a performant and maintainable manner. Whereas Data Scientists at large companies focus on the \"big picture\" by finding solutions to business problems, Machine Learning Engineers focus on the details, implementing the solutions created by the Data Scientists in the best way possible. Data Scientists focus more on analytics and statistics, whereas Machine Learning Engineers will have a stronger command of backend engineering, data structures and algorithms, and software engineering overall. The following diagram lays out the relationship between different technical roles well:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/data-careers-venn-diagram.png\" height=\"80%\" width=\"80%\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eDeploying vs. Productionizing\u003c/h2\u003e\n\n\u003cp\u003eIf we think back to the CRISP-DM process model, Deployment is the final step. We have previously discussed model pickling and how to ensure that data science processes are reproducible, as part of the deployment process:\u003c/p\u003e\n\n\u003cp\u003e\u003ca title=\"Kenneth Jensen, CC BY-SA 3.0 \u003chttps://creativecommons.org/licenses/by-sa/3.0\u003e, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:CRISP-DM_Process_Diagram.png\"\u003e\u003cimg width=\"512\" alt=\"CRISP-DM Process Diagram\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/512px-CRISP-DM_Process_Diagram.png\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eSo, if a Data Scientist toolkit already includes deployment, what additional skills and techniques play into the \u003cstrong\u003eproductionizing\u003c/strong\u003e of models that Machine Learning Engineers perform?\u003c/p\u003e\n\n\u003cp\u003eThere is no bright-line distinction between deploying and productionizing, but in general deploying focuses on the bare minimum to get a model into a context where it is usable for the client, whereas productionizing considers broader factors such as scaling, maintenance, and security. A deployed model might be manually re-trained on the latest data once a month, whereas a productionized model might be continuously re-training as new data comes in. Productionized models might also have test coverage, metric tracking, and \u003ca href=\"https://ml-ops.org/\"\u003emore\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eData Science Skills and the Job Market\u003c/h2\u003e\n\n\u003cp\u003eAs you start to look at job postings, you probably notice that \u003cstrong\u003ea \"Data Scientist\" job can mean many, many different things\u003c/strong\u003e. In some companies, it means a data analyst or a DBA focused on databases or data pipelines. In others, it means someone with a scientific mindset skilled with running A/B tests. Yet others may be highly specialized machine learning roles in areas like NLP, Computer Vision, or Deep Learning -- and these roles may break down further into specializations focused on either research or implementation. As a Junior Data Scientist entering the workforce, it's most likely that you'll land in a generalist role, spending the first few years of your career working on various tasks that focus on all of these areas at least a little bit. Specialization happens later in your career. Out of the gate, the best thing that you can be is a \u003cstrong\u003estrong generalist\u003c/strong\u003e, with the demonstrated ability to contribute to many different sorts of projects that might be expected of a Data Science team.\u003c/p\u003e\n\n\u003ch3\u003eBeing a 'Scrappy' Data Scientist\u003c/h3\u003e\n\n\u003cp\u003eLarge companies with official Machine Learning Engineer roles are typically only looking for more-advanced candidates. For example, a Machine Learning Engineer posting from Amazon we found lists these required qualifications:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e¬∑ 3+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. \u003cbr\u003e\n¬∑ 4+ years of non-internship professional software development, data engineering, or machine learning experience \u003cbr\u003e\n¬∑ Bachelor‚Äôs degree in Electrical Engineering, Computer Sciences, Mathematics or equivalent work experience \u003cbr\u003e\n¬∑ Experience deploying and running services in AWS and in engineering big-data solutions using technologies like Glue, S3, and Spark \u003cbr\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn companies like that, there is less need for anyone in a Data Scientist role to have model productionizing skillsets, since the size of their data teams allows for this kind of specialization.\u003c/p\u003e\n\n\u003cp\u003eWith small and medium-sized companies, it's much less likely that a role like this will exist. Data Scientists in smaller organizations are expected to be a bit more independent, and will likely have to \"wear more hats\".\u003c/p\u003e\n\n\u003cp\u003eFor a data science role at a startup, it's a common expectation for their ata scientists to handle every part of a data science project. This means starting by interviewing key stakeholders and identifying the problem to be solved, followed by rapidly prototyping a solution until you've trained/tuned/validated a model that meets your standards, followed by actually putting that model in production!\u003c/p\u003e\n\n\u003cp\u003eThis means that it's very important to be 'scrappy', and be able to handle anything that's thrown at you as a Data Scientist. Smaller companies often don't have the funds or the infrastructure for a separate Machine Learning Engineering team to handle the details of implementation. In this respect, being able to productionize a machine learning model can make you a much more attractive candidate to employers, and give you a competitive advantage!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about the similarities and differences between Data Scientists and Machine Learning Engineers. We also learned why the ability to productionize a machine learning model is a crucial skill for data scientists at small companies, as well as how this skill can provide a competitive advantage when applying for jobs!\u003c/p\u003e","exportId":"data-science-and-machine-learning-engineering"},{"id":458562,"title":"Introduction to Flask","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-flask-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you'll look at a very simple web application using a framework called Flask.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecall the client-server model and request-response cycle\u003c/li\u003e\n\u003cli\u003eIdentify the key functionality of a web server\u003c/li\u003e\n\u003cli\u003ePractice running a Flask web server on your local computer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClient-Server Model and Request-Response Cycle\u003c/h2\u003e\n\n\u003cp\u003eLet's review some of the fundamentals of web architecture.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/request_response_cycle.png\" alt=\"request response cycle\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Icons made by \u003ca href=\"https://www.flaticon.com/authors/freepik\"\u003eFreepik\u003c/a\u003e from \u003ca href=\"http://www.flaticon.com\"\u003ewww.flaticon.com\u003c/a\u003e)\u003c/p\u003e\n\n\u003ch3\u003eClient\u003c/h3\u003e\n\n\u003cp\u003eThe client makes the \u003cstrong\u003erequest\u003c/strong\u003e and waits for the \u003cstrong\u003eresponse\u003c/strong\u003e. Probably the most familiar HTTP client is a web browser. We have also previously used the \u003ccode\u003erequests\u003c/code\u003e library to make a Python code client.\u003c/p\u003e\n\n\u003ch3\u003eServer\u003c/h3\u003e\n\n\u003cp\u003eThe server runs constantly, waiting for requests, and then responds to requests when it receives them. Most of the time as a data scientist you will be interacting with a server that someone else is managing. However in this lesson we'll learn how to run a server of our own!\u003c/p\u003e\n\n\u003ch3\u003eWeb Server\u003c/h3\u003e\n\n\u003cp\u003eIn this lesson we're specifically looking at a \u003cstrong\u003eweb server\u003c/strong\u003e called Flask. Not all servers are web servers (e.g. database servers are a different kind of server), but web servers are a particularly valuable tool because they allow resources and services to be accessed via the Internet.\u003c/p\u003e\n\n\u003cp\u003eWeb servers accept requests and serve responses with an \u003cstrong\u003eHTTP protocol\u003c/strong\u003e. This protocol means that the client and server can operate using totally different languages, and easily interact so long as they use the right HTTP methods, paths, headers, and responses.\u003c/p\u003e\n\n\u003cp\u003eIn this example, we'll set up:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eHTTP \u003ccode\u003eGET\u003c/code\u003e method\n\n\u003cul\u003e\n\u003cli\u003eUsed by clients to request to read some form of data from the server\u003c/li\u003e\n\u003cli\u003eCorresponds to the \u003ccode\u003e.get()\u003c/code\u003e method in the \u003ccode\u003erequests\u003c/code\u003e library\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/\u003c/code\u003e path\n\n\u003cul\u003e\n\u003cli\u003eEssentially asking for the \"home page\" of the website\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eNo particular headers\u003c/li\u003e\n\u003cli\u003eA string response\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eA \"Hello World\" Flask App\u003c/h2\u003e\n\n\u003cp\u003eFor the rest of this lesson we'll be creating a very basic Flask app. Clone this repository and follow along on your local computer, using your preferred local code editor (e.g. VS Code) and your terminal application.\u003c/p\u003e\n\n\u003ch3\u003eSetting up a Flask Environment\u003c/h3\u003e\n\n\u003cp\u003eLet's make a new \u003ccode\u003econda\u003c/code\u003e environment for developing our Flask app.\u003c/p\u003e\n\n\u003cp\u003eRun this code in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e flask-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8.12 pip\nconda activate flask-env\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003eFlask\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.0.3\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTest whether it worked by running this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich flask\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIt should print out a path that includes \u003ccode\u003eflask-env\u003c/code\u003e. If it doesn't, try repeatedly running \u003ccode\u003econda deactivate\u003c/code\u003e until there is no current active conda environment, then \u003ccode\u003econda activate flask-env\u003c/code\u003e again.\u003c/p\u003e\n\n\u003ch3\u003eRunning the Flask Application\u003c/h3\u003e\n\n\u003cp\u003eNow, run the following commands in the terminal, from the root of this repository:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eexport \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_ENV\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003edevelopment\n\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should produce an output that looks something like:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e * Serving Flask app 'app.py' (lazy loading)\n * Environment: development\n * Debug mode: on\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: \u0026lt;PIN\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf this works, your server is now up and running!\u003c/p\u003e\n\n\u003ch4\u003eTroubleshooting Running the Flask Application\u003c/h4\u003e\n\n\u003cp\u003eIf you do not see an output like the one above, here are some things to investigate:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you get \u003ccode\u003eError: Could not import 'app'\u003c/code\u003e, make sure that you are running the above code \u003cem\u003efrom the root of this repository\u003c/em\u003e. \u003ccode\u003eapp.py\u003c/code\u003e needs to be in the same directory where you are running the \u003ccode\u003eflask run\u003c/code\u003e command. Use \u003ccode\u003ecd\u003c/code\u003e until you are in the correct directory, then try again.\u003c/li\u003e\n\u003cli\u003eIf you get an \u003ccode\u003eOSError\u003c/code\u003e such as \u003ccode\u003eAddress already in use\u003c/code\u003e or \u003ccode\u003eAn attempt was made to access a socket in a way forbidden by its access permissions\u003c/code\u003e, that means that there is another program already running on the default port (5000).\n\n\u003cul\u003e\n\u003cli\u003eIf you think there is a chance that the program using port 5000 is another Flask app, but you don't know where that terminal window is, go through the instructions at the bottom of this page under \"What If I Accidentally Closed the Terminal Window?\"\u003c/li\u003e\n\u003cli\u003eIf this is the first time you are running Flask and there is still something using port 5000 (e.g. macOS Monterey appears to use this port for AirPlay), you can tell Flask to use a different port instead. For example, instead of \u003ccode\u003eenv FLASK_APP=app.py flask run\u003c/code\u003e you could run \u003ccode\u003eenv FLASK_APP=app.py flask run --port 5001\u003c/code\u003e. Just make sure you replace \u003ccode\u003e5000\u003c/code\u003e with \u003ccode\u003e5001\u003c/code\u003e in any of the following examples.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eOpening the Flask Application in the Browser\u003c/h4\u003e\n\n\u003cp\u003eLike Jupyter Notebook, this server needs to stay running in the terminal for the application to work. If you want to do something else in the terminal, you will need to open a new window/tab, or shut down the server with control-C.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eDO NOT\u003c/strong\u003e just close the terminal window when you are done running the Flask app. It will keep running in the background and cause problems unless you locate the process ID and terminate it. Always make sure you use control-C.\u003c/p\u003e\n\n\u003cp\u003eUnlike Jupyter notebook, this doesn't open in the browser automatically. You need to copy the URL \u003ccode\u003ehttp://127.0.0.1:5000/\u003c/code\u003e and paste it into a web browser address bar. Once you do that, you should see this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNow, go ahead and shut down the Flask server by typing control-C in the terminal.\u003c/p\u003e\n\n\u003cp\u003e(If you accidentally closed the terminal window, there are troubleshooting steps at the bottom of this page under \"What If I Accidentally Closed the Terminal Window?\")\u003c/p\u003e\n\n\u003ch2\u003eFlask Source Code\u003c/h2\u003e\n\n\u003cp\u003eThis line\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003emeans that the Flask source code is located in a file called \u003ccode\u003eapp.py\u003c/code\u003e. Open up that file in your favorite text editor.\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003eapp.py\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import flask here\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# define routes for your new flask app\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat's it, that's the entire web server code! The Flask library does a lot of work for us.\u003c/p\u003e\n\n\u003cp\u003eLet's break down each line of \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch3\u003eImporting Flask\u003c/h3\u003e\n\n\u003cp\u003eFirst, we imported the \u003ccode\u003eFlask\u003c/code\u003e class from the \u003ccode\u003eflask\u003c/code\u003e library:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eInstantiating \u003ccode\u003eFlask\u003c/code\u003e Object\u003c/h3\u003e\n\n\u003cp\u003eThen we create a new instance of \u003ccode\u003eFlask\u003c/code\u003e, called \u003ccode\u003eapp\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can find more documentation \u003ca href=\"https://flask.palletsprojects.com/en/2.0.x/api/#flask.Flask\"\u003ehere\u003c/a\u003e, including an explanation for the \u003ccode\u003e__name__\u003c/code\u003e parameter.\u003c/p\u003e\n\n\u003ch3\u003eDefining a \u003ccode\u003e/\u003c/code\u003e Route\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003e@app.route\u003c/code\u003e is a \u003cem\u003edecorator\u003c/em\u003e that adds the function immediately below it as a route on the Flask app. This particular route uses the HTTP \u003ccode\u003eGET\u003c/code\u003e method and the \u003ccode\u003e/\u003c/code\u003e path.\u003c/p\u003e\n\n\u003cp\u003eThe name of the function, \u003ccode\u003eindex()\u003c/code\u003e, is conventional for the home page (\u003ccode\u003e/\u003c/code\u003e path), but it can be anything you want it to be. The important part is the content of the function.\u003c/p\u003e\n\n\u003cp\u003eIn this case, it simply returns a string. In a more complex Flask app, this might take in additional information from the body of the request or the URL parameters, and would typically return JSON or HTML rather than simply a string like \u003ccode\u003e'Hello, world!'\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eExercises\u003c/h2\u003e\n\n\u003cp\u003ePractice defining a few more routes in \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eDefine a route \u003ccode\u003eGET '/welcome'\u003c/code\u003e which shows the text \u003ccode\u003e'Welcome to an amazing Flask App!'\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eDefine a route \u003ccode\u003eGET '/goodbye'\u003c/code\u003e which shows the text \u003ccode\u003e'Thanks for looking around. Come back again soon!'\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTest these out by running the app again:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen go to the browser and try:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:5000/welcome\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:5000/goodbye\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eFinishing Up\u003c/h2\u003e\n\n\u003cp\u003eMake sure you shut down the Flask server by typing control-C in the terminal window where it is running.\u003c/p\u003e\n\n\u003ch2\u003eWhat If I Accidentally Closed the Terminal Window?\u003c/h2\u003e\n\n\u003cp\u003eIt's ok! You will still be able to shut down the Flask server, it will just take more steps. First you need to identify the process ID of your Flask server, then run a command to terminate that process.\u003c/p\u003e\n\n\u003ch3\u003eIdentifying the Process Using the Port\u003c/h3\u003e\n\n\u003cp\u003eFor these examples we will assume that you did not specify a port when you started the Flask server, so it is running on port 5000. If you used a different port (e.g. 5001 due to macOS Monterey) then make sure you replace the port numbers when following these instructions.\u003c/p\u003e\n\n\u003ch4\u003eMac or Linux\u003c/h4\u003e\n\n\u003cp\u003eOn Mac or Linux, you should be able to use the \u003ccode\u003elsof\u003c/code\u003e command. \u003ccode\u003elsof\u003c/code\u003e is short for \"list open files\". Run this in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003elsof \u003cspan class=\"nt\"\u003e-P\u003c/span\u003e \u003cspan class=\"nt\"\u003e-i\u003c/span\u003e :5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eCOMMAND   PID     USER   FD  TYPE             DEVICE SIZE/OFF NODE NAME\nPython  30786 XXXXXXXX   3u  IPv4 0xXXXXXXXXXXXXXXXX      0t0  TCP localhost:5000 (LISTEN)\nPython  30786 XXXXXXXX   4u  IPv4 0xXXXXXXXXXXXXXXXX      0t0  TCP localhost:5000 (LISTEN)\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe process ID is the value in the \u003ccode\u003ePID\u003c/code\u003e column of that output.\u003c/p\u003e\n\n\u003ch4\u003eWindows\u003c/h4\u003e\n\n\u003cp\u003eOn Windows, you should be able to use the \u003ccode\u003enetstat\u003c/code\u003e command. \u003ccode\u003enetstat\u003c/code\u003e is short for \"network statistics\". Run this in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003enetstat \u003cspan class=\"nt\"\u003e-ano\u003c/span\u003e | findstr 5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eProto  Local Address Foreign Address     State   PID\nTCP   127.0.0.1:5000       0.0.0.0:0 LISTENING 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eTerminating the Process\u003c/h3\u003e\n\n\u003cp\u003eIn both of the above examples, the process ID is 30786. Make sure you replace this with the actual process ID that you identified!\u003c/p\u003e\n\n\u003ch4\u003eMac or Linux\u003c/h4\u003e\n\n\u003cp\u003eYou can use the \u003ccode\u003ekill\u003c/code\u003e command to terminate the process in the command line on Mac or Linux.\u003c/p\u003e\n\n\u003cp\u003eFor example, \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003ekill\u003c/span\u003e \u003cspan class=\"nt\"\u003e-9\u003c/span\u003e 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can also use the \"Activity Monitor\" application on Mac if you are more comfortable with a graphical user interface. Just find the process with the relevant ID, click on the process, and click the button with the X.\u003c/p\u003e\n\n\u003ch4\u003eWindows\u003c/h4\u003e\n\n\u003cp\u003eYou can use the \u003ccode\u003etaskkill\u003c/code\u003e command to terminate the process in the command line on Windows.\u003c/p\u003e\n\n\u003cp\u003eFor example,\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003etaskkill /F /PID 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can also use the \"Task Manager\" application on Windows if you are more comfortable with a graphical user interface. If you don't immediately see the process you're looking for, try clicking \"More details\" to see the full list. Select the process you want to terminate and then click \"End task\".\u003c/p\u003e\n\n\u003ch3\u003eChecking Port 5000 Again\u003c/h3\u003e\n\n\u003cp\u003eNow if you re-run the command checking port 5000 (either \u003ccode\u003elsof\u003c/code\u003e or \u003ccode\u003enetstat\u003c/code\u003e), no processes should be displayed. You should now be able to execute the \u003ccode\u003eflask run\u003c/code\u003e command without getting an \u003ccode\u003eOSError\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you reviewed the client-server model and request-response cycle, and saw a specific application of it using a basic Flask app.\u003c/p\u003e","exportId":"introduction-to-flask"},{"id":458564,"title":"Deploying a Model with Flask","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-flask-deployment\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-deployment\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-deployment/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have learned the basics of the Flask web framework, you will combine that knowledge with your prior knowledge of cloud functions to deploy a machine learning model as an HTTP API with Flask!\u003c/p\u003e\n\n\u003cp\u003eClone this repository and work locally so that you can run and test your Flask app. Start by running \u003ccode\u003ejupyter notebook\u003c/code\u003e so that you can run the code examples in this notebook.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecall the model pickling and unpickling process from the cloud function approach\u003c/li\u003e\n\u003cli\u003eIncorporate a model prediction function into a Flask web app\u003c/li\u003e\n\u003cli\u003eDeploy a machine learning model as an HTTP API using Flask and Heroku\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRecall: Cloud Functions\u003c/h2\u003e\n\n\u003cp\u003eIn a previous lesson, you were introduced to cloud functions. With a cloud function, you need:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eA pickled model file\u003c/li\u003e\n\u003cli\u003eA Python file defining the function\u003c/li\u003e\n\u003cli\u003eA requirements file\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eWe will reuse the model file and Python code from the previous cloud functions lesson, so you may want to go back and review that lesson if you're confused about any of the details.\u003c/p\u003e\n\n\u003cp\u003eThe model file has already been included in this repository as \u003ccode\u003emodel.pkl\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e \u003cspan class=\"n\"\u003els\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe'll also be reusing this code from the cloud function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFinally, we'll also build our environment starting with the \u003ccode\u003erequirements.txt\u003c/code\u003e from that lesson:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003escikit-learn==0.23.2\njoblib==0.17.0\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eCloud Functions without Flask\u003c/h3\u003e\n\n\u003cp\u003ePreviously, we deployed this cloud function using this \u003ccode\u003epredict\u003c/code\u003e function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    `request` is an HTTP request object that will automatically be passed\n    in by Google Cloud Functions\n\n    You can find all of its properties and methods here:\n    https://flask.palletsprojects.com/en/1.0.x/api/#flask.Request\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen bundling the model file, Python file, and requirements file into a single archive and uploading that to Google Cloud Functions.\u003c/p\u003e\n\n\u003cp\u003eThat required a fair amount of configuration within Google Cloud Functions to specify the function to be invoked (\u003ccode\u003epredict\u003c/code\u003e), the permissions (public on the web), and the storage location for the archive.\u003c/p\u003e\n\n\u003ch2\u003eCloud Functions with Flask\u003c/h2\u003e\n\n\u003cp\u003eWhen using Flask directly (rather than via the Google Cloud Functions implementation) and deploying on Heroku, we will need to import and declare a few more things within the code itself, but at the same time we won't need to configure as much within the website interface. We'll also be able to test our code locally!\u003c/p\u003e\n\n\u003ch3\u003eRecall: Flask App Basics\u003c/h3\u003e\n\n\u003cp\u003eHere was the source code of our previous simple Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import flask here\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# define routes for your new flask app\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe imported the Flask library, created a Flask app, and defined a single route \u003ccode\u003e/\u003c/code\u003e, which just returns the text \u003ccode\u003e'Hello, world!'\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eNow let's add in those functions from our cloud function.\u003c/p\u003e\n\n\u003ch3\u003eAdding ML Prediction Functionality to Our Flask App\u003c/h3\u003e\n\n\u003ch4\u003eImports\u003c/h4\u003e\n\n\u003cp\u003eInstead of just importing Flask, we'll also need to add in the \u003ccode\u003ejoblib\u003c/code\u003e and \u003ccode\u003ejson\u003c/code\u003e imports from the cloud function. We also need to import \u003ccode\u003erequest\u003c/code\u003e from Flask so that we can parse the request data.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Flask is the overall web framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# joblib is used to unpickle the model\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# json is used to prepare the result\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eFlask App Setup\u003c/h4\u003e\n\n\u003cp\u003eThis is the same as in our simple Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eAdding Cloud Function\u003c/h4\u003e\n\n\u003cp\u003eThen we include our \u003ccode\u003eiris_prediction\u003c/code\u003e function from previously. In a more complex Flask app, this would likely be stored in a separate \u003ccode\u003e.py\u003c/code\u003e file, but we're keeping it all in one place for the sake of simplicity.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eDefining Routes\u003c/h4\u003e\n\n\u003cp\u003eFor now, let's keep the \u003ccode\u003e/\u003c/code\u003e route as-is, then also add the \u003ccode\u003e/predict\u003c/code\u003e route.\u003c/p\u003e\n\n\u003cp\u003eSome notes on this change:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e/predict\u003c/code\u003e accepts HTTP \u003ccode\u003ePOST\u003c/code\u003e requests, which is conventional for a form submission. Therefore we specify \u003ccode\u003emethods=['POST']\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eInstead of having \u003ccode\u003erequest\u003c/code\u003e be a function parameter like it was in our cloud function, instead it's something we imported earlier. However it works the same way as the function parameter.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003ePulling It All Together\u003c/h4\u003e\n\n\u003cp\u003eWhen we bring together the imports, app setup, cloud function, and routes, the entire contents of \u003ccode\u003eapp.py\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Flask is the overall web framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# joblib is used to unpickle the model\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# json is used to prepare the result\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# helper function here\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# defining routes here\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eRunning the Flask App Locally\u003c/h2\u003e\n\n\u003cp\u003eYou should already have a local environment called \u003ccode\u003eflask-env\u003c/code\u003e from the \u003cstrong\u003eIntroduction to Flask\u003c/strong\u003e lesson. If you do not, go back to that lesson and follow the steps under \u003ccode\u003eSetting up a Flask Environment\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch3\u003ePreparing the Environment\u003c/h3\u003e\n\n\u003cp\u003eRun this code in a new terminal window (separate from where you are running \u003ccode\u003ejupyter notebook\u003c/code\u003e) to activate \u003ccode\u003eflask-env\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate flask-env\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis environment has everything you need to run a basic Flask app, but it doesn't have the cloud function dependencies yet.\u003c/p\u003e\n\n\u003cp\u003eRun these commands in the terminal to install those dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.17.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003escikit-learn\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.23.2\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we should be ready to run our app!\u003c/p\u003e\n\n\u003ch3\u003eRunning the Flask Application\u003c/h3\u003e\n\n\u003cp\u003eAs previously, run this command in the terminal from the root of this repository:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eexport \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_ENV\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003edevelopment\n\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you open \u003ca href=\"http://127.0.0.1:5000/\"\u003ehttp://127.0.0.1:5000/\u003c/a\u003e in the browser, you should see this, just like before:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eLeave the server running\u003c/strong\u003e and let's use the \u003ccode\u003erequests\u003c/code\u003e library to send a request to our app!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erequests\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://127.0.0.1:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e\u0026lt;Response [200]\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe expected output of the above code cell is \u003ccode\u003e\u0026lt;Response [200]\u0026gt;\u003c/code\u003e. If you get a different response code, make sure that the code above matches the Flask app output where it says \"Running on\". For example, if you're running on port 5001 instead of 5000, make sure the \u003ccode\u003eurl\u003c/code\u003e specified above matches.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'predicted_class': 0}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat! You have now made an API request to a locally-running Flask app!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eGo ahead and shut down the current Flask app by typing control-C in the terminal.\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch2\u003eDeploying to Heroku\u003c/h2\u003e\n\n\u003cp\u003eThe real goal of deploying an app is not just to get a web server running on your local computer, it's to get it hosted live on the web!\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.heroku.com/\"\u003eHeroku\u003c/a\u003e is a platform-as-a-service company that is great for hosting this kind of application. We'll plan to use that, because it has a completely-free tier and allows you to host a Flask app with minimal setup steps.\u003c/p\u003e\n\n\u003ch3\u003ePreparing the Repository for Heroku\u003c/h3\u003e\n\n\u003ch4\u003eRunning a Production Server\u003c/h4\u003e\n\n\u003cp\u003ePreviously when we ran our Flask app, it was always in development mode. This is useful for playing around and editing code, but is unnecessarily slow for a published app.\u003c/p\u003e\n\n\u003cp\u003eLet's use a production-quality web server called \u003ca href=\"https://docs.pylonsproject.org/projects/waitress/en/latest/\"\u003eWaitress\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eFirst, install it in the \u003ccode\u003eflask-env\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ewaitress\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow instead of the \u003ccode\u003eflask run\u003c/code\u003e command, use this command to run the production server:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewaitress-serve \u003cspan class=\"nt\"\u003e--port\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e5000 app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(You may need to allow Python to access the network, if your operating system gives you a pop-up.)\u003c/p\u003e\n\n\u003cp\u003eThis should produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eINFO:waitress:Serving on http://0.0.0.0:5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eJust like before, you should be able to copy the specified URL, paste it into the browser, and see your \"Hello, World!\" page.\u003c/p\u003e\n\n\u003cp\u003eThe code below should also work:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://0.0.0.0:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'predicted_class': 0}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat's it! \u003cstrong\u003eGo ahead and shut down the server again using control-C.\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch4\u003eRequirements Files\u003c/h4\u003e\n\n\u003cp\u003eWhen we made a cloud function for Google Cloud Functions, we used a \u003ccode\u003erequirements.txt\u003c/code\u003e file. For Heroku, we'll need three files like this:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e: tells Heroku that we are running a Python application, and what version of Python\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e: lists the required Python packages (same as we did for the Google Cloud Function, adding Flask as a requirement)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eProcfile\u003c/code\u003e: tells Heroku what command to run\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eAll of these files are already located in this repository, but we'll explain how they work below so that you know how to make your own!\u003c/p\u003e\n\n\u003cp\u003eOur \u003ccode\u003eruntime.txt\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003epython-3.8.13\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is because we are running Python 3.8 in this conda environment. If you get an error about the \"runtime\" when trying to deploy with Heroku, it's possible that this version of Python is no longer supported. Look at the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes\u003c/a\u003e list to find other options.\u003c/p\u003e\n\n\u003cp\u003eOur \u003ccode\u003erequirements.txt\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThose are all the packages we installed with pip!\u003c/p\u003e\n\n\u003cp\u003eFinally, our \u003ccode\u003eProcfile\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is similar to what we ran in the terminal locally, except we added a \u003ccode\u003eweb:\u003c/code\u003e to the beginning to indicate that this is a web process, and we parameterized \u003ccode\u003e$PORT\u003c/code\u003e so that it will use whatever port Heroku is configured to use, rather than hard-coding it to 5000.\u003c/p\u003e\n\n\u003ch3\u003eSetting Up the App on Heroku\u003c/h3\u003e\n\n\u003cp\u003eGo to \u003ca href=\"https://signup.heroku.com/login\"\u003ehttps://signup.heroku.com/login\u003c/a\u003e and create an account (or log in if you already have one).\u003c/p\u003e\n\n\u003cp\u003eThen go to \u003ca href=\"https://dashboard.heroku.com/new-app\"\u003ehttps://dashboard.heroku.com/new-app\u003c/a\u003e to make a new app on Heroku.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe name can be anything you want, but must be unique. You can fill in a name if you have one in mind, or you can just click \u003cstrong\u003eCreate app\u003c/strong\u003e and you'll get a randomly-suggested name.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003eDeployment method\u003c/strong\u003e and choose \u003cstrong\u003eGitHub\u003c/strong\u003e. This will open another menu section, where you should click the \u003cstrong\u003eConnect to GitHub\u003c/strong\u003e button. You will get a pop-up window where you will be asked to sign in with GitHub.\u003c/p\u003e\n\n\u003cp\u003eOnce connected, a text box should appear where you can search for the repository you want to use. (If you're just practicing with this lesson repo, make sure you have forked this repo to your GitHub account, then search for the lesson repo name.) Click \u003cstrong\u003eSearch\u003c/strong\u003e, then click \u003cstrong\u003eConnect\u003c/strong\u003e on the appropriate repository.\u003c/p\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003eManual deploy\u003c/strong\u003e, choose the appropriate branch, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eIf everything goes smoothly, you should see a build log, then the message \u003cstrong\u003eYour app was successfully deployed.\u003c/strong\u003e Then if you click the \u003cstrong\u003eView\u003c/strong\u003e button, that should open the \"Hello, World!\" page in a new browser tab.\u003c/p\u003e\n\n\u003cp\u003eIn the cell below, replace the value of \u003ccode\u003ebase_url\u003c/code\u003e with your actual Heroku app URL.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# base URL (ending with .herokuapp.com, no trailing /)\n\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eTroubleshooting Workflow on Heroku\u003c/h3\u003e\n\n\u003cp\u003eEspecially because the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes\u003c/a\u003e list changes very frequently, it's likely that your deployment won't succeed on the first try. That's ok!\u003c/p\u003e\n\n\u003ch4\u003eIdentifying the Problem\u003c/h4\u003e\n\n\u003cp\u003e\u003cstrong\u003eFirst make sure that the code works on your local computer.\u003c/strong\u003e It is MUCH easier to debug when working locally vs. working on a cloud service like Heroku!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eThen make sure you read the error message\u003c/strong\u003e to understand what is going on and why:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAre any of the necessary files missing? Double-check that you used Git to add, commit, and push all of the relevant pieces:\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e: the Python version\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eProcfile\u003c/code\u003e: the terminal command for Heroku to run\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e: the Python package requirements\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eapp.py\u003c/code\u003e: the actual Flask app source code\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emodel.pkl\u003c/code\u003e: the pickled model file\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eIf the error message mentions the \"runtime\", you probably need to review the list of supported runtimes and modify \u003ccode\u003eruntime.txt\u003c/code\u003e so that it reflects the new version\u003c/li\u003e\n\u003cli\u003eIf the error message happens during the \u003ccode\u003epip install\u003c/code\u003e step, that might mean that one of the packages you're using is no longer available from the Python Package Index (the source where \u003ccode\u003epip\u003c/code\u003e installs things from). Go to \u003ca href=\"https://pypi.org/\"\u003ehttps://pypi.org/\u003c/a\u003e to research the packages you are trying to use, make a new \u003ccode\u003econda\u003c/code\u003e environment locally, and try installing the packages one by one until you have a working \u003ccode\u003erequirements.txt\u003c/code\u003e file.\u003c/li\u003e\n\u003cli\u003eIf the error message happens when you're actually trying to view a page or run \u003ccode\u003erequests.post\u003c/code\u003e, most likely you didn't include all of the requirements in \u003ccode\u003erequirements.txt\u003c/code\u003e. You can run \u003ccode\u003epip freeze\u003c/code\u003e in the terminal to see all of the packages you're using locally\u003c/li\u003e\n\u003cli\u003eIf the build logs aren't giving you enough information, go to \u003cstrong\u003eMore\u003c/strong\u003e --\u0026gt; \u003cstrong\u003eView logs\u003c/strong\u003e to see the logs from the actual application running. This will give you information about the incoming requests.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eUpdating the Source Code on Heroku\u003c/h4\u003e\n\n\u003cp\u003eFirst, use Git to add, commit, and push your changes to GitHub. Then go back to the \u003cstrong\u003eDeploy\u003c/strong\u003e tab, scroll to the bottom, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e. Then wait to see if you get the \"Your app was successfully deployed\" message, and repeat the \"Identifying the Problem\" steps as needed.\u003c/p\u003e\n\n\u003cp\u003eYou can also enable automatic deploys if you want to, but we tend to find that the manual process is easier to debug.\u003c/p\u003e\n\n\u003ch2\u003eLevel Up\u003c/h2\u003e\n\n\u003cp\u003eCurrently we are mainly using Flask to serve JSON content, but Flask is also a web server that can serve HTML!\u003c/p\u003e\n\n\u003cp\u003eIf you are comfortable writing HTML, try modifying the \u003ccode\u003e/\u003c/code\u003e route so that it displays useful information, e.g. explaining how to call the API and make a prediction.\u003c/p\u003e\n\n\u003cp\u003eYou can write multi-line HTML directly within \u003ccode\u003eapp.py\u003c/code\u003e using a triple-quoted Python string like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\"\n    \u0026lt;h1\u0026gt;API Documentation\u0026lt;/h1\u0026gt;\n    \u0026lt;p\u0026gt;\n      Paragraph of text here\n    \u0026lt;/p\u0026gt;\n    \"\"\"\u003c/span\u003e    \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAlternatively, you can create a \u003ccode\u003estatic\u003c/code\u003e folder containing a file called \u003ccode\u003eindex.html\u003c/code\u003e, then re-write the \u003ccode\u003e/\u003c/code\u003e route so it looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003esend_from_directory\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003esend_from_directory\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"static\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"index.html\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThat's it! You have now learned about how to incorporate a cloud function into a Flask app, and how to deploy that Flask app on Heroku!\u003c/p\u003e","exportId":"deploying-a-model-with-flask"},{"id":458567,"title":"Introduction to Dash","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-dash-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have learned how to build a basic web application using Flask, you'll learn about a web framework called Dash! Dash is built on top of Flask and allows you to build interactive web applications with minimal HTML and no JavaScript.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine the difference between a static and a dynamic web page\u003c/li\u003e\n\u003cli\u003eRun a Dash app directly within Jupyter Notebook\u003c/li\u003e\n\u003cli\u003eIteratively build a Dash app that contains a layout made of components as well as a callback\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eStatic vs. Dynamic Web Pages\u003c/h2\u003e\n\n\u003ch3\u003eStatic Web Pages\u003c/h3\u003e\n\n\u003cp\u003eRecall our simple Flask app home page (from the \u003ccode\u003e/\u003c/code\u003e route):\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThat home page is able to display information, but the interface is fundamentally \u003cstrong\u003e\u003cem\u003estatic\u003c/em\u003e\u003c/strong\u003e. In other words, the content served by the backend server is always the same. It also doesn't matter whether the user clicks anywhere on the page; the page will always just say \u003ccode\u003e\"Hello, world!\"\u003c/code\u003e. Static web pages are built using \u003cstrong\u003eHTML\u003c/strong\u003e and \u003cstrong\u003eCSS\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eDynamic Web Pages\u003c/h3\u003e\n\n\u003cp\u003eWhen we developed our \u003ccode\u003e/predict\u003c/code\u003e route, we made an API interface that could dynamically generate results, but that interface was only accessible through code. What if we want an interface where a user can specify the values being used for prediction?\u003c/p\u003e\n\n\u003cp\u003eTo do that, we'll make a \u003cstrong\u003e\u003cem\u003edynamic\u003c/em\u003e\u003c/strong\u003e web page. The user can change values using familiar web form inputs (text boxes, drop-downs, checkboxes, sliders, etc.) and the model's predictions will automatically appear on the page. This kind of interface is much easier and more intuitive than using the \u003ccode\u003erequests\u003c/code\u003e library, and looks great in a data science portfolio!\u003c/p\u003e\n\n\u003cp\u003eDynamic web pages are built using \u003cstrong\u003eJavaScript\u003c/strong\u003e in addition to HTML and CSS. JavaScript is able to attach \u003cstrong\u003e\u003cem\u003ecallbacks\u003c/em\u003e\u003c/strong\u003e to the HTML elements (e.g. triggered by clicking on a button), which can optionally interact with the backend server before ultimately making some change to the page's HTML and/or CSS.\u003c/p\u003e\n\n\u003cp\u003eLearning JavaScript can be complicated. Some of the constructs are similar to Python (e.g. first-class functions) but the syntax and error behavior are fairly different. Luckily with \u003cstrong\u003eDash\u003c/strong\u003e we can create \u003cstrong\u003e\u003cem\u003ecomponents\u003c/em\u003e\u003c/strong\u003e and callbacks just using Python, and they will be translated into the appropriate HTML, CSS, and JavaScript code by Dash!\u003c/p\u003e\n\n\u003ch2\u003eA \"Hello World\" Dash App\u003c/h2\u003e\n\n\u003cp\u003eDash is built on top of Flask, and therefore has a similar setup. Once you have the appropriate libraries installed and imported, you instantiate an \u003ccode\u003eapp\u003c/code\u003e, then you can specify properties of that app before running the web server.\u003c/p\u003e\n\n\u003ch3\u003eSetting up a Dash Environment\u003c/h3\u003e\n\n\u003cp\u003eClone this repository locally so you can work through these examples!\u003c/p\u003e\n\n\u003cp\u003eLet's make a new \u003ccode\u003econda\u003c/code\u003e environment for developing our Dash app.\u003c/p\u003e\n\n\u003cp\u003eRun this code in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e dash-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8.12 pip\nconda activate dash-env\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003enotebook\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003eWerkzeug\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.0.3\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ejupyter-dash\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.4\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003edash-bootstrap-components\u003cspan class=\"o\"\u003e==\u003c/span\u003e1.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epandas\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e1.4\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.17.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003escikit-learn\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.23.2\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow, launch this notebook using \u003ccode\u003ejupyter notebook\u003c/code\u003e\u003c/p\u003e\n\n\u003ch3\u003eRunning the Dash Application\u003c/h3\u003e\n\n\u003cp\u003eUnlike with Flask alone, there is functionality to run a Dash app directly within a Jupyter Notebook!\u003c/p\u003e\n\n\u003cp\u003eWe'll run a basic Dash app below, and when you run the cell containing \u003ccode\u003eapp.run_server\u003c/code\u003e, the dynamic web page should appear directly below the cell:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import jupyter notebook version of dash framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# import html elements for dash\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf this works, you have now run a Dash app! That was easier than running a Flask app!\u003c/p\u003e\n\n\u003ch4\u003eTroubleshooting\u003c/h4\u003e\n\n\u003cp\u003eIf the above code didn't work, make sure you read the error message.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you get a \u003ccode\u003eModuleNotFoundError\u003c/code\u003e that means that something went wrong with either installing the dependencies or pointing Jupyter Notebook to the right environment\n\n\u003cul\u003e\n\u003cli\u003eTroubleshooting dependency installation:\u003c/li\u003e\n\u003cli\u003eGo to the terminal and make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003ewhich python\u003c/code\u003e and make sure that it prints out a path that includes \u003ccode\u003edash-env\u003c/code\u003e. If it doesn't, run \u003ccode\u003econda deactivate\u003c/code\u003e then \u003ccode\u003econda remove --name dash-env --all\u003c/code\u003e and start over with the instructions to create \u003ccode\u003edash-env\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eLaunch a Python shell by running \u003ccode\u003epython\u003c/code\u003e in the terminal. Then test out the import statements there, and see if you get a \u003ccode\u003eModuleNotFoundError\u003c/code\u003e. If you get the error, that means you should try again with \u003ccode\u003epip install\u003c/code\u003eing the required packages. If you don't get the error, it means that your problem is probably with pointing Jupyter Notebook to the right environment\u003c/li\u003e\n\u003cli\u003eTroubleshooting Jupyter Notebook environment:\u003c/li\u003e\n\u003cli\u003eGo to the terminal and make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003epython -m ipykernel install --user --name dash-env --display-name \"Python (dash-env)\"\u003c/code\u003e to install this conda environment as an IPython kernel\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003ejupyter notebook\u003c/code\u003e, then select the \u003cstrong\u003eKernel\u003c/strong\u003e --\u0026gt; \u003cstrong\u003eChange kernel\u003c/strong\u003e menu option. \u003ccode\u003ePython (dash-env)\u003c/code\u003e should be one of the options. Select it. Now you should be able to run the above cells successfully.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eIf you get an \u003ccode\u003eOSError\u003c/code\u003e such as \u003ccode\u003eAddress already in use\u003c/code\u003e or \u003ccode\u003eAn attempt was made to access a socket in a way forbidden by its access permissions\u003c/code\u003e, that's the same issue as with Flask, where something else is running on port 5000 on your computer\n\n\u003cul\u003e\n\u003cli\u003eIn \u003ccode\u003eapp.run_server\u003c/code\u003e, change the value of the \u003ccode\u003eport\u003c/code\u003e argument to something other than 5000 (e.g. 5001). This should resolve the \u003ccode\u003eOSError\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eUtilizing Components in Our Dash App Layout\u003c/h2\u003e\n\n\u003cp\u003eRight now the only thing in our app is the text \"Hello, World!\". Let's make it a bit more interesting!\u003c/p\u003e\n\n\u003ch3\u003eMarkdown Components\u003c/h3\u003e\n\n\u003cp\u003ePreviously we used an HTML \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag to display the \"Hello, World!\" text. In Dash, this is instantiated using \u003ccode\u003ehtml.P\u003c/code\u003e. You can find documentation for this component and all other Dash HTML components \u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eHowever as a data scientist who has typically been working in a Jupyter Notebook, you are probably more familiar with Markdown than HTML. Luckily there is a Markdown component we can use that will translate Markdown into HTML for us. This is the \u003ccode\u003edcc.Markdown\u003c/code\u003e component (\u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003edocumentation here\u003c/a\u003e). Usage is fairly straightforward; you just specify the Markdown as a string argument (typically a triple-quoted multi-line string):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import dash core components\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to an extended markdown example\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Welcome to the Home Page\n\n## Introduction\n\nHello, World! Here is some **bold** and *italic* text, a `code snippet`,\n and a [hyperlink](https://www.google.com/).\n\n## Some Lists\n\n* Unordered list item 1\n* Unordered list item 2\n\n1. Ordered list item 1\n2. Ordered list item 2\n\n## This Is Much Better than the Old Home Page\n\nBelow is an image embedded using Markdown, showing the old home page.\n\n![hello world page](https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png)\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eDataTable Components\u003c/h3\u003e\n\n\u003cp\u003eFor a data science app, it is often useful to be able to display tabular data. Let's go ahead and load in the Iris Dataset from scikit-learn:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWhat if we wanted to display this data in our web page? Enter the DataTable component (\u003ca href=\"https://dash.plotly.com/datatable\"\u003edocumentation here\u003c/a\u003e). This is a Dash component designed for just this purpose!\u003c/p\u003e\n\n\u003cp\u003eLet's go ahead and display a random sample of 10 records from the dataset:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to a data table\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e350\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat!\u003c/p\u003e\n\n\u003ch3\u003eCombining Multiple Components\u003c/h3\u003e\n\n\u003cp\u003eSo far, we have reassigned the \u003ccode\u003elayout\u003c/code\u003e attribute of our app each time, so that it originally was a \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag containing \"Hello, World!\", then it was a Markdown component with various headings and other content, then it was a DataTable with data from the Iris Dataset.\u003c/p\u003e\n\n\u003cp\u003eIf we want to use more than one component in the same web page?\u003c/p\u003e\n\n\u003cp\u003eThe most straightforward way is to use multiple nested Div components (\u003ca href=\"https://dash.plotly.com/dash-html-components/div\"\u003edocumentation here\u003c/a\u003e). Div components for Dash are represented as HTML \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e tags, which are generic HTML container elements.\u003c/p\u003e\n\n\u003cp\u003eThe example below combines some Markdown text with the DataTable with data from the Iris Dataset.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# declaring our individual components\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# creating an app layout with these components as children\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"450\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we have both Markdown and DataTable components in the same web page!\u003c/p\u003e\n\n\u003ch3\u003eStyling Our Components\u003c/h3\u003e\n\n\u003cp\u003eThis is an optional step, but it makes the components look a bit better together. If you know how to work with CSS, you can define your own custom styles and follow \u003ca href=\"https://dash.plotly.com/external-resources\"\u003ethese instructions\u003c/a\u003e, but for now we'll just use the recommended style sheet from Dash.\u003c/p\u003e\n\n\u003cp\u003eStyle sheets are added when the \u003ccode\u003eapp\u003c/code\u003e is instantiated. Then we can add our Markdown and DataTable elements and see them with their new styles:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create a list of external stylesheets, with just one CSS file (for now)\n\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'https://codepen.io/chriddyp/pen/bWLwgP.css'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNot a huge change, but the look and feel is more polished with the stylesheet than without it.\u003c/p\u003e\n\n\u003ch2\u003eCallbacks\u003c/h2\u003e\n\n\u003cp\u003eSo far, we have used Dash components to avoid writing HTML and CSS directly, but we still fundamentally have a static page. Let's add a callback to create some dynamic, interactive functionality!\u003c/p\u003e\n\n\u003ch3\u003eHTML and JavaScript Background: Element \u003ccode\u003eid\u003c/code\u003es\u003c/h3\u003e\n\n\u003cp\u003eOne of the strategies for connecting HTML and JavaScript logic uses the \u003ccode\u003eid\u003c/code\u003e attribute of the HTML elements. In properly-formatted HTML, the \u003ccode\u003eid\u003c/code\u003e attribute is a unique identifier that only applies to a single element on the page. When the \u003ccode\u003eid\u003c/code\u003e has been declared, then JavaScript can locate the element using that \u003ccode\u003eid\u003c/code\u003e in order to specify callback behavior.\u003c/p\u003e\n\n\u003cp\u003eLet's start with a simple HTML page, consisting of a \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e containing a \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag and a \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight html\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e\u0026lt;div\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;button\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003eClick here\u003cspan class=\"nt\"\u003e\u0026lt;/button\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;p\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003eThe button has not been clicked\u003cspan class=\"nt\"\u003e\u0026lt;/p\u0026gt;\u003c/span\u003e\n\u003cspan class=\"nt\"\u003e\u0026lt;/div\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd let's say that when we click on that \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag, we want the text of the \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag to change to say \"The button was clicked!\" instead of saying \"The button has not been clicked\".\u003c/p\u003e\n\n\u003cp\u003eTo do that in JavaScript, the code would look something like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight javascript\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ebutton\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003edocument\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003egetElementById\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003ebtn\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ep\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003edocument\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003egetElementById\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003ep\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"nx\"\u003ebutton\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eaddEventListener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003eclick\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nx\"\u003ee\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"nx\"\u003ep\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003einnerText\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003eThe button was clicked!\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eDon't worry too much about the specific syntax here. The main takeaway is that:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eJavaScript code is able to locate HTML elements by their \u003ccode\u003eid\u003c/code\u003e property\u003c/li\u003e\n\u003cli\u003eOnce JavaScript has located the HTML element, it can add \"event listeners\" that define what should happen when an event (e.g. clicking) happens\u003c/li\u003e\n\u003cli\u003eOnce JavaScript has located the HTML element, it can modify the attributes of the element (e.g. setting the inner text)\u003c/li\u003e\n\u003cli\u003eSteps 2 and 3 are often combined together, so that an event can trigger the modification of the attributes of one or more HTML element\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3\u003eA Simple Callback\u003c/h3\u003e\n\n\u003cp\u003eLet's implement the HTML and JavaScript code above using Dash instead. We'll need a layout consisting of a Div component for the \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e tag, a Button component (\u003ca href=\"https://dash.plotly.com/dash-html-components/button\"\u003edocumentation here\u003c/a\u003e) for the \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag, a P component for the \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag, a function that modifies the component's text, and a decorator that connects the click event to the text modification.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to our simple html page with id attributes\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eButton\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Click here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# attach a callback so that when n_clicks of the Button changes,\n# the children text of the P changes\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"n_clicks\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eset_text\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en_clicks\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003en_clicks\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"The button has not been clicked\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"The button was clicked!\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you have worked with JavaScript callbacks before, note that the setup with Dash is \u003cstrong\u003edifferent from a typical JavaScript control flow\u003c/strong\u003e. Instead of being event-driven, where clicking the Button \u003cstrong\u003e\u003cem\u003etriggers\u003c/em\u003e\u003c/strong\u003e the change to the P text, the callback function in Dash essentially means that the Button and P components are \u003cstrong\u003e\u003cem\u003esynchronized\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eThis synchronization means that properties of the P component (in this case, the \u003ccode\u003echildren\u003c/code\u003e attribute, which specifies the inner contents) can be automatically connected to properties of the Button component (in this case, the \u003ccode\u003en_clicks\u003c/code\u003e attribute, which counts how many times the button has been clicked).\u003c/p\u003e\n\n\u003cp\u003eThis is more like a spreadsheet cell that calculates a value based on the value of another cell; the calculation occurs as soon as the page loads, rather than waiting for a particular user interaction. This also works similarly to socket programming.\u003c/p\u003e\n\n\u003ch2\u003eBringing It All Together\u003c/h2\u003e\n\n\u003cp\u003eLet's take our Markdown + DataTable example from earlier and make it interactive!\u003c/p\u003e\n\n\u003cp\u003eSpecifically we'll add a Modal component (essentially like a pop-up, although it is part of the same HTML page) that displays additional information about a record in our DataTable when the user clicks on the table.\u003c/p\u003e\n\n\u003cp\u003eInside that Modal component, we'll display a photo of the iris type as well as a list of all attributes of the selected record.\u003c/p\u003e\n\n\u003cp\u003eThere are a lot of nested components in use here; feel free to look up more information in the \u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003eDash HTML Components documentation\u003c/a\u003e and the \u003ca href=\"https://dash-bootstrap-components.opensource.faculty.ai/docs/components/\"\u003eDash Bootstrap Components documentation\u003c/a\u003e but don't worry too much about the details. The main goal is to showcase the complex layout functionality you can achieve with only about 70 lines of Python code (not counting comments)!\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eIf you have some background in front-end web development and are already familiar with Bootstrap CSS styling, you can apply that knowledge here! The same CSS styles should work here, and if you want to specify a CSS class, you can use the component attribute called \u003ccode\u003eclassName\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APP ##########\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# this time use bootstrap styles instead of Dash recommended styles\n\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# markdown component is almost identical to before, we just added a line\n# telling the user to select a record\n\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# we want the user to be able to select a row\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# suppress default cell selection styling (we are selecting by row, not cell)\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# set an id so we can make attributes of this table into callback inputs\n\u003c/span\u003e    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a modal (has built-in functionality for user to close it)\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# modal header will always be the same\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# modal body will depend on what was clicked\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# set and id so we can make this component's children a callback output\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"c1\"\u003e# set an id so we can make the modal's open/closed status\n\u003c/span\u003e                  \u003cspan class=\"c1\"\u003e# a callback output\n\u003c/span\u003e                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"c1\"\u003e# by default, the modal is not open; it opens when a row\n\u003c/span\u003e                  \u003cspan class=\"c1\"\u003e# in the data table is selected\n\u003c/span\u003e                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# similar layout to before, just adding the modal to the end\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Helper function that takes in a dictionary of data\n    and returns a formatted list component\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Helper function that takes in a dictionary of data\n    and returns a card with the relevant iris image and name\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    When the `selected_rows` attribute of the data table (id=\"tbl\") changes,\n    set the `is_open` attribute of the modal (id=\"modal\") to True\n\n    `selected_rows` is None when the page first loads, then is a list of\n    row indices that have been selected by the user\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    When the `selected_rows` attribute of the data table (id=\"tbl\") changes,\n    set the `children` attribute of the modal body (id=\"modal-body\") to display\n    data about the selected info\n\n    We have a list of two inputs rather than just one this time, because we\n    need to know the actual contents of the row's data, not just the selected\n    index:\n      1) The `derived_virtual_data` attribute of the data table is a list of\n         dictionaries that represent the data currently being shown in the\n         table. The reason we don't just use the original dataframe that we\n         passed in to create the table is that Dash data tables can allow the\n         user to filter, edit, and delete data. We don't have these settings\n         turned on right now, but feel free to explore them!\n         For the sake of simplicity, we map the `derived_virtual_data`\n         attribute onto a parameter called `rows`.\n      2) The `selected_rows` attribute of the data table is a list of index\n         values (i.e. integers). The values in this list correspond to the\n         indices of `derived_virtual_data`.\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# set up a layout with one row and two columns\n\u003c/span\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# left column is a picture + name of the iris class\n\u003c/span\u003e            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# right column is a list of all the attributes and their values\n\u003c/span\u003e            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we introduced the Dash library, which is built on top of Flask. Unlike Flask, Dash has functionality to render web pages directly within a Jupyter Notebook! Dash also lets us create HTML and JavaScript functionality, just by writing Python code. HTML and CSS functionality is generally created using Dash \u003cem\u003ecomponents\u003c/em\u003e, whereas JavaScript functionality is generally created using Dash \u003cem\u003ecallbacks\u003c/em\u003e. Particularly with the Dash Bootstrap Components, it is possible to create sophisticated, dynamic web pages with relatively few lines of Python code.\u003c/p\u003e","exportId":"introduction-to-dash"},{"id":458570,"title":"Deploying a Model with Dash","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-dash-deployment\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-deployment\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-deployment/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn addition to allowing you to create complex dynamic web pages using Python code, Dash is \"the most downloaded, trusted framework for building machine learning web apps in Python\" (\u003ca href=\"https://plotly.com/building-machine-learning-web-apps-in-python/\"\u003esource\u003c/a\u003e). Let's build one of those machine learning web apps!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCombine Flask and Dash apps to serve API responses as well as dynamic web pages\u003c/li\u003e\n\u003cli\u003eIncorporate machine learning predictions into a Dash app\u003c/li\u003e\n\u003cli\u003eDeploy a machine learning dashboard using Dash and Heroku\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eClone this lesson locally so you can follow along using your local \u003ccode\u003edash-env\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eCombining Flask and Dash\u003c/h2\u003e\n\n\u003cp\u003eWe previously mentioned that Dash is built on top of Flask. Specifically, when the Dash app is instantiated, an underlying Flask app is created by default.\u003c/p\u003e\n\n\u003cp\u003eIf we want to customize the behavior of the underlying Flask app, we can actually instantiate it separately, then pass it in as an argument when we instantiate the Dash app.\u003c/p\u003e\n\n\u003cp\u003eBelow is a simple \"Hello, World!\" example where the Flask and Dash apps have been combined in this way:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a new flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# create a new dash app built on that flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSo far, this works identically to our \"Hello, World!\" Dash app without Flask.\u003c/p\u003e\n\n\u003cp\u003eHowever, now we can also add a \u003cem\u003eroute\u003c/em\u003e to the Flask app that returns JSON:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a new flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# create a new dash app built on that flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# add a route to the flask app that returns json\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"/get_json\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"GET\"\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ehello_json\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e({\u003c/span\u003e\n        \u003cspan class=\"s\"\u003e\"hello\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"world!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s\"\u003e\"key\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value!\"\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe web page view looks exactly the same, but we can also run a query directly to the backend and get a JSON result!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erequests\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/get_json\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow that we have those basic elements, let's combine our Iris Dataset Flask API and Dash dashboard from the previous lessons.\u003c/p\u003e\n\n\u003ch2\u003eCreating a Machine Learning Dash App\u003c/h2\u003e\n\n\u003ch3\u003eRecall: Previous Flask and Dash Apps\u003c/h3\u003e\n\n\u003cp\u003eOur previous Flask app looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is a basic web server that returns the text \"Hello, world!\" when it receives a \u003ccode\u003eGET\u003c/code\u003e request to view the home page (\u003ccode\u003e/\u003c/code\u003e route), and returns an iris classification prediction when it receives a \u003ccode\u003ePOST\u003c/code\u003e request to the \u003ccode\u003e/predict\u003c/code\u003e route.\u003c/p\u003e\n\n\u003cp\u003eOur previous Dash app looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is an interactive web page that displays a table of data, where the user can click on a record and a modal will pop up with additional information.\u003c/p\u003e\n\n\u003ch3\u003eA Basic Combination\u003c/h3\u003e\n\n\u003cp\u003eIf we just want to combine the functionality of the two applications, we just need to declare the two apps appropriately, and change the names from \u003ccode\u003eapp\u003c/code\u003e to either \u003ccode\u003eflask_app\u003c/code\u003e or \u003ccode\u003edash_app\u003c/code\u003e. We'll go ahead and remove the \u003ccode\u003e/\u003c/code\u003e route from the Flask app because the Dash app is using the home page to display our interactive table.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAs you can see, the Dash app works like it did before:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd so does the Flask app!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eIncorporating Predictions into Our Dash App\u003c/h3\u003e\n\n\u003cp\u003eRight now our modal is interactive, but it only displays static data from the table. Let's zoom in on that code with some example data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"sepal length (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.8\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"sepal width (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"petal length (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"petal width (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])))\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWhat if instead of just displaying the \u003ccode\u003eclass\u003c/code\u003e from the table, we showed both the actual class and the predicted class?\u003c/p\u003e\n\n\u003cp\u003eRemember, we already have a helper function from our Flask app called \u003ccode\u003eiris_prediction\u003c/code\u003e. Let's make an additional helper function that takes in the dictionary of data, passes the relevant arguments to \u003ccode\u003eiris_prediction\u003c/code\u003e, then displays information about whether the prediction was correct.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# make a copy so we don't mess up the original data record\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove and store the actual class\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels and replace spaces with underscores\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# get the result dictionary from iris_prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# extract the predicted class from the result dictionary\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# determine whether the prediction was correct\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# adding a horizontal rule divider here\n\u003c/span\u003e        \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# adding the prediction check here\n\u003c/span\u003e        \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])))\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCombining that all together with our data table, our complete app now looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Return an Alert component with information about the model's prediction\n    vs. the true class value\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(We changed the random seed used to generate the sample so that it includes some places where the model makes a mistake. Try clicking through to find them!)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNice! Now we have a dashboard that dynamically generates machine learning predictions whenever the user clicks on a record!\u003c/p\u003e\n\n\u003ch3\u003ePredictions on Unseen Data\u003c/h3\u003e\n\n\u003cp\u003eSo far we have an interesting view into our model's performance on the training data, but typically the value of a deployed model is to make predictions on new, unseen data.\u003c/p\u003e\n\n\u003cp\u003eLet's make an interface that allows the user to enter values into a form, then makes predictions using those user-supplied values.\u003c/p\u003e\n\n\u003cp\u003eIn order to figure out what kind of inputs our form should have, let's look at our \u003ccode\u003eX\u003c/code\u003e training data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edescribe\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat, so it looks like these can all be numeric inputs. One way we might implement numeric inputs would be using a text box, but let's use a Dash \u003ca href=\"https://dash.plotly.com/dash-core-components/slider\"\u003eSlider\u003c/a\u003e component instead. Sliders feel a bit more interactive, and they also let you set upper and lower bounds on what inputs the user can specify.\u003c/p\u003e\n\n\u003cp\u003eA basic slider looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# minimum value\n\u003c/span\u003e    \u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# maximum value\n\u003c/span\u003e    \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mf\"\u003e3.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# default value before the user changes anything\n\u003c/span\u003e    \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"c1\"\u003e# always display selected value\n\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eLet's make a set of four sliders, with ranges based on the four features:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# loop over all of the columns in X\n\u003c/span\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# make a label with the column name\n\u003c/span\u003e        \u003cspan class=\"n\"\u003elabel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH5\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# get the minimum, maximum, and median values for the column\n\u003c/span\u003e        \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003evalue\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003emedian\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# make a slider with the right values\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eslider\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set median as default\n\u003c/span\u003e            \u003cspan class=\"n\"\u003emarks\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n            \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set id based on column name\n\u003c/span\u003e        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# make a list item with the label and the slider\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eslider\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Prediction will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"info\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow let's add a callback so that the slider values are fed into the prediction function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# list comprehension to specify all of the input columns\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003egenerate_user_input_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"s\"\u003e'predicted_class'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry out the slider values to see if you can get the predicted class to change!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAwesome, now we are making predictions on unseen data!\u003c/p\u003e\n\n\u003cp\u003eTo combine the two interfaces, let's make a set of Tab components (\u003ca href=\"https://dash-bootstrap-components.opensource.faculty.ai/docs/components/tabs/\"\u003edocumentation here\u003c/a\u003e) so the user can switch between the table view and the form view.\u003c/p\u003e\n\n\u003cp\u003eHere is a minimal version of our Tabs:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etabs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTabs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Form will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"secondary\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Generate Predictions on New Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Table will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"secondary\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Analyze Performance on Past Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH1\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Classification Model\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003etabs\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry clicking on the tab names to switch between them:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow let's add the actual content to those tabs. Below is the full, final version of our Dash + Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003elabel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH5\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003evalue\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003emedian\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003eslider\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set median as default\n\u003c/span\u003e            \u003cspan class=\"n\"\u003emarks\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n            \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set id based on column name\n\u003c/span\u003e        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eslider\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Return an Alert component with information about the model's prediction\n    vs. the true class value\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eprediction_layout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Prediction will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"info\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n## Iris Training Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003epast_data_layout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etabs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTabs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eprediction_layout\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Generate Predictions on New Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epast_data_layout\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Analyze Performance on Past Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eContainer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH1\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Classification Model\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003etabs\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# list comprehension to specify all of the input columns\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003egenerate_user_input_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"s\"\u003e'predicted_class'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e550\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that the API backend also still works!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eDeploying to Heroku\u003c/h2\u003e\n\n\u003cp\u003eDeploying our Dash app to Heroku is very similar to deploying our Flask app to Heroku. We'll need to:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eInstall a \u003cstrong\u003eproduction server\u003c/strong\u003e and make sure we can successfully run our app locally via the command line\u003c/li\u003e\n\u003cli\u003eCreate our \u003cstrong\u003erequirements files\u003c/strong\u003e and push them to GitHub\u003c/li\u003e\n\u003cli\u003eCreate a new app through the \u003cstrong\u003eHeroku web interface\u003c/strong\u003e and connect it to our GitHub repo\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\n\u003ch3\u003eInstalling and Running a Production Server\u003c/h3\u003e\n\n\u003ch4\u003eInstalling Waitress\u003c/h4\u003e\n\n\u003cp\u003eOnce again, we'll use a production-quality server called \u003ca href=\"https://docs.pylonsproject.org/projects/waitress/en/latest/\"\u003eWaitress\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eIn the terminal, make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated, then run:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ewaitress\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eOrganizing the Code into a \u003ccode\u003e.py\u003c/code\u003e File\u003c/h4\u003e\n\n\u003cp\u003eWaitress needs the code to be located in a \u003ccode\u003e.py\u003c/code\u003e file rather than directly within a Jupyter Notebook. We have already copied the above code into a file called \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eNote that there is one small difference between the code above and the code in \u003ccode\u003eapp.py\u003c/code\u003e: instead of importing \u003ccode\u003eDash\u003c/code\u003e from the \u003ccode\u003ejupyter_dash\u003c/code\u003e library, we imported it directly from the \u003ccode\u003edash\u003c/code\u003e library. In other words, instead of\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003eapp.py\u003c/code\u003e has\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is because when we're deploying the application, we don't want the version of Dash designed to run in a notebook, we want the standalone version. But otherwise the code is identical to the \"final version\" code shown in this notebook.\u003c/p\u003e\n\n\u003ch4\u003eRunning the Production Server\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewaitress-serve \u003cspan class=\"nt\"\u003e--port\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e5000 app:flask_app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that this is very similar to our command when we were deploying our Flask app, which was \u003ccode\u003ewaitress-serve --port=5000 app:app\u003c/code\u003e. The difference is that the Flask app inside of \u003ccode\u003eapp.py\u003c/code\u003e had a variable name of \u003ccode\u003eapp\u003c/code\u003e, whereas now it has the name \u003ccode\u003eflask_app\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eYou should see an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eINFO:waitress:Serving on http://0.0.0.0:5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand you should be able to open up that link in your browser!\u003c/p\u003e\n\n\u003cp\u003eOnce you have confirmed that this works, go ahead and shut down the server using control-C.\u003c/p\u003e\n\n\u003ch3\u003eRequirements Files\u003c/h3\u003e\n\n\u003cp\u003eAgain, this is very similar to when we deployed the Flask app. We just have a longer list of requirements, and our \u003ccode\u003eProcfile\u003c/code\u003e specifies that the app variable name is \u003ccode\u003eflask_app\u003c/code\u003e rather than app. These files have already been included in this repository.\u003c/p\u003e\n\n\u003ch4\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eThis is the same as when we deployed our Flask app. Remember that if you get an error related to the runtime, that means that the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes list\u003c/a\u003e has changed. Check that link to find the most up-to-date Python 3.8 runtime and edit \u003ccode\u003eruntime.txt\u003c/code\u003e accordingly.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003epython-3.8.13\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eOur previous \u003ccode\u003erequirements.txt\u003c/code\u003e looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOur new \u003ccode\u003erequirements.txt\u003c/code\u003e has those same items, with additional ones added:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\ndash==2.3\ndash-bootstrap-components==1.0\npandas==1.4\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo explain further:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edash\u003c/code\u003e and \u003ccode\u003edash-bootstrap-components\u003c/code\u003e have been added so that we can create layouts and callbacks with Dash\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epandas\u003c/code\u003e has been added so that we can manipulate the dataset in preparation for displaying it in a table. If you just want your app to make predictions on unseen data, you won't need \u003ccode\u003epandas\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis is also slightly different from the \u003ccode\u003edash-env\u003c/code\u003e requirements we installed earlier, because the deployed version of our app does not need \u003ccode\u003enotebook\u003c/code\u003e or \u003ccode\u003ejupyter-dash\u003c/code\u003e (or be tethered to a specific version of \u003ccode\u003eWerkzeug\u003c/code\u003e, which was needed at the time of this writing to make \u003ccode\u003ejupyter-dash\u003c/code\u003e work correctly).\u003c/p\u003e\n\n\u003ch4\u003e\u003ccode\u003eProcfile\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eOur \u003ccode\u003eProcfile\u003c/code\u003e is also slightly different because our app variable name is different.\u003c/p\u003e\n\n\u003cp\u003eOur previous \u003ccode\u003eProcfile\u003c/code\u003e looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd our new one looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:flask_app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eDeploying the App on Heroku\u003c/h3\u003e\n\n\u003cp\u003eThis is the same set of steps as before, but we'll include them here for convenience:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eMake sure you are \u003cstrong\u003elogged in\u003c/strong\u003e to Heroku. You can go to \u003ca href=\"https://dashboard.heroku.com/\"\u003ehttps://dashboard.heroku.com/\u003c/a\u003e and it will either show you your list of apps or redirect you to the login page.\n\n\u003cul\u003e\n\u003cli\u003eYou should already have an account if you followed the steps from the Flask deployment lesson, but you can also create an account now.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eGo to \u003ca href=\"https://dashboard.heroku.com/new-app\"\u003ehttps://dashboard.heroku.com/new-app\u003c/a\u003e to make a new app on Heroku.\u003c/li\u003e\n\u003cli\u003eEither fill in a name for your app then click \u003cstrong\u003eCreate app\u003c/strong\u003e, or just click \u003cstrong\u003eCreate app\u003c/strong\u003e if you want a name to be generated for you.\u003c/li\u003e\n\u003cli\u003eScroll down to \u003cstrong\u003eDeployment method\u003c/strong\u003e and choose \u003cstrong\u003eGitHub\u003c/strong\u003e.\n\n\u003cul\u003e\n\u003cli\u003eYou should already be signed in with GitHub if you followed the steps from the Flask deployment lesson, but you can also approve the connection in the pop-up window now if you haven't previously.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSearch\u003c/strong\u003e for the repository you want, then click \u003cstrong\u003eConnect\u003c/strong\u003e on the repository in the list of search results.\u003c/li\u003e\n\u003cli\u003eScroll down to \u003cstrong\u003eManual deploy\u003c/strong\u003e, choose the appropriate branch, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eWait for the app to build, then once you see the message \"Your app was successfully deployed\" click the \u003cstrong\u003eView\u003c/strong\u003e button to open up your Dash app!\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eThe interface should be much more interesting than the \"Hello, world!\" from your Flask app. You should also be able to make API requests (replace \u003ccode\u003ebase_url\u003c/code\u003e with your actual Heroku app URL).\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# base URL (ending with .herokuapp.com, no trailing /)\n\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eLevel Up\u003c/h2\u003e\n\n\u003cp\u003eDash is created by Plotly, which also makes a well-known \u003ca href=\"https://plotly.com/python/\"\u003ePython graphing library\u003c/a\u003e that creates interactive graphs using Python. Check out the examples \u003ca href=\"https://dash.plotly.com/dash-core-components/graph\"\u003ehere\u003c/a\u003e and try adding a visualization to your dashboard!\u003c/p\u003e\n\n\u003cp\u003eIn addition to being used as layout elements, Plotly graphs can be attached to callbacks in a Dash page. So, for example, the graph axis scale could change using a slider input, or a user could click on a point on a graph and send that to their model to make a prediction. Try it out for yourself!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eYou have now learned how to combine Flask with Dash to build and deploy powerful dynamic web applications using machine learning. We can't wait to see what you'll make next!\u003c/p\u003e","exportId":"deploying-a-model-with-dash"},{"id":458574,"title":"Productionizing a Model with Docker and SageMaker","type":"Assignment","indent":0,"locked":false,"submissionTypes":null,"graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-models-with-sagemaker\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-models-with-sagemaker/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eComplete this exercise on your local computer.\u003c/p\u003e","exportId":"ge49973b1f11da2d1d2ab006198d397c0"},{"id":458590,"title":"Amazon Web Services - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":"must_view","completed":true,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAWS is a \u003cstrong\u003e\u003cem\u003eCloud-Computing Platform\u003c/em\u003e\u003c/strong\u003e which we can use for a variety of use cases in data science.\u003c/li\u003e\n\u003cli\u003eIn this section, we learned about how to sign up for AWS, and how to make sure that we have the right region selected when working in AWS.\u003c/li\u003e\n\u003cli\u003eAmazon has centralized all of the major data science services inside \u003cstrong\u003e\u003cem\u003eAmazon SageMaker\u003c/em\u003e\u003c/strong\u003e. SageMaker provides numerous services for things such as:\n\n\u003cul\u003e\n\u003cli\u003eData Labeling\u003c/li\u003e\n\u003cli\u003eCloud-based Notebooks\u003c/li\u003e\n\u003cli\u003eTraining and Model Tuning\u003c/li\u003e\n\u003cli\u003eInference\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWe can set up our own models, or use the preexisting models provided by AWS. Similarly, we can set up our own inference endpoints, or make use of preexisting endpoints created by AWS. \u003c/li\u003e\n\u003cli\u003eCreating our own endpoint requires us to use a Docker instance, as we saw in the previous codealong. Much of the work required to create an endpoint for our own model is boilerplate, and we can use it again and again across multiple projects. \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-productionizing-machine-learning-models-section-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-productionizing-machine-learning-models-section-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"amazon-web-services-recap"}]},{"id":47112,"name":"üèÜ Milestones","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g4ced624eeaf253578a9cdbfadc24c3d5","items":[{"id":458598,"title":"CODE ASSESSMENTS","type":"ContextModuleSubHeader","indent":0,"locked":false},{"id":458602,"title":"Checkpoints","type":"ContextModuleSubHeader","indent":1,"locked":false},{"id":458619,"title":"Code Challenge","type":"ContextModuleSubHeader","indent":1,"locked":false},{"id":458623,"title":"Phase 4 Code Challenge","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":14.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"","exportId":"g5064eeb2f06b614d0adc83eb248fe7ef"},{"id":458627,"title":"PHASE 4 PROJECT","type":"ContextModuleSubHeader","indent":0,"locked":false},{"id":458630,"title":"Project Overview","type":"ContextModuleSubHeader","indent":1,"locked":false},{"id":458635,"title":"Phase 4 Project Description","type":"WikiPage","indent":1,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-phase-4-project-v2-3\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-project-v2-3\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-project-v2-3/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eFinal phase down -- you're absolutely crushing it! You've made it all the way through one of the toughest phases of this course. You must have an amazing brain in your head!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-phase-4-project-v2-3/main/images/brain.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eYou have one last project to complete before the Capstone!\u003c/p\u003e\n\u003cp\u003eIn this project description, we will cover:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProject Overview\u003c/li\u003e\n\u003cli\u003eDeliverables\u003c/li\u003e\n\u003cli\u003eGrading\u003c/li\u003e\n\u003cli\u003eGetting Started\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eFor this project, you will engage in an \u003cstrong\u003eadvanced supervised modeling process\u003c/strong\u003e from start to finish, solving either a classification or a regression problem using an advanced dataset.\u003c/p\u003e\n\u003ch3\u003eBusiness Problem and Data\u003c/h3\u003e\n\u003cp\u003eSimilar to the Phase 3 project, you are responsible for choosing a dataset as well as defining a stakeholder and business problem. In addition to these choices, you can choose between any of the four advanced supervised modeling techniques covered in Phase 4:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTime Series Modeling\u003c/li\u003e\n\u003cli\u003eRecommendation System\u003c/li\u003e\n\u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e\n\u003cli\u003eNatural Language Processing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor complete details, see \u003ca href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\"\u003ePhase 4 Project - Choosing a Dataset\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003eKey Points\u003c/h3\u003e\n\u003ch3\u003eAdvanced Data Types and Modeling\u003c/h3\u003e\n\u003cp\u003eThe purpose of this project is to demonstrate that you have mastered the basics of some type of modeling technique beyond the techniques introduced in Phase 3. This is your chance to tailor your work to a \u003cstrong\u003edata science audience\u003c/strong\u003e in particular, with a clear notebook narrative that illustrates your process. The resulting presentation slides will be substantially similar to a Phase 3 presentation, but someone reading your notebook should be able to see your grasp of the specific advanced modeling technique.\u003c/p\u003e\n\u003ch3\u003eValidation Strategy\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003evalidation strategy\u003c/strong\u003e means a strategy to demonstrate that your model will actually perform well on unseen data. In Phase 3 this was relatively straightforward to accomplish with the \u003ccode\u003etrain_test_split\u003c/code\u003e function from scikit-learn. This may or may not be appropriate for the project you select. Make sure that you are thinking about this strategy from the start and incorporating it into your notebook narrative.\u003c/p\u003e\n\u003ch3\u003eChoosing a Dataset\u003c/h3\u003e\n\u003cp\u003eWe've given you a lot of choices - don't get stuck spending too much time choosing which project to do. Give yourself a firm time limit for picking a project (e.g. 2 hours) so you can get on with making something great. Don't worry about picking the perfect project - remember that you will get to do a new, larger Capstone project very soon!\u003c/p\u003e\n\u003ch2\u003eThe Deliverables\u003c/h2\u003e\n\u003cp\u003eThere are three deliverables for this project:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003enon-technical presentation\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003eJupyter Notebook\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003eGitHub repository\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe checklist of requirements is the same for Phase 4 as it was in Phase 3. This will also be the checklist for Capstone!\u003c/p\u003e\n\u003ch3\u003eNon-Technical Presentation\u003c/h3\u003e\n\u003cp\u003eThe non-technical presentation should be very similar to the presentation you gave in Phase 3. You can feel free to mention the specific models and metrics you used, but make sure you translate everything for an audience who is not familiar with data science.\u003c/p\u003e\n\u003ch3\u003eJupyter Notebook\u003c/h3\u003e\n\u003cp\u003eThe notebook will have the same checklist elements as in Phase 3. However, \u003cstrong\u003ethis time around the Communication rubric element will focus on the technical notebook\u003c/strong\u003e. A data science professional reading your notebook should be able to understand all of your data preparation and modeling decisions.\u003c/p\u003e\n\u003ch3\u003eGitHub Repository\u003c/h3\u003e\n\u003cp\u003eThe GitHub repository should also be very similar to the Phase 3 repository.\u003c/p\u003e\n\u003cp\u003eThe main additional element to consider is \u003cstrong\u003ereproducibility\u003c/strong\u003e, since many of the dataset options are too large to be saved directly in a GitHub repository. Make sure you include clear instructions for how someone would reproduce your modeling process, potentially including any scripts you used to organize data into directories.\u003c/p\u003e\n\u003ch2\u003eGrading\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTo pass this project, you must pass each rubric objective.\u003c/em\u003e\u003c/strong\u003e The project rubric objectives for Phase 4 are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAttention to Detail\u003c/li\u003e\n\u003cli\u003eAdvanced ML Communication\u003c/li\u003e\n\u003cli\u003eAdvanced Data Preparation\u003c/li\u003e\n\u003cli\u003eAdvanced ML Modeling\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eAttention to Detail\u003c/h3\u003e\n\u003cp\u003eOnce again, the Attention to Detail standard has increased. \u003cstrong\u003e\u003cem\u003eIn Phase 4, you need to complete 90% (9 out of 10) or more of the checklist elements in order to pass the Attention to Detail objective.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE THAT THE PASSING BAR IS HIGHER IN PHASE 4 THAN IT WAS IN PHASE 3!\u003c/strong\u003e\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003e100% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003e90% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003e80% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003e70% or fewer of the project checklist items are complete\u003c/p\u003e\n\u003ch3\u003eAdvanced ML Communication\u003c/h3\u003e\n\u003cp\u003eOnce again, you are expected to communicate the results of an ML modeling process. Just like in Phase 3, we are looking for \u003cem\u003erationale, results, limitations, and recommendations.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn Phase 4, the emphasis is on the \u003cstrong\u003eJupyter Notebook\u003c/strong\u003e. The notebook should include a \u003cstrong\u003esummary\u003c/strong\u003e at the beginning that briefly and accurately describes your process. The summary should be approximately 250 words -- about the size of a research paper abstract.\u003c/p\u003e\n\u003cp\u003eSummary elements:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBusiness and data understanding: \u003cem\u003ewhat kind of data are you using, and what makes it well-suited for the business problem?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eYou do not need to include any data visualizations in your summary, but consider including relevant descriptive statistics\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eData preparation: \u003cem\u003ewhy did you choose the data preparation steps that you did, and what was the result?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eThis should be specific to the kind of data you are working with. For example, if you are doing an NLP project, what did you decide to do with stopwords?\u003c/li\u003e\n\u003cli\u003eBe sure to list the packages/libraries used to prepare the data, and why\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eModeling: \u003cem\u003ewhat modeling package(s) did you use, which model(s) within the package(s), and what tuning steps did you take?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eFor some projects there may be only one applicable package; you should still briefly explain why this was the appropriate choice\u003c/li\u003e\n\u003cli\u003eFor neural networks projects, be sure to describe your model architecture choices\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEvaluation: \u003cem\u003ehow well did your final model perform?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eInclude one or more relevant metrics\u003c/li\u003e\n\u003cli\u003eBe sure to briefly describe your validation approach\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eCommunicates advanced modeling summary as well as a narrative throughout the notebook text that demonstrates mastery of an advanced topic\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDecisions should be justified and outcomes evaluated in Markdown throughout the notebook\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully communicates a summary of an advanced modeling technique including business and data understanding, data preparation, modeling, and evaluation\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIt is possible to meet this bar with just a summary and not a narrative throughout the notebook, so long as the steps taken are justifiable and free of major errors. See the Approaching Objective section for an explanation of what a \"major error\" means.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003eCommunicates advanced modeling summary with at least one major error\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA major error means that one of the required elements of the summary was missing, or some aspect of the communication was fundamentally incorrect. For example, if you stated that you performed \"deep learning\" when you actually used \u003ccode\u003eCountVectorizer\u003c/code\u003e and \u003ccode\u003eMultinomialNB\u003c/code\u003e from scikit-learn, that would be a major error. Another example would be if you described a regression task as a classification task, or if you described supervised learning as unsupervised learning.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not communicate advanced modeling summary\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMarkdown headings and occasional narrative text throughout the notebook are not sufficient in this phase, even if they were in previous phases. You need to include a summary at the beginning of your notebook.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eAdvanced Data Preparation\u003c/h3\u003e\n\u003cp\u003eOnce again, this objective is very similar to Phase 3, although the complexity has increased.\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eGoes above and beyond with data preparation, such as feature engineering, using pipelines, or using unsupervised techniques\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSupervised learning is the core of this project, but feel free to use unsupervised techniques for data analysis or preparation\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully prepares data for modeling, using at least one Python package other than scikit-learn\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYour final model does not need to use anything other than scikit-learn, but you should explore other tools during your modeling process\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003ePrepares some data successfully, but has at least one major error\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not prepare data for modeling\u003c/p\u003e\n\u003ch3\u003eAdvanced ML Modeling\u003c/h3\u003e\n\u003cp\u003eThis is your real opportunity to flex those new Phase 4 skills!\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eGoes above and beyond in the modeling process, such as using models from multiple different packages or model explainability tools\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are encouraged but not required to use models from multiple different packages. The feasibility of this depends on your choice of project. For time series, this might mean trying both StatsModels and Prophet. For image classification, this might mean using TensorFlow with and without transfer learning.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://christophm.github.io/interpretable-ml-book/lime.html\"\u003ethis book chapter\u003c/a\u003e for an introduction to LIME for model explainability\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully builds and evaluates multiple models using an appropriate model validation technique\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAs noted previously, the \u003ccode\u003etrain_test_split\u003c/code\u003e from scikit-learn may or may not be appropriate for your modeling task. Be sure to investigate appropriate techniques so you are confident in the performance of your final model on unseen data\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003eBuilds multiple models with at least one major error\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not build multiple models\u003c/p\u003e\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\u003cp\u003ePlease start by reviewing the contents of this project description. If you have any questions, please ask your instructor ASAP.\u003c/p\u003e\n\u003cp\u003eOnce you are ready to begin the project, you will need to complete the \u003cstrong\u003e\u003cem\u003e\u003ca title=\"Phase 4 Project Proposal\" href=\"quizzes/g1daef7be675ef2b7bc60c9ddf372ac38\"\u003eProject Proposal\u003c/a\u003e\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eRecall that more information is available in \u003ca href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\"\u003ePhase 4 Project - Choosing a Dataset\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo get started with project development, create a new repository on GitHub. For this project, we recommend that you do not fork the template repository, but rather that you make a new repository from scratch, starting by going to \u003ca href=\"https://github.com/new\"\u003egithub.com/new\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eThis project is your chance to show off your data science prowess with some advanced machine learning algorithms. Now that you've gone through all of the core course content, we're excited to see what you are able to do!\u003c/p\u003e","exportId":"phase-4-project-description"},{"id":458639,"title":"Phase 4 Project - Choosing a Dataset","type":"WikiPage","indent":1,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-phase-4-choosing-a-dataset\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e  \u003cp\u003eFor this phase, you will choose a project that relates to one of the following topics:\u003c/p\u003e  \u003cul\u003e \u003cli\u003eTime Series Modeling\u003c/li\u003e \u003cli\u003eRecommendation Systems\u003c/li\u003e \u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e \u003cli\u003eNatural Language Processing\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eThe Data\u003c/h2\u003e  \u003cp\u003eWe have provided a dataset suitable to each topic, but you are also welcome to source your own dataset. If you choose your own dataset, \u003cstrong\u003erun the dataset and business problem by your instructor for approval\u003c/strong\u003e before starting your project.\u003c/p\u003e  \u003ch3\u003eHow to Choose a Project\u003c/h3\u003e  \u003cp\u003eWhen choosing a project, consider one of the following approaches:\u003c/p\u003e  \u003col\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDepth:\u003c/strong\u003e Choose a project that similar to what you want to do for your capstone project (Phase 5). This will allow you to practice those methods in a group setting before needing to use it independently. This will help you build a better Capstone project and a portfolio that demonstrates the ability to deeply learn and implement one modeling approach.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eBreadth:\u003c/strong\u003e Choose a problem that you don't necessarily plan to use in your capstone project. This will allow you to develop applied experience with multiple modeling approaches. This will help you refine your areas of interest and build a portfolio that demonstrates the ability to learn and implement multiple modeling approaches.\u003c/p\u003e\u003c/li\u003e \u003c/ol\u003e  \u003cp\u003eIf you are feeling overwhelmed or behind, we recommend you choose Topic 3: Image Classification with Deep Learning.\u003c/p\u003e  \u003ch3\u003eTopic 1: Time Series Modeling\u003c/h3\u003e  \u003cp\u003eIf you choose the Time Series option, you will be forecasting real estate prices of various zip codes using data from \u003ca href=\"https://www.zillow.com/research/data/\"\u003eZillow Research\u003c/a\u003e. For this project, you will be acting as a consultant for a fictional real-estate investment firm. The firm has asked you what seems like a simple question:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eWhat are the top 5 best zip codes for us to invest in?\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eThis may seem like a simple question at first glance, but there's more than a little ambiguity here that you'll have to think through in order to provide a solid recommendation. Should your recommendation be focused on profit margins only? What about risk? What sort of time horizon are you predicting against?  Your recommendation will need to detail your rationale and answer any sort of lingering questions like these in order to demonstrate how you define \"best\".\u003c/p\u003e  \u003cp\u003eThere are many datasets on the \u003ca href=\"https://www.zillow.com/research/data/\"\u003eZillow Research Page\u003c/a\u003e, and making sure you have exactly what you need can be a bit confusing. For simplicity's sake, we have already provided the dataset for you in this repo -- you will find it in the file \u003ccode\u003etime-series/zillow_data.csv\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eThe goal of this project is to have you complete a very common real-world task in regard to time series modeling. However, real world problems often come with a significant degree of ambiguity, which requires you to use your knowledge of statistics and data science to think critically about and answer. While the main task in this project is time series modeling, that isn't the overall goal -- it is important to understand that time series modeling is a tool in your toolbox, and the forecasts it provides you are what you'll use to answer important questions.\u003c/p\u003e  \u003cp\u003eIn short, to pass this project, demonstrating the quality and thoughtfulness of your overall recommendation is at least as important as successfully building a time series model!\u003c/p\u003e  \u003ch4\u003eStarter Jupyter Notebook\u003c/h4\u003e  \u003cp\u003eFor this project, you will be provided with a Jupyter notebook, \u003ccode\u003etime-series/starter_notebook.ipynb\u003c/code\u003e, containing some starter code. If you inspect the Zillow dataset file, you'll notice that the datetimes for each sale are the actual column names -- this is a format you probably haven't seen before. To ensure that you're not blocked by preprocessing, we've provided some helper functions to help simplify getting the data into the correct format. You're not required to use this notebook or keep it in its current format, but we strongly recommend you consider making use of the helper functions so you can spend your time working on the parts of the project that matter.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eIn addition to deciding which quantitative metric(s) you want to target (e.g. minimizing mean squared error), you need to start with a definition of \"best investment\".  Consider additional metrics like risk vs. profitability, or ROI yield.\u003c/p\u003e  \u003ch3\u003eTopic 2: Recommendation Systems\u003c/h3\u003e  \u003cp\u003eIf you choose the Recommendation System option, you will be making movie recommendations based on the \u003ca href=\"https://grouplens.org/datasets/movielens/latest/\"\u003eMovieLens\u003c/a\u003e dataset from the GroupLens research lab at the University of Minnesota.  Unless you are planning to run your analysis on a paid cloud platform, we recommend that you use the \"small\" dataset containing 100,000 user ratings (and potentially, only a particular subset of that dataset).\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that provides top 5 movie recommendations to a user, based on their ratings of other movies.\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eThe MovieLens dataset is a \"classic\" recommendation system dataset, that is used in numerous academic papers and machine learning proofs-of-concept.  You will need to create the specific details about how the user will provide their ratings of other movies, in addition to formulating a more specific business problem within the general context of \"recommending movies\".\u003c/p\u003e  \u003ch4\u003eCollaborative Filtering\u003c/h4\u003e  \u003cp\u003eAt minimum, your recommendation system must use collaborative filtering.  If you have time, consider implementing a hybrid approach, e.g. using collaborative filtering as the primary mechanism, but using content-based filtering to address the \u003ca href=\"https://en.wikipedia.org/wiki/Cold_start_(computing)\"\u003ecold start problem\u003c/a\u003e.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eThe MovieLens dataset has explicit ratings, so achieving some sort of evaluation of your model is simple enough.  But you should give some thought to the question of metrics. Since the rankings are ordinal, we know we can treat this like a regression problem.  But when it comes to regression metrics there are several choices: RMSE, MAE, etc.  \u003ca href=\"http://fastml.com/evaluating-recommender-systems/\"\u003eHere\u003c/a\u003e are some further ideas.\u003c/p\u003e  \u003ch3\u003eTopic 3: Image Classification with Deep Learning\u003c/h3\u003e  \u003cp\u003eIf you choose this option, you'll put everything you've learned together to build a deep neural network that trains on a large dataset for classification on a non-trivial task.  In this case, using x-ray images of pediatric patients to identify whether or not they have pneumonia.  The dataset comes from Kermany et al. on \u003ca href=\"https://data.mendeley.com/datasets/rscbjbr9sj/3\"\u003eMendeley\u003c/a\u003e, although there is also a version on \u003ca href=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\"\u003eKaggle\u003c/a\u003e that may be easier to use.\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that can classify whether a given patient has pneumonia, given a chest x-ray image.\u003c/p\u003e \u003c/blockquote\u003e  \u003ch4\u003eAim for a Proof of Concept\u003c/h4\u003e  \u003cp\u003eWith Deep Learning, data is king -- the more of it, the better. However, the goal of this project isn't to build the best model possible -- it's to demonstrate your understanding by building a model that works. You should try to avoid datasets and model architectures that won't run in reasonable time on your own machine. For many problems, this means downsampling your dataset and only training on a portion of it. Once you're absolutely sure that you've found the best possible architecture and other hyperparameters for your model, then consider training your model on your entire dataset overnight (or, as larger portion of the dataset that will still run in a feasible amount of time).\u003c/p\u003e  \u003cp\u003eAt the end of the day, we want to see your thought process as you iterate and improve on a model. A project that achieves a lower level of accuracy but has clearly iterated on the model and the problem until it found the best possible approach is more impressive than a model with high accuracy that did no iteration. We're not just interested in seeing you finish a model -- we want to see that you understand it, and can use this knowledge to try and make it even better!\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eEvaluation is fairly straightforward for this project.  But you'll still need to think about which metric to use and about how best to cross-validate your results.\u003c/p\u003e  \u003ch3\u003eTopic 4: Natural Language Processing (NLP)\u003c/h3\u003e  \u003cp\u003eIf you choose this option, you'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via \u003ca href=\"https://data.world/crowdflower/brands-and-product-emotions\"\u003edata.world\u003c/a\u003e. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that can rate the sentiment of a Tweet based on its content.\u003c/p\u003e \u003c/blockquote\u003e  \u003ch4\u003eAim for a Proof of Concept\u003c/h4\u003e  \u003cp\u003eThere are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eEvaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics.\u003c/p\u003e  \u003ch3\u003eSourcing Your Own Data\u003c/h3\u003e  \u003cp\u003eSourcing new data is a valuable skill for data scientists, but it requires a great deal of care. An inappropriate dataset or an unclear business problem can lead you spend a lot of time on a project that delivers underwhelming results. The guidelines below will help you complete a project that demonstrates your ability to engage in the full data science process.\u003c/p\u003e  \u003cp\u003eYour dataset must be...\u003c/p\u003e  \u003col\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eAppropriate for one of this phase's models.\u003c/strong\u003e These are time series, recommendation systems, image classification, or natural language processing.   \u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eUsable to solve a specific business problem.\u003c/strong\u003e This solution must rely on your model.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eSomewhat complex.\u003c/strong\u003e It should contain thousands of rows and features that require creativity to use.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eUnfamiliar.\u003c/strong\u003e It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. MNIST).\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eManageable.\u003c/strong\u003e Stick to datasets that you can model using the techniques introduced in Phase 4.\u003c/p\u003e\u003c/li\u003e \u003c/ol\u003e  \u003ch4\u003eProblem First, or Data First?\u003c/h4\u003e  \u003cp\u003eThere are two ways that you can source your own dataset: \u003cstrong\u003e\u003cem\u003eProblem First\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003eData First\u003c/em\u003e\u003c/strong\u003e. The less time you have to complete the project, the more strongly we recommend a Data First approach to this project.\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003e\u003cem\u003eProblem First\u003c/em\u003e\u003c/strong\u003e: Start with a problem that you are interested in that you could potentially solve with a classification model. Then look for data that you could use to solve that problem. This approach is high-risk, high-reward: Very rewarding if you are able to solve a problem you are invested in, but frustrating if you end up sinking lots of time in without finding appropriate data. To mitigate the risk, set a firm limit for the amount of time you will allow yourself to look for data before moving on to the Data First approach.\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003e\u003cem\u003eData First\u003c/em\u003e\u003c/strong\u003e: Take a look at some of the most popular internet repositories of cool data sets we've listed below. If you find a data set that's particularly interesting for you, then it's totally okay to build your problem around that data set.\u003c/p\u003e  \u003ch4\u003ePotential Data Sources\u003c/h4\u003e  \u003cp\u003eThere are plenty of amazing places that you can get your data from. We recommend you start looking at data sets in some of these resources first:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ca href=\"https://archive.ics.uci.edu/ml/datasets.php\"\u003eUCI Machine Learning Datasets Repository\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://www.kaggle.com/datasets\"\u003eKaggle Datasets\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://github.com/awesomedata/awesome-public-datasets\"\u003eAwesome Datasets Repo on Github\u003c/a\u003e\u003c/li\u003e \u003cli\u003eLocal data portals for state and local government resources  \u003cul\u003e \u003cli\u003eExamples: \u003ca href=\"https://opendata.cityofnewyork.us/\"\u003eNYC\u003c/a\u003e, \u003ca href=\"http://data.houstontx.gov/\"\u003eHouston\u003c/a\u003e, \u003ca href=\"https://data.seattle.gov/\"\u003eSeattle\u003c/a\u003e, \u003ca href=\"https://data.ca.gov/\"\u003eCalifornia\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"http://insideairbnb.com/\"\u003eInside AirBNB\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://data.fivethirtyeight.com/\"\u003eFiveThirtyEights data portal\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0\"\u003eData is Plurals Archive Spreadsheet\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://www.reddit.com/r/datasets/\"\u003eDatasets Subreddit\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e","exportId":"phase-4-project-choosing-a-dataset"},{"id":458642,"title":"Phase 4 Project Checklist","type":"ExternalUrl","indent":1,"locked":false,"requirement":null,"completed":false,"content":"https://docs.google.com/document/d/1Z8ExaBcn_nyTPgcfP0lRj3z1oKW0buzBNCsINb-MJYc/edit?usp=sharing"},{"id":458644,"title":"Submit Your Project Here","type":"ContextModuleSubHeader","indent":1,"locked":false},{"id":458647,"title":"Phase 4 Project Proposal","type":"Quizzes::Quiz","indent":1,"locked":false,"assignmentExportId":"g15e923edb32fb85fd62fc5c9e95b0410","questionCount":3,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":3.0,"dueAt":"2022-10-29T23:59:00-04:00","lockAt":null,"unlockAt":"2022-10-21T00:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003eFor this phase, you will choose a project that requires building one of these four models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTime Series Modeling\u003c/li\u003e\n\u003cli\u003eRecommendation System\u003c/li\u003e\n\u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e\n\u003cli\u003eNatural Language Processing\u003c/li\u003e\n\u003c/ul\u003e","exportId":"g1daef7be675ef2b7bc60c9ddf372ac38"},{"id":458656,"title":"Phase 4 Project - GitHub Repository URL","type":"Assignment","indent":1,"locked":false,"submissionTypes":"a website url","graded":true,"pointsPossible":0.0,"dueAt":"2022-10-31T23:59:00-04:00","lockAt":"2022-10-31T23:59:59-04:00","unlockAt":"2022-10-27T00:00:00-04:00","requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan\u003ePlease put the URL to your Phase 4 Project GitHub Repository here.\u0026nbsp;\u003c/span\u003e\u003c/p\u003e","exportId":"gbe0099d3814703e5ba2b18886068f8e5"},{"id":458662,"title":"BLOG POST","type":"ContextModuleSubHeader","indent":0,"locked":false},{"id":458665,"title":"Blogging Overview","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-blogging-overview\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-blogging-overview\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-blogging-overview/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e  \u003ch2\u003eIntroduction\u003c/h2\u003e  \u003cp\u003eIn this lesson, we discuss how to write good blog posts that meet Flatiron School's requirements.\u003c/p\u003e  \u003ch2\u003eObjectives\u003c/h2\u003e  \u003cp\u003eThis lesson covers...\u003c/p\u003e  \u003cul\u003e \u003cli\u003eWhy blogging is valuable\u003c/li\u003e \u003cli\u003eTopics to blog about\u003c/li\u003e \u003cli\u003eWhat makes for a good blog post\u003c/li\u003e \u003cli\u003eHow to start your blog\u003c/li\u003e \u003cli\u003eFlatiron School blog requirements \u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhy Should I Blog?\u003c/h2\u003e  \u003cp\u003eBlogging has many benefits:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDevelop your written communication skills.\u003c/strong\u003e Your writing ability will be critical to your success when completing job applications and presenting your work to colleagues. Blogging is great practice for identifying and clearly communicating the most important points of any subject.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDemonstrate your talent to employers.\u003c/strong\u003e Potential employers will review your blog to determine whether to offer you an interview or a job. Some students have even been invited to interview or exempted from technical interviews based on their blogs.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eStrengthen your knowledge.\u003c/strong\u003e Blogging helps you explore new topics, deepen your understanding, and crystallize what you've learned.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eHelp your peers and the broader community.\u003c/strong\u003e Have you ever Googled a question you had and found the answer on a blog? Writing blog posts helps others who are following in your footsteps!\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhat Should I Blog About?\u003c/h2\u003e  \u003cp\u003eHere are some blog topic ideas:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eWhy did you decide to learn data science?\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eDescribe how a DS technique works, when you might use it, and its strengths/weaknesses.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eSummarize an End of Phase Project by explaining your problem, the dataset, your methodology, and your results.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eDive into something that you want to learn more about, maybe because you find it challenging or it wasn't covered in the course.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eWrite a tutorial to help aspiring data scientists to implement a tool or method.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eFind an interesting data science paper and summarize why it is important. This can be a new paper from the past few months, or you can refer to \u003ca href=\"https://docs.google.com/spreadsheets/d/1UYmAT13AAknrOatzLeeAsN4tS7ENjn2fpJNGzOZ67rQ/edit?usp=sharing\"\u003ethis spreadsheet\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhat Does A Good Blog Post Look Like?\u003c/h2\u003e  \u003cp\u003eWe recommend you take a look at our \u003ca href=\"https://drive.google.com/drive/folders/1UBiRCRLzVP5CHU3PJNwoMZAe3ajUBm2a?usp=sharing\"\u003eblog templates\u003c/a\u003e and \u003ca href=\"https://docs.google.com/document/d/1eqL8Dsj7dH7s_MRnf_4-3kCiSz72POHTfb-sBRN5Zhs/edit?usp=sharing\"\u003eexamples\u003c/a\u003e to get an idea for what makes a blog post good.\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eStrike a balance between providing a meaningful investigation of your topic and being concise. Constrain the scope so it will be interesting and digestible in about 1000-3000 words (this is not a firm limit).\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eUse clear and consistent formatting to make your content accessible and professional-looking.\u003c/p\u003e  \u003cul\u003e \u003cli\u003eWhen presenting code, use code snippets instead of screenshots.\u003c/li\u003e \u003cli\u003eMake URLs into hyperlinks that are easy for readers to click into.\u003c/li\u003e \u003cli\u003eUse headings to provide structure and flow to your post.\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003cli\u003e\u003cp\u003eCite and link to resources you used to write your post.\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eHow Do I Start My Blog?\u003c/h2\u003e  \u003cp\u003eIf you already have a professional blog that you'd like to use for your data science content, you can add your posts to that. Otherwise, you will need to start a new blog. If you have a personal blog, you should avoid using it for this purpose so that you can continue using it for personal content without worrying about how it might be perceived by potential employers.\u003c/p\u003e  \u003cp\u003eThere are multiple blogging platforms to choose from that make it easy to start a blog, here are some of our favorites:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ca href=\"https://www.blogger.com/\"\u003eBlogger\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://dev.to/\"\u003edev.to\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://pages.github.com/\"\u003eGitHub Pages\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://medium.com/\"\u003eMedium\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://wordpress.com/\"\u003eWordpress\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eDifferent platforms have different pros and cons, so do a little research to decide what is best for you.\u003c/p\u003e  \u003ch2\u003eBlog Requirements\u003c/h2\u003e  \u003cp\u003eTo succeed in your career transition and graduate from Flatiron School, you must complete the following activities. These requirements are designed to give you the best opportunity to deepen your knowledge, practice communication skills, and showcase yourself to potential employers.\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eSet up a publicly accessible blog \u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003ePublish at least four blog posts on it, including \u003cstrong\u003eone per Phase for Phases 1-4\u003c/strong\u003e\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eSubmit URLs to your posts \u003cstrong\u003eby the end of each Phase\u003c/strong\u003e in the Blog Post assignments\u003c/p\u003e  \u003cul\u003e \u003cli\u003eThese assignments are located in the Milestones topics of the Phase 1-4 Canvas courses\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eWrite blog posts that...\u003c/p\u003e  \u003cul\u003e \u003cli\u003eDiscuss data science topics\u003c/li\u003e \u003cli\u003eAre composed primarily of original material you wrote\u003c/li\u003e \u003cli\u003eInclude proper attribution\u003c/li\u003e \u003cli\u003eHave high-quality content and formatting\u003c/li\u003e \u003cli\u003eAre something you would proudly show to a potential employer\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eAfter you submit your blog posts, your teacher will grade them as Complete or Incomplete. Your blogs must all be submitted on time and receive Complete grades in order to continue through your program.\u003c/p\u003e  \u003cp\u003e‚ú®Have fun and happy blogging!‚ú®\u003c/p\u003e","exportId":"blogging-overview"},{"id":458668,"title":"Phase 4 Blog Post","type":"Assignment","indent":0,"locked":false,"submissionTypes":"a website url","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cp\u003e\u003cspan\u003ePlease put the URL to your Phase 4 Blog Post here. \u003c/span\u003e\u003cspan\u003eRefer to the \u003c/span\u003e\u003ca title=\"Blogging Overview\" href=\"pages/blogging-overview\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/blogging-overview\" data-api-returntype=\"Page\"\u003eBlogging Overview\u003c/a\u003e\u003cspan\u003e to learn about how to write good blog posts that\u003c/span\u003e\u003cspan style=\"font-family: inherit; font-size: 1rem;\"\u003e meet Flatiron School‚Äôs requirements.\u003c/span\u003e\u003c/p\u003e","exportId":"g3bc84ea730ea0626dd9fa8f8b194dbdf"}]},{"id":47119,"name":"APPENDIX: More Time Series","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g9f7eddb4c2ad4c55c1b6f443cdd47aac","items":[{"id":458676,"title":"Time Series: SARIMA Models - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sarima-models-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sarima-models-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g491127544b4db88dbe24733f9fe3552c"},{"id":458680,"title":"Time Series: Facebook Prophet - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-facebook-prophet-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-facebook-prophet-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"gc6aab54daaa8b90b09373a53eddfc8a3"}]},{"id":47120,"name":"APPENDIX: Graph Theory (Recommendation Systems)","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g61c32519bd09eb763ec5d7f8aea48ee6","items":[{"id":458688,"title":"Graph Theory - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll investigate a new data structure: networks! Networks are a useful data structure to map a range of applications from driving directions to social networks.\u003c/p\u003e\n\n\u003ch2\u003eNetwork Graphs\u003c/h2\u003e\n\n\u003cp\u003eNetworks are another way of representing data that you have yet to fully investigate. In their most simple case, a network contains \u003cstrong\u003enodes\u003c/strong\u003e connected by \u003cstrong\u003eedges\u003c/strong\u003e like this:\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-network-introduction/master/images/graph.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNodes represent some object such as people, languages, countries, or tags, to name a few. The relationships between these objects are the edges between them. For example, later in this section you'll investigate the relationship of various technology tags on the popular website \u003ca href=\"stackoverflow.com\"\u003eStackOverflow\u003c/a\u003e. One potential network visualization of this data looks like this:\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-network-introduction/master/images/stackoverflow_clusters.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003ePath Searching\u003c/h2\u003e\n\n\u003cp\u003eAn important concept in network analysis are path searching algorithms. Finding the shortest path between two nodes is a foundational concept for creating a distance metric which can then be used to conduct more advanced analyses. Mapping applications such as Google Maps, Apple Maps, Waze, or Uber are also natural applications for path searching algorithms. In this section, you'll investigate Dijkstra's algorithm for finding the shortest path between two points, coding it from scratch using Python.\u003c/p\u003e\n\n\u003ch2\u003eCentrality\u003c/h2\u003e\n\n\u003cp\u003eOnce you've familiar with the concept of path searching, you'll then go on to investigate properties of nodes and edges. Centrality is a key concept in this, helping to determine which nodes are most influential in a network, or hold pivotal positions in connecting the network.\u003c/p\u003e\n\n\u003ch2\u003eCliques and Clustering\u003c/h2\u003e\n\n\u003cp\u003eMoving from the study of single objects nodes and edges within the network, you'll then start to investigate larger structures. With this, you'll investigate the concept of cliques and clusters in order to subdivide a network into smaller groups. Natural applications of this include sub-setting social networks into groups or categorizing items such as books or languages.\u003c/p\u003e\n\n\u003ch2\u003eRecommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eTo round out this section, you'll investigate how networks can be used to fuel recommendation systems, a popular and exciting topic. With this, you'll work on recommending amazon products to customers.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eGet ready to dive into the exciting realm of networks! In this section, you'll get to play around with a range of datasets from Twitter, Game of Thrones, and the Amazon Marketplace!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-network-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-network-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-network-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"graph-theory-introduction"},{"id":458692,"title":"Introduction to Graph Theory","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-intro-graph-theory\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-intro-graph-theory\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-intro-graph-theory/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll get an introduction to some basic terminology regarding graphs and graph theory. To start, here's a graph!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph1.png\"\u003e\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain what nodes and edges are in graph theory\u003c/li\u003e\n\u003cli\u003eExplain the difference between directed and undirected graphs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eNodes and Edges: The Building Blocks of Graphs\u003c/h2\u003e\n\u003cp\u003eTo start, graphs are composed of two primary objects: \u003cstrong\u003enodes\u003c/strong\u003e and \u003cstrong\u003eedges\u003c/strong\u003e. In the picture above, the nodes are the circles, while the lines that connect them are edges. Typically, nodes represent some entity such as a person, businesses, places, or webpages. In turn, edges then represent the relationships between these entities. For example, you might have a graph of a social network in which each node represents a person, and each edge represents whether those two individuals are connected or friends within the network.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph2.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, Jen is a well connected character in this scenario: she has a connecting edge with literally every other node in the graph! On the other hand, Jake is the least connected. He has no other connections other than Jen.\u003c/p\u003e\n\u003ch2\u003eDirected vs Undirected Graphs\u003c/h2\u003e\n\u003cp\u003eAnother important concept in graph theory is the difference between directed and undirected graphs. The previous two examples have demonstrated undirected graphs. As the name implies, the edges in an undirected graph represent a mutual connection between two nodes. For example, the previous undirected graph could represent a mutual relationship such as \"Friends\" on Facebook or \"Connections\" on LinkedIn. In contrast, a direct graph looks like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph3.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, each of the edges now has an arrow indicating a direction. This scenario could represent an alternative type of social network such as Twitter in which individual's relationships are not necessarily mutual. Instead, Twitter users can follow other users to stay up to date with their activity. In the graph depicted above, Sally isn't following anyone. However, both Bob and Jen are following Sally. There is also one mutual relationship depicted: Jake is following Jen and she is also following him.\u003c/p\u003e\n\u003ch2\u003eConnectedness\u003c/h2\u003e\n\u003cp\u003eConnectedness aims to quantify the number of edges attached to a node. In the graphs above, Jen is undoubtedly the most connected of the individuals depicted. In the undirected graph, she was connected to everyone. Similarly, if your goal is to become an \u003cem\u003einfluencer\u003c/em\u003e, you're going to need to develop quite the following and become a very connected node. You'll explore more details in how connectedness is quantified in the upcoming lessons. For now, take some time to think about other implications of connectedness. For example, how might you be able to use connectedness to determine friend circles or cliques in social networks?\u003c/p\u003e\n\u003ch2\u003ePath Searching\u003c/h2\u003e\n\u003cp\u003ePath searching algorithms aim to find the shortest distance between any two nodes. This can then be used as a distance metric between nodes. Additionally, this can have interesting implications. For example, in a graph network of a website, a path searching algorithm might outline how many steps are required for a customer to move from the homepage, to browsing for an item, all the way through completing their purchase at checkout. You've actually already seen some basic examples of path searching algorithms in your work with traversing JSON files. There, you took a look at developing breadth-first versus depth-first recursive procedures to create an outline of the structure of an arbitrary JSON file.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you got a brief introduction to graph theory, including some basic definitions and foundational concepts. Remember that graphs are composed of primary objects called nodes and the relationships between those objects, known as edges. Additionally, graphs can be directed or undirected depending on the nature of the edges and the relationships between nodes.\u003c/p\u003e","exportId":"introduction-to-graph-theory"},{"id":458695,"title":"Introduction to NetworkX","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g988d100e6dd9f0593536f8173205f9cf"},{"id":458698,"title":"Introduction to NetworkX - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g6a0a3aa597d6c42d20d6798dbf5b319a"},{"id":458702,"title":"Simple and Shortest Paths","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g6a73e37fcc782d5bb5b0a0d47b481f8a"},{"id":458706,"title":"Simple and Shortest Paths - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"gb2c0e874e98934e6056a2c837a348601"},{"id":458711,"title":"Node Centrality","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g280f526a996dd50d5819bc4c13287887"},{"id":458714,"title":"Node Centrality - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g9cebafc0818e68bfe27738a9efc0054d"},{"id":458717,"title":"Network Clustering","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"gcbda9c0c8cf4870d33f4b156ea179ddf"},{"id":458720,"title":"Network Clustering - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g0bdc5cf5c0a13490bce55a686a409437"},{"id":458723,"title":"Network Connectivity:  Community Detection -Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-community-detection-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-community-detection-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"ga33602690c95464485538bd4f4f79d50"},{"id":458728,"title":"Recommendation Systems","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recommendation-systems\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recommendation-systems/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g6c78ceda6b7362bce45a8e4e549f34c2"},{"id":458732,"title":"Amazon Recommendation System - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recomendation-systems-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recomendation-systems-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g7a5c7a20ee6168c80c5a3b5385a1219a"},{"id":458736,"title":"Graph Theory - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networks-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networks-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you explored a new data structure: networks! While network analysis is a deep topic with many additional topics to explore, you should have a good initial introduction and enough to conduct some preliminary analyses for social networks and building recommendation systems.\u003c/p\u003e\n\n\u003ch2\u003eNetworks\u003c/h2\u003e\n\n\u003cp\u003eYou've seen that networks can represent a range of different underlying data. From directions, social networks, and customer databases, networks are a wonderful way to represent the relationships between individuals. They also make for some snazzy visuals!\u003c/p\u003e\n\n\u003ch2\u003ePaths\u003c/h2\u003e\n\n\u003cp\u003eThe first stop along your journey was paths! Here, you investigated Dijkstra's algorithm to find the shortest path between nodes. This harked back to some of your experience scraping the web when you used recursive functions to perform breadth and depth based search techniques to transverse a json file. While you didn't directly explore this application, networks are also a natural representation for exploring internet traffic and web page structures.\u003c/p\u003e\n\n\u003ch2\u003eCentrality\u003c/h2\u003e\n\n\u003cp\u003eOnce you had a metric to calculate the distance between nodes, you then started to investigate other important concepts of networks such as which nodes were most influential or connected within a graph. You saw how alternative metrics can provide different insights on node structure. As a quick recap:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eDegree-centrality\u003c/strong\u003e: The number of edges attached to a node\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eCloseness-centrality\u003c/strong\u003e: The reciprocal of the sum of the distances to all other nodes in the network \u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eBetweeness-centrality\u003c/strong\u003e: The number of shortest paths between all node pairs the node lies on divided by the maximum number of shortests-paths any one node in the network lies on \u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eEigenvalue-centrality\u003c/strong\u003e: An iterative algorithm which assigns relative influence to a node based on the number and importance of connected nodes. Can be very computationally expensive to compute for large networks. Google's PageRank algorithm is a variation of eigenvalue-centrality \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003eAfter discussing centrality, you then focused on larger structures within a network, breaking apart nodes into clusters to examine subgroups. While this is a common and useful application, it is an ill-defined problem mathematically, often making it difficult to definitively determine an optimal clustering schema. \u003c/p\u003e\n\n\u003ch2\u003eRecommendations\u003c/h2\u003e\n\n\u003cp\u003eFinally, you rounded out the section by investigating how networks can be used to provide recommendations to users. To do this, you investigated a preliminary approach known as collaborative filtering, specifically exploring user-based collaborative filtering in which similar users are identified and their preferences are used to generate recommendations to the user in question. There are many alternative approaches to recommendations systems such as using Singular Value Decomposition. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eA lot was covered in this section! From this, you should have a solid introduction to networks, and some of their applications. Going forward, continue to explore ongoing developments in clustering social networks, and generating recommendations from these fascinating data structures.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-networks-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-networks-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-networks-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"graph-theory-recap"}]},{"id":47125,"name":"APPENDIX: Transfer Learning (Image Classification)","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g37cb0f077afc22eff21cb45775d36cb3","items":[{"id":458745,"title":"Transfer Learning - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll learn all about transfer learning and how it could be specifically applied to convolutional neural networks. There are also other applications of transfer learning like NLP.\u003c/p\u003e\n\n\u003ch2\u003eConvolutional Neural Networks (Continued)\u003c/h2\u003e\n\n\u003cp\u003eIn an earlier section, you learned about the fundamentals of convolutional neural networks and how to use them. In this section, you'll deepen your CNN knowledge and learn about concepts that will allow you to reuse pretrained models from other image recognition tasks. This will help you solve problems where only limited data is available.\u003c/p\u003e\n\n\u003ch3\u003eUsing Pretrained Networks\u003c/h3\u003e\n\n\u003cp\u003eYou will learn about the concept of \"convolutional bases\" and why they are useful. The use of a convolutional base, or a \"pretrained network\" has the advantage that hierarchical features that already have been \"pre-learned\" by this network can act as a generic model. Because of that reason, these networks can be used for a wide variety of computer vision tasks, even if your new problem involves completely different classes of images. You'll learn about the pretrained networks that are available in Keras, the use of pretrained networks through feature extraction (meaning that you run your new data through the pretrained network and training a new classifier on top of the pretrained network), and the use of pretrained networks through finetuning.\u003c/p\u003e\n\n\u003ch3\u003eImage Classification\u003c/h3\u003e\n\n\u003cp\u003eAt the end of this section, you'll work through a lab that combines the knowledge you gained in this section and the previous one. You'll work on a dog breed classification problem, a dataset used in a Kaggle competition, and build both a convolutional neural network from scratch, and a CNN using a pretrained network.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll extend your deep learning knowledge by learning about transfer learning. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-transfer-learning-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-transfer-learning-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"transfer-learning-introduction"},{"id":458748,"title":"Using Pretrained Networks","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g07a414e2616adbbca8a771ce819c55a2"},{"id":458752,"title":"Using Pretrained Networks - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g08342aab578be640fa974343cc984690"},{"id":458755,"title":"Image Classification - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"gc5165593162487d3d1978299a82ee876"},{"id":458758,"title":"Transfer Learning - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you learned how you can adapt pretrained models to improve the performance of neural networks when limited training data is available. While you specifically investigated CNNs and the VGG-19 model, these concepts are also applicable to other domains as well. For example, GloVe (Global Vectors for Word Representation) is a pretrained model that can be useful in a variety of natural language processing tasks.\u003c/p\u003e\n\n\u003cp\u003eRemember that the general process for transfer learning begins by taking a pretrained model like VGG-19 and freezing the weights so that they remain constant. From there, you can then append a standard densely connected classifier to perform the task at hand. In essence, the pretrained model acts as a form of feature engineering applied to the underlying dataset. \u003c/p\u003e\n\n\u003cp\u003eAfter the classifier is trained with the frozen pretrained model, a few of the top layers from the pretrained model can be unfrozen for fine tuning. Remember that you should only do this after training the classifier on top of the fully frozen model. Unfreezing parts of the pretrained model earlier is prone to overwriting any useful feature weights encoded in the pretrained model as there will be large gradients in forward and backward propagation passes until the densely connected layers converge to a stable solution. Also, remember that little is to be gained by unfreezing more than a few of the top layers from a pretrained model. Base layers of models such as VGG-19 will pick up very granular features such as colors or edges in image recognition. As such, these base layers are typically well formulated features across many domains. Unfreezing top layers has far more impact on tuning as these final layers often pick up domain specific features, so when adopting a model to a new problem domain such as predicting flower species instead of predicting animal kingdoms, these top layers can often be more impactful if retrained to the specific application.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you got an overview of transfer learning and how to adapt pretrained models. From here, you'll continue to learn about other neural network architectures and build upon your growing deep learning knowledge.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-transfer-learning-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-transfer-learning-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"transfer-learning-recap"}]},{"id":47127,"name":"APPENDIX: Deep NLP","status":"completed","unlockDate":null,"prereqs":[],"requirement":null,"sequential":false,"exportId":"g1f77693b457fdccc4722d6c342c5f1fe","items":[{"id":458763,"title":"Deep NLP with Word Embeddings - Introduction","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll strengthen your deep learning and natural language processing skills by learning about word embeddings! Word embeddings are a unique coding schema for text corpora that preserve many underlying features, allowing for interesting geometric relations in this hyperspace. Specifically, you'll look at how similarity metrics can represent how two words relate to each other, and these transformations can be applied to multiple word pairs. For example, a similarity metric could encapsulate analogies like \"man is to woman as king is to ____\". \u003c/p\u003e\n\n\u003ch3\u003eWord Embeddings\u003c/h3\u003e\n\n\u003cp\u003eIn this section, you'll learn about the concept of word embeddings, and how you can use them to model the semantic meanings of words in a high-dimensional embedding space! Word embeddings use similarity metrics to represent how two words relate to each other. This way, we can understand the words in our corpus to a bigger extent. A typical example is the example of \"Man\" vs \"woman\" and \"king\" vs \"queen\": word embeddings can capture that the word \"man\" relates to the word \"woman\" the same way the word \"king\" relates to \"queen\"!\u003c/p\u003e\n\n\u003ch3\u003eUsing Word2Vec\u003c/h3\u003e\n\n\u003cp\u003eCreating word embeddings is not an easy task. Word embeddings can be created using so-called \"Word2Vec\" models that are  given enough training data. At its core, Word2Vec is just another deep neural network, that looks at sequences of words and words that are often used in similar contexts (or \u003cem\u003eclose\u003c/em\u003e to each other in sentences). In this section you'll learn how to train a Word2Vec model, and you'll explore the embedding space.\u003c/p\u003e\n\n\u003ch3\u003eClassification with Word Embeddings\u003c/h3\u003e\n\n\u003cp\u003eTo wrap up this section, we'll focus on the practical aspects of how Word2Vec and word embeddings can be used to improve our text classification models. We'll start by learning how transfer learning can be used by loading pre-trained word vectors into our Word2Vec model. Then, we'll learn about how we can get the word vectors we need and combine them into mean word vectors, and how we can streamline this process by writing our own vectorizer class that is compatible with scikit-learn pipelines. Next, we'll see how deep neural networks with their own embedding layers can be trained, and how Keras preprocesses the text data to make everything run smoothly!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll dive deeper into NLP and get better classification results using word embeddings!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-deep-nlp-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-deep-nlp-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"deep-nlp-with-word-embeddings-introduction"},{"id":458766,"title":"Word Embeddings","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll learn about the concept of \u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e, and how you can use them to model the semantic meanings of words in a high-dimensional embedding space!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDemonstrate how word vectors are structured \u003c/li\u003e\n\u003cli\u003eCompare and contrast word vector embeddings with other text vectorization strategies \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat Are Word Embeddings?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e are a type of vectorization strategy that computes word vectors from a text corpus by training a neural network, which results in a high-dimensional embedding space, where each word in the corpus is a unique vector in that space. In this embedding space, the position of the vector relative to the other vectors captures semantic meaning. This method of creating distributed representations of words in a high-dimensional embedding space was first introduced in a landmark paper from members of the Google Brain team in 2013 at the Neural Information Processing Systems (NeurIPS, for short). You can read the full paper from Mikolov et al by following \u003ca href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\"\u003ethis link\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCapturing Semantic Relationships\u003c/h3\u003e\n\n\u003cp\u003eSo far, the vectorization strategies you've learned have focused only on how often a word appears in a given text, but they don't focus at all on capturing the semantic meaning. This is one area where using the Word2Vec model to create \u003cstrong\u003e\u003cem\u003eWord Vector Embeddings\u003c/em\u003e\u003c/strong\u003e really shines, because it will capture those semantic relationships between words, for instance, a Word2Vec model that is given enough data and training will learn that there is a semantic relationship between the word 'person' and 'people'. Furthermore, vector one would need to travel to get from the singular 'person' to the plural 'people' will be the same vector that will get you from the singular version of a word to it's plural - meaning that our model will 'learn' how to model the relationship between singular and plural versions of the same word. Take a look at the examples below:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-word-embeddings/master/images/embeddings.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs you can see in the diagram above, the embedding space shows that the model has positioned the words 'king' and 'queen' in the same relationship that the vector 'man' has to 'woman'. The vector that gets you from 'king' to 'queen' or from 'man' to 'woman' is the vector for gender! You can see other examples show that the model also learns representations for verb tense, or even for countries and their capitals. This is more impressive when you realize that the model learns these relationships from reading a large enough corpus of text, without being given an explicit direction or instruction - that is, the researchers did not expressly feed the model sentences like \"Madrid is the capital of Spain\".  \u003c/p\u003e\n\n\u003cp\u003eSince the words are all embedded in the same high-dimensional space, you can use the same similarity metrics you've used before, such as things like \u003cem\u003eCosine Similarity\u003c/em\u003e or even \u003cem\u003eEuclidean Distance\u003c/em\u003e. In a future lab, you'll experiment with using a trained Word2Vec model for tasks like finding the most similar word(s) to a given word. Trained Word2Vec models also excel at things like the analogies questions that were made famous by the SAT test.\u003c/p\u003e\n\n\u003cp\u003eLet's end this lesson by taking a look at how the word vectors are actually structured. \u003c/p\u003e\n\n\u003ch2\u003eA Small Example\u003c/h2\u003e\n\n\u003cp\u003eSo far, you've learned vectorization strategies such as \u003cem\u003eCount Vectorization\u003c/em\u003e and \u003cem\u003eTF-IDF Vectorization\u003c/em\u003e. Recall that the vectors created by these algorithms are \u003cstrong\u003e\u003cem\u003eSparse Vectors\u003c/em\u003e\u003c/strong\u003e. The length of a vector created by TF-IDF or Count Vectorization is the length of the total vocabulary of the text corpus. In these vectors, the vast majority of elements in the vector are 0, which is a massive waste of space, and a ton of extra dimensionality that can hurt our model's performance (recall the \u003cstrong\u003e\u003cem\u003eCurse of Dimensionality\u003c/em\u003e\u003c/strong\u003e)! If you were to use TF-IDF vectorization to turn the word 'apple' into a vector representation with a text corpus containing 100,000 words, then our word vector would contain a value at the element that corresponds to the word 'apple', and then 99,999 \u003cem\u003e0\u003c/em\u003es!\u003c/p\u003e\n\n\u003cp\u003eVectors created through word embeddings are different - the size of the vector is a tunable parameter you can set. \u003c/p\u003e\n\n\u003cp\u003eLet's look at a toy example. Consider the diagram below. First, pay attention to what each of the columns mean. Let's assume that you built a model to 'rate' each of the animals across each of these four categories, relative to one another.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-word-embeddings/master/images/vectors.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn this embedding space, the vectorized representation of the word 'dog' would be \u003ccode\u003e[-0.4, 0.37, 0.02, -0.34]\u003c/code\u003e. As you'll see when you study the actual Word2Vec model, you can use some nifty tricks to train a neural network to act as a sort of 'lookup table', where you can get the vector out for any given word. In the next lesson, you'll spend a bit more time understanding exactly how the model learns the correct values for each word. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about the concept of \u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e, and explored how they work. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-word-embeddings\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-word-embeddings\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"word-embeddings"},{"id":458768,"title":"Using Word2Vec","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll take a look at how the \u003cstrong\u003e\u003cem\u003eWord2Vec\u003c/em\u003e\u003c/strong\u003e model actually works, and then learn how you can make use of Word2Vec using the open-source \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the tunable parameters of a Word2Vec model \u003c/li\u003e\n\u003cli\u003eDescribe the architecture of the Word2Vec model \u003c/li\u003e\n\u003cli\u003eTrain a Word2Vec model and transform words into vectors \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eHow Word2Vec Works\u003c/h2\u003e\n\n\u003cp\u003eBy now, you've gained an understanding of what a word embedding space is, and you've learned a little bit about how the words are represented as Dense vectors. However, we haven't touched on how the model actually learns the correct values for all the word vectors in the embedding space. To put it another way, how does the Word2Vec model learn exactly \u003cem\u003ewhere\u003c/em\u003e to embed each word vector inside the high dimensional embedding space?\u003c/p\u003e\n\n\u003cp\u003eNote that this explanation will stay fairly high-level, since you don't actually need to understand every part of how the Word2Vec model works in order to use it effectively for Data Science tasks. If you'd like to dig deeper in to how the model actually works, we recommend you start by reading this tutorial series from Chris McCormick (\u003ca href=\"http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\"\u003epart 1\u003c/a\u003e and \u003ca href=\"http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\"\u003epart 2\u003c/a\u003e), and then moving onto the actual \u003ca href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\"\u003eWord2Vec White Paper by Mikolov et al\u003c/a\u003e. The graphics used in this lesson are actually from Chris McCormick's excellent blog posts explaining how Word2Vec actually works.\u003c/p\u003e\n\n\u003ch3\u003eWindow Size and Training Data\u003c/h3\u003e\n\n\u003cp\u003eAt its core, Word2Vec is just another deep neural network. It's not even a particularly complex neural network -- the model contains an input layer, a single hidden layer, and and an output layer that uses the softmax activation function, meaning that the model is meant for multiclass classification. The model examines a \u003cstrong\u003e\u003cem\u003ewindow\u003c/em\u003e\u003c/strong\u003e of words, which is a tunable parameter that you can set when working with the model. Let's take a look at a graphic that explains how this all actually looks on a real example of data:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/training_data.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, the model has a window size of 5, meaning that the model considers a word, and the two words to the left and right of this word.  \u003c/p\u003e\n\n\u003ch3\u003eThe Skip-Gram Architecture\u003c/h3\u003e\n\n\u003cp\u003eSo what exactly is this deep neural network predicting?\u003c/p\u003e\n\n\u003cp\u003eThe most clever thing about the Word2Vec model is the type of problem it trains the network to solve, which creates the dense vectors for every word as a side effect! A typical task for a neural network is sentence completion. A trained model should be able to take in a sentence like \"the cat sat on the\" and output the most likely next word in the sentence, which should be something like \"mat\", or \"floor\". This is a form of \u003cstrong\u003e\u003cem\u003eSequence Generation\u003c/em\u003e\u003c/strong\u003e. Given a certain context (the words that came before), the model should be able to generate the next most plausible word (or words) in the sequence. \u003c/p\u003e\n\n\u003cp\u003eWord2Vec takes this idea, and flips it on its head. Instead of predicting the next word given a context, the model trains to predict the context surrounding a given word! This means that given the example word \"fox\" from above, the model should learn to predict the words \"quick\", \"brown\", \"jumps\", and \"over\", although crucially, not in any particular order. You're likely asking yourself why a model like this would be useful -- there are a massive amount of correct contexts that can surround a given word, which means that the output trained model itself likely isn't very useful to us. This intuition is correct -- the \u003cem\u003eoutput\u003c/em\u003e of the model is pretty useless to us.  However, in the case of Word2Vec, it's not the model that we're interested in. It turns out that by training to predict the context window for a given word, the neurons in the hidden layer end up learning the embedding space!  This is the reason why the size of the word vectors output by a Word2Vec model are a parameter that you can set ourselves. If you want word vectors of size 300, then you just include 300 neurons in our hidden layer. If you want vectors of size 100, then you include 100 neurons, and so on. Take a look at the following diagram of the Word2Vec model's architecture:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/new_skip_gram_net_arch.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eHidden Layers as a \"Lookup Table\"\u003c/h3\u003e\n\n\u003cp\u003eTo recap, the Word2Vec model learns to solve a \"fake\" problem, which you don't actually care about. The input layer of the network contains one neuron for every word in the vocabulary. If there are 10,000 words, then there are 10,000 input neurons, with each one corresponding to a unique word in the vocabulary. Since these input neurons feed into a dense hidden layer, this means that each neuron will have a unique weight for each of the 10,000 words in the vocabulary. If there are 10,000 words and you want vectors of size 300, then this means the hidden layer will be of shape \u003ccode\u003e[10000, 300]\u003c/code\u003e. To put it another way -- each of the 10,000 words will have it's own unique vector of weights, which will be of size 300, since there are 300 neurons.  \u003c/p\u003e\n\n\u003cp\u003eOnce you've trained the model, you don't actually need the output layer anymore -- all that matters is the hidden layer, which will now act as a \"Lookup Table\" that allows us to quickly get the vector for any given word in the vocabulary. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/new_word2vec_weight_matrix_lookup_table.png\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's the beautiful thing about this lookup table -- when you input a given word, it is passed into the model in a one-hot encoded format. This means that in a vocabulary of 10,000 words, you'll have a \u003ccode\u003e1\u003c/code\u003e at the element that corresponds to the word that we're looking up the word vector for, and \u003ccode\u003e0\u003c/code\u003e for every other element in the vector. If you multiply this one-hot encoded vector by the weight matrix that is our hidden layer, then the vector for every word will be zeroed out, except for the vector that corresponds to the word that you are most interested in!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/matrix_mult_w_one_hot.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eUnderstanding the Intuition Behind Word2Vec\u003c/h3\u003e\n\n\u003cp\u003eSo how does the model actually learn the correct weights for each word in a way that captures their semantic context and meaning? The intuition behind Word2Vec is actually quite simple, when you think about the idea of the context window that it's learning to predict. Recall the following quote, which you've seen before:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"You shall know a word by the company it keeps.\"  -- J.R. Firth, Linguist\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn the case of the Word2Vec model, the \"company\" a word keeps are the words surrounding it, and the model is learning to predict these companions! By exploring many different contexts, the model attempts to decipher which words are appropriate in which contexts. For example, consider the sentence \"we have two cats as pets\". You could easily substitute the word \"cats\" for \"dogs\" and the entire sentence would still make perfect sense. While the meaning of the sentence is undoubtedly changed, there is also a lesson regarding the fact that both are nouns and pets. Without even worrying about the embedding space, you can easily understand that words that have similar meanings will likely also be used in many of the same kinds of sentences. The more similar words are, the more sentences in which they are likely to share context windows! This is exactly what the model is learning, and this is why words that are similar end up near each other inside the embedding space. The ways that they are \u003cem\u003enot\u003c/em\u003e similar also helps the model learn to differentiate between them, since there will be patterns here as well. For instance, consider \"ran\" and \"run\", and \"walk\" and \"walked\". They differ only in tense. From the perspective of the sentences present in a large text corpus (models are commonly trained on all of Wikipedia, to give you an idea of the sheer size and scale of most datasets), the model will see numerous examples of how \"ran\" is similar to \"walked\", as well as examples of how the context windows for \"ran\" are different from \"run\" in the same ways that the context windows for \"walked\" are different from \"walk\"! \u003c/p\u003e\n\n\u003ch2\u003eTraining A Word2Vec Model with \u003ccode\u003egensim\u003c/code\u003e\n\u003c/h2\u003e\n\n\u003cp\u003eNow, take look at how you can apply the Word2Vec model using the \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\n\u003cp\u003eTo train a Word2Vec model, you first need to import the model from the \u003ccode\u003egensim\u003c/code\u003e library and instantiate it. Upon instantiation, you'll need to provide the model with certain parameters including:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ethe dataset you'll be training on\u003c/li\u003e\n\u003cli\u003ethe \u003ccode\u003esize\u003c/code\u003e of the word vectors you want to learn \u003c/li\u003e\n\u003cli\u003ethe \u003ccode\u003ewindow\u003c/code\u003e size to use when training the model\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003emin_count\u003c/code\u003e, which corresponds to the minimum number of times a word must be used in the corpus in order to be included in the training (for instance, \u003ccode\u003emin_count=5\u003c/code\u003e would only learn word embeddings for words that appear 5 or more times throughout the entire training set)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eworkers\u003c/code\u003e, the number of threads to use for training, which can speed up processing (\u003ccode\u003e4\u003c/code\u003e is typically used, since most processors nowadays have at least 4 cores). \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOnce you've instantiated the model, you'll still need to call the model's \u003ccode\u003e.train()\u003c/code\u003e method, and pass in the following parameters:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe same dataset that you passed in at instantiation\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etotal_examples\u003c/code\u003e, which is the number of words in the model. You don't need to calculate this manually -- instead, you can just pass in the instantiated model's \u003ccode\u003e.corpus_count\u003c/code\u003e attribute for this parameter.\u003c/li\u003e\n\u003cli\u003eThe number of \u003ccode\u003eepochs\u003c/code\u003e to train the model for. \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe following example demonstrates how to instantiate and train a Word2Vec model:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"python\"\u003efrom gensim.models import Word2Vec\n\nmodel = Word2Vec(data, size=100, window=5, min_count=1, workers=4)\n\nmodel.train(data, total_examples=model.corpus_count)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3\u003eExploring the Embedding Space\u003c/h3\u003e\n\n\u003cp\u003eOnce you have trained the model, you can easily explore the embedding space using the built-in methods and functionality provided by gensim's \u003ccode\u003eWord2Vec\u003c/code\u003e class. \u003c/p\u003e\n\n\u003cp\u003eThe actual Word2Vec model itself is quite large. Normally, you only need the actual vectors and the words that correspond to them, which are stored inside of \u003ccode\u003emodel.wv\u003c/code\u003e as a \u003ccode\u003eWord2VecKeyedVectors\u003c/code\u003e object. To save time and space, it's usually easiest to just store the \u003ccode\u003emodel.wv\u003c/code\u003e inside it's own variable, and then work directly with that. You can then use this model for various sorts of functionality, which you'll demonstrate below!\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"python\"\u003ewv = model.wv\n\nwv.most_similar('Cat')\n\nwv.most_similar(negative='Cat')\n\nwv['Cat']\n\nwv.vectors\n\nwv.most_similar(positive=['king', 'woman'], negative=['man'])\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eIn the next lab, you'll train a Word2Vec model, and then explore the embedding space it has learned. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about how the Word2Vec model actually works, and how you can train and use a Word2Vec model using the \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-using-word2vec\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-using-word2vec\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"using-word2vec"},{"id":458769,"title":"Generating Word Embeddings - Lab","type":"Assignment","indent":1,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-generating-word-embeddings-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-generating-word-embeddings-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g3f13c1f812ad456b8924567383fc3f66"},{"id":458771,"title":"Classification with Word Embeddings","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll look at the practical aspects of how you can use word embeddings and Word2Vec models for text classification!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe what an embedding layer is in a neural network \u003c/li\u003e\n\u003cli\u003eUse pretrained word embeddings from popular pretrained models such as GloVe \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll start by reviewing \u003cstrong\u003e\u003cem\u003eTransfer Learning\u003c/em\u003e\u003c/strong\u003e and loading pre-trained word vectors. Then, you'll learn about how to get important word vectors, combine them into \u003cstrong\u003e\u003cem\u003eMean Word Vectors\u003c/em\u003e\u003c/strong\u003e, and streamline this process by writing a custom vectorizer class compatible with scikit-learn pipelines. Finally, you'll end the lesson by examining how to train deep neural networks that include their own word embedding layers, and how you can use Keras to preprocess text data conveniently!\u003c/p\u003e\n\n\u003ch2\u003eUsing Pretrained Word Vectors With GloVe\u003c/h2\u003e\n\n\u003cp\u003ePerhaps the single best way to improve performance for text classification is to make use of weights from a Word2Vec model that has been trained for a very long time on a massive amount of text data. With deep learning, more data is almost always the single best thing that can improve model performance, and the embedded word vectors created by a Word2Vec model are no exception. For this reason, it's almost always a good idea to load one of the top-tier, industry-standard models that been open sourced for this exact purpose. The most common model to use for this is the \u003cstrong\u003e\u003cem\u003eGloVe\u003c/em\u003e\u003c/strong\u003e (short for \u003cstrong\u003e\u003cem\u003eGlobal Vectors for Word Representation\u003c/em\u003e\u003c/strong\u003e) model by the Stanford NLP Group. This model is trained on massive datasets, such as the entirety of Wikipedia, for a very long time on server clusters with multiple GPUs. It would be absolutely impossible for us to train a model of similar quality on our own machines. However, because the model weights are open-source, you don't need to! Instead, you'll simply download the weights and go from there. \u003c/p\u003e\n\n\u003cp\u003eFor text classification purposes, loading the weights precludes the need for us to instantiate or train a Word2Vec model entirely -- instead, you just:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGet the total vocabulary in our dataset\u003c/li\u003e\n\u003cli\u003eDownload and unzip the GloVe file needed from the Stanford NLP Group's website\u003c/li\u003e\n\u003cli\u003eRead the GloVe file, and save only the vectors that correspond to the words that appear in the vocabulary of our dataset \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis can be a fairly involved process, so the code for this is provided for you in the next lab. That said, it's important to take some time and examine this code until you have at least general idea of what's going on!\u003c/p\u003e\n\n\u003ch2\u003eMean Word Embeddings\u003c/h2\u003e\n\n\u003cp\u003eLoading a pretrained model like GloVe may provide you with the most accurate word vectors we could possibly hope, but each vector is still just a single word. This isn't very conducive to classification as is at this stage, because it's highly likely that any text classification will be focused on arbitrarily-sized blobs of text, such as sentences or paragraphs. With that, the question is how to get these sentences and paragraphs into a format that can be used for classification, while making use of the word vectors from GloVe?\u003c/p\u003e\n\n\u003cp\u003eThe answer is to compute a \u003cstrong\u003e\u003cem\u003eMean Word Embedding\u003c/em\u003e\u003c/strong\u003e. The idea behind this is simple. To get the vector representation for any arbitrarily-sized block of text, all you need to do is get the vector for every individual word that appears in that block of text, and average them together! The benefit of this is that no matter how big or small that block of text is, the mean word embedding of that sentence will be the same size as all of the others, because the vectors you're averaging together all have the exact same dimensionality! This makes it a simple matter to get a block of text into a format that we can use with traditional supervised learning models such as Support Vector Machines or Gradient Boosted Trees. \u003c/p\u003e\n\n\u003ch3\u003eWorking With scikit-learn pipelines\u003c/h3\u003e\n\n\u003cp\u003eAs you'll see in the next lab, it's worth the extra bit of work to build a class that works with the requirements of a scikit-learn \u003ccode\u003ePipeline()\u003c/code\u003e class, so that you can pass the data straight in and generate the mean word embeddings on the fly. This way, you don't need to write the same set of code twice to generate mean word embeddings for both the training and test set. This is also important if the dataset is too large to fit into your computer's memory, as it will allow you to partially train models and load in different chunks of the dataset. By building a vectorizer class that handles creating the mean word embeddings rather than just writing the code procedurally, you'll save yourself a lot of work in the long run!\u003c/p\u003e\n\n\u003cp\u003eThe code for the mean embedding vectorizer class is also provided for you in the next lab. As you'll see, the class requires both \u003ccode\u003e.fit()\u003c/code\u003e and \u003ccode\u003e.transform()\u003c/code\u003e methods to be compliant with scikit-learn's \u003ccode\u003ePipeline()\u003c/code\u003e class. Take some time to study this code until you understand what it's doing -- it isn't complex, and understanding how to do this yourself will pay dividends in the long run. After all, writing clean, reusable code always does!\u003c/p\u003e\n\n\u003ch2\u003eDeep Learning \u0026amp; Embedding Layers\u003c/h2\u003e\n\n\u003cp\u003eOne problem you may have noticed with the mean word embedding strategy is that by combining all the words, you lose some information that is contained in the sequence of the words. In natural language, the position and phrasing of words in a sentence can often contain information that we pick up on. This is a downside to this approach, and one of the reasons why \u003cstrong\u003e\u003cem\u003eSequence Models\u003c/em\u003e\u003c/strong\u003e tend to outperform all of the 'shallow' algorithms (note: this term just refers to any machine learning algorithms that do not fall under the umbrella of deep learning -- it doesn't make any judgments about whether they are better or worse, as that is almost always dependent on the situation!). In the next lesson, you'll learn about sequence models including \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e. Moreover, in the next lab, you'll also see a preview example of these, so that you can see how to use \u003cstrong\u003e\u003cem\u003eEmbedding Layers\u003c/em\u003e\u003c/strong\u003e directly within neural networks!\u003c/p\u003e\n\n\u003cp\u003eAn \u003cstrong\u003e\u003cem\u003eEmbedding Layer\u003c/em\u003e\u003c/strong\u003e is just a layer that learns the word embeddings for our dataset on the fly, right there inside the neural network. Essentially, its a way to make use of all the benefits of Word2Vec, without worrying about finding a way to include a separately trained Word2Vec model's output into our neural networks (which are probably already complicated enough!). You'll see an example of an \u003cstrong\u003e\u003cem\u003eEmbedding Layer\u003c/em\u003e\u003c/strong\u003e in the next lab. You should make note of a couple caveats that come with using embedding layers in your neural network -- namely:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe embedding layer must always be the first layer of the network, meaning that it should immediately follow the \u003ccode\u003eInput()\u003c/code\u003e layer \u003c/li\u003e\n\u003cli\u003eAll words in the text should be integer-encoded, with each unique word encoded as it's own unique integer\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eThe size of the embedding layer must always be greater than the total vocabulary size of the dataset! The first parameter denotes the vocabulary size, while the second denotes the size of the actual word vectors\u003c/li\u003e\n\u003cli\u003eThe size of the sequences passed in as data must be set when creating the layer (all data will be converted to padded sequences of the same size during the preprocessing step)\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn the next lab, you'll make use of Keras' text preprocessing tools to convert the data from text to a tokenized format. Then, you'll convert the tokenized sentences to sequences. Finally, you'll pad the sequences, so that they're all the same length. During this step, you'll exclusively make use of the preprocessing tools provided by Keras. Don't worry if this all seems a bit complex right now, as you'll soon see, this is actually the most straightforward part of the next lab!\u003c/p\u003e\n\n\u003cp\u003eFor a full rundown of how to use embedding layers in Keras, see the \u003ca href=\"https://keras.io/layers/embeddings/\"\u003eKeras Documentation for Embedding Layers\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you focused on the practical and pragmatic elements of using Word2Vec and word embeddings for text classification. You learned about how to load professional-quality pretrained word vectors with the Stanford NLP Group's open source GloVe data, as well as how to generate mean word embeddings that work with scikit-learn pipelines, and how to add embedding layers into neural networks with Keras!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-classification-with-word-embeddings\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-classification-with-word-embeddings\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"classification-with-word-embeddings"},{"id":458773,"title":"Classification with Word Embeddings - Codealong","type":"Assignment","indent":0,"locked":false,"submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","exportId":"g4542f7e2ca39617c6d3b3e57a39c97aa"},{"id":458775,"title":"Sequence Model Use Cases","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-sequence-model-use-cases\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sequence-model-use-cases\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sequence-model-use-cases/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about \u003cstrong\u003e\u003cem\u003eSequence Models\u003c/em\u003e\u003c/strong\u003e, and what makes them different from traditional multi-layer perceptrons. You'll also examine some of the common things sequence models can be used for!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDefine a Sequence Model\u003c/li\u003e\n\u003cli\u003eList some of the use cases for Sequence Models\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eWhat is a Sequence Model?\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003e\u003cem\u003eSequence Model\u003c/em\u003e\u003c/strong\u003e is a general term for a special class of deep neural networks that work with time series of data as input (or any data where you want the model to consider the data one point at a time, in order). This means that they are great for problems where the order of the data matters - for instance, stock price data or text. In both cases, the data only makes sense in order. For instance, scrambling the words in a sentence destroys the meaning of the sentence, and it's impossible to predict if a stock price is going to go up or down if you don't see the prices in sequential order. In both cases, the sequence of the data matters.\u003c/p\u003e\n\u003cp\u003eConsider the following problem: you are given the sentence \"you are going to\" and asked to complete the sentence by generating at least 5 more words. The second word that you choose will depend heavily on the first word that you choose. The third word that you choose will depend heavily on the first and second words that you choose, and so on. Because of this, it is crucial that the models \u003cem\u003eremember\u003c/em\u003e the previous words that they generated. In computer science, you call this being \u003cstrong\u003e\u003cem\u003estateful\u003c/em\u003e\u003c/strong\u003e. This means that when the model is generating the second word, it needs to know what it generated as the first word! To do this, \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e feed their output for timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=%5Clarge%20x_t\"\u003e back into the model as input for timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=%5Clarge%20x_%7Bt%20%2b%201%7D\"\u003e !\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/rnn.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eThere are many different kinds of sequence models, and they are most generally referred to as \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eRNNs\u003c/em\u003e\u003c/strong\u003e. In the next lesson, you'll dig into how they work. Let's examine some of the things that RNNs can do!\u003c/p\u003e\n\u003ch2\u003eSequence Model Use Cases\u003c/h2\u003e\n\u003ch3\u003eText Classification\u003c/h3\u003e\n\u003cp\u003eOne of the most common applications of RNNs is for plain old text classification. Recall that all the models that you've used so far for text generation have been incapable of focusing on the order of the words, which means that they're likely to miss out on more advanced pieces of information such as connotation, context, sarcasm, etc. However, since RNNs examine the words one at a time and remember what they've seen at each time step, they're able to capture this information quite effectively in most cases! As the final part of this section, we'll actually build one of these models which will be able to detect toxic comments from real-world Wikipedia comments!\u003c/p\u003e\n\u003ch3\u003eSequence Generation\u003c/h3\u003e\n\u003cp\u003eSequence generation is probably some of the most incredible things you can do with neural networks, because they excel at coming up with wacky, almost-human sounding names for things when fed the right data. For instance, all of the following cookie names were generated by feeding a dataset of actual cookie names from recipes. The model was built to generate it's own cookie names letter by letter, based on what it saw in the recipe names. Since the model is responsible for generating its own output letter by letter, one at a time, this makes it a prime example of \u003cstrong\u003e\u003cem\u003eSequence Generation\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/rnn_cookie_names.png\"\u003e\u003c/p\u003e\n\u003ch3\u003eSequence-to-Sequence Models\u003c/h3\u003e\n\u003cp\u003eIf you've ever used Google Translate before, then you've already interacted with a \u003cstrong\u003e\u003cem\u003eSequence to Sequence Model\u003c/em\u003e\u003c/strong\u003e. These models learn to map an input sequence to an output sequence, usually through an \u003cstrong\u003e\u003cem\u003eEncoder-Decoder\u003c/em\u003e\u003c/strong\u003e architecture. Note that although going from a sequence of English words to the corresponding sequence of French words is probably the basic example of Sequence to Sequence models, there are many other kinds of problems that are Sequence to Sequence that aren't immediately obvious. For instance, check out this example of a neural network that completes drawings of a mosquito based on how you start drawing the bug!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/multi_sketch_mosquito.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eHere's another example from \u003ca href=\"https://phillipi.github.io/pix2pix/\"\u003epix2pix\u003c/a\u003e. Now, stop what you're doing, follow that link, and take a few minutes to play around with pix2pix -- watching it generate photos from your own drawings is really cool!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/pix2pix.gif\"\u003e\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about sequence models, and some of their more common use cases.\u003c/p\u003e","exportId":"sequence-model-use-cases"},{"id":458777,"title":"Understanding Recurrent Neural Networks","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-understanding-recurrent-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about a new type of model architecture you haven't seen yet ‚Äî \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain the role time steps play in RNN models\u003c/li\u003e\n\u003cli\u003eExplain back propagation through time\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eData as Time Sequences\u003c/h2\u003e\n\u003cp\u003eThe hallmark of Recurrent Neural Networks is that they are used to evaluate \u003cstrong\u003e\u003cem\u003eSequences\u003c/em\u003e\u003c/strong\u003e of data, rather than just individual data points. So what is sequence data, and how do you distinguish it from other kinds of data, so that you know when to use an RNN?\u003c/p\u003e\n\u003cp\u003eTime series data is a classic example of sequence data. You care about the value over time, and any given point in time can really only be examined relative to the other points of time in that sequence. For instance, knowing the price of Google stock today doesn't provide enough information for us to classify it as a something you should or shouldn't buy ‚Äî for that, you would need to examine today's price relative to the previous day(s) price to see if it's going up or down.\u003c/p\u003e\n\u003cp\u003eAnother great example of sequence data is text. All text data is sequence data by default ‚Äî a letter only makes sense when it's words are in the proper order. You would lose all information if you made a \"Bag of Letters\". Words themselves are sequence data, and can be used for all kinds of novel sequence generation tasks. You've probably seen articles in popular culture about people using neural networks to generate novel band names, cookie names, Pokemon names, etc. These are always done with Recurrent Neural Networks, because they are a perfect fit for sequence data. For this reason, RNNs excel at NLP tasks, because they can take in text as full sequences of words, from a single sentence up to an entire document or book! Because of this, they do not suffer the same loss of information that comes from a traditional Bag-of-Words vectorization approach.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/master/images/unrolled.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eLet's take a look at the overall structure of an RNN to see how it interacts with this sequence data!\u003c/p\u003e\n\u003ch2\u003eBasic RNN Architecture\u003c/h2\u003e\n\u003cp\u003eA basic Recurrent Neural Network is just a neural network that passes it's output from a given example back into itself as input for the next example. Intuitively, this approach makes sense. If you want to predict what Google's stock price is going to be two days from now, the most important input you can give it is what you think the price will be one day from now!\u003c/p\u003e\n\u003cp\u003eWhen drawn as a diagram, RNNs are usually represented in an \u003cstrong\u003e\u003cem\u003eUnrolled\u003c/em\u003e\u003c/strong\u003e representation, which shows the components at each given timestep. The image on the left is a how an RNN is denoted in a diagram \"rolled up\", while the image on the right is \"unrolled\". The current timestep is denoted with the input node \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_t\"\u003e , which makes the previous timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_%7Bt-1%7D\"\u003e and the next timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_%7Bt%2b1%7D\"\u003e . \u003cimg src=\"https://render.githubusercontent.com/render/math?math=H_0\"\u003e represents the model's output for timestep 0, which will then be passed back into the model in \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_1\"\u003e .\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/master/images/new-RNN-unrolled.png\"\u003e\u003c/p\u003e\n\u003ch2\u003eBackpropagation Through Time\u003c/h2\u003e\n\u003cp\u003eOne interesting aspect of working with RNNs is that they use a modified form of back propagation called \u003cstrong\u003e\u003cem\u003eBack Propagation Through Time (BPTT)\u003c/em\u003e\u003c/strong\u003e. Because the model is trained on sequence data, it has the potential to be right or wrong at every point in that sequence. This means that you need to adjust the model's weights at each time point to effectively learn from sequence data. Because the model starts at the most recent output, and then works backwards to calculate the loss and update the weights at each time step, the model is said to be going \"back in time\" to learn. Since you have to update every single weight at every single time step, that means that BPTT is much more computationally expensive than traditional back propagation. For instance, if a single data point is a sequence with 1000 time steps, then the model will perform a full round of back propagation for each of the 1000 points in that single sequence.\u003c/p\u003e\n\u003ch3\u003eTruncated Back Prop Through Time\u003c/h3\u003e\n\u003cp\u003eThis was a major hurdle for traditional RNN architectures, but a solution exists in the form of the \u003cstrong\u003e\u003cem\u003eTruncated Back Propagation Through Time (TBPTT)\u003c/em\u003e\u003c/strong\u003e algorithm! We won't go deep into the specifics, but essentially, this algorithm increases performance by breaking a big sequence of 1000 points into 50 sequences of 20. This significantly improves training time over regular BPTT, but is still significantly slower than vanilla back propagation.\u003c/p\u003e\n\u003cp\u003eFun Fact: Truncated Back Prop Through Time was invented in the dissertation of Ilya Sutskever, one of the lead researchers at Open AI!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about the sequence data. You also learned about the architecture of RNNs, and the modified back prop algorithm they use for training!\u003c/p\u003e","exportId":"understanding-recurrent-neural-networks"},{"id":458779,"title":"LSTMs and GRUs","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-lstms-and-grus\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-lstms-and-grus\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-lstms-and-grus/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about two advanced types of neurons that typically outperform basic RNNs, \u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eGated Recurrent Units\u003c/em\u003e\u003c/strong\u003e! You'll explore the problems they solve that increase their effectiveness compared to traditional vanilla RNNs, and compare and contrast the two neurons types to get a feel for what exactly they do and how they do it!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain why vanishing and exploding gradients exist when training RNNs\u003c/li\u003e\n\u003cli\u003eDescribe the basic architecture and function of a GRU\u003c/li\u003e\n\u003cli\u003eDescribe the architecture and function of an LSTM cell\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eRNNs and Gradient Problems\u003c/h2\u003e\n\u003cp\u003eOne of the biggest problems with standard Recurrent Neural Networks is that they get \u003cstrong\u003e\u003cem\u003eSaturated\u003c/em\u003e\u003c/strong\u003e. The problem with this it that they use a sigmoid or tanh activation function, and there are large areas of each function where the derivative is very, very close to 0. When the derivatives are low, this means the weight updates are small, which means that the \"learning\" of the model slows to a crawl! This happens because after many, many weight updates, many weights will have been pushed into an extremely positive or extremely negative value. All you have to do is get past -5 or +5 to get to very small values.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_vanishing_gradient.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWhen gradients are close to 0 because the values are extremely low, this is called \u003cstrong\u003e\u003cem\u003eVanishing Gradient\u003c/em\u003e\u003c/strong\u003e. Similarly, networks can also get to the point where the gradients are much, much large, resulting in massive weight updates that cause the model to thrash between 1 extremely wrong answer and another. When this happens, it is called \u003cstrong\u003e\u003cem\u003eExploding Gradient\u003c/em\u003e\u003c/strong\u003e. In practice, you can easily solve exploding gradients by just \"clipping\" the weight updates by bounding them at a maximum value. However, there's no good solution for vanishing gradients!\u003c/p\u003e\n\u003cp\u003eAn intuitive way to think of this in terms of Information Theory -- the network is trying to encapsulate too much information from all of the time steps. Take a look at the following diagram, which you saw in the previous lesson. Pay attention to the colors that represent each word:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/unrolled.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eNotice how the further along the sequence goes, the less overall area the navy blue color (for the first word, \"What\") gets. As each new word in the sequence gets processed, the amount of \"room\" the RNN has to remember things gets saturated. It turns out, remembering too many things is a pretty surefire way to get your model to crash and burn. This makes it hard for dealing with long-term dependencies in the data. For instance, consider the following sentence:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"Marilyn studied in France during the summer and fall semesters of college in 2016. As a result, she speaks fluent {_}\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIf you were to use a traditional RNN to predict the next word in this sentence, it would likely have trouble figuring out the answer because of the number of time steps between the word to predict and the word that contains the information necessary to make a prediction, \"France\".\u003c/p\u003e\n\u003ch2\u003eRemembering and Forgetting\u003c/h2\u003e\n\u003cp\u003eThis is where the modern versions of RNNs come in. In practice, when building models for sequence data, people rarely use traditional RNN architectures anymore. Instead they make use of \u003cstrong\u003e\u003cem\u003eLSTMs\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eGRUs\u003c/em\u003e\u003c/strong\u003e. Both of these models can be thought of as special types of neurons that can be used in an RNN. Although they work a little differently, they have the same strength -- the ability to \u003cstrong\u003e\u003cem\u003eforget information\u003c/em\u003e\u003c/strong\u003e! By constantly updating their internal state, they can learn what is important to remember, and when it is okay to forget it.\u003c/p\u003e\n\u003cp\u003eConsider the word prediction example you just looked at. You clearly need to remember the word \"France\", but there are plenty of words in between France and the word you need to predict that aren't that important, and you can safely ignore, such as \"during the\", \"and\", \"of\", etc. Furthermore, let's assume that the model learns enough to answer this question, but the next thousand words in the sequence is about something completely different. Do you really still need to hold on to the information about where Marilyn studied? How can you tell when you need to remember something and when you need to forget something? This is where GRUs and LSTMs have different approaches. Let's take a quick look at how they both work.\u003c/p\u003e\n\u003ch2\u003eGated Recurrent Units (GRUs)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eGated Recurrent Units\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eGRUs\u003c/em\u003e\u003c/strong\u003e, are a special type of cell that passes along it's internal state at each time step. However, not every part of the internal state is passed along, but only the important stuff! GRUs make use of two \"gate\" functions: a \u003cstrong\u003e\u003cem\u003eReset Gate\u003c/em\u003e\u003c/strong\u003e, which determines what should be removed from the cell's internal state before passing itself along to the next time step, and an \u003cstrong\u003e\u003cem\u003eUpdate Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the state from the previous time step should be used in the current time step.\u003c/p\u003e\n\u003cp\u003eThe following technical diagram shows the internal operations of how a GRU cell works. Don't worry about trying to understand what every part of this diagram means. Internally, its just some equations for the update and reset operations, coupled with matrix multiplication and sigmoid functions. Instead, focus on the the \u003cimg src=\"https://render.githubusercontent.com/render/math?math=S_t\"\u003e line, which moves from left to right and denotes the state being updated and passed onto the next layer.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_gru.png\" width=\"400\"\u003e\u003c/p\u003e\n\u003ch2\u003eLong Short Term Memory Cells (LSTMs)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eLSTMs\u003c/em\u003e\u003c/strong\u003e, are another sort of specialized neurons for use in RNNs that are able to effectively learn what to remember and what to forget in sequence models.\u003c/p\u003e\n\u003cp\u003eLSTMs are generally like GRUs, except that they use three gates instead of two. LSTMs have:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ean \u003cstrong\u003e\u003cem\u003eInput Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the cell state that was passed along should be kept\u003c/li\u003e\n\u003cli\u003ea \u003cstrong\u003e\u003cem\u003eForget Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the current state should be forgotten\u003c/li\u003e\n\u003cli\u003ean \u003cstrong\u003e\u003cem\u003eOutput Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the current state should be exposed to the next layers in the network\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs you can see, they essentially accomplish the same thing as GRUs, but they do it in a slightly different way. Both models do a great job learning patterns from sequences, even when they are long and extremely complex! You'll find a diagram of a LSTM cell below. Just like with GRUs, don't worry about what the symbols mean or the math behind it. You can always pick that up later if you're curious. Instead, try to focus on how the information flows through this diagram from left to right, and where the various gates are for each function performed!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_LSTM3_chain.png\" width=\"800\"\u003e\u003c/p\u003e\n\u003cp\u003eThere's no good answer yet as to whether GRUs or LSTMs are superior to one another. In practice, GRUs tend to have a slight advantage in many use cases, but this is far from guaranteed. The best thing to do is to build a model with each and see which one does better.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about how LSTMs and GRUs can help the models avoid problems such as vanishing and exploding gradients when working with large sequences of data. You also learned about the structure of LSTMs and GRUs, and how they are able to \"forget\" information!\u003c/p\u003e","exportId":"lstms-and-grus"},{"id":458781,"title":"Deep NLP with Word Embeddings - Recap","type":"WikiPage","indent":0,"locked":false,"requirement":null,"completed":false,"content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eCongratulations! You know have a myriad of powerful NLP tools that you can begin to tap into and further explore. With that, take a minute to review some of the key concepts you were exposed to in this section. \u003c/p\u003e\n\n\u003ch2\u003eRNNs and Word Embeddings\u003c/h2\u003e\n\n\u003cp\u003eRemember that word embeddings are a type of vectorization strategy that computes word vectors from a text corpus. They use similarity metrics, which can reveal how certain words relate to each other, or \"semantic relationships\".\u003c/p\u003e\n\n\u003cp\u003eUnlike TF-IDF vectorization, the size of word embeddings is a tunable parameter, which can help overcoming the curse of dimensionality. Word embeddings can be created using Word2Vec models -- given enough training data. \u003c/p\u003e\n\n\u003cp\u003eSince deep learning is used to create Word2Vec models, training word embeddings can be really time consuming, and when building a predictive model you'd want to avoid spending a lot of time here. Pretrained word vectors are very useful here, and GLoVe is the most commonly used model. When using GLoVe, and moving towards a vector representation for any arbitrarily-sized block of text, mean word embeddings can be used.\u003c/p\u003e\n\n\u003ch2\u003eGRUs and LSTMs\u003c/h2\u003e\n\n\u003cp\u003eBuilding on this, you then took a look at some new architectures for neural nets. Aside from having a temporal aspect as with RNNs, GRUs (Gated Recurrent Units) and LSTMs (Long Short Term Memory Cells) have capabilities for both summarizing important information seen prior and forgetting needless details to free up memory. This acts as an analogy to human memory and allows for improved performance in many tasks. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section you learned about advanced deep network architectures including RNNs, GRUs, and LSTMs. You also saw how to create word embeddings, an alternative methodology for encoding textual data into numerical spaces. With that, you also saw how to use transfer learning to apply Word2Vec models and improve NLP classification algorithms.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-deep-nlp-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-deep-nlp-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","exportId":"deep-nlp-with-word-embeddings-recap"}]}],"pages":[{"exportId":"unsupervised-learning","title":"Unsupervised Learning","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll get a high-level overview of unsupervised learning, an entire class of algorithms in machine learning. To date, you've only seen examples of supervised learning tasks such as regression and classification. As the name implies, unsupervised learning is a bit different than these tasks. In supervised learning, you define an \u003ccode\u003eX\u003c/code\u003e and \u003ccode\u003ey\u003c/code\u003e, and the algorithm attempts to generalize this transformation in order to predict \u003ccode\u003ey\u003c/code\u003e given \u003ccode\u003eX\u003c/code\u003e. In unsupervised learning, you do not define an \u003ccode\u003eX\u003c/code\u003e or \u003ccode\u003ey\u003c/code\u003e. Instead, you feed in a given dataset and the unsupervised learning algorithm returns some new representation of the data based on the structure and patterns within the data itself.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine unsupervised learning \u003c/li\u003e\n\u003cli\u003eCompare and contrast supervised and unsupervised learning \u003c/li\u003e\n\u003cli\u003eIdentify real-world scenarios in which you would use unsupervised learning \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSupervised vs. Unsupervised Learning\u003c/h2\u003e\n\n\u003cp\u003eThe main difference between supervised and unsupervised learning are their goals. Supervised learning needs concrete, ground-truth labels to train models that answer very specific questions. Unsupervised learning differs in that the task it is trying to accomplish is much less well-defined - it can usually be summed up as \"are there any natural patterns in this data that are recognizable?\"  To illustrate this, assume that you have a basket of various different kinds of fruit. A supervised learning task would be building an apple classifier that tells us if a given fruit is or isn't an apple, based on the size, shape, color, texture, taste, and any other data that you've encoded for each piece of fruit. An unsupervised learning task on the same data would analyze only the features, and sort them into groups without being told what type of fruit each was. In general, supervised learning uses data to accomplish a clear task while unsupervised learning has no clear task, but is instead used to identify patterns.\u003c/p\u003e\n\n\u003ch2\u003eUnsupervised Learning Tasks\u003c/h2\u003e\n\n\u003cp\u003eThe two most common unsupervised learning tasks are clustering and dimensionality reduction. Clustering groups data into homogeneous groups, where members share common traits. Dimensionality reduction attempts to reduce the overall number of features of a dataset while preserving as much information as possible. With that, let's take a deeper look into some general notes on each.\u003c/p\u003e\n\n\u003ch3\u003eClustering\u003c/h3\u003e\n\n\u003cp\u003eThere are a few different kinds of clustering algorithms, but they all do the same thing - finding different ways to group a dataset based on patterns in the data.  One common use-case for clustering is market segmentation. In market segmentation, you would try to decompose an audience into subsets for more precise targeting for business purposes, such as advertising. Even though there's no way to verify that these groups are correct, in practice it usually does quite well, often providing useful subgroups which can then be individually examined.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-unsupervised-learning/master/images/kmeans.gif\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eSource: \u003ca href=\"https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/\"\u003eGIF by David Sheehan\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3\u003eDimensionality Reduction\u003c/h3\u003e\n\n\u003cp\u003eThe most common dimensionality reduction algorithm is Principal Component Analysis (PCA). Dimensionality reduction algorithms work by projecting data from its current n-dimensional subspace into a smaller subspace, while losing as little information as possible in the process. Dimensionality reduction algorithms still lose \u003cem\u003esome\u003c/em\u003e information, but you can quantify this information loss to make an informed decision about the number of dimensions reduced versus the overall information lost. Dimensionality reduction algorithms are a must-have in any data scientist's toolbox, because they provide a way for us to deal with the \u003cstrong\u003eCurse of Dimensionality\u003c/strong\u003e. The curse of dimensionality is a key concept as datasets scale. In short, as the number of features in a dataset increases, the processing power and search space required to optimize a given machine learning algorithm explodes exponentially. Because this often creates intractable computational problems, dimensionality reduction techniques such as PCA can be an essential preprocessing technique.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-unsupervised-learning/master/images/pca.gif\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eSource: \u003ca href=\"https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/140579#140579\"\u003eGIF by amoeba\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you explored the differences between supervised and unsupervised learning. You also learned about the types of problems we can solve with unsupervised learning, including clustering and dimensionality reduction. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-unsupervised-learning\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-unsupervised-learning\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-unsupervised-learning/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"short-video-the-bag-of-words-model","title":"Short Video: The Bag of Words Model","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713814376?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"amazon-web-services-introduction","title":"Amazon Web Services - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll be introduced to Amazon Web Services (AWS) - the most popular cloud service. \u003c/p\u003e\n\n\u003ch2\u003eMachine Learning and the Cloud\u003c/h2\u003e\n\n\u003cp\u003eWe'll begin this section by learning about all the ways that cloud computing services such as \u003cstrong\u003e\u003cem\u003eAmazon Web Services (AWS)\u003c/em\u003e\u003c/strong\u003e have made things better and easier for data scientists. We'll also explore why being able to productionize the machine learning models you create so that other people can use them is one of the most valuable skills you can have as a data scientist. \u003c/p\u003e\n\n\u003ch2\u003eAmazon Web Services (AWS)\u003c/h2\u003e\n\n\u003cp\u003eOne we understand the importance of cloud services and how they fit into the picture for data scientists, we'll jump right in to the most popular cloud service, AWS. We'll learn about what AWS ecosystem contains and how we can use it. We'll also create an account and learn our way around the AWS dashboard. \u003c/p\u003e\n\n\u003ch2\u003eAWS SageMaker\u003c/h2\u003e\n\n\u003cp\u003eOnce we know the basics of AWS, we'll learn how we can make use of the most important tool for Data Scientists, \u003cstrong\u003e\u003cem\u003eAWS SageMaker\u003c/em\u003e\u003c/strong\u003e! We'll see how we can incorporate AWS SageMaker into our workflow to simplify things like distributed training or model productionization! \u003c/p\u003e\n\n\u003ch2\u003eHands-On Practice Shipping Models\u003c/h2\u003e\n\n\u003cp\u003eFinally, we will train and ship real-world models using AWS SageMaker. We'll start by training and productionizing some classical machine learning models with scikit-learn and then set up endpoints with AWS SageMaker so that we can make them available for inference. Then, we'll move onto training a Deep Learning model with SageMaker, so that we can make use of distributed training to speed things up, and then ship the model to production. Finally, we'll use SageMaker to train and productionize a more advanced Convolutional Neural Network for image classification. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eBy the end of this section, you'll know the basics of how to use AWS for Data Science projects, and you'll have hands-on experience training and productionizing three different machine learning models. This will set you up for success with your capstone project!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-productionizing-machine-learning-models-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-productionizing-machine-learning-models-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"recommendation-systems-recap","title":"Recommendation Systems - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommendation-section-recap\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecommendation approaches can consist of simply recommending popular items (without personalization), or using algorithms which takes into account past customer behavior\u003c/li\u003e\n\u003cli\u003eWhen using algorithms, the two main types are content-based algorithms (recommending new content based on similar \u003cem\u003econtent\u003c/em\u003e), or collaborative filtering based (recommending new content based on similar types of \u003cem\u003eusers\u003c/em\u003e)\u003c/li\u003e\n\u003cli\u003eCollaborative Filtering (CF) is currently the most widely used approach to build recommendation systems\u003c/li\u003e\n\u003cli\u003eThe key idea behind CF is that similar users have similar interests and that a user generally likes items that are similar to other items they like\u003c/li\u003e\n\u003cli\u003eCF is filling an \"empty cell\" in the utility matrix based on the similarity between users or item. Matrix factorization or decomposition can help us solve this problem by determining what the overall \"topics\" are when a matrix is factored\u003c/li\u003e\n\u003cli\u003eMatrix decomposition can be reformulated as an optimization problem with loss functions and constraints\u003c/li\u003e\n\u003cli\u003eMatrix decomposition can be done using either Singular Value Decomposition (SVD) or Alternating Least Squares (ALS)\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003esurprise\u003c/code\u003e library allows you to build models for CF\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"deploying-a-model-with-dash","title":"Deploying a Model with Dash","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-dash-deployment\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-deployment\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-deployment/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn addition to allowing you to create complex dynamic web pages using Python code, Dash is \"the most downloaded, trusted framework for building machine learning web apps in Python\" (\u003ca href=\"https://plotly.com/building-machine-learning-web-apps-in-python/\"\u003esource\u003c/a\u003e). Let's build one of those machine learning web apps!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCombine Flask and Dash apps to serve API responses as well as dynamic web pages\u003c/li\u003e\n\u003cli\u003eIncorporate machine learning predictions into a Dash app\u003c/li\u003e\n\u003cli\u003eDeploy a machine learning dashboard using Dash and Heroku\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eClone this lesson locally so you can follow along using your local \u003ccode\u003edash-env\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eCombining Flask and Dash\u003c/h2\u003e\n\n\u003cp\u003eWe previously mentioned that Dash is built on top of Flask. Specifically, when the Dash app is instantiated, an underlying Flask app is created by default.\u003c/p\u003e\n\n\u003cp\u003eIf we want to customize the behavior of the underlying Flask app, we can actually instantiate it separately, then pass it in as an argument when we instantiate the Dash app.\u003c/p\u003e\n\n\u003cp\u003eBelow is a simple \"Hello, World!\" example where the Flask and Dash apps have been combined in this way:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a new flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# create a new dash app built on that flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSo far, this works identically to our \"Hello, World!\" Dash app without Flask.\u003c/p\u003e\n\n\u003cp\u003eHowever, now we can also add a \u003cem\u003eroute\u003c/em\u003e to the Flask app that returns JSON:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a new flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# create a new dash app built on that flask app\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# add a route to the flask app that returns json\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"/get_json\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"GET\"\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ehello_json\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e({\u003c/span\u003e\n        \u003cspan class=\"s\"\u003e\"hello\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"world!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s\"\u003e\"key\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value!\"\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e})\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe web page view looks exactly the same, but we can also run a query directly to the backend and get a JSON result!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erequests\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/get_json\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow that we have those basic elements, let's combine our Iris Dataset Flask API and Dash dashboard from the previous lessons.\u003c/p\u003e\n\n\u003ch2\u003eCreating a Machine Learning Dash App\u003c/h2\u003e\n\n\u003ch3\u003eRecall: Previous Flask and Dash Apps\u003c/h3\u003e\n\n\u003cp\u003eOur previous Flask app looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is a basic web server that returns the text \"Hello, world!\" when it receives a \u003ccode\u003eGET\u003c/code\u003e request to view the home page (\u003ccode\u003e/\u003c/code\u003e route), and returns an iris classification prediction when it receives a \u003ccode\u003ePOST\u003c/code\u003e request to the \u003ccode\u003e/predict\u003c/code\u003e route.\u003c/p\u003e\n\n\u003cp\u003eOur previous Dash app looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is an interactive web page that displays a table of data, where the user can click on a record and a modal will pop up with additional information.\u003c/p\u003e\n\n\u003ch3\u003eA Basic Combination\u003c/h3\u003e\n\n\u003cp\u003eIf we just want to combine the functionality of the two applications, we just need to declare the two apps appropriately, and change the names from \u003ccode\u003eapp\u003c/code\u003e to either \u003ccode\u003eflask_app\u003c/code\u003e or \u003ccode\u003edash_app\u003c/code\u003e. We'll go ahead and remove the \u003ccode\u003e/\u003c/code\u003e route from the Flask app because the Dash app is using the home page to display our interactive table.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAs you can see, the Dash app works like it did before:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd so does the Flask app!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eIncorporating Predictions into Our Dash App\u003c/h3\u003e\n\n\u003cp\u003eRight now our modal is interactive, but it only displays static data from the table. Let's zoom in on that code with some example data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"sepal length (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.8\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"sepal width (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"petal length (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"s\"\u003e\"petal width (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])))\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWhat if instead of just displaying the \u003ccode\u003eclass\u003c/code\u003e from the table, we showed both the actual class and the predicted class?\u003c/p\u003e\n\n\u003cp\u003eRemember, we already have a helper function from our Flask app called \u003ccode\u003eiris_prediction\u003c/code\u003e. Let's make an additional helper function that takes in the dictionary of data, passes the relevant arguments to \u003ccode\u003eiris_prediction\u003c/code\u003e, then displays information about whether the prediction was correct.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# make a copy so we don't mess up the original data record\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove and store the actual class\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels and replace spaces with underscores\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# get the result dictionary from iris_prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# extract the predicted class from the result dictionary\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# determine whether the prediction was correct\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# adding a horizontal rule divider here\n\u003c/span\u003e        \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# adding the prediction check here\n\u003c/span\u003e        \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexample_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])))\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal_body\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCombining that all together with our data table, our complete app now looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Return an Alert component with information about the model's prediction\n    vs. the true class value\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(We changed the random seed used to generate the sample so that it includes some places where the model makes a mistake. Try clicking through to find them!)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNice! Now we have a dashboard that dynamically generates machine learning predictions whenever the user clicks on a record!\u003c/p\u003e\n\n\u003ch3\u003ePredictions on Unseen Data\u003c/h3\u003e\n\n\u003cp\u003eSo far we have an interesting view into our model's performance on the training data, but typically the value of a deployed model is to make predictions on new, unseen data.\u003c/p\u003e\n\n\u003cp\u003eLet's make an interface that allows the user to enter values into a form, then makes predictions using those user-supplied values.\u003c/p\u003e\n\n\u003cp\u003eIn order to figure out what kind of inputs our form should have, let's look at our \u003ccode\u003eX\u003c/code\u003e training data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edescribe\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat, so it looks like these can all be numeric inputs. One way we might implement numeric inputs would be using a text box, but let's use a Dash \u003ca href=\"https://dash.plotly.com/dash-core-components/slider\"\u003eSlider\u003c/a\u003e component instead. Sliders feel a bit more interactive, and they also let you set upper and lower bounds on what inputs the user can specify.\u003c/p\u003e\n\n\u003cp\u003eA basic slider looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# minimum value\n\u003c/span\u003e    \u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# maximum value\n\u003c/span\u003e    \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mf\"\u003e3.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# default value before the user changes anything\n\u003c/span\u003e    \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"c1\"\u003e# always display selected value\n\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eLet's make a set of four sliders, with ranges based on the four features:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# loop over all of the columns in X\n\u003c/span\u003e    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# make a label with the column name\n\u003c/span\u003e        \u003cspan class=\"n\"\u003elabel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH5\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# get the minimum, maximum, and median values for the column\n\u003c/span\u003e        \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003evalue\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003emedian\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# make a slider with the right values\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eslider\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set median as default\n\u003c/span\u003e            \u003cspan class=\"n\"\u003emarks\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n            \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set id based on column name\n\u003c/span\u003e        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# make a list item with the label and the slider\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eslider\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Prediction will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"info\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow let's add a callback so that the slider values are fed into the prediction function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# list comprehension to specify all of the input columns\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003egenerate_user_input_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"s\"\u003e'predicted_class'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry out the slider values to see if you can get the predicted class to change!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAwesome, now we are making predictions on unseen data!\u003c/p\u003e\n\n\u003cp\u003eTo combine the two interfaces, let's make a set of Tab components (\u003ca href=\"https://dash-bootstrap-components.opensource.faculty.ai/docs/components/tabs/\"\u003edocumentation here\u003c/a\u003e) so the user can switch between the table view and the form view.\u003c/p\u003e\n\n\u003cp\u003eHere is a minimal version of our Tabs:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etabs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTabs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Form will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"secondary\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Generate Predictions on New Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Table will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"secondary\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Analyze Performance on Past Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH1\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Classification Model\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003etabs\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry clicking on the tab names to switch between them:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow let's add the actual content to those tabs. Below is the full, final version of our Dash + Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APPS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eserver\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003elabel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH5\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n        \u003cspan class=\"n\"\u003evalue\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003emedian\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003eslider\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSlider\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elower_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eupper_bound\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003evalue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set median as default\n\u003c/span\u003e            \u003cspan class=\"n\"\u003emarks\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etooltip\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"always_visible\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n            \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"c1\"\u003e# set id based on column name\n\u003c/span\u003e        \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eslider\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eslider_items\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# model.predict takes a list of records and returns a list of predictions\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# but we are only making a single prediction\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Return an Alert component with information about the model's prediction\n    vs. the true class value\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epop\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# remove \" (cm)\" from labels\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" (cm)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ereplace\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edata_copy\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()}\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003edata_cleaned\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eactual_class\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ecorrect_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"success\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"danger\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003epredicted_class\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eprediction_layout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecreate_sliders\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eAlert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Prediction will go here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"info\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n## Iris Training Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003epast_data_layout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etabs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTabs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eprediction_layout\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Generate Predictions on New Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTab\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epast_data_layout\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elabel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Analyze Performance on Past Data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eContainer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eH1\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Classification Model\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003etabs\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"prediction-output\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# list comprehension to specify all of the input columns\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"value\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003egenerate_user_input_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Predicted class: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"s\"\u003e'predicted_class'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e      \n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHr\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"n\"\u003echeck_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## ROUTES ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eflask_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003edash_app\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e550\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that the API backend also still works!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://localhost:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eDeploying to Heroku\u003c/h2\u003e\n\n\u003cp\u003eDeploying our Dash app to Heroku is very similar to deploying our Flask app to Heroku. We'll need to:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eInstall a \u003cstrong\u003eproduction server\u003c/strong\u003e and make sure we can successfully run our app locally via the command line\u003c/li\u003e\n\u003cli\u003eCreate our \u003cstrong\u003erequirements files\u003c/strong\u003e and push them to GitHub\u003c/li\u003e\n\u003cli\u003eCreate a new app through the \u003cstrong\u003eHeroku web interface\u003c/strong\u003e and connect it to our GitHub repo\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eLet's get started!\u003c/p\u003e\n\n\u003ch3\u003eInstalling and Running a Production Server\u003c/h3\u003e\n\n\u003ch4\u003eInstalling Waitress\u003c/h4\u003e\n\n\u003cp\u003eOnce again, we'll use a production-quality server called \u003ca href=\"https://docs.pylonsproject.org/projects/waitress/en/latest/\"\u003eWaitress\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eIn the terminal, make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated, then run:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ewaitress\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eOrganizing the Code into a \u003ccode\u003e.py\u003c/code\u003e File\u003c/h4\u003e\n\n\u003cp\u003eWaitress needs the code to be located in a \u003ccode\u003e.py\u003c/code\u003e file rather than directly within a Jupyter Notebook. We have already copied the above code into a file called \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eNote that there is one small difference between the code above and the code in \u003ccode\u003eapp.py\u003c/code\u003e: instead of importing \u003ccode\u003eDash\u003c/code\u003e from the \u003ccode\u003ejupyter_dash\u003c/code\u003e library, we imported it directly from the \u003ccode\u003edash\u003c/code\u003e library. In other words, instead of\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003eapp.py\u003c/code\u003e has\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is because when we're deploying the application, we don't want the version of Dash designed to run in a notebook, we want the standalone version. But otherwise the code is identical to the \"final version\" code shown in this notebook.\u003c/p\u003e\n\n\u003ch4\u003eRunning the Production Server\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewaitress-serve \u003cspan class=\"nt\"\u003e--port\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e5000 app:flask_app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that this is very similar to our command when we were deploying our Flask app, which was \u003ccode\u003ewaitress-serve --port=5000 app:app\u003c/code\u003e. The difference is that the Flask app inside of \u003ccode\u003eapp.py\u003c/code\u003e had a variable name of \u003ccode\u003eapp\u003c/code\u003e, whereas now it has the name \u003ccode\u003eflask_app\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eYou should see an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eINFO:waitress:Serving on http://0.0.0.0:5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand you should be able to open up that link in your browser!\u003c/p\u003e\n\n\u003cp\u003eOnce you have confirmed that this works, go ahead and shut down the server using control-C.\u003c/p\u003e\n\n\u003ch3\u003eRequirements Files\u003c/h3\u003e\n\n\u003cp\u003eAgain, this is very similar to when we deployed the Flask app. We just have a longer list of requirements, and our \u003ccode\u003eProcfile\u003c/code\u003e specifies that the app variable name is \u003ccode\u003eflask_app\u003c/code\u003e rather than app. These files have already been included in this repository.\u003c/p\u003e\n\n\u003ch4\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eThis is the same as when we deployed our Flask app. Remember that if you get an error related to the runtime, that means that the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes list\u003c/a\u003e has changed. Check that link to find the most up-to-date Python 3.8 runtime and edit \u003ccode\u003eruntime.txt\u003c/code\u003e accordingly.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003epython-3.8.13\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eOur previous \u003ccode\u003erequirements.txt\u003c/code\u003e looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOur new \u003ccode\u003erequirements.txt\u003c/code\u003e has those same items, with additional ones added:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\ndash==2.3\ndash-bootstrap-components==1.0\npandas==1.4\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo explain further:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edash\u003c/code\u003e and \u003ccode\u003edash-bootstrap-components\u003c/code\u003e have been added so that we can create layouts and callbacks with Dash\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epandas\u003c/code\u003e has been added so that we can manipulate the dataset in preparation for displaying it in a table. If you just want your app to make predictions on unseen data, you won't need \u003ccode\u003epandas\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis is also slightly different from the \u003ccode\u003edash-env\u003c/code\u003e requirements we installed earlier, because the deployed version of our app does not need \u003ccode\u003enotebook\u003c/code\u003e or \u003ccode\u003ejupyter-dash\u003c/code\u003e (or be tethered to a specific version of \u003ccode\u003eWerkzeug\u003c/code\u003e, which was needed at the time of this writing to make \u003ccode\u003ejupyter-dash\u003c/code\u003e work correctly).\u003c/p\u003e\n\n\u003ch4\u003e\u003ccode\u003eProcfile\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eOur \u003ccode\u003eProcfile\u003c/code\u003e is also slightly different because our app variable name is different.\u003c/p\u003e\n\n\u003cp\u003eOur previous \u003ccode\u003eProcfile\u003c/code\u003e looked like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd our new one looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:flask_app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eDeploying the App on Heroku\u003c/h3\u003e\n\n\u003cp\u003eThis is the same set of steps as before, but we'll include them here for convenience:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eMake sure you are \u003cstrong\u003elogged in\u003c/strong\u003e to Heroku. You can go to \u003ca href=\"https://dashboard.heroku.com/\"\u003ehttps://dashboard.heroku.com/\u003c/a\u003e and it will either show you your list of apps or redirect you to the login page.\n\n\u003cul\u003e\n\u003cli\u003eYou should already have an account if you followed the steps from the Flask deployment lesson, but you can also create an account now.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eGo to \u003ca href=\"https://dashboard.heroku.com/new-app\"\u003ehttps://dashboard.heroku.com/new-app\u003c/a\u003e to make a new app on Heroku.\u003c/li\u003e\n\u003cli\u003eEither fill in a name for your app then click \u003cstrong\u003eCreate app\u003c/strong\u003e, or just click \u003cstrong\u003eCreate app\u003c/strong\u003e if you want a name to be generated for you.\u003c/li\u003e\n\u003cli\u003eScroll down to \u003cstrong\u003eDeployment method\u003c/strong\u003e and choose \u003cstrong\u003eGitHub\u003c/strong\u003e.\n\n\u003cul\u003e\n\u003cli\u003eYou should already be signed in with GitHub if you followed the steps from the Flask deployment lesson, but you can also approve the connection in the pop-up window now if you haven't previously.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSearch\u003c/strong\u003e for the repository you want, then click \u003cstrong\u003eConnect\u003c/strong\u003e on the repository in the list of search results.\u003c/li\u003e\n\u003cli\u003eScroll down to \u003cstrong\u003eManual deploy\u003c/strong\u003e, choose the appropriate branch, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eWait for the app to build, then once you see the message \"Your app was successfully deployed\" click the \u003cstrong\u003eView\u003c/strong\u003e button to open up your Dash app!\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eThe interface should be much more interesting than the \"Hello, world!\" from your Flask app. You should also be able to make API requests (replace \u003ccode\u003ebase_url\u003c/code\u003e with your actual Heroku app URL).\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# base URL (ending with .herokuapp.com, no trailing /)\n\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eLevel Up\u003c/h2\u003e\n\n\u003cp\u003eDash is created by Plotly, which also makes a well-known \u003ca href=\"https://plotly.com/python/\"\u003ePython graphing library\u003c/a\u003e that creates interactive graphs using Python. Check out the examples \u003ca href=\"https://dash.plotly.com/dash-core-components/graph\"\u003ehere\u003c/a\u003e and try adding a visualization to your dashboard!\u003c/p\u003e\n\n\u003cp\u003eIn addition to being used as layout elements, Plotly graphs can be attached to callbacks in a Dash page. So, for example, the graph axis scale could change using a slider input, or a user could click on a point on a graph and send that to their model to make a prediction. Try it out for yourself!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eYou have now learned how to combine Flask with Dash to build and deploy powerful dynamic web applications using machine learning. We can't wait to see what you'll make next!\u003c/p\u003e","frontPage":false},{"exportId":"the-curse-of-dimensionality","title":"The Curse of Dimensionality","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is an interesting paradox for data scientists. On the one hand, one often hopes to garner more information to improve the accuracy of a machine learning algorithm. However, there are also some interesting phenomena that come along with larger datasets. In particular, the curse of dimensionality is based on the exploding volume of n-dimensional spaces as the number of dimensions, n, increases.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what is meant by the curse of dimensionality and its implications when training machine learning algorithms \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSparseness in N-Dimensional Space\u003c/h2\u003e\n\n\u003cp\u003ePoints in n-dimensional space become increasingly sparse as the number of dimensions increases. That is, the distance between points will continue to grow as the number of dimensions grows. This can be problematic in a number of machine learning algorithms, in particular, when clustering points into groups. Due to the exploding nature of n-dimensional space, there is also an unwieldy number of possible combinations when searching for optimal parameters for a machine learning algorithm. \u003c/p\u003e\n\n\u003cp\u003eTo demonstrate this, you'll generate this graph in the upcoming lab:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-curse-of-dimensionality/master/images/sparsity.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis image demonstrates how the average distance between points and the origin continues to grow as the number of dimensions increases, even though each dimension has a fixed range. Simply increasing the number of dimensions continues to make individual points more and more sparse.\u003c/p\u003e\n\n\u003ch2\u003eImplications\u003c/h2\u003e\n\n\u003cp\u003eThe main implication of the curse dimensionality is that optimization problems can become infeasible as the number of features increases. The practical limit will vary based on your particular computer and the time that you have to invest in a problem. As you'll see in the upcoming lab, this relationship is exponential. For machine learning algorithms that involve backpropagation, or iterative convergence, including Lasso and Ridge regression, this will drastically impact the size of feasible solvable problems.\u003c/p\u003e\n\n\u003cp\u003eThe sparsity of points also has additional consequences. Due to the sheer scale of potential points in an n-dimensional space, as n continues to grow, the probability of seeing a particular point (or even nearby point) continues to plummet. Therefore, it is likely that there are entire regions of an n-dimensional space that have yet to be explored. As such, if no such information from the training set is available regarding such cases, then making predictions regarding these cases will be guesswork. Put another way, with the increasing sparsity of points, you have an ever decreasing proportionate sample of the space. For example, a thousand observations in a 3-dimensional space might be quite powerful and provide sufficient information to determine a relevant classification or regression model. However, a thousand observations in a million-dimensional space is likely to be utterly useless in determining which features are most influential and to what degree. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality presents an intriguing paradox. On the one hand, more features allow one to account for variance and nuances required to accurately model a given machine learning model. On the other hand, as the number of dimensions increases, the accompanying volume of the hyperspace explodes exponentially. As such, the potential amount of information required to accurately model such a space becomes increasingly complex. (This is not always the case; a simple line can still exist in a 10-dimensional space, but the problems one is likely to be tackling when employing 10 features are most likely more complex than a 2-dimensional model.) With this, more and more observations will be required to produce an adequate model.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-curse-of-dimensionality\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-curse-of-dimensionality\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"short-video-calculating-a-silhouette-coefficient","title":"Short Video: Calculating a Silhouette Coefficient","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813625?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"deploying-a-model-with-flask","title":"Deploying a Model with Flask","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-flask-deployment\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-deployment\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-deployment/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have learned the basics of the Flask web framework, you will combine that knowledge with your prior knowledge of cloud functions to deploy a machine learning model as an HTTP API with Flask!\u003c/p\u003e\n\n\u003cp\u003eClone this repository and work locally so that you can run and test your Flask app. Start by running \u003ccode\u003ejupyter notebook\u003c/code\u003e so that you can run the code examples in this notebook.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecall the model pickling and unpickling process from the cloud function approach\u003c/li\u003e\n\u003cli\u003eIncorporate a model prediction function into a Flask web app\u003c/li\u003e\n\u003cli\u003eDeploy a machine learning model as an HTTP API using Flask and Heroku\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRecall: Cloud Functions\u003c/h2\u003e\n\n\u003cp\u003eIn a previous lesson, you were introduced to cloud functions. With a cloud function, you need:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eA pickled model file\u003c/li\u003e\n\u003cli\u003eA Python file defining the function\u003c/li\u003e\n\u003cli\u003eA requirements file\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eWe will reuse the model file and Python code from the previous cloud functions lesson, so you may want to go back and review that lesson if you're confused about any of the details.\u003c/p\u003e\n\n\u003cp\u003eThe model file has already been included in this repository as \u003ccode\u003emodel.pkl\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e \u003cspan class=\"n\"\u003els\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe'll also be reusing this code from the cloud function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFinally, we'll also build our environment starting with the \u003ccode\u003erequirements.txt\u003c/code\u003e from that lesson:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003escikit-learn==0.23.2\njoblib==0.17.0\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eCloud Functions without Flask\u003c/h3\u003e\n\n\u003cp\u003ePreviously, we deployed this cloud function using this \u003ccode\u003epredict\u003c/code\u003e function:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    `request` is an HTTP request object that will automatically be passed\n    in by Google Cloud Functions\n\n    You can find all of its properties and methods here:\n    https://flask.palletsprojects.com/en/1.0.x/api/#flask.Request\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen bundling the model file, Python file, and requirements file into a single archive and uploading that to Google Cloud Functions.\u003c/p\u003e\n\n\u003cp\u003eThat required a fair amount of configuration within Google Cloud Functions to specify the function to be invoked (\u003ccode\u003epredict\u003c/code\u003e), the permissions (public on the web), and the storage location for the archive.\u003c/p\u003e\n\n\u003ch2\u003eCloud Functions with Flask\u003c/h2\u003e\n\n\u003cp\u003eWhen using Flask directly (rather than via the Google Cloud Functions implementation) and deploying on Heroku, we will need to import and declare a few more things within the code itself, but at the same time we won't need to configure as much within the website interface. We'll also be able to test our code locally!\u003c/p\u003e\n\n\u003ch3\u003eRecall: Flask App Basics\u003c/h3\u003e\n\n\u003cp\u003eHere was the source code of our previous simple Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import flask here\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# define routes for your new flask app\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe imported the Flask library, created a Flask app, and defined a single route \u003ccode\u003e/\u003c/code\u003e, which just returns the text \u003ccode\u003e'Hello, world!'\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eNow let's add in those functions from our cloud function.\u003c/p\u003e\n\n\u003ch3\u003eAdding ML Prediction Functionality to Our Flask App\u003c/h3\u003e\n\n\u003ch4\u003eImports\u003c/h4\u003e\n\n\u003cp\u003eInstead of just importing Flask, we'll also need to add in the \u003ccode\u003ejoblib\u003c/code\u003e and \u003ccode\u003ejson\u003c/code\u003e imports from the cloud function. We also need to import \u003ccode\u003erequest\u003c/code\u003e from Flask so that we can parse the request data.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Flask is the overall web framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# joblib is used to unpickle the model\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# json is used to prepare the result\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eFlask App Setup\u003c/h4\u003e\n\n\u003cp\u003eThis is the same as in our simple Flask app:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eAdding Cloud Function\u003c/h4\u003e\n\n\u003cp\u003eThen we include our \u003ccode\u003eiris_prediction\u003c/code\u003e function from previously. In a more complex Flask app, this would likely be stored in a separate \u003ccode\u003e.py\u003c/code\u003e file, but we're keeping it all in one place for the sake of simplicity.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eDefining Routes\u003c/h4\u003e\n\n\u003cp\u003eFor now, let's keep the \u003ccode\u003e/\u003c/code\u003e route as-is, then also add the \u003ccode\u003e/predict\u003c/code\u003e route.\u003c/p\u003e\n\n\u003cp\u003eSome notes on this change:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e/predict\u003c/code\u003e accepts HTTP \u003ccode\u003ePOST\u003c/code\u003e requests, which is conventional for a form submission. Therefore we specify \u003ccode\u003emethods=['POST']\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eInstead of having \u003ccode\u003erequest\u003c/code\u003e be a function parameter like it was in our cloud function, instead it's something we imported earlier. However it works the same way as the function parameter.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003ePulling It All Together\u003c/h4\u003e\n\n\u003cp\u003eWhen we bring together the imports, app setup, cloud function, and routes, the entire contents of \u003ccode\u003eapp.py\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Flask is the overall web framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# joblib is used to unpickle the model\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# json is used to prepare the result\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejson\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# helper function here\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Given sepal length, sepal width, petal length, and petal width,\n    predict the class of iris\n    \"\"\"\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Load the model from the file\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"rb\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Construct the 2D matrix of values that .predict is expecting\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"n\"\u003esepal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esepal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_length\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epetal_width\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Get a list of predictions and select only 1st\n\u003c/span\u003e    \u003cspan class=\"n\"\u003epredictions\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epredictions\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"predicted_class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eprediction\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# defining routes here\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/predict'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'POST'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# Get the request data from the user in JSON format\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_json\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# We are expecting the request to look like this:\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# {\"sepal_length\": \u0026lt;x1\u0026gt;, \"sepal_width\": \u0026lt;x2\u0026gt;, \"petal_length\": \u0026lt;x3\u0026gt;, \"petal_width\": \u0026lt;x4\u0026gt;}\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# Send it to our prediction function using ** to unpack the arguments\n\u003c/span\u003e    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_prediction\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e**\u003c/span\u003e\u003cspan class=\"n\"\u003erequest_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e# Return the result as a string with JSON format\n\u003c/span\u003e    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edumps\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eRunning the Flask App Locally\u003c/h2\u003e\n\n\u003cp\u003eYou should already have a local environment called \u003ccode\u003eflask-env\u003c/code\u003e from the \u003cstrong\u003eIntroduction to Flask\u003c/strong\u003e lesson. If you do not, go back to that lesson and follow the steps under \u003ccode\u003eSetting up a Flask Environment\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch3\u003ePreparing the Environment\u003c/h3\u003e\n\n\u003cp\u003eRun this code in a new terminal window (separate from where you are running \u003ccode\u003ejupyter notebook\u003c/code\u003e) to activate \u003ccode\u003eflask-env\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate flask-env\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis environment has everything you need to run a basic Flask app, but it doesn't have the cloud function dependencies yet.\u003c/p\u003e\n\n\u003cp\u003eRun these commands in the terminal to install those dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.17.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003escikit-learn\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.23.2\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we should be ready to run our app!\u003c/p\u003e\n\n\u003ch3\u003eRunning the Flask Application\u003c/h3\u003e\n\n\u003cp\u003eAs previously, run this command in the terminal from the root of this repository:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eexport \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_ENV\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003edevelopment\n\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you open \u003ca href=\"http://127.0.0.1:5000/\"\u003ehttp://127.0.0.1:5000/\u003c/a\u003e in the browser, you should see this, just like before:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eLeave the server running\u003c/strong\u003e and let's use the \u003ccode\u003erequests\u003c/code\u003e library to send a request to our app!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003erequests\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://127.0.0.1:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e\u0026lt;Response [200]\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe expected output of the above code cell is \u003ccode\u003e\u0026lt;Response [200]\u0026gt;\u003c/code\u003e. If you get a different response code, make sure that the code above matches the Flask app output where it says \"Running on\". For example, if you're running on port 5001 instead of 5000, make sure the \u003ccode\u003eurl\u003c/code\u003e specified above matches.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'predicted_class': 0}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat! You have now made an API request to a locally-running Flask app!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eGo ahead and shut down the current Flask app by typing control-C in the terminal.\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch2\u003eDeploying to Heroku\u003c/h2\u003e\n\n\u003cp\u003eThe real goal of deploying an app is not just to get a web server running on your local computer, it's to get it hosted live on the web!\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.heroku.com/\"\u003eHeroku\u003c/a\u003e is a platform-as-a-service company that is great for hosting this kind of application. We'll plan to use that, because it has a completely-free tier and allows you to host a Flask app with minimal setup steps.\u003c/p\u003e\n\n\u003ch3\u003ePreparing the Repository for Heroku\u003c/h3\u003e\n\n\u003ch4\u003eRunning a Production Server\u003c/h4\u003e\n\n\u003cp\u003ePreviously when we ran our Flask app, it was always in development mode. This is useful for playing around and editing code, but is unnecessarily slow for a published app.\u003c/p\u003e\n\n\u003cp\u003eLet's use a production-quality web server called \u003ca href=\"https://docs.pylonsproject.org/projects/waitress/en/latest/\"\u003eWaitress\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eFirst, install it in the \u003ccode\u003eflask-env\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ewaitress\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow instead of the \u003ccode\u003eflask run\u003c/code\u003e command, use this command to run the production server:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewaitress-serve \u003cspan class=\"nt\"\u003e--port\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e5000 app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(You may need to allow Python to access the network, if your operating system gives you a pop-up.)\u003c/p\u003e\n\n\u003cp\u003eThis should produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eINFO:waitress:Serving on http://0.0.0.0:5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eJust like before, you should be able to copy the specified URL, paste it into the browser, and see your \"Hello, World!\" page.\u003c/p\u003e\n\n\u003cp\u003eThe code below should also work:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://0.0.0.0:5000/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'predicted_class': 0}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat's it! \u003cstrong\u003eGo ahead and shut down the server again using control-C.\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch4\u003eRequirements Files\u003c/h4\u003e\n\n\u003cp\u003eWhen we made a cloud function for Google Cloud Functions, we used a \u003ccode\u003erequirements.txt\u003c/code\u003e file. For Heroku, we'll need three files like this:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e: tells Heroku that we are running a Python application, and what version of Python\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e: lists the required Python packages (same as we did for the Google Cloud Function, adding Flask as a requirement)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eProcfile\u003c/code\u003e: tells Heroku what command to run\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eAll of these files are already located in this repository, but we'll explain how they work below so that you know how to make your own!\u003c/p\u003e\n\n\u003cp\u003eOur \u003ccode\u003eruntime.txt\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003epython-3.8.13\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is because we are running Python 3.8 in this conda environment. If you get an error about the \"runtime\" when trying to deploy with Heroku, it's possible that this version of Python is no longer supported. Look at the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes\u003c/a\u003e list to find other options.\u003c/p\u003e\n\n\u003cp\u003eOur \u003ccode\u003erequirements.txt\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eFlask==2.0.3\njoblib==0.17.0\nscikit-learn==0.23.2\nwaitress==2.1.1\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThose are all the packages we installed with pip!\u003c/p\u003e\n\n\u003cp\u003eFinally, our \u003ccode\u003eProcfile\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eweb: waitress-serve --port=$PORT app:app\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis is similar to what we ran in the terminal locally, except we added a \u003ccode\u003eweb:\u003c/code\u003e to the beginning to indicate that this is a web process, and we parameterized \u003ccode\u003e$PORT\u003c/code\u003e so that it will use whatever port Heroku is configured to use, rather than hard-coding it to 5000.\u003c/p\u003e\n\n\u003ch3\u003eSetting Up the App on Heroku\u003c/h3\u003e\n\n\u003cp\u003eGo to \u003ca href=\"https://signup.heroku.com/login\"\u003ehttps://signup.heroku.com/login\u003c/a\u003e and create an account (or log in if you already have one).\u003c/p\u003e\n\n\u003cp\u003eThen go to \u003ca href=\"https://dashboard.heroku.com/new-app\"\u003ehttps://dashboard.heroku.com/new-app\u003c/a\u003e to make a new app on Heroku.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe name can be anything you want, but must be unique. You can fill in a name if you have one in mind, or you can just click \u003cstrong\u003eCreate app\u003c/strong\u003e and you'll get a randomly-suggested name.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003eDeployment method\u003c/strong\u003e and choose \u003cstrong\u003eGitHub\u003c/strong\u003e. This will open another menu section, where you should click the \u003cstrong\u003eConnect to GitHub\u003c/strong\u003e button. You will get a pop-up window where you will be asked to sign in with GitHub.\u003c/p\u003e\n\n\u003cp\u003eOnce connected, a text box should appear where you can search for the repository you want to use. (If you're just practicing with this lesson repo, make sure you have forked this repo to your GitHub account, then search for the lesson repo name.) Click \u003cstrong\u003eSearch\u003c/strong\u003e, then click \u003cstrong\u003eConnect\u003c/strong\u003e on the appropriate repository.\u003c/p\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003eManual deploy\u003c/strong\u003e, choose the appropriate branch, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eIf everything goes smoothly, you should see a build log, then the message \u003cstrong\u003eYour app was successfully deployed.\u003c/strong\u003e Then if you click the \u003cstrong\u003eView\u003c/strong\u003e button, that should open the \"Hello, World!\" page in a new browser tab.\u003c/p\u003e\n\n\u003cp\u003eIn the cell below, replace the value of \u003ccode\u003ebase_url\u003c/code\u003e with your actual Heroku app URL.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# base URL (ending with .herokuapp.com, no trailing /)\n\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erequests\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epost\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eurl\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e/predict\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s\"\u003e\"sepal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e5.1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"sepal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e3.5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_length\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.4\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"petal_width\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eTroubleshooting Workflow on Heroku\u003c/h3\u003e\n\n\u003cp\u003eEspecially because the \u003ca href=\"https://devcenter.heroku.com/articles/python-support#supported-runtimes\"\u003esupported runtimes\u003c/a\u003e list changes very frequently, it's likely that your deployment won't succeed on the first try. That's ok!\u003c/p\u003e\n\n\u003ch4\u003eIdentifying the Problem\u003c/h4\u003e\n\n\u003cp\u003e\u003cstrong\u003eFirst make sure that the code works on your local computer.\u003c/strong\u003e It is MUCH easier to debug when working locally vs. working on a cloud service like Heroku!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eThen make sure you read the error message\u003c/strong\u003e to understand what is going on and why:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAre any of the necessary files missing? Double-check that you used Git to add, commit, and push all of the relevant pieces:\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eruntime.txt\u003c/code\u003e: the Python version\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eProcfile\u003c/code\u003e: the terminal command for Heroku to run\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erequirements.txt\u003c/code\u003e: the Python package requirements\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eapp.py\u003c/code\u003e: the actual Flask app source code\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emodel.pkl\u003c/code\u003e: the pickled model file\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eIf the error message mentions the \"runtime\", you probably need to review the list of supported runtimes and modify \u003ccode\u003eruntime.txt\u003c/code\u003e so that it reflects the new version\u003c/li\u003e\n\u003cli\u003eIf the error message happens during the \u003ccode\u003epip install\u003c/code\u003e step, that might mean that one of the packages you're using is no longer available from the Python Package Index (the source where \u003ccode\u003epip\u003c/code\u003e installs things from). Go to \u003ca href=\"https://pypi.org/\"\u003ehttps://pypi.org/\u003c/a\u003e to research the packages you are trying to use, make a new \u003ccode\u003econda\u003c/code\u003e environment locally, and try installing the packages one by one until you have a working \u003ccode\u003erequirements.txt\u003c/code\u003e file.\u003c/li\u003e\n\u003cli\u003eIf the error message happens when you're actually trying to view a page or run \u003ccode\u003erequests.post\u003c/code\u003e, most likely you didn't include all of the requirements in \u003ccode\u003erequirements.txt\u003c/code\u003e. You can run \u003ccode\u003epip freeze\u003c/code\u003e in the terminal to see all of the packages you're using locally\u003c/li\u003e\n\u003cli\u003eIf the build logs aren't giving you enough information, go to \u003cstrong\u003eMore\u003c/strong\u003e --\u0026gt; \u003cstrong\u003eView logs\u003c/strong\u003e to see the logs from the actual application running. This will give you information about the incoming requests.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eUpdating the Source Code on Heroku\u003c/h4\u003e\n\n\u003cp\u003eFirst, use Git to add, commit, and push your changes to GitHub. Then go back to the \u003cstrong\u003eDeploy\u003c/strong\u003e tab, scroll to the bottom, and click \u003cstrong\u003eDeploy Branch\u003c/strong\u003e. Then wait to see if you get the \"Your app was successfully deployed\" message, and repeat the \"Identifying the Problem\" steps as needed.\u003c/p\u003e\n\n\u003cp\u003eYou can also enable automatic deploys if you want to, but we tend to find that the manual process is easier to debug.\u003c/p\u003e\n\n\u003ch2\u003eLevel Up\u003c/h2\u003e\n\n\u003cp\u003eCurrently we are mainly using Flask to serve JSON content, but Flask is also a web server that can serve HTML!\u003c/p\u003e\n\n\u003cp\u003eIf you are comfortable writing HTML, try modifying the \u003ccode\u003e/\u003c/code\u003e route so that it displays useful information, e.g. explaining how to call the API and make a prediction.\u003c/p\u003e\n\n\u003cp\u003eYou can write multi-line HTML directly within \u003ccode\u003eapp.py\u003c/code\u003e using a triple-quoted Python string like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\"\n    \u0026lt;h1\u0026gt;API Documentation\u0026lt;/h1\u0026gt;\n    \u0026lt;p\u0026gt;\n      Paragraph of text here\n    \u0026lt;/p\u0026gt;\n    \"\"\"\u003c/span\u003e    \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAlternatively, you can create a \u003ccode\u003estatic\u003c/code\u003e folder containing a file called \u003ccode\u003eindex.html\u003c/code\u003e, then re-write the \u003ccode\u003e/\u003c/code\u003e route so it looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003esend_from_directory\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003esend_from_directory\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"static\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"index.html\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThat's it! You have now learned about how to incorporate a cloud function into a Flask app, and how to deploy that Flask app on Heroku!\u003c/p\u003e","frontPage":false},{"exportId":"text-classification","title":"Text Classification","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-text-classification\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-text-classification/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll discuss the general process for setting up text datasets for classification problems.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the steps for classifying text data \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClassification for Text Data\u003c/h2\u003e\n\n\u003cp\u003eFor the final lab of this section, we'll use everything we've learned so far to build a classifier that works well with text data. As you've probably guessed, text data is significantly harder to work with than most traditional datasets, because of the sheer amount of preprocessing needed to get the data into a format acceptable to a machine learning algorithm. \u003c/p\u003e\n\n\u003cp\u003eThe main challenge in working with text data isn't just the preprocessing -- its the number of decisions you have to make about how you'll clean and structure the data. In a traditional dataset full of numerical and categorical features, the preprocessing steps are fairly straightforward. Generally, we normalize the numeric data, check for and deal with multicollinearity, convert categorical data to numerical format through one-hot encoding, and so forth. Although the steps themselves may not be easy, there's generally little ambiguity about \u003cem\u003ewhat needs to be done\u003c/em\u003e. Text data is a bit more ambiguous. Let's examine some of the decisions we generally need to make when working with text data.\u003c/p\u003e\n\n\u003ch2\u003eCleaning and Preprocessing Text Data\u003c/h2\u003e\n\n\u003cp\u003eOnce we have our data, the fun part begins. We'll need to begin by preprocessing and cleaning our text data. As you've seen throughout this section, preprocessing text data is a bit more challenging than working with more traditional data types because there's no clear-cut answer for exactly what sort of preprocessing and cleaning we need to do. When working with traditional datasets, our goals are generally pretty clear for this stage -- normalize and clean our numerical data, convert categorical data to a numeric format, check for and deal with multicollinearity, etc. The steps we take are largely dependent on what the data already looks like when we get a hold of it. Text data is different -- if we inspect a raw text dataset, we'll generally see that it only has one dimension -- the actual text, in the form of a string. This could be anything from a tweet to a full novel. This means that we need to make some decisions about how to preprocess our data. Before we can begin cleaning and preprocessing our text data, we need to make some decisions about things such as:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDo we remove stop words or not?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we stem or lemmatize our text data, or leave the words as is?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eIs basic tokenization enough, or do we need to support special edge cases through the use of regex?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we use the entire vocabulary, or just limit the model to a subset of the most frequently used words? If so, how many?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eDo we engineer other features, such as bigrams, or POS tags, or Mutual Information Scores?\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat sort of vectorization should we use in our model? Boolean Vectorization? Count Vectorization? TF-IDF? More advanced vectorization strategies such as Word2Vec?\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThese are all questions that we'll need to think about pretty much anytime we begin working with text data.\u003c/p\u003e\n\n\u003ch2\u003eFeature Engineering\u003c/h2\u003e\n\n\u003cp\u003eAnother common decision point when working with text data is exactly what features to include in the dataset. As we saw in a previous lab, NLTK makes it quite easy to do things like generate part-of-speech tags for words, or create word or character-level n-grams. In general, there's no great answer for exactly which features will improve the performance of your model, and which won't. This means that your best bet is to experiment, and treat the entire project as an iterative process! When working with text data, don't be afraid to try modeling on alternative forms of the text data, such as bigrams or n-grams. Similarly, we encourage you to explore how adding in additional features such as POS tags or mutual information scores affect the overall model performance. Sometimes, it has a great effect on performance. Other times, not much. Either way, you won't know until you try!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we discussed the challenges that come with working with text data for classification, and the types of decisions we should be ready to make when cleaning and preprocessing a dataset!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-text-classification\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-text-classification\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-text-classification/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"short-video-tf-idf-vectorization","title":"Short Video: TF-IDF Vectorization","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713724950?h=6c82571832\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"Untitled\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"transfer-learning-introduction","title":"Transfer Learning - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll learn all about transfer learning and how it could be specifically applied to convolutional neural networks. There are also other applications of transfer learning like NLP.\u003c/p\u003e\n\n\u003ch2\u003eConvolutional Neural Networks (Continued)\u003c/h2\u003e\n\n\u003cp\u003eIn an earlier section, you learned about the fundamentals of convolutional neural networks and how to use them. In this section, you'll deepen your CNN knowledge and learn about concepts that will allow you to reuse pretrained models from other image recognition tasks. This will help you solve problems where only limited data is available.\u003c/p\u003e\n\n\u003ch3\u003eUsing Pretrained Networks\u003c/h3\u003e\n\n\u003cp\u003eYou will learn about the concept of \"convolutional bases\" and why they are useful. The use of a convolutional base, or a \"pretrained network\" has the advantage that hierarchical features that already have been \"pre-learned\" by this network can act as a generic model. Because of that reason, these networks can be used for a wide variety of computer vision tasks, even if your new problem involves completely different classes of images. You'll learn about the pretrained networks that are available in Keras, the use of pretrained networks through feature extraction (meaning that you run your new data through the pretrained network and training a new classifier on top of the pretrained network), and the use of pretrained networks through finetuning.\u003c/p\u003e\n\n\u003ch3\u003eImage Classification\u003c/h3\u003e\n\n\u003cp\u003eAt the end of this section, you'll work through a lab that combines the knowledge you gained in this section and the previous one. You'll work on a dog breed classification problem, a dataset used in a Kaggle competition, and build both a convolutional neural network from scratch, and a CNN using a pretrained network.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll extend your deep learning knowledge by learning about transfer learning. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-transfer-learning-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-transfer-learning-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"py-spark-basics","title":"(Py)Spark Basics","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-basics\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-basics\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-basics/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eBefore we begin writing PySpark code, let's go over some more of the concepts that underpin Apache Spark.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the high-level architecture of Apache Spark\u003c/li\u003e\n\u003cli\u003eDescribe the driver, worker, and executor in the context of Spark's parallelism\u003c/li\u003e\n\u003cli\u003eDescribe the data structures used by Apache Spark and PySpark in particular\u003c/li\u003e\n\u003cli\u003eList use cases for Spark\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSpark Architecture\u003c/h2\u003e\n\n\u003cp\u003eThe high-level architecture of the Apache Spark stack looks like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1007%2Fs41060-016-0027-9/MediaObjects/41060_2016_27_Fig1_HTML.gif?as=webp\" alt=\"Spark Architecture\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Figure from \u003cem\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e\u003c/em\u003e)\u003c/p\u003e\n\n\u003cp\u003eWe'll start at the bottom and work our way up.\u003c/p\u003e\n\n\u003ch3\u003eStorage\u003c/h3\u003e\n\n\u003cp\u003eWe won't focus too much on the specifics here, since they are applicable to all sorts of distributed computing systems. The main thing to be aware of is that production-grade Big Data stacks require specialized file systems.\u003c/p\u003e\n\n\u003cp\u003eSome storage options that are compatible with Spark are:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\"\u003eHDFS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cassandra.apache.org/_/index.html\"\u003eCassandra\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://hbase.apache.org/\"\u003eHBase\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.alluxio.io/\"\u003eAlluxio\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eCluster Manager\u003c/h3\u003e\n\n\u003cp\u003e\u003cimg src=\"https://spark.apache.org/docs/latest/img/cluster-overview.png\" alt=\"Cluster manager diagram\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Figure from \u003ca href=\"https://spark.apache.org/docs/latest/cluster-overview.html\"\u003eCluster Mode Overview\u003c/a\u003e)\u003c/p\u003e\n\n\u003cp\u003eAs mentioned previously, Big Data tools typically rely on distributed and parallel computing. This is implemented in the Apache Spark stack using a cluster manager.\u003c/p\u003e\n\n\u003cp\u003eThe main takeaway here should be a basic familiarity with the terminology.\u003c/p\u003e\n\n\u003cp\u003eA \u003cstrong\u003e\u003cem\u003ecluster\u003c/em\u003e\u003c/strong\u003e is a group of interconnected computers used for distributed and parallel computing. A \u003cstrong\u003e\u003cem\u003ecluster manager\u003c/em\u003e\u003c/strong\u003e manages those machines by allocating resources and connecting the driver program and worker nodes. A \u003cstrong\u003e\u003cem\u003edriver\u003c/em\u003e\u003c/strong\u003e program maintains information about your application, responds to external programs, and analyzes, distributes, and schedules work across worker nodes. \u003cstrong\u003e\u003cem\u003eWorker\u003c/em\u003e\u003c/strong\u003e nodes contain \u003cstrong\u003e\u003cem\u003eexecutor\u003c/em\u003e\u003c/strong\u003e processes that execute the code assigned by the driver.\u003c/p\u003e\n\n\u003cp\u003eHere are links to some cluster manager options:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html\"\u003eHadoop YARN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mesos.apache.org/\"\u003eApache Mesos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/ec2/\"\u003eAmazon EC2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\"\u003eKubernetes\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eA Note About The Spark Curriculum\u003c/h3\u003e\n\n\u003cp\u003eBecause the curriculum lessons and labs are smaller, proof-of-concept applications of Spark, we will \u003cstrong\u003enot\u003c/strong\u003e be using a special distributed file storage system like HDFS or a full-fledged cluster manager like YARN. Instead, we will use \u003ca href=\"https://spark.apache.org/docs/latest/spark-standalone.html\"\u003eSpark Standalone\u003c/a\u003e with a local cluster.\u003c/p\u003e\n\n\u003cp\u003eTypically a data scientist or data engineer would not be responsible for managing a cluster. In fact, you can refer to the \u003ca href=\"https://spark.apache.org/docs/latest/api/python/\"\u003ePySpark documentation\u003c/a\u003e, which contains a version of the Spark architecture diagram that doesn't even include the storage and cluster manager layers. Instead it just focuses on the Spark Core and upper-level libraries:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://spark.apache.org/docs/latest/api/python/_images/pyspark-components.png\" alt=\"Simplified Spark Architecture\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eSpark Core (Unstructured API)\u003c/h3\u003e\n\n\u003ch4\u003eAdvantages Over MapReduce\u003c/h4\u003e\n\n\u003cp\u003eThe Spark Core is where Spark's advantages over MapReduce appear. To quote from \u003cem\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e\u003c/em\u003e (emphasis added):\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eApache Spark has emerged as the de facto standard for big data analytics after Hadoop‚Äôs MapReduce. As a framework, it combines a core engine for distributed computing with an advanced programming model for in-memory processing. Although it has the same linear scalability and fault tolerance capabilities as those of MapReduce, it comes with a multistage in-memory programming model comparing to the rigid map-then-reduce disk-based model. With such an advanced model, Apache Spark is much faster and easier to use.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eApache Spark leverages the memory of a computing cluster to reduce the dependency on the underlying distributed file system, leading to dramatic performance gains in comparison with Hadoop‚Äôs MapReduce.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eRecall the difference between data or models \u003cem\u003ein memory\u003c/em\u003e (e.g. data stored in a Python variable) vs. \u003cem\u003eon disk\u003c/em\u003e (e.g. a CSV or pickled model file). Almost all of the data work we do in this curriculum is in memory, since this is much faster and more flexible than performing all of the IO operations needed to save everything to disk. Spark uses this same approach.\u003c/p\u003e\n\n\u003cp\u003eYou can read more about the specific performance gains made by Spark compared to MapReduce \u003ca href=\"https://research.ijcaonline.org/volume113/number1/pxc3900531.pdf\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eUnstructured API\u003c/h4\u003e\n\n\u003cp\u003eFunctionality within the Spark Core is also referred to as the \"Unstructured API\".\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eNote: \"API\" doesn't necessarily mean an HTTP API accessed over the internet -- in this case it just means the interface of classes and functions that your code can invoke.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe Unstructured API is the older, lower-level interface.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eNote: \"lower-level\" is literally true in the case of the figure shown at the top of this lesson, but it also generally means that a tool is closer to the underlying machine code executing on a computer. That means that it is usually more configurable than a higher-level tool, but also that it tends to be more difficult to use and is possibly not optimized for specific use cases.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIt includes some constructs that resemble MapReduce constructs, such as Accumulators and Broadcast variables, as well as SparkContext and Resilient Distributed Datasets (RDDs). You can find the full PySpark Unstructured API documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eSparkContext\u003c/h4\u003e\n\n\u003cp\u003eSparkContext is the entry point for using the Unstructured API. You'll notice it is inside the \"Driver Program\" rectangle in the cluster manager figure above. We will cover more details of how SparkContext is used with PySpark in a future lesson. You can also read more from the PySpark documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eResilient Distributed Datasets (RDDs)\u003c/h4\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDDs) are the fundamental data structure used by the Spark Core and accessible via the Unstructured API. Once again, we will cover more details in a future lesson, and you can read more from the PySpark documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.html#rdd-apis\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3\u003eUpper-Level Libraries (Structured API)\u003c/h3\u003e\n\n\u003cp\u003eThe upper-level libraries, also known as the Structured API, is where Spark gets really exciting. They are higher-level, easier to use, and optimized for particular tasks.\u003c/p\u003e\n\n\u003cp\u003eFor data analysis and manipulation, the Structured API offers Spark SQL, a \u003ccode\u003epandas\u003c/code\u003e API, and Spark Streaming. For machine learning the Structured API offers MLlib.\u003c/p\u003e\n\n\u003ch4\u003eSpark SQL\u003c/h4\u003e\n\n\u003cp\u003eSpark SQL has data structures called DataFrame and Dataset.\u003c/p\u003e\n\n\u003cp\u003eA Spark SQL \u003cstrong\u003e\u003cem\u003eDataFrame\u003c/em\u003e\u003c/strong\u003e is similar to a \u003ccode\u003epandas\u003c/code\u003e DataFrame in that it keeps track of column names and types, which improves efficiency and makes the data easier to work with. It is not the same as the DataFrame used in the \u003ccode\u003epandas\u003c/code\u003e API, although it is possible to convert between them if necessary. You can find more documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eA Spark SQL \u003cstrong\u003e\u003cem\u003eDataset\u003c/em\u003e\u003c/strong\u003e works similar to a DataFrame except it has an additional Row construct. Datasets are not usable in PySpark (only in Scala and Java) at this time, although you may see references to them in the main Spark documentation.\u003c/p\u003e\n\n\u003cp\u003eRather than a SparkContext like is used for the Unstructured API, the entry point to Spark SQL is a \u003cstrong\u003e\u003cem\u003eSparkSession\u003c/em\u003e\u003c/strong\u003e. You can find more documentation \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003ePandas API\u003c/h4\u003e\n\n\u003cp\u003eThe \u003ccode\u003epandas\u003c/code\u003e API allows you to use familiar \u003ccode\u003epandas\u003c/code\u003e class and function names, with the power of Spark! \u003ca href=\"https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/faq.html#should-i-use-pyspark-s-dataframe-api-or-pandas-api-on-spark\"\u003eThe PySpark maintainers recommend\u003c/a\u003e that anyone who already knows how to use \u003ccode\u003epandas\u003c/code\u003e uses this API. You can find the API reference \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html\"\u003ehere\u003c/a\u003e and user guide \u003ca href=\"https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eSpark Streaming\u003c/h4\u003e\n\n\u003cp\u003eStreaming data is outside the scope of this curriculum, but it's useful to know that Spark has functionality for it. You can find the PySpark documentation for Spark Streaming \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.streaming.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch4\u003eMLlib\u003c/h4\u003e\n\n\u003cp\u003eMLlib allows you to perform many of the same machine learning tasks as scikit-learn, including transforming data, building and evaluating supervised and unsupervised machine learning models, and even building pipelines. There is also an Alternating Least Squares (ALS) implementation, which we will apply to a recommender system!\u003c/p\u003e\n\n\u003cp\u003eYou can find the PySpark documentation for MLlib \u003ca href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s41060-016-0027-9\"\u003eBig data analytics on Apache Spark\u003c/a\u003e (2016) is an excellent review article. It should take 90-120 minutes to read, and we highly encourage you to take the time if you're interested in using Spark.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://stanford.edu/%7Erezab/sparkclass/slides/itas_workshop.pdf\"\u003eIntro to Apache Spark\u003c/a\u003e (2014) is a 194-slide presentation that goes into more detail about Spark with many code examples. Note: it appears that links in the slide deck starting with \u003ccode\u003ecdn.liber118.com\u003c/code\u003e are no longer working, but the GitHub links are still functional.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eAt a high level, Spark's architecture consists of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStorage\u003c/li\u003e\n\u003cli\u003eCluster Manager\u003c/li\u003e\n\u003cli\u003eSpark Core (Unstructured API)\u003c/li\u003e\n\u003cli\u003eUpper-Level Libraries (Structured API)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe Cluster Manager divides and shares the physical resources of a cluster of machines, utilizing a driver program that specifies tasks for executors within worker nodes.\u003c/p\u003e\n\n\u003cp\u003eThe Spark Core (Unstructured API) is accessed using SparkContext, and utilizes the RDD data structure.\u003c/p\u003e\n\n\u003cp\u003eThe upper-level libraries (Structured API) include code for specific use cases, including data analysis and manipulation (Spark SQL, \u003ccode\u003epandas\u003c/code\u003e API, Spark Streaming) and machine learning (MLlib). Spark SQL is accessed using SparkSession and introduces two additional data structures (DataFrame and Dataset).\u003c/p\u003e\n\n\u003cp\u003eNow that we've covered the concepts, let's dive into some specific implementations!\u003c/p\u003e","frontPage":false},{"exportId":"installing-and-configuring-pyspark-with-docker","title":"Installing and Configuring PySpark with Docker","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-docker-installation\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn a large-scale enterprise environment, you would typically run (Py)Spark on a distributed cloud system or possibly a dedicated hardware in a datacenter. However it is also possible to run it on your local computer as a standalone cluster. In this lesson we'll walk through how to do just that!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUnderstand how to install PySpark on your local computer\u003c/li\u003e\n\u003cli\u003eExplain the utility of Docker when dealing with package management \u003c/li\u003e\n\u003cli\u003eInstall a Docker container that comes packaged with Spark \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eInstalling PySpark without Docker\u003c/h2\u003e\n\n\u003cp\u003eIt is possible to install PySpark without Docker, but it will require more-advanced systems administration skills. Follow these instructions if you want to get the best possible Spark performance from your personal computer, but be aware that \u003cstrong\u003eyou can feel free to skip this\u003c/strong\u003e because there are a lot of little places that things can go wrong, and it can be difficult to troubleshoot.\u003c/p\u003e\n\n\u003ch3\u003eCreating a New \u003ccode\u003econda\u003c/code\u003e Environment\u003c/h3\u003e\n\n\u003cp\u003eIf you want to work on a project using PySpark, we recommend that you make a new \u003ccode\u003econda\u003c/code\u003e environment. Execute the following commands in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate base\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate spark-env\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eChecking for Successful Environment Creation\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich python\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure that the path displayed includes \u003ccode\u003espark-env\u003c/code\u003e before proceeding to the next step. If it doesn't, try \u003ccode\u003econda deactivate\u003c/code\u003e repeatedly until no environment is shown, then \u003ccode\u003econda activate spark-env\u003c/code\u003e again.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Java\u003c/h3\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, execute this line in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge \u003cspan class=\"nv\"\u003eopenjdk\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e11\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis installs OpenJDK, an open-source version of Java, within your \u003ccode\u003econda\u003c/code\u003e environment.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful Java Installation\u003c/h4\u003e\n\n\u003cp\u003eRun this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich java\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure the path displayed includes \u003ccode\u003espark-env\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eLaunch an interactive \u003cstrong\u003eJava shell\u003c/strong\u003e by running:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ejshell\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003ejshell\u0026gt;\u003c/code\u003e prompt.\u003c/p\u003e\n\n\u003cp\u003eIf you want to write some Java code here, you can! Or you can just quit the Java shell by typing \u003ccode\u003e/exit\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch3\u003eInstalling PySpark\u003c/h3\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, execute this line in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epyspark\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e3\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis installs a setup for a standalone Spark cluster as well as the PySpark library to interact with that cluster.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Installation: Spark\u003c/h4\u003e\n\n\u003cp\u003eFirst, check that Spark installed successfully by launching an interactive \u003cstrong\u003eSpark shell\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003espark-shell\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003escala\u0026gt;\u003c/code\u003e prompt. It's normal for this to take several seconds, and also to print out several lines of warnings, such as \u003ccode\u003eWARNING: Illegal reflective access\u003c/code\u003e, as well as some fun ASCII art:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\\n      /_/\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTry typing \u003ccode\u003esc\u003c/code\u003e and hitting Enter to see the string representation of the SparkContext in Scala. Then quit the Scala shell by typing \u003ccode\u003e:quit\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Installation: PySpark\u003c/h4\u003e\n\n\u003cp\u003eThen, check that PySpark installed successfully by launching an interactive \u003cstrong\u003ePySpark shell\u003c/strong\u003e. Run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epyspark\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should launch a CLI application that displays a \u003ccode\u003e\u0026gt;\u0026gt;\u0026gt;\u003c/code\u003e prompt, as well as the same warnings and ASCII art as the \u003ccode\u003espark-shell\u003c/code\u003e did. Try typing \u003ccode\u003esc\u003c/code\u003e and hitting Enter to see the string representation of the SparkContext in Python (and you can test out any other random Python commands). Then quit the PySpark shell by typing \u003ccode\u003equit()\u003c/code\u003e and hitting Enter.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Jupyter Notebook and Other Useful Libraries\u003c/h3\u003e\n\n\u003cp\u003eIn theory \u003ccode\u003espark-env\u003c/code\u003e already has everything you need to start developing PySpark code! But there are a couple more tools that we typically use for data science that you probably want to install as well.\u003c/p\u003e\n\n\u003cp\u003eWith \u003ccode\u003espark-env\u003c/code\u003e activated, run these commands in the terminal to install Jupyter Notebook and Matplotlib. Afterwards you can install any other libraries you like to use as well.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003epython \u003cspan class=\"nt\"\u003e-m\u003c/span\u003e ipykernel \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e--user\u003c/span\u003e \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nt\"\u003e--display-name\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"Python (spark-env)\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ematplotlib\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eRunning a PySpark Notebook Locally\u003c/h3\u003e\n\n\u003cp\u003eNow you can clone this notebook and run \u003ccode\u003ejupyter notebook\u003c/code\u003e to start it in your \u003ccode\u003espark-env\u003c/code\u003e. The three cells below should run with no errors (although there may be warnings):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003esc\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epyspark\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSparkContext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'local[*]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e22/03/07 20:38:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003erdd\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparallelize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etakeSample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e[597, 803, 304, 458, 603]\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\n\u003chr\u003e\n\n\u003ch2\u003eInstalling PySpark with Docker\u003c/h2\u003e\n\n\u003cp\u003eIf you're lucky, all of the commands above ran smoothly and you are now able to use PySpark directly on your machine using \u003ccode\u003econda\u003c/code\u003e. However we recognize that this process frequently goes wrong, and troubleshooting often involves some tricky systems administration tasks, configuring environment variables such as \u003ccode\u003e$PATH\u003c/code\u003e, \u003ccode\u003e$JAVA_PATH\u003c/code\u003e, etc.\u003c/p\u003e\n\n\u003cp\u003eIn the rest of this lesson, we'll describe an alternative way to install PySpark using \u003cstrong\u003eDocker\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eWhy Docker?\u003c/h3\u003e\n\n\u003cp\u003eDocker is a container technology that allows \u003cstrong\u003epackaging\u003c/strong\u003e and \u003cstrong\u003edistribution\u003c/strong\u003e of software  so that it takes away the headache of things like setting up an environment, configuring logging, configuring options, etc. Docker basically removes the excuse of \u003cem\u003eIt doesn't work on my machine\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.zdnet.com/article/what-is-docker-and-why-is-it-so-darn-popular/\"\u003eVisit this link learn more about docker and containers\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003eHow Does Docker Work?\u003c/h3\u003e\n\n\u003cp\u003eWithout getting too much into the details of virtualization and underlying operating systems, a Docker \u003cstrong\u003eimage\u003c/strong\u003e is deployed in a \u003cstrong\u003econtainer\u003c/strong\u003e where it essentially operates as a self-contained computer wherever it is run. It can be running on a Windows desktop, a Mac laptop, or an AWS cloud server, and the dependencies and environment should work exactly the same.\u003c/p\u003e\n\n\u003cp\u003eKind of like the \u003ccode\u003e.yml\u003c/code\u003e file we used to create \u003ccode\u003elearn-env\u003c/code\u003e, Docker containers have a static specification that tells the software what to install. Only instead of just Python packages, the \u003cstrong\u003eDockerfile\u003c/strong\u003e (as it's called) specifies the operating system, shell language, permissions, environment variables, etc.\u003c/p\u003e\n\n\u003cp\u003eThe Dockerfile we'll be using is for an image maintained by Jupyter called \u003ccode\u003epyspark-notebook\u003c/code\u003e. You can view the full Dockerfile \u003ca href=\"https://github.com/jupyter/docker-stacks/blob/master/pyspark-notebook/Dockerfile\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eIn order to turn that file into a functioning container, we need to install Docker.\u003c/p\u003e\n\n\u003ch3\u003eInstalling Docker\u003c/h3\u003e\n\n\u003cp\u003eGo to the \u003ca href=\"https://docs.docker.com/get-docker/\"\u003eGet Docker\u003c/a\u003e page, click on your operating system, and follow the instructions. Note that there is a graphical user interface called \"Docker Desktop\" available for Mac and Windows users, whereas at the time of this writing there is not an equivalent tool for Linux users. Linux users can install the \"server\" version.\u003c/p\u003e\n\n\u003ch3\u003ePulling the PySpark Stack from DockerHub\u003c/h3\u003e\n\n\u003cp\u003eIf you were developing your own Dockerfiles, you could just work locally, similarly to how you could write Python code locally without connecting to any remote repositories. But we want to run an image created by someone else, so we want to use the \u003ccode\u003edocker pull\u003c/code\u003e command from \u003ca href=\"https://hub.docker.com/r/jupyter/pyspark-notebook\"\u003eDockerHub\u003c/a\u003e. This is roughly equivalent to running \u003ccode\u003egit pull\u003c/code\u003e from GitHub, except you're downloading a pre-built computer image.\u003c/p\u003e\n\n\u003cp\u003eSpecifically, run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will initiate a download that will likely take a while, then finally you should see a message like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eStatus: Downloaded newer image for jupyter/pyspark-notebook:latest\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou have now pulled down the PySpark stack!\u003c/p\u003e\n\n\u003ch3\u003eRunning Jupyter Notebook with Docker\u003c/h3\u003e\n\n\u003cp\u003eNow that you have pulled down \u003ccode\u003epyspark-notebook\u003c/code\u003e, run this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(The \u003ccode\u003e-p\u003c/code\u003e flag is setting the ports on your computer as well as the container to be connected.)\u003c/p\u003e\n\n\u003cp\u003eThis will launch a notebook server that should look fairly similar to when you run a regular \u003ccode\u003ejupyter notebook\u003c/code\u003e command!\u003c/p\u003e\n\n\u003cp\u003eHowever you will most likely need to copy the URL displayed in the terminal and paste it into a browser window, rather than having it automatically open like \u003ccode\u003ejupyter notebook\u003c/code\u003e usually does. The URL will look something like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:8888/lab?token=\u0026lt;token\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen once you paste it into the browser address bar, you'll be redirected to just \u003ccode\u003ehttp://127.0.0.1:8888/lab\u003c/code\u003e, which is a Jupyter Lab interface:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-spark-docker-installation/raw/master/images/jupyter_lab.png\" alt=\"jupyter lab screenshot\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIf you want to navigate back to the classic \u003ccode\u003ejupyter notebook\u003c/code\u003e file window, simply enter \u003ccode\u003ehttp://127.0.0.1:8888/tree\u003c/code\u003e in the address bar (replacing \u003ccode\u003elab\u003c/code\u003e with \u003ccode\u003etree\u003c/code\u003e).\u003c/p\u003e\n\n\u003ch4\u003eChecking for Successful PySpark Image Installation\u003c/h4\u003e\n\n\u003cp\u003eFrom here, you can create a new notebook and run these lines of code, which should not produce an error:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epyspark\u003c/span\u003e\n\u003cspan class=\"n\"\u003esc\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epyspark\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSparkContext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'local[*]'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparallelize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003erdd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etakeSample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eConnecting Docker Container to Your File System\u003c/h3\u003e\n\n\u003cp\u003eYou might have noticed something strange when you were creating that notebook: there was only a directory called \u003ccode\u003ework\u003c/code\u003e, nothing related to the directory on your computer where you launched \u003ccode\u003edocker run\u003c/code\u003e!\u003c/p\u003e\n\n\u003cp\u003eThis is because even though the notebook server looked very similar to one being run directly on your computer, this one only had access to the container's file system.\u003c/p\u003e\n\n\u003cp\u003eIf you want to be able to use notebooks from the curriculum or files on disk (e.g. CSV files), it's useful to be able to connect your computer's file system to the container.\u003c/p\u003e\n\n\u003ch4\u003eShutting Down Previous Docker Container\u003c/h4\u003e\n\n\u003cp\u003eShut down the currently-running container by typing \u003ccode\u003econtrol-C\u003c/code\u003e in the terminal window where it is currently running. If you accidentally closed that terminal window, you can:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eUse a command-line approach:\n\n\u003cul\u003e\n\u003cli\u003eRun \u003ccode\u003edocker ps\u003c/code\u003e to see a list of all currently-running docker containers\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003edocker stop \u0026lt;container id\u0026gt;\u003c/code\u003e where \u003ccode\u003e\u0026lt;container id\u0026gt;\u003c/code\u003e is from the \u003ccode\u003edocker ps\u003c/code\u003e print-out. For example, \u003ccode\u003edocker stop efb990e0e054\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eOr, use Docker Desktop:\n\n\u003cul\u003e\n\u003cli\u003eOpen Docker Desktop and locate the currently-running container in the \"Containers / Apps\" list\u003c/li\u003e\n\u003cli\u003eClick the square stop button\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch4\u003eStarting Docker Again, Connected to Your File System\u003c/h4\u003e\n\n\u003cp\u003eThe formal language of this is called \"mounting a volume\", so it uses the \u003ccode\u003e-v\u003c/code\u003e command-line option.\u003c/p\u003e\n\n\u003cp\u003eThe general structure looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003eabsolute file path of current directory\u003cspan class=\"o\"\u003e}\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe are mapping \u003ccode\u003e{absolute file path of current directory}\u003c/code\u003e on your computer onto \u003ccode\u003e/home/jovyan/work\u003c/code\u003e in the container.\u003c/p\u003e\n\n\u003cp\u003e(Fun fact: the username \u003ccode\u003ejovyan\u003c/code\u003e is a \u003ca href=\"https://docs.jupyter.org/en/latest/community/content-community.html#what-is-a-jovyan\"\u003eplay on the name Jupyter\u003c/a\u003e. \u003cem\u003eJovyan\u003c/em\u003e is to \u003ca href=\"https://en.wiktionary.org/wiki/Jovian\"\u003e\u003cem\u003eJovian\u003c/em\u003e\u003c/a\u003e as \u003cem\u003eJupyter\u003c/em\u003e is to \u003cem\u003eJupiter\u003c/em\u003e.)\u003c/p\u003e\n\n\u003cp\u003eFor \u003cstrong\u003eMac\u003c/strong\u003e or \u003cstrong\u003eLinux\u003c/strong\u003e, the actual command looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor \u003cstrong\u003eWindows\u003c/strong\u003e, the actual command looks like this (executed in Command Prompt, not Git Bash):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker run -p 8888:8888 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow you should be able to navigate to the \u003ccode\u003ework\u003c/code\u003e directory and find this notebook there!\u003c/p\u003e\n\n\u003ch4\u003eA Couple More Command-Line Options\u003c/h4\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e-it\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis starts the container in \"interactive mode\" and allows you to access the Bash shell inside the container.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e--rm\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis removes the container from your list of images as soon as you shut it down. Since you are storing your data on your computer's file system, this is a good option to avoid creating a lot of extra unnecessary files.\u003c/p\u003e\n\n\u003cp\u003eTherefore we recommend that you run this complete command:\u003c/p\u003e\n\n\u003cp\u003eOn \u003cstrong\u003eMac/Linux\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work \u003cspan class=\"nt\"\u003e-it\u003c/span\u003e \u003cspan class=\"nt\"\u003e--rm\u003c/span\u003e jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOn \u003cstrong\u003eWindows\u003c/strong\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker run -p 8888:8888 -v %cd%:/home/jovyan/work -it --rm jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at installing Spark with and without a Docker container.\u003c/p\u003e\n\n\u003cp\u003eTo recap the steps:\u003c/p\u003e\n\n\u003ch3\u003eWithout Docker\u003c/h3\u003e\n\n\u003cp\u003eRun all of these commands, following the instructions above to ensure that each step worked as expected:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda activate base\nconda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8\nconda activate spark-env\nconda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge \u003cspan class=\"nv\"\u003eopenjdk\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e11\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epyspark\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e3\nconda \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e-c\u003c/span\u003e conda-forge notebook\npython \u003cspan class=\"nt\"\u003e-m\u003c/span\u003e ipykernel \u003cspan class=\"nb\"\u003einstall\u003c/span\u003e \u003cspan class=\"nt\"\u003e--user\u003c/span\u003e \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e spark-env \u003cspan class=\"nt\"\u003e--display-name\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"Python (spark-env)\"\u003c/span\u003e\nconda \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ematplotlib\njupyter notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eWith Docker\u003c/h3\u003e\n\n\u003cp\u003eGo to the \u003ca href=\"https://docs.docker.com/get-docker/\"\u003eGet Docker\u003c/a\u003e page, click on your operating system, and follow the instructions.\u003c/p\u003e\n\n\u003cp\u003eFor Mac/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\ndocker run \u003cspan class=\"nt\"\u003e-p\u003c/span\u003e 8888:8888 \u003cspan class=\"nt\"\u003e-v\u003c/span\u003e \u003cspan class=\"si\"\u003e$(\u003c/span\u003e\u003cspan class=\"nb\"\u003epwd\u003c/span\u003e\u003cspan class=\"si\"\u003e)\u003c/span\u003e:/home/jovyan/work jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor Windows:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003edocker pull jupyter/pyspark-notebook\ndocker run -p 8888:8888 -v %cd%:/home/jovyan/work -it --rm jupyter/pyspark-notebook\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","frontPage":false},{"exportId":"blogging-overview","title":"Blogging Overview","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-blogging-overview\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-blogging-overview\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-blogging-overview/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e  \u003ch2\u003eIntroduction\u003c/h2\u003e  \u003cp\u003eIn this lesson, we discuss how to write good blog posts that meet Flatiron School's requirements.\u003c/p\u003e  \u003ch2\u003eObjectives\u003c/h2\u003e  \u003cp\u003eThis lesson covers...\u003c/p\u003e  \u003cul\u003e \u003cli\u003eWhy blogging is valuable\u003c/li\u003e \u003cli\u003eTopics to blog about\u003c/li\u003e \u003cli\u003eWhat makes for a good blog post\u003c/li\u003e \u003cli\u003eHow to start your blog\u003c/li\u003e \u003cli\u003eFlatiron School blog requirements \u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhy Should I Blog?\u003c/h2\u003e  \u003cp\u003eBlogging has many benefits:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDevelop your written communication skills.\u003c/strong\u003e Your writing ability will be critical to your success when completing job applications and presenting your work to colleagues. Blogging is great practice for identifying and clearly communicating the most important points of any subject.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDemonstrate your talent to employers.\u003c/strong\u003e Potential employers will review your blog to determine whether to offer you an interview or a job. Some students have even been invited to interview or exempted from technical interviews based on their blogs.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eStrengthen your knowledge.\u003c/strong\u003e Blogging helps you explore new topics, deepen your understanding, and crystallize what you've learned.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eHelp your peers and the broader community.\u003c/strong\u003e Have you ever Googled a question you had and found the answer on a blog? Writing blog posts helps others who are following in your footsteps!\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhat Should I Blog About?\u003c/h2\u003e  \u003cp\u003eHere are some blog topic ideas:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eWhy did you decide to learn data science?\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eDescribe how a DS technique works, when you might use it, and its strengths/weaknesses.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eSummarize an End of Phase Project by explaining your problem, the dataset, your methodology, and your results.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eDive into something that you want to learn more about, maybe because you find it challenging or it wasn't covered in the course.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eWrite a tutorial to help aspiring data scientists to implement a tool or method.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003eFind an interesting data science paper and summarize why it is important. This can be a new paper from the past few months, or you can refer to \u003ca href=\"https://docs.google.com/spreadsheets/d/1UYmAT13AAknrOatzLeeAsN4tS7ENjn2fpJNGzOZ67rQ/edit?usp=sharing\"\u003ethis spreadsheet\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eWhat Does A Good Blog Post Look Like?\u003c/h2\u003e  \u003cp\u003eWe recommend you take a look at our \u003ca href=\"https://drive.google.com/drive/folders/1UBiRCRLzVP5CHU3PJNwoMZAe3ajUBm2a?usp=sharing\"\u003eblog templates\u003c/a\u003e and \u003ca href=\"https://docs.google.com/document/d/1eqL8Dsj7dH7s_MRnf_4-3kCiSz72POHTfb-sBRN5Zhs/edit?usp=sharing\"\u003eexamples\u003c/a\u003e to get an idea for what makes a blog post good.\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eStrike a balance between providing a meaningful investigation of your topic and being concise. Constrain the scope so it will be interesting and digestible in about 1000-3000 words (this is not a firm limit).\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eUse clear and consistent formatting to make your content accessible and professional-looking.\u003c/p\u003e  \u003cul\u003e \u003cli\u003eWhen presenting code, use code snippets instead of screenshots.\u003c/li\u003e \u003cli\u003eMake URLs into hyperlinks that are easy for readers to click into.\u003c/li\u003e \u003cli\u003eUse headings to provide structure and flow to your post.\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003cli\u003e\u003cp\u003eCite and link to resources you used to write your post.\u003c/p\u003e\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eHow Do I Start My Blog?\u003c/h2\u003e  \u003cp\u003eIf you already have a professional blog that you'd like to use for your data science content, you can add your posts to that. Otherwise, you will need to start a new blog. If you have a personal blog, you should avoid using it for this purpose so that you can continue using it for personal content without worrying about how it might be perceived by potential employers.\u003c/p\u003e  \u003cp\u003eThere are multiple blogging platforms to choose from that make it easy to start a blog, here are some of our favorites:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ca href=\"https://www.blogger.com/\"\u003eBlogger\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://dev.to/\"\u003edev.to\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://pages.github.com/\"\u003eGitHub Pages\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://medium.com/\"\u003eMedium\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://wordpress.com/\"\u003eWordpress\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eDifferent platforms have different pros and cons, so do a little research to decide what is best for you.\u003c/p\u003e  \u003ch2\u003eBlog Requirements\u003c/h2\u003e  \u003cp\u003eTo succeed in your career transition and graduate from Flatiron School, you must complete the following activities. These requirements are designed to give you the best opportunity to deepen your knowledge, practice communication skills, and showcase yourself to potential employers.\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003cp\u003eSet up a publicly accessible blog \u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003ePublish at least four blog posts on it, including \u003cstrong\u003eone per Phase for Phases 1-4\u003c/strong\u003e\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eSubmit URLs to your posts \u003cstrong\u003eby the end of each Phase\u003c/strong\u003e in the Blog Post assignments\u003c/p\u003e  \u003cul\u003e \u003cli\u003eThese assignments are located in the Milestones topics of the Phase 1-4 Canvas courses\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003cli\u003e\n\u003cp\u003eWrite blog posts that...\u003c/p\u003e  \u003cul\u003e \u003cli\u003eDiscuss data science topics\u003c/li\u003e \u003cli\u003eAre composed primarily of original material you wrote\u003c/li\u003e \u003cli\u003eInclude proper attribution\u003c/li\u003e \u003cli\u003eHave high-quality content and formatting\u003c/li\u003e \u003cli\u003eAre something you would proudly show to a potential employer\u003c/li\u003e \u003c/ul\u003e\n\u003c/li\u003e \u003c/ul\u003e  \u003cp\u003eAfter you submit your blog posts, your teacher will grade them as Complete or Incomplete. Your blogs must all be submitted on time and receive Complete grades in order to continue through your program.\u003c/p\u003e  \u003cp\u003e‚ú®Have fun and happy blogging!‚ú®\u003c/p\u003e","frontPage":false},{"exportId":"understanding-recurrent-neural-networks","title":"Understanding Recurrent Neural Networks","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-understanding-recurrent-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about a new type of model architecture you haven't seen yet ‚Äî \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain the role time steps play in RNN models\u003c/li\u003e\n\u003cli\u003eExplain back propagation through time\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eData as Time Sequences\u003c/h2\u003e\n\u003cp\u003eThe hallmark of Recurrent Neural Networks is that they are used to evaluate \u003cstrong\u003e\u003cem\u003eSequences\u003c/em\u003e\u003c/strong\u003e of data, rather than just individual data points. So what is sequence data, and how do you distinguish it from other kinds of data, so that you know when to use an RNN?\u003c/p\u003e\n\u003cp\u003eTime series data is a classic example of sequence data. You care about the value over time, and any given point in time can really only be examined relative to the other points of time in that sequence. For instance, knowing the price of Google stock today doesn't provide enough information for us to classify it as a something you should or shouldn't buy ‚Äî for that, you would need to examine today's price relative to the previous day(s) price to see if it's going up or down.\u003c/p\u003e\n\u003cp\u003eAnother great example of sequence data is text. All text data is sequence data by default ‚Äî a letter only makes sense when it's words are in the proper order. You would lose all information if you made a \"Bag of Letters\". Words themselves are sequence data, and can be used for all kinds of novel sequence generation tasks. You've probably seen articles in popular culture about people using neural networks to generate novel band names, cookie names, Pokemon names, etc. These are always done with Recurrent Neural Networks, because they are a perfect fit for sequence data. For this reason, RNNs excel at NLP tasks, because they can take in text as full sequences of words, from a single sentence up to an entire document or book! Because of this, they do not suffer the same loss of information that comes from a traditional Bag-of-Words vectorization approach.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/master/images/unrolled.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eLet's take a look at the overall structure of an RNN to see how it interacts with this sequence data!\u003c/p\u003e\n\u003ch2\u003eBasic RNN Architecture\u003c/h2\u003e\n\u003cp\u003eA basic Recurrent Neural Network is just a neural network that passes it's output from a given example back into itself as input for the next example. Intuitively, this approach makes sense. If you want to predict what Google's stock price is going to be two days from now, the most important input you can give it is what you think the price will be one day from now!\u003c/p\u003e\n\u003cp\u003eWhen drawn as a diagram, RNNs are usually represented in an \u003cstrong\u003e\u003cem\u003eUnrolled\u003c/em\u003e\u003c/strong\u003e representation, which shows the components at each given timestep. The image on the left is a how an RNN is denoted in a diagram \"rolled up\", while the image on the right is \"unrolled\". The current timestep is denoted with the input node \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_t\"\u003e , which makes the previous timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_%7Bt-1%7D\"\u003e and the next timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_%7Bt%2b1%7D\"\u003e . \u003cimg src=\"https://render.githubusercontent.com/render/math?math=H_0\"\u003e represents the model's output for timestep 0, which will then be passed back into the model in \u003cimg src=\"https://render.githubusercontent.com/render/math?math=X_1\"\u003e .\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-understanding-recurrent-neural-networks/master/images/new-RNN-unrolled.png\"\u003e\u003c/p\u003e\n\u003ch2\u003eBackpropagation Through Time\u003c/h2\u003e\n\u003cp\u003eOne interesting aspect of working with RNNs is that they use a modified form of back propagation called \u003cstrong\u003e\u003cem\u003eBack Propagation Through Time (BPTT)\u003c/em\u003e\u003c/strong\u003e. Because the model is trained on sequence data, it has the potential to be right or wrong at every point in that sequence. This means that you need to adjust the model's weights at each time point to effectively learn from sequence data. Because the model starts at the most recent output, and then works backwards to calculate the loss and update the weights at each time step, the model is said to be going \"back in time\" to learn. Since you have to update every single weight at every single time step, that means that BPTT is much more computationally expensive than traditional back propagation. For instance, if a single data point is a sequence with 1000 time steps, then the model will perform a full round of back propagation for each of the 1000 points in that single sequence.\u003c/p\u003e\n\u003ch3\u003eTruncated Back Prop Through Time\u003c/h3\u003e\n\u003cp\u003eThis was a major hurdle for traditional RNN architectures, but a solution exists in the form of the \u003cstrong\u003e\u003cem\u003eTruncated Back Propagation Through Time (TBPTT)\u003c/em\u003e\u003c/strong\u003e algorithm! We won't go deep into the specifics, but essentially, this algorithm increases performance by breaking a big sequence of 1000 points into 50 sequences of 20. This significantly improves training time over regular BPTT, but is still significantly slower than vanilla back propagation.\u003c/p\u003e\n\u003cp\u003eFun Fact: Truncated Back Prop Through Time was invented in the dissertation of Ilya Sutskever, one of the lead researchers at Open AI!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about the sequence data. You also learned about the architecture of RNNs, and the modified back prop algorithm they use for training!\u003c/p\u003e","frontPage":false},{"exportId":"tuning-neural-networks-with-normalization","title":"Tuning Neural Networks with Normalization","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-normalization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we've investigated some methods for tuning our networks, we will investigate some further methods and concepts regarding reducing training time. These concepts will begin to form a more cohesive framework for choices along the modeling process.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what normalization does to training time with neural networks and why \u003c/li\u003e\n\u003cli\u003eExplain what a vanishing or exploding gradient is, and how it is related to model convergence \u003c/li\u003e\n\u003cli\u003eCompare the different optimizer strategies for neural networks \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eNormalized Inputs: Speed up Training\u003c/h2\u003e\n\n\u003cp\u003eOne way to speed up training of your neural networks is to normalize the input. In fact, even if training time were not a concern, normalization to a consistent scale (typically 0 to 1) across features should be used to ensure that the process converges to a stable solution. Similar to some of our previous work in training models, one general process for standardizing our data is subtracting the mean and dividing by the standard deviation. \u003c/p\u003e\n\n\u003ch2\u003eVanishing or Exploding Gradients\u003c/h2\u003e\n\n\u003cp\u003eNot only will normalizing your inputs speed up training, it can also mitigate other risks inherent in training neural networks. For example, in a neural network, having input of various ranges can lead to difficult numerical problems when the algorithm goes to compute gradients during forward and back propagation. This can lead to untenable solutions and will prevent the algorithm from converging to a solution. In short, make sure you normalize your data! Here's a little more mathematical background: \u003c/p\u003e\n\n\u003cp\u003eTo demonstrate, imagine a very deep neural network. Assume \u003cimg class=\"equation_image\" title=\"g(z)=z\" src=\"https://learning.flatironschool.com/equation_images/g(z)=z\" alt=\"{\" data-equation-content=\"g(z)=z\"\u003e (so no transformation, just a linear activation function), and biases equal to 0. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\hat y = w^{[L]}w^{[L-1]}w^{[L-2]}... w^{[3]}w^{[2]}w^{[1]}x\" src=\"/equation_images/%255Chat%20y%20=%20w^{[L]}w^{[L-1]}w^{[L-2]}...%20w^{[3]}w^{[2]}w^{[1]}x\" alt=\"{\" data-equation-content=\"\\hat y = w^{[L]}w^{[L-1]}w^{[L-2]}... w^{[3]}w^{[2]}w^{[1]}x\"\u003e \u003c/p\u003e\n\n\u003cp\u003erecall that \u003cimg class=\"equation_image\" title=\"z^{[1]} =w^{[1]}x \" src=\"/equation_images/z^{[1]}%20=w^{[1]}x\" alt=\"{\" data-equation-content=\"z^{[1]} =w^{[1]}x \"\u003e, and that \u003cimg class=\"equation_image\" title=\"a^{[1]}=g(z^{[1]})=z^{[1]}\" src=\"/equation_images/a^{[1]}=g(z^{[1]})=z^{[1]}\" alt=\"{\" data-equation-content=\"a^{[1]}=g(z^{[1]})=z^{[1]}\"\u003e\u003c/p\u003e\n\n\u003cp\u003esimilarly, \u003cimg class=\"equation_image\" title=\"a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\" src=\"/equation_images/a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\" alt=\"{\" data-equation-content=\"a^{[2]}=g(z^{[2]})=g(w^{[2]}a^{[1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003eImagine two nodes in each layer, and w =  \u003cimg class=\"equation_image\" title=\"\\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}\" src=\"/equation_images/%255Cbegin{bmatrix}%201.3%20\u0026amp;%200%20%255C%200%20\u0026amp;%201.3%20%255Cend{bmatrix}\" alt=\"{\" data-equation-content=\"\\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}\"\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\hat y = w^{[L]} \\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}^{L-1}   x\" src=\"/equation_images/%255Chat%20y%20=%20w^{[L]}%20%255Cbegin{bmatrix}%201.3%20\u0026amp;%200%20%255C%200%20\u0026amp;%201.3%20%255Cend{bmatrix}^{L-1}%20%20%20x\" alt=\"{\" data-equation-content=\"\\hat y = w^{[L]} \\begin{bmatrix} 1.3 \u0026amp; 0 \\ 0 \u0026amp; 1.3 \\end{bmatrix}^{L-1}   x\"\u003e\u003c/p\u003e\n\n\u003cp\u003eEven if the \u003cimg class=\"equation_image\" title=\"w\" src=\"https://learning.flatironschool.com/equation_images/w\" alt=\"{\" data-equation-content=\"w\"\u003e's are slightly smaller than 1 or slightly larger, the activations will explode when there are many layers in the network!   \u003c/p\u003e\n\n\u003ch2\u003eOther Solutions to Vanishing and Exploding Gradients\u003c/h2\u003e\n\n\u003cp\u003eAside from normalizing the data, you can also investigate the impact of changing the initialization parameters when you first launch the gradient descent algorithm. \u003c/p\u003e\n\n\u003cp\u003eFor initialization, the more input features feeding into layer l, the smaller you want each \u003cimg class=\"equation_image\" title=\"w_i\" src=\"https://learning.flatironschool.com/equation_images/w_i\" alt=\"{\" data-equation-content=\"w_i\"\u003e to be.   \u003c/p\u003e\n\n\u003cp\u003eA common rule of thumb is:   \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Var(w_i) = 1/n \" src=\"https://learning.flatironschool.com/equation_images/Var(w_i)%20=%201/n\" alt=\"{\" data-equation-content=\"Var(w_i) = 1/n \"\u003e  \u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Var(w_i) = 2/n\" src=\"https://learning.flatironschool.com/equation_images/Var(w_i)%20=%202/n\" alt=\"{\" data-equation-content=\"Var(w_i) = 2/n\"\u003e  \u003c/p\u003e\n\n\u003cp\u003eOne common initialization strategy for the relu activation function is:  \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ew^{[l]} = np.random.randn(shape)*np.sqrt(2/n_(l-1)) \n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eLater, we'll discuss other initialization strategies pertinent to other activation functions.\u003c/p\u003e\n\n\u003ch2\u003eOptimization\u003c/h2\u003e\n\n\u003cp\u003eIn addition, you could even use an alternative convergence algorithm instead of gradient descent. One issue with gradient descent is that it oscillates to a fairly big extent, because the derivative is bigger in the vertical direction.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization/master/images/new_optimizer.png\" alt=\"oscillating gradient descent\" width=\"600\"\u003e  \u003c/p\u003e\n\n\u003cp\u003eWith that, here are some optimization algorithms that work faster than gradient descent:\u003c/p\u003e\n\n\u003ch3\u003eGradient Descent with Momentum\u003c/h3\u003e\n\n\u003cp\u003eCompute an exponentially weighted average of the gradients and use that gradient instead. The intuitive interpretation is that this will successively dampen oscillations, improving convergence.\u003c/p\u003e\n\n\u003cp\u003eMomentum: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"dW\" src=\"https://learning.flatironschool.com/equation_images/dW\" alt=\"{\" data-equation-content=\"dW\"\u003e and \u003cimg class=\"equation_image\" title=\"db\" src=\"https://learning.flatironschool.com/equation_images/db\" alt=\"{\" data-equation-content=\"db\"\u003e on the current minibatch \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"V_{dw} = \\beta V_{dw} + (1-\\beta)dW\" src=\"/equation_images/V_{dw}%20=%20%255Cbeta%20V_{dw}%20+%20(1-%255Cbeta)dW\" alt=\"{\" data-equation-content=\"V_{dw} = \\beta V_{dw} + (1-\\beta)dW\"\u003e and\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003ecompute \u003cimg class=\"equation_image\" title=\"V_{db} = \\beta V_{db} + (1-\\beta)db\" src=\"/equation_images/V_{db}%20=%20%255Cbeta%20V_{db}%20+%20(1-%255Cbeta)db\" alt=\"{\" data-equation-content=\"V_{db} = \\beta V_{db} + (1-\\beta)db\"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cem\u003eThese are the moving averages for the derivatives of \u003cimg class=\"equation_image\" title=\"W\" src=\"https://learning.flatironschool.com/equation_images/W\" alt=\"{\" data-equation-content=\"W\"\u003e and \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha Vdw\" src=\"https://learning.flatironschool.com/equation_images/W:=%20W-%20%255Calpha%20Vdw\" alt=\"{\" data-equation-content=\"W:= W- \\alpha Vdw\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha Vdb\" src=\"https://learning.flatironschool.com/equation_images/b:=%20b-%20%255Calpha%20Vdb\" alt=\"{\" data-equation-content=\"b:= b- \\alpha Vdb\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThis averages out gradient descent, and will \"dampen\" oscillations. Generally, \u003cimg class=\"equation_image\" title=\"\\beta=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta=0.9\" alt=\"{\" data-equation-content=\"\\beta=0.9\"\u003e is a good hyperparameter value.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch3\u003eRMSprop\u003c/h3\u003e\n\n\u003cp\u003eRMSprop stands for \"root mean square\" prop. It slows down learning in one direction and speed up in another one. On each iteration, it uses exponentially weighted average of the squares of the derivatives. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{dw} = \\beta S_{dw} + (1-\\beta)dW^2\" src=\"/equation_images/S_{dw}%20=%20%255Cbeta%20S_{dw}%20+%20(1-%255Cbeta)dW^2\" alt=\"{\" data-equation-content=\"S_{dw} = \\beta S_{dw} + (1-\\beta)dW^2\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{db} = \\beta S_{dw} + (1-\\beta)db^2\" src=\"/equation_images/S_{db}%20=%20%255Cbeta%20S_{dw}%20+%20(1-%255Cbeta)db^2\" alt=\"{\" data-equation-content=\"S_{db} = \\beta S_{dw} + (1-\\beta)db^2\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}\" src=\"/equation_images/W:=%20W-%20%255Calpha%20%255Cdfrac{dw}{%255Csqrt{S_{dw}}}\" alt=\"{\" data-equation-content=\"W:= W- \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}\"\u003e and\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha \\dfrac{db}{\\sqrt{S_{db}}}\" src=\"/equation_images/b:=%20b-%20%255Calpha%20%255Cdfrac{db}{%255Csqrt{S_{db}}}\" alt=\"{\" data-equation-content=\"b:= b- \\alpha \\dfrac{db}{\\sqrt{S_{db}}}\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the direction where we want to learn fast, the corresponding \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e will be small, so dividing by a small number. On the other hand, in the direction where we will want to learn slow, the corresponding \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e will be relatively large, and updates will be smaller. \u003c/p\u003e\n\n\u003cp\u003eOften, add small \u003cimg class=\"equation_image\" title=\"\\epsilon\" src=\"https://learning.flatironschool.com/equation_images/%255Cepsilon\" alt=\"{\" data-equation-content=\"\\epsilon\"\u003e in the denominator to make sure that you don't end up dividing by 0.\u003c/p\u003e\n\n\u003ch3\u003eAdam Optimization Algorithm\u003c/h3\u003e\n\n\u003cp\u003e\"Adaptive Moment Estimation\", basically using the first and second moment estimations. Works very well in many situations! It takes momentum and RMSprop to put it together!\u003c/p\u003e\n\n\u003cp\u003eInitialize:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0\" src=\"/equation_images/V_{dw}=0,%20S_{dw}=0,%20V_{db}=0,%20S_{db}=0\" alt=\"{\" data-equation-content=\"V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0\"\u003e \u003c/p\u003e\n\n\u003cp\u003eFor each iteration:\u003c/p\u003e\n\n\u003cp\u003eCompute \u003cimg class=\"equation_image\" title=\"dW, db\" src=\"https://learning.flatironschool.com/equation_images/dW,%20db\" alt=\"{\" data-equation-content=\"dW, db\"\u003e using the current mini-batch: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dW\" src=\"/equation_images/V_{dw}%20=%20%255Cbeta_1%20V_{dw}%20+%20(1-%255Cbeta_1)dW\" alt=\"{\" data-equation-content=\"V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dW\"\u003e, \u003cimg class=\"equation_image\" title=\"V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db\" src=\"/equation_images/V_{db}%20=%20%255Cbeta_1%20V_{db}%20+%20(1-%255Cbeta_1)db\" alt=\"{\" data-equation-content=\"V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db\"\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dW^2\" src=\"/equation_images/S_{dw}%20=%20%255Cbeta_2%20S_{dw}%20+%20(1-%255Cbeta_2)dW^2\" alt=\"{\" data-equation-content=\"S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dW^2\"\u003e, \u003cimg class=\"equation_image\" title=\"S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2\" src=\"/equation_images/S_{db}%20=%20%255Cbeta_2%20S_{db}%20+%20(1-%255Cbeta_2)db^2\" alt=\"{\" data-equation-content=\"S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2\"\u003e \u003c/p\u003e\n\n\u003cp\u003eIt's like momentum and then RMSprop. We need to perform a correction! This is sometimes also done in RSMprop, but definitely here too.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"V^{corr}\u003cem\u003e{dw}= \\dfrac{V\u003c/em\u003e{dw}}{1-\\beta_1^t}\" src=\"/equation_images/V^{corr}\u003cem\u003e{dw}=%20%255Cdfrac{V\u003c/em\u003e{dw}}{1-%255Cbeta_1^t}\" alt=\"{\"\u003e{dw}= \\dfrac{V{dw}}{1-\\beta_1^t}}' data-equation-content='V^{corr}\u003cem\u003e{dw}= \\dfrac{V\u003c/em\u003e{dw}}{1-\\beta_1^t}' /\u0026gt;, \u003cimg class=\"equation_image\" title=\"V^{corr}\u003cem\u003e{db}= \\dfrac{V\u003c/em\u003e{db}}{1-\\beta_1^t}\" src=\"/equation_images/V^{corr}\u003cem\u003e{db}=%20%255Cdfrac{V\u003c/em\u003e{db}}{1-%255Cbeta_1^t}\" alt=\"{\"\u003e{db}= \\dfrac{V{db}}{1-\\beta_1^t}}' data-equation-content='V^{corr}\u003cem\u003e{db}= \\dfrac{V\u003c/em\u003e{db}}{1-\\beta_1^t}' /\u0026gt;\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"S^{corr}\u003cem\u003e{dw}= \\dfrac{S\u003c/em\u003e{dw}}{1-\\beta_2^t}\" src=\"/equation_images/S^{corr}\u003cem\u003e{dw}=%20%255Cdfrac{S\u003c/em\u003e{dw}}{1-%255Cbeta_2^t}\" alt=\"{\"\u003e{dw}= \\dfrac{S{dw}}{1-\\beta_2^t}}' data-equation-content='S^{corr}\u003cem\u003e{dw}= \\dfrac{S\u003c/em\u003e{dw}}{1-\\beta_2^t}' /\u0026gt;, \u003cimg class=\"equation_image\" title=\"S^{corr}\u003cem\u003e{db}= \\dfrac{S\u003c/em\u003e{db}}{1-\\beta_2^t}\" src=\"/equation_images/S^{corr}\u003cem\u003e{db}=%20%255Cdfrac{S\u003c/em\u003e{db}}{1-%255Cbeta_2^t}\" alt=\"{\"\u003e{db}= \\dfrac{S{db}}{1-\\beta_2^t}}' data-equation-content='S^{corr}\u003cem\u003e{db}= \\dfrac{S\u003c/em\u003e{db}}{1-\\beta_2^t}' /\u0026gt;\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W:= W- \\alpha \\dfrac{V^{corr}\u003cem\u003e{dw}}{\\sqrt{S^{corr}\u003c/em\u003e{dw}+\\epsilon}}\" src=\"/equation_images/W:=%20W-%20%255Calpha%20%255Cdfrac{V^{corr}\u003cem\u003e{dw}}{%255Csqrt{S^{corr}\u003c/em\u003e{dw}+%255Cepsilon}}\" alt=\"{\"\u003e{dw}}{\\sqrt{S^{corr}{dw}+\\epsilon}}}' data-equation-content='W:= W- \\alpha \\dfrac{V^{corr}\u003cem\u003e{dw}}{\\sqrt{S^{corr}\u003c/em\u003e{dw}+\\epsilon}}' /\u0026gt; and\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b:= b- \\alpha \\dfrac{V^{corr}\u003cem\u003e{db}}{\\sqrt{S^{corr}\u003c/em\u003e{db}+\\epsilon}}\" src=\"/equation_images/b:=%20b-%20%255Calpha%20%255Cdfrac{V^{corr}\u003cem\u003e{db}}{%255Csqrt{S^{corr}\u003c/em\u003e{db}+%255Cepsilon}}\" alt=\"{\"\u003e{db}}{\\sqrt{S^{corr}{db}+\\epsilon}}}' data-equation-content='b:= b- \\alpha \\dfrac{V^{corr}\u003cem\u003e{db}}{\\sqrt{S^{corr}\u003c/em\u003e{db}+\\epsilon}}' /\u0026gt;  \u003c/p\u003e\n\n\u003cp\u003eHyperparameters: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\beta_1 = 0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_1%20=%200.9\" alt=\"{\" data-equation-content=\"\\beta_1 = 0.9\"\u003e\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\beta_2 = 0.999\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_2%20=%200.999\" alt=\"{\" data-equation-content=\"\\beta_2 = 0.999\"\u003e\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"\\epsilon = 10^{-8}\" src=\"/equation_images/%255Cepsilon%20=%2010^{-8}\" alt=\"{\" data-equation-content=\"\\epsilon = 10^{-8}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eGenerally, only \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e gets tuned.\u003c/p\u003e\n\n\u003ch3\u003eLearning Rate Decay\u003c/h3\u003e\n\n\u003cp\u003eLearning rate decreases across epochs.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = \\dfrac{1}{1+\\text{decay_rate * epoch_nb}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%20%255Cdfrac{1}{1+%255Ctext{decay_rate%20*%20epoch_nb}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = \\dfrac{1}{1+\\text{decay_rate * epoch_nb}}* \\alpha_0\"\u003e\u003c/p\u003e\n\n\u003cp\u003eother methods:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = 0.97 ^{\\text{epoch_nb}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%200.97%20^{%255Ctext{epoch_nb}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = 0.97 ^{\\text{epoch_nb}}* \\alpha_0\"\u003e (or exponential decay)\u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\alpha = \\dfrac{k}{\\sqrt{\\text{epoch_nb}}}* \\alpha_0\" src=\"/equation_images/%255Calpha%20=%20%255Cdfrac{k}{%255Csqrt{%255Ctext{epoch_nb}}}*%20%255Calpha_0\" alt=\"{\" data-equation-content=\"\\alpha = \\dfrac{k}{\\sqrt{\\text{epoch_nb}}}* \\alpha_0\"\u003e\u003c/p\u003e\n\n\u003cp\u003eor\u003c/p\u003e\n\n\u003cp\u003eManual decay!\u003c/p\u003e\n\n\u003ch2\u003eHyperparameter Tuning\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen some optimization algorithms, take another look at all the hyperparameters that need tuning: \u003c/p\u003e\n\n\u003cp\u003eMost important:\n- \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNext:\n- \u003cimg class=\"equation_image\" title=\"\\beta\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta\" alt=\"{\" data-equation-content=\"\\beta\"\u003e (momentum)\n- Number of hidden units\n- mini-batch-size\u003c/p\u003e\n\n\u003cp\u003eFinally:\n- Number of layers\n- Learning rate decay\u003c/p\u003e\n\n\u003cp\u003eAlmost never tuned:\n- \u003cimg class=\"equation_image\" title=\"\\beta_1\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_1\" alt=\"{\" data-equation-content=\"\\beta_1\"\u003e, \u003cimg class=\"equation_image\" title=\"\\beta_2\" src=\"https://learning.flatironschool.com/equation_images/%255Cbeta_2\" alt=\"{\" data-equation-content=\"\\beta_2\"\u003e, \u003cimg class=\"equation_image\" title=\"\\epsilon\" src=\"https://learning.flatironschool.com/equation_images/%255Cepsilon\" alt=\"{\" data-equation-content=\"\\epsilon\"\u003e (Adam)\u003c/p\u003e\n\n\u003cp\u003eThings to do:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDon't use a grid, because hard to say in advance which hyperparameters will be important\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.coursera.org/learn/deep-neural-network/lecture/lXv6U/normalizing-inputs\"\u003ehttps://www.coursera.org/learn/deep-neural-network/lecture/lXv6U/normalizing-inputs\u003c/a\u003e \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum\"\u003ehttps://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum\u003c/a\u003e \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you began learning about issues regarding the convergence of neural networks training. This included the need for normalization as well as initialization parameters and some optimization algorithms. In the upcoming lab, you'll further investigate these ideas in practice and observe their impacts from various perspectives.\u003c/p\u003e","frontPage":false},{"exportId":"natural-language-processing-recap","title":"Natural Language Processing - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNLP has become increasingly popular over the past few years, and NLP researchers have achieved very insightful insights\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eThe Natural Language Tool Kit (NLTK) is one of the most popular Python libraries for NLP\u003c/li\u003e\n\u003cli\u003eRegular Expressions are an important part of NLP, which can be used for pattern matching and filtering\u003c/li\u003e\n\u003cli\u003eRegular Expressions can become confusing, so make sure to use our provided cheat sheet the first few times you work with regex\u003c/li\u003e\n\u003cli\u003eIt is strongly recommended you take some time to use regex tester websites to ensure you understand how changing your regex pattern affects your results when working towards a correct answer!\u003c/li\u003e\n\u003cli\u003eFeature Engineering is essential when working with text data, and to understand the dynamics of your text\u003c/li\u003e\n\u003cli\u003eCommon feature engineering techniques are removing stop words, stemming, lemmatization, and n-grams\u003c/li\u003e\n\u003cli\u003eWhen diving deeper into grammar and linguistics, context-free grammars and part-of-speech tagging is important\u003c/li\u003e\n\u003cli\u003eIn this context, parse trees can help computers when dealing with ambiguous words \u003c/li\u003e\n\u003cli\u003e\n\u003cem\u003eHow\u003c/em\u003e you clean and preprocess your data will have a major effect on the conclusions you'll be able to draw in your NLP classification problems \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-nlp-section-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-nlp-section-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"k-means-clustering","title":"K-means Clustering","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-k-means-clustering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about the most popular and widely-used clustering algorithm, K-means clustering. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare the different approaches to clustering networks \u003c/li\u003e\n\u003cli\u003eExplain the steps behind the K-means clustering algorithm \u003c/li\u003e\n\u003cli\u003ePerform k-means clustering in scikit-learn \u003c/li\u003e\n\u003cli\u003eExplain how clusters are evaluated \u003c/li\u003e\n\u003cli\u003eDefine an \"elbow plot\" and how to interpret it \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eClustering\u003c/em\u003e\u003c/strong\u003e techniques are among the most popular unsupervised machine learning algorithms. The main idea behind clustering is that you want to group objects into similar classes, in a way that:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eintra-class similarity is high (similarity amongst members of the same group is high)\u003c/li\u003e\n\u003cli\u003einter-class similarity is low (similarity of different groups is low)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhat does \u003cem\u003esimilarity\u003c/em\u003e mean? You should be thinking of it in terms of \u003cem\u003edistance\u003c/em\u003e, just like we did with the k-nearest-neighbors algorithm. The closer two points are, the more similar they are. It is useful to make a distinction between \u003cem\u003ehierarchical\u003c/em\u003e and \u003cem\u003enonhierarchical\u003c/em\u003e clustering algorithms:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eIn cluster analysis, an \u003cstrong\u003e\u003cem\u003eagglomerative hierarchical\u003c/em\u003e\u003c/strong\u003e algorithm starts with \u003cem\u003en\u003c/em\u003e clusters (where \u003cem\u003en\u003c/em\u003e is the number of observations, so each observation is a cluster), then combines the two most similar clusters, combines the next two most similar clusters, and so on. A \u003cstrong\u003e\u003cem\u003edivisive\u003c/em\u003e\u003c/strong\u003e hierarchical algorithm does the exact opposite, going from 1 to \u003cem\u003en\u003c/em\u003e clusters.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eA \u003cstrong\u003e\u003cem\u003enonhierarchical\u003c/em\u003e\u003c/strong\u003e algorithm chooses \u003cem\u003ek\u003c/em\u003e initial clusters and reassigns observations until no improvement can be obtained. How initial clusters and reassignments are done depends on the specific type of algorithm.\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAn essential understanding when using clustering methods is that you are basically trying to group data points together without knowing what the \u003cem\u003eactual\u003c/em\u003e cluster/classes are. This is also the main distinction between clustering and classification (which is a supervised learning method). This is why technically, you also don't know how many clusters you're looking for.\u003c/p\u003e\n\n\u003ch2\u003eNon-Hierarchical Clustering With K-Means Clustering\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eK-means clustering\u003c/em\u003e\u003c/strong\u003e is the most well-known clustering technique, and it belongs to the class of non-hierarchical clustering methods. When performing k-means clustering, you're essentially trying to find \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e cluster centers as the mean of the data points that belong to these clusters. One challenging aspect of k-means is that the number \u003cem\u003ek\u003c/em\u003e needs to be decided upon before you start running the algorithm.\u003c/p\u003e\n\n\u003cp\u003eThe k-means clustering algorithm is an iterative algorithm that reaches for a pre-determined number of clusters within an unlabeled dataset, and basically works as follows:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eSelect \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e initial seeds \u003c/li\u003e\n\u003cli\u003eAssign each observation to the cluster to which it is \"closest\"\u003c/li\u003e\n\u003cli\u003eRecompute the cluster centroids\u003c/li\u003e\n\u003cli\u003eReassign the observations to one of the clusters according to some rule\u003c/li\u003e\n\u003cli\u003eStop if there is no reallocation \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eTwo assumptions are of main importance for the k-means clustering algorithm:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eTo compute the \"cluster center\", you calculate the (arithmetic) mean of all the points belonging to the cluster.  Each cluster center is recalculated in the beginning of each new iteration\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eAfter the cluster center has been recalculated, if a given point is now closer to a different cluster center than the center of its current cluster, then that point is reassigned to the closest center \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2\u003eVisualization of K-means Clustering Algorithm\u003c/h2\u003e\n\n\u003cp\u003eIn the animation below, the green dots are the centroids. Notice how they are randomly assigned at the beginning, and shift with each iteration as they are recalculated to match the center of the points assigned to their cluster. The clustering ends when the centroids find a position in which points are no longer reassigned, meaning that the centroids no longer need to move. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/good-centroid-start.gif\" alt=\"k-means clustering animation\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eImplementing K-means Clustering in scikit-learn\u003c/h2\u003e\n\n\u003cp\u003eImplementing k-means clustering with scikit-learn is quite simple because the API mirrors the same functionality that we've seen before. The same preprocessing steps used for supervised learning methods are required -- missing values must be dealt with and all data must be in numerical format (meaning that non-numerical columns must be dropped or one-hot encoded). \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.cluster\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eKMeans\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Set number of clusters at initialization time\n\u003c/span\u003e\u003cspan class=\"n\"\u003ek_means\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eKMeans\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en_clusters\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Run the clustering algorithm\n\u003c/span\u003e\u003cspan class=\"n\"\u003ek_means\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Generate cluster index values for each row\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecluster_assignments\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ek_means\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# Cluster predictions for each point are also stored in k_means.labels_\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eEvaluating Cluster Fitness\u003c/h2\u003e\n\n\u003cp\u003eRunning K-means on a dataset is easy enough, but how do we know if we have the best value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e?  The best bet is to use an accepted metric for evaluating cluster fitness such as \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html\"\u003e\u003cstrong\u003e\u003cem\u003eCalinski Harabasz Score\u003c/em\u003e\u003c/strong\u003e\u003c/a\u003e, which is more often referred to by a simpler, \u003cstrong\u003e\u003cem\u003eVariance Ratio\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eComputing Variance Ratios\u003c/h3\u003e\n\n\u003cp\u003eThe \u003cem\u003evariance ratio\u003c/em\u003e is a ratio of the variance of the points within a cluster, to the variance of a point to points in other clusters. Intuitively, we can understand that we want intra-cluster variance to be low (suggesting that the clusters are tightly knit), and inter-cluster variance to be high (suggesting that there is little to no ambiguity about which cluster the points belong to). \u003c/p\u003e\n\n\u003cp\u003eWe can easily calculate the variance ratio by importing a function from scikit-learn to calculate it for us, as shown below. To use this metric, we just need to pass in the points themselves, and the predicted labels given to each point by the clustering algorithm. The higher the score, the better the fit.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# This code builds on the previous example\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.metrics\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ecalinski_harabasz_score\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Note that we could also pass in k_means.labels_ instead of cluster_assignments\n\u003c/span\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecalinski_harabasz_score\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_df\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecluster_assignments\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThere are other metrics that can also be used to evaluate the fitness, such as \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score\"\u003eSilhouette Score\u003c/a\u003e. No one metric is best -- they all have slightly different strengths and weaknesses depending on the given dataset and goals. Because of this, it's generally accepted that it's best to pick one metric and stick to it. \u003c/p\u003e\n\n\u003ch3\u003eFinding the Optimal Value of K\u003c/h3\u003e\n\n\u003cp\u003eNow that we have a way to evaluate how well our clusters fit the dataset, we can use this to find the optimal value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e. The best way to do this is to create and fit different k-means clustering objects for every value of \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e that we want to try, and then compare the variance ratio scores for each. \u003c/p\u003e\n\n\u003cp\u003eWe can then visualize the scores using an \u003cstrong\u003e\u003cem\u003eElbow Plot\u003c/em\u003e\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_elbow-method.png\" alt=\"Calinski Harabaz scores for different values of k\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAn \u003cem\u003eelbow plot\u003c/em\u003e is a general term for plots like this where we can easily see where we hit a point of diminishing returns. In the plot above, we can see that performance peaks at \u003cem\u003ek=6\u003c/em\u003e, and then begins to drop off. That tells us that our data most likely has 6 naturally occurring clusters in our data. \u003c/p\u003e\n\n\u003cp\u003eElbow plots aren't exclusively used with variance ratios -- it's also quite common to calculate something like distortion (another clustering metric), which will result in a graph with a negative as opposed to a positive slope. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_elbow_2.png\" alt=\"the elbow method showing the optimal k\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003ch4\u003eUnderstanding the Elbow\u003c/h4\u003e\n\n\u003cp\u003eA note on elbow plots: higher scores aren't always better. Higher values of \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e mean introducing more overall complexity -- we will sometimes see elbow plots that look like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-k-means-clustering/master/images/new_dim_returns.png\" alt=\"plot with the number of clusters on the x-axis and the sum of squared distances to cluster center on the y-axis\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, although k=20 technically scores better than k=4, we choose k=4 because it is the \u003cstrong\u003e\u003cem\u003eElbow\u003c/em\u003e\u003c/strong\u003e on the graph. After the elbow, the metric we're trying to optimize for gets better at a much slower rate. Dealing with 20 clusters, when the fit is only slightly better, isn't worth it -- it's better to treat our data as having only 4 clusters, because that is the simplest overall model that provides the most value with the least complexity!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about different kinds of clustering and explored how the k-means clustering algorithm works. We also learned about how we can quantify the performance of a clustering algorithm using metrics such as variance ratios, and how we can use these metrics to find the optimal value for \u003cimg class=\"equation_image\" title=\"k\" src=\"https://learning.flatironschool.com/equation_images/k\" alt=\"{\" data-equation-content=\"k\"\u003e by creating elbow plots!\u003c/p\u003e","frontPage":false},{"exportId":"recommendation-systems-introduction","title":"Recommendation Systems - Introduction","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommender-section-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommender-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommender-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about machine learning algorithms that we encounter every day in our lives:  recommendation systems! \u003c/p\u003e\n\n\u003ch2\u003eRecommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll learn about recommendation system modeling approaches and implementations.\u003c/p\u003e\n\n\u003cp\u003eA recommendation system allows predicting the future preference list for a certain customer or user, and recommends the top preference for this user. Examples include: which books would a customer prefer to buy on Amazon, which Netflix movie or series would a user watch next, etc. You'll learn about several different types of recommendation system algorithms and how they work.\u003c/p\u003e\n\n\u003ch2\u003eMatrix Factorization\u003c/h2\u003e\n\n\u003cp\u003eUnder the hood, many recommendation system algorithms use matrix factorization. This can be accomplished using techniques such as Singular Value Decomposition (SVD) and Alternating Least Squares (ALS), which you'll learn about in this section.\u003c/p\u003e\n\n\u003ch2\u003eImplementing Recommender Systems with \u003ccode\u003esurprise\u003c/code\u003e\u003c/h2\u003e\n\n\u003cp\u003e\u003ccode\u003esurprise\u003c/code\u003e is a library that is optimized to efficiently create recommendations. You'll get a chance to use this library to code up different implementations of collaborative filtering recommendation systems.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the basics of recommendation systems and how to implement them in \u003ccode\u003esurprise\u003c/code\u003e!\u003c/p\u003e","frontPage":false},{"exportId":"word-embeddings","title":"Word Embeddings","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll learn about the concept of \u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e, and how you can use them to model the semantic meanings of words in a high-dimensional embedding space!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDemonstrate how word vectors are structured \u003c/li\u003e\n\u003cli\u003eCompare and contrast word vector embeddings with other text vectorization strategies \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat Are Word Embeddings?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e are a type of vectorization strategy that computes word vectors from a text corpus by training a neural network, which results in a high-dimensional embedding space, where each word in the corpus is a unique vector in that space. In this embedding space, the position of the vector relative to the other vectors captures semantic meaning. This method of creating distributed representations of words in a high-dimensional embedding space was first introduced in a landmark paper from members of the Google Brain team in 2013 at the Neural Information Processing Systems (NeurIPS, for short). You can read the full paper from Mikolov et al by following \u003ca href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\"\u003ethis link\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCapturing Semantic Relationships\u003c/h3\u003e\n\n\u003cp\u003eSo far, the vectorization strategies you've learned have focused only on how often a word appears in a given text, but they don't focus at all on capturing the semantic meaning. This is one area where using the Word2Vec model to create \u003cstrong\u003e\u003cem\u003eWord Vector Embeddings\u003c/em\u003e\u003c/strong\u003e really shines, because it will capture those semantic relationships between words, for instance, a Word2Vec model that is given enough data and training will learn that there is a semantic relationship between the word 'person' and 'people'. Furthermore, vector one would need to travel to get from the singular 'person' to the plural 'people' will be the same vector that will get you from the singular version of a word to it's plural - meaning that our model will 'learn' how to model the relationship between singular and plural versions of the same word. Take a look at the examples below:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-word-embeddings/master/images/embeddings.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs you can see in the diagram above, the embedding space shows that the model has positioned the words 'king' and 'queen' in the same relationship that the vector 'man' has to 'woman'. The vector that gets you from 'king' to 'queen' or from 'man' to 'woman' is the vector for gender! You can see other examples show that the model also learns representations for verb tense, or even for countries and their capitals. This is more impressive when you realize that the model learns these relationships from reading a large enough corpus of text, without being given an explicit direction or instruction - that is, the researchers did not expressly feed the model sentences like \"Madrid is the capital of Spain\".  \u003c/p\u003e\n\n\u003cp\u003eSince the words are all embedded in the same high-dimensional space, you can use the same similarity metrics you've used before, such as things like \u003cem\u003eCosine Similarity\u003c/em\u003e or even \u003cem\u003eEuclidean Distance\u003c/em\u003e. In a future lab, you'll experiment with using a trained Word2Vec model for tasks like finding the most similar word(s) to a given word. Trained Word2Vec models also excel at things like the analogies questions that were made famous by the SAT test.\u003c/p\u003e\n\n\u003cp\u003eLet's end this lesson by taking a look at how the word vectors are actually structured. \u003c/p\u003e\n\n\u003ch2\u003eA Small Example\u003c/h2\u003e\n\n\u003cp\u003eSo far, you've learned vectorization strategies such as \u003cem\u003eCount Vectorization\u003c/em\u003e and \u003cem\u003eTF-IDF Vectorization\u003c/em\u003e. Recall that the vectors created by these algorithms are \u003cstrong\u003e\u003cem\u003eSparse Vectors\u003c/em\u003e\u003c/strong\u003e. The length of a vector created by TF-IDF or Count Vectorization is the length of the total vocabulary of the text corpus. In these vectors, the vast majority of elements in the vector are 0, which is a massive waste of space, and a ton of extra dimensionality that can hurt our model's performance (recall the \u003cstrong\u003e\u003cem\u003eCurse of Dimensionality\u003c/em\u003e\u003c/strong\u003e)! If you were to use TF-IDF vectorization to turn the word 'apple' into a vector representation with a text corpus containing 100,000 words, then our word vector would contain a value at the element that corresponds to the word 'apple', and then 99,999 \u003cem\u003e0\u003c/em\u003es!\u003c/p\u003e\n\n\u003cp\u003eVectors created through word embeddings are different - the size of the vector is a tunable parameter you can set. \u003c/p\u003e\n\n\u003cp\u003eLet's look at a toy example. Consider the diagram below. First, pay attention to what each of the columns mean. Let's assume that you built a model to 'rate' each of the animals across each of these four categories, relative to one another.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-word-embeddings/master/images/vectors.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn this embedding space, the vectorized representation of the word 'dog' would be \u003ccode\u003e[-0.4, 0.37, 0.02, -0.34]\u003c/code\u003e. As you'll see when you study the actual Word2Vec model, you can use some nifty tricks to train a neural network to act as a sort of 'lookup table', where you can get the vector out for any given word. In the next lesson, you'll spend a bit more time understanding exactly how the model learns the correct values for each word. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about the concept of \u003cstrong\u003e\u003cem\u003eWord Embeddings\u003c/em\u003e\u003c/strong\u003e, and explored how they work. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-word-embeddings\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-word-embeddings\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-word-embeddings/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"introduction-to-recommendation-systems","title":"Introduction to Recommendation Systems","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-recommendation-system-introduction\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-system-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-recommendation-system-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson will give you a brief introduction to recommendation system modeling approaches. We will develop intuition into how these systems work and how collaborative filtering is used to make accurate recommendation systems that can harness the power of big data.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the role and rationale for recommendation systems \u003c/li\u003e\n\u003cli\u003eDescribe collaborative filtering recommender systems and their benefits/limitations \u003c/li\u003e\n\u003cli\u003eDescribe content-based recommenders and their benefits/limitations \u003c/li\u003e\n\u003cli\u003eDefine implicit and explicit rating systems \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eProblem Domain\u003c/h2\u003e\n\n\u003cp\u003eThe goal of a recommendation system is to expose people to items that they will like. In exact terms, a recommendation system predicts the future preference of a set of items for a user, and recommends the top items from this set. In today's world, due to the internet and its global reach, people have more options to choose from than ever before.\u003c/p\u003e\n\n\u003cp\u003eConsider buying an album from a traditional music store where the options are always limited and mainly depend upon size and type of the store. There is a physical limitation to how many songs, albums, and artists can be offered. An online product like Spotify, however has a much higher ceiling in terms of storage space. With this new method of selecting products, recommendation systems are a popular way for users to sort through millions of songs to find the ones that are customized exactly for them. Recommendation systems cast a direct impact on profitability and customer satisfaction for most businesses today. With the nearly limitless options consumers have for products online, they need some guidance!\u003c/p\u003e\n\n\u003cp\u003eThis idea can be represented by a concept called the \"Long Tail,\" which is a set of statistical distributions that have a very long \"tail\" of the distribution, representing many occurrences of low frequency things. In the context of consumer products, there are some products that everyone is going to buy: light bulbs, toilet paper, bread etc. There are also items that are far more obscure: specific toys, sports equipment, movies. Recommendation systems are made to help consumers tap into this long tail to assist them in picking from the endless number of options that are made available to them via the internet.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/LongTailConcept.png\" alt=\"graph showing products on the x-axis and popularity on the y-axis. a few products are very popular, labeled Head. many other products are not very popular, labeled Long Tail\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's a formal definition of recommendation systems from authors \u003ca href=\"https://misq.org/e-commerce-product-recommendation-agents-use-characteristics-and-impact.html\"\u003eBo Xiao and Izak Benbasat, 2017\u003c/a\u003e\n :\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRecommendation Systems are software agents that elicit the interests and preferences of individual consumers [‚Ä¶] and make recommendations accordingly. They have the potential to support and improve the quality of the\ndecisions consumers make while searching for and selecting products online.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch2\u003eApplications of Recommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eLet's understand what all recommendation systems can do for businesses:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eHelp in suggesting the merchants/items which a customer might be interested in after buying a product in a marketplace \u003c/li\u003e\n\u003cli\u003eEstimate profit \u0026amp; loss of many competing items and make recommendations to the customer (e.g. buying and selling stocks)\u003c/li\u003e\n\u003cli\u003eBased on the experience of the customer, recommend a customer centric or product centric offering\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eEnhance customer engagement by providing offers which can be highly appealing to the customer \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRecommendation Systems Approaches\u003c/h2\u003e\n\n\u003cp\u003eThere are two main types of recommendation systems: unpersonalized and personalized. In the majority of this section, we will focus on personalized recommendation systems because that's where data scientists can provide the most value to companies, but to start off, let's investigate some unpersonalized systems because they can be productive in their own right.\u003c/p\u003e\n\n\u003ch3\u003eUnpersonalized Recommendations\u003c/h3\u003e\n\n\u003cp\u003eUnpersonalized recommendation systems have been happening since way before machine learning was ever in the public knowledge base. An example of an unpersonalized recommendation would be on YouTube when it recommends the most viewed videos. These are videos that the most people have watched. For the most part, these recommendations aren't too bad. After all, there's a reason why things are popular. This approach, however, is not going to help more niche videos get exposure. It also won't be immensely beneficial to those who have very particular tastes. Of course, there are times when a simple approach like this might be best. An example of a simple popularity recommender working well is with the news. There's a high chance that everyone who visits a news website is going to want to see whatever is the most popular at that moment in time.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/news.png\" alt=\"home page of the New York Times\" width=\"900\"\u003e\u003c/p\u003e\n\n\u003cp\u003eBecause unpersonalized recommendations are based on the entire user pool, whatever item is the most popular at any given time would be recommended to you, even if it's something you are completely uninterested in. There are so many items that are far too obscure to be the \"most popular\" item that might make someone's day. To make more informed recommendations, personalized recommendation systems make use of big data to ensure that users are getting items tailored towards there personal interests, no matter how niche they are.\u003c/p\u003e\n\n\u003ch3\u003ePersonalized Recommendations\u003c/h3\u003e\n\n\u003cp\u003eThe general problem of personalized recommendation systems can be summarized as:\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eGiven\u003c/strong\u003e: \nThe profile of the \"active\" user and possibly some situational context, i.e. user browsing a product or making a purchase etc. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eRequired\u003c/strong\u003e:\nCreating a set of items, and a score for each recommendable item in that set\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eProfile\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cp\u003eUser profile may contain past purchases, ratings in either implicit or explicit form, demographics and interest scores for item features \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThere are two ways to gather such data. The first method is to ask for explicit ratings from a user, typically on a concrete rating scale (such as rating a movie from one to five stars). The second is to gather data implicitly as the user is in the domain of the system - that is, to log the actions of a user on the site.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cstrong\u003eProblem\u003c/strong\u003e:\nWe want to learn a function that predicts the relevance score for a given (typically unseen) item based on user user profile and context \u003c/p\u003e\n\n\u003cp\u003eWithin personalized recommendation systems there are many different possible algorithms. We're going to go over the important ones now.\u003c/p\u003e\n\n\u003cp\u003eEach of these techniques make use of different similarity metrics to determine how \"similar\" items are to one another. The most common similarity metrics are \u003ca href=\"https://en.wikipedia.org/wiki/Euclidean_distance\"\u003eEuclidean distance\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Cosine_similarity\"\u003ecosine similarity\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\"\u003ePearson correlation\u003c/a\u003e and the \u003ca href=\"https://en.wikipedia.org/wiki/Jaccard_index\"\u003eJaccard index (useful with binary data)\u003c/a\u003e. Each one of these distance metrics has its advantages and disadvantages depending on the type of ratings you are using and the characteristics of your data.\u003c/p\u003e\n\n\u003ch3\u003eContent-Based Recommenders\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eMain Idea\u003c/strong\u003e: If you like an item, you will also like \"similar\" items.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/content_based.png\" alt=\"content based filtering. user watches movies, then similar movies are recommended to the user\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThese systems are based on the characteristics of the items themselves. If you ever see a banner ad saying \"try other items like this\", it is most likely a content-based recommender system. The advantage of a content-based recommender system is that it is a recommender system that gives the user a bit more information as to why they are seeing these recommendations. If they are on a page of a book they very much like, they will be happy to see another book that is similar to it. If they are told that this book is similar to their favorite book, they're more than likely to get that book. A disadvantage of content-based recommender systems is that they often require manual or semi-manual tagging of each of products. More advanced versions of content-based recommender systems allow for the development of an average of all the items a user has liked. This allows for a more nuanced approach to incorporate more than one item when calculating which items are most similar.\u003c/p\u003e\n\n\u003ch3\u003eCollaborative Filtering Systems\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eMain Idea\u003c/strong\u003e: If user A likes items 5, 6, 7, and 8 and user B likes items 5, 6, and 7, then it is highly likely that user B will also like item 8.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-recommendation-system-introduction/master/images/collaborative_filtering.png\" alt=\"collaborative filtering: movies watched by both users indicate that the users are similar, then movies are recommended by one user to another user\" width=\"450\"\u003e\u003c/p\u003e\n\n\u003cp\u003eCollaborative filtering systems use a collection of user rating of items to make recommendations. The issue with collaborative filtering is that you have what is called the \"cold start problem.\" The idea behind it is, how to recommend something based off of user activity if you do not have any user activity to begin with! This can be overcome through various techniques. The most important thing to realize is that there is no one best recommendation system technique. In the end, what matters most is what system actually gets people to get recommendations that they will act upon. It might be that on the aggregate, recommending the most popular items is the most cost effective way to introduce users to new products. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eThe key idea behind collaborative filtering is that similar users share similar interests and that users tend to like items that are similar to one another.\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003eWhile this may not be completely true on every occasion, if we have a large enough dataset, if there are patterns present, they will start to emerge.\nAssume there are some users who have bought certain items, we can use a matrix with size \u003cimg class=\"equation_image\" title=\"\\text{num_users} * \\text{num_items}\" src=\"/equation_images/%255Ctext{num_users}%20*%20%255Ctext{num_items}\" alt=\"{\" data-equation-content=\"\\text{num_users} * \\text{num_items}\"\u003e to denote the past behavior of users. Each cell in the matrix represents the associated opinion that a user holds. Such a matrix is called a \u003cstrong\u003eUtility Matrix\u003c/strong\u003e. For instance, \u003cimg class=\"equation_image\" title=\"M_{i, j}\" src=\"/equation_images/M_{i,%20j}\" alt=\"{\" data-equation-content=\"M_{i, j}\"\u003e denotes how user \u003cimg class=\"equation_image\" title=\"u\" src=\"https://learning.flatironschool.com/equation_images/u\" alt=\"{\" data-equation-content=\"u\"\u003e likes item \u003cimg class=\"equation_image\" title=\"i\" src=\"https://learning.flatironschool.com/equation_images/i\" alt=\"{\" data-equation-content=\"i\"\u003e. Sometimes these individual ratings are written as \u003cimg class=\"equation_image\" title=\"r_{ui}\" src=\"/equation_images/r_{ui}\" alt=\"{\" data-equation-content=\"r_{ui}\"\u003e for a rating for a given user and a given item. Using the table below as a reference point, if we replaced the \u003cimg class=\"equation_image\" title=\"u\" src=\"https://learning.flatironschool.com/equation_images/u\" alt=\"{\" data-equation-content=\"u\"\u003e and \u003cimg class=\"equation_image\" title=\"i\" src=\"https://learning.flatironschool.com/equation_images/i\" alt=\"{\" data-equation-content=\"i\"\u003e variable subscripts with actual values it would look like \u003cimg class=\"equation_image\" title=\"r_{\\text{Mike},\\text{Little Mermaid}} = 3\" src=\"/equation_images/r_{%255Ctext{Mike},%255Ctext{Little%20Mermaid}}%20=%203\" alt=\"{\" data-equation-content=\"r_{\\text{Mike},\\text{Little Mermaid}} = 3\"\u003e.\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eToy Story\u003c/th\u003e\n\u003cth\u003eCinderella\u003c/th\u003e\n\u003cth\u003eLittle Mermaid\u003c/th\u003e\n\u003cth\u003eLion King\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eMatt\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLore\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e4\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMike\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e3\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eForest\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTaylor\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eThe task of a recommendation system would be to come up with ratings for users in the spots that are currently empty. As you can imagine, most of the time, these values will be largely empty. For user 1, our recommendation system would try to predict what user 1 would rate Toy Story and the Little Mermaid and then recommend whichever product our model predicts they would rate the highest. The utility matrix above is what's known as an explicit rating. Each person has rated the movies that they've seen. Frequently, we must infer some meaning from the data and use our own judgment to determine how to use it for a recommendation system. Assume that rather than ratings, we only knew whether or not users bought a movie from a streaming website. Let's take a look at what this table would look like:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eToy Story\u003c/th\u003e\n\u003cth\u003eCinderella\u003c/th\u003e\n\u003cth\u003eLittle Mermaid\u003c/th\u003e\n\u003cth\u003eLion King\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eMatt\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLore\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMike\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eForest\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTaylor\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eThese are \u003cstrong\u003eimplicit\u003c/strong\u003e ratings because we are assuming that because a person has bought something, they would like to buy other items like it. Of course, this is not necessarily true, but it's better than nothing!\u003c/p\u003e\n\n\u003cp\u003eWithin the domain of collaborative filtering, there are both memory-based approaches and model-based approaches that you will learn about in the upcoming lessons.\u003c/p\u003e\n\n\u003ch2\u003eFurther Reading\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"http://infolab.stanford.edu/%7Eullman/mmds/ch9.pdf\"\u003eChapter 9: Mining of Massive Datasets (MMDS)\u003c/a\u003e - A must read for in-depth knowledge about how recommendation systems work, their underlying algorithms and evaluation approaches. This covers most of the topic from this lesson and also the upcoming lessons in great detail. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at an overview of recommendation systems. Focusing on collaborative filtering systems, we will move on to developing user-based engines. \u003c/p\u003e","frontPage":false},{"exportId":"market-segmentation-with-clustering","title":"Market Segmentation with Clustering","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we'll learn about one of the most popular use cases for clustering in the business world -- market segmentation!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain market segmentation and how clustering can be used for it\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eWhat is Market Segmentation?\u003c/h2\u003e\n\u003cp\u003ePerhaps the most common use case for clustering algorithms in the real world, \u003cstrong\u003e\u003cem\u003eMarket Segmentation\u003c/em\u003e\u003c/strong\u003e refers to using \u003cstrong\u003e\u003cem\u003eCluster Analysis\u003c/em\u003e\u003c/strong\u003e to segment a customer base into different \u003cem\u003emarket segments\u003c/em\u003e using the clustering techniques we've learned.\u003c/p\u003e\n\u003cp\u003eConsider the following scenario: You're a movie executive, and you have a new superhero film coming out. You need to decide how to best allocate your advertising budget in order to attract the most customers. This film is a sequel, so you have good demographic data on who went to see the last film. The advertising options available to you are TV, newspaper, radio, and internet. How do you best allocate your advertising budget to ensure that the movie does as well as possible?\u003c/p\u003e\n\u003cp\u003eThe answer depends on your data. A regression analysis on last year's data can give you a general idea of how much you can expect to make overall, assuming that there aren't major differences between last year and this year. However, regression just tells you what you can expect \u003cem\u003eoverall\u003c/em\u003e -- what if we're trying to optimize where we spend our money, rather than just predict what the returns will be, based on the overall amount of money we spent?\u003c/p\u003e\n\u003cp\u003eThe answer lies in knowing who your customer is. All forms of advertising are not consumed equally by every age group or demographic. By identifying \u003cstrong\u003e\u003cem\u003esegments\u003c/em\u003e\u003c/strong\u003e in our customer data, we can look for trends that identify one group or another, and create personalized regression models for each group.\u003c/p\u003e\n\u003cp\u003eIn order to understand this better, let's take a sample question that market segmentation can help us answer. For our TV advertising budget, we still have to decide what channel to run our commercials on. What effect will advertising on the Disney channel have on a person's likelihood of coming to see our superhero movie? If the person in question is 12 years old, then it's probably very likely that our commercial convinces this person to see our movie. But what about if they're 68 years old? In that case, advertising during a cartoon on the Disney channel might not be the most effective way to reach that person. If we're worried about reaching this customer, the first question we should ask is what kind of customer they are. In the case of a superhero movie, we can likely assume that all things equal, a 12-year-old child is more likely to be interested in seeing a superhero movie after seeing our commercial than a 68-year-old, so we should probably pay attention to what the data tells us about how 12-year-olds are affected by each type of media advertisement we can use!\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_old-man-little-boy-talking.png\" width=\"600\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTwo potential customers deep in conversation about what movie to see\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eYou can bet that movie studio executives have complex, well-defined models to predict their Return on Investment (RoI) for things as granular as advertising on Disney, versus advertising on the History channel. This is because different market segments of customers behave differently, and market segmentation allows us to zoom in on those groups!\u003c/p\u003e\n\u003ch3\u003eIdentifying Market Segmentation\u003c/h3\u003e\n\u003cp\u003eAt the most basic level, market segmentation allows us to look at our data and identify which customers belong to which groups. Once we have this information, we can examine each individual segment and use it to answer important questions and build individual, targeted models for each segment.\u003c/p\u003e\n\u003cp\u003eOnce we understand our market segments, then we can begin making informed decisions that are specific to each segment. So how do we find these market segments?\u003c/p\u003e\n\u003cp\u003eWith clustering, of course! By definition, market segments are groups within our dataset with substantive differences between them. A segment only matters to us if it is different from other groups -- we don't really care about identifying the segment of children with red hair versus children with brown hair in our data if they both act the same way and have the same level of interest in our movie. Before data scientists became commonplace, this sort of segmentation was usually handled by marketers using their intuition about their customer base to create \u003cem\u003ecustomer personas\u003c/em\u003e, and then seek out data to back up their assumptions. As data scientists, we know that the best option is not to seek data to confirm our beliefs -- instead, it is to pull our beliefs from evidence in the data. Clustering provides a great way for us to allow the data to tell us what is and isn't significant -- lest we get caught up chasing down market segments that aren't actually all that different -- or worse, don't actually exist at all!\u003c/p\u003e\n\u003ch2\u003eSegmentation and Targeting\u003c/h2\u003e\n\u003cp\u003eIn modern business analytics, segmentation is only the first step.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_marketing-strategy.png\" width=\"700\"\u003e\u003c/p\u003e\n\u003cp\u003eAfter we've identified the different market segments, the next step is to build individualized strategies to \u003cstrong\u003e\u003cem\u003eTarget\u003c/em\u003e\u003c/strong\u003e them! In the movie example we used above, we would first start by answering questions such as \"which market segment is most valuable to us?\" This can be answered through research or through analyzing our data, or a combination of both. Once we realized that the 12-to-18-year-old demographic is most valuable to us, we can then decide how to target them in the most effective way possible. This brings us back to our earlier question -- how do we allocate our advertising budget? If we've used regression to determine that we're most likely to get the return on investment for our advertising dollars with the 12-to-18-year-old age group, then our next step is to determine which ad channels are most effective to us. We'll likely find that TV advertisements and internet ads are very effective at reaching this particular market segment, but radio is less effective (since a solid portion of the target segment can't yet drive), and newspaper ads are unlikely to reach them at all (because when is the last time you saw a 12-year-old read a newspaper?).\u003c/p\u003e\n\u003cp\u003eThe third step in this process is a bit outside the scope of clustering. This is where the marketing team really shines -- figuring out how to position our product to make it both as desirable as possible to a given segment, while also making our product stand out from competitors.\u003c/p\u003e\n\u003cp\u003eLet's look at one more example to consider what this looks like: car advertisements!\u003c/p\u003e\n\u003cp\u003eScenario: You are the newest data scientist at Tesla Motors. Next year, you are introducing a new SUV in the $30-50k price range. The SUV is roomy, spacious, fast, and affordable, in addition to having a very high safety rating and a ton of technological bells and whistles. One day, Elon Musk asks you (presumably, on Twitter) who your valuable market segments are, and what parts of the car he should highlight in several upcoming interviews. How do you answer this question?\u003c/p\u003e\n\u003cp\u003ePresumably, the first thing you would do is to look at the results of your market segmentation and identify the most profitable market segments to target. Once you know who these segments are, you can target them with ads -- but this only brings us to the second step in our diagram above. The third step means personalizing these ads to have maximum impact on a given targeted segment. Is your target market middle-class families? Then maybe it makes sense to highlight the car's affordability, space, and safety rating. What about if your target is upper-middle-class customers between 30 and 40 years of age that enjoy luxury cars? In that case, you'd probably focus on the speed, luxury, and looks of the car, because they're more likely to care about these qualities than the others.\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-market-segmentation-clustering/master/images/new_market_seg.png\" width=\"70%\" height=\"70%\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eWhen you know your market segment, you can market to them in the most effective way possible!\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eStep 3 in this process is usually done with the help of survey data, under the umbrella of \u003cem\u003eUser Research\u003c/em\u003e. This is not something that data scientists typically have to worry about too much, as it is a different domain of expertise. However, the first two stages are very much something that data scientists can expect to do multiple times in their career!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we learned about how cluster analysis can be applied to determine market segmentation, and how these market segments are used in the real world to plan and execute effective business strategies!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\n\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" title=\"Thumbs up!\" alt=\"thumbs up\" data-repository=\"dsc-market-segmentation-clustering\"\u003e\u003cimg id=\"thumbs-down\" title=\"Thumbs down!\" alt=\"thumbs down\" data-repository=\"dsc-market-segmentation-clustering\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\n\u003c/footer\u003e","frontPage":false},{"exportId":"using-word2vec","title":"Using Word2Vec","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll take a look at how the \u003cstrong\u003e\u003cem\u003eWord2Vec\u003c/em\u003e\u003c/strong\u003e model actually works, and then learn how you can make use of Word2Vec using the open-source \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the tunable parameters of a Word2Vec model \u003c/li\u003e\n\u003cli\u003eDescribe the architecture of the Word2Vec model \u003c/li\u003e\n\u003cli\u003eTrain a Word2Vec model and transform words into vectors \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eHow Word2Vec Works\u003c/h2\u003e\n\n\u003cp\u003eBy now, you've gained an understanding of what a word embedding space is, and you've learned a little bit about how the words are represented as Dense vectors. However, we haven't touched on how the model actually learns the correct values for all the word vectors in the embedding space. To put it another way, how does the Word2Vec model learn exactly \u003cem\u003ewhere\u003c/em\u003e to embed each word vector inside the high dimensional embedding space?\u003c/p\u003e\n\n\u003cp\u003eNote that this explanation will stay fairly high-level, since you don't actually need to understand every part of how the Word2Vec model works in order to use it effectively for Data Science tasks. If you'd like to dig deeper in to how the model actually works, we recommend you start by reading this tutorial series from Chris McCormick (\u003ca href=\"http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\"\u003epart 1\u003c/a\u003e and \u003ca href=\"http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\"\u003epart 2\u003c/a\u003e), and then moving onto the actual \u003ca href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\"\u003eWord2Vec White Paper by Mikolov et al\u003c/a\u003e. The graphics used in this lesson are actually from Chris McCormick's excellent blog posts explaining how Word2Vec actually works.\u003c/p\u003e\n\n\u003ch3\u003eWindow Size and Training Data\u003c/h3\u003e\n\n\u003cp\u003eAt its core, Word2Vec is just another deep neural network. It's not even a particularly complex neural network -- the model contains an input layer, a single hidden layer, and and an output layer that uses the softmax activation function, meaning that the model is meant for multiclass classification. The model examines a \u003cstrong\u003e\u003cem\u003ewindow\u003c/em\u003e\u003c/strong\u003e of words, which is a tunable parameter that you can set when working with the model. Let's take a look at a graphic that explains how this all actually looks on a real example of data:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/training_data.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, the model has a window size of 5, meaning that the model considers a word, and the two words to the left and right of this word.  \u003c/p\u003e\n\n\u003ch3\u003eThe Skip-Gram Architecture\u003c/h3\u003e\n\n\u003cp\u003eSo what exactly is this deep neural network predicting?\u003c/p\u003e\n\n\u003cp\u003eThe most clever thing about the Word2Vec model is the type of problem it trains the network to solve, which creates the dense vectors for every word as a side effect! A typical task for a neural network is sentence completion. A trained model should be able to take in a sentence like \"the cat sat on the\" and output the most likely next word in the sentence, which should be something like \"mat\", or \"floor\". This is a form of \u003cstrong\u003e\u003cem\u003eSequence Generation\u003c/em\u003e\u003c/strong\u003e. Given a certain context (the words that came before), the model should be able to generate the next most plausible word (or words) in the sequence. \u003c/p\u003e\n\n\u003cp\u003eWord2Vec takes this idea, and flips it on its head. Instead of predicting the next word given a context, the model trains to predict the context surrounding a given word! This means that given the example word \"fox\" from above, the model should learn to predict the words \"quick\", \"brown\", \"jumps\", and \"over\", although crucially, not in any particular order. You're likely asking yourself why a model like this would be useful -- there are a massive amount of correct contexts that can surround a given word, which means that the output trained model itself likely isn't very useful to us. This intuition is correct -- the \u003cem\u003eoutput\u003c/em\u003e of the model is pretty useless to us.  However, in the case of Word2Vec, it's not the model that we're interested in. It turns out that by training to predict the context window for a given word, the neurons in the hidden layer end up learning the embedding space!  This is the reason why the size of the word vectors output by a Word2Vec model are a parameter that you can set ourselves. If you want word vectors of size 300, then you just include 300 neurons in our hidden layer. If you want vectors of size 100, then you include 100 neurons, and so on. Take a look at the following diagram of the Word2Vec model's architecture:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/new_skip_gram_net_arch.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eHidden Layers as a \"Lookup Table\"\u003c/h3\u003e\n\n\u003cp\u003eTo recap, the Word2Vec model learns to solve a \"fake\" problem, which you don't actually care about. The input layer of the network contains one neuron for every word in the vocabulary. If there are 10,000 words, then there are 10,000 input neurons, with each one corresponding to a unique word in the vocabulary. Since these input neurons feed into a dense hidden layer, this means that each neuron will have a unique weight for each of the 10,000 words in the vocabulary. If there are 10,000 words and you want vectors of size 300, then this means the hidden layer will be of shape \u003ccode\u003e[10000, 300]\u003c/code\u003e. To put it another way -- each of the 10,000 words will have it's own unique vector of weights, which will be of size 300, since there are 300 neurons.  \u003c/p\u003e\n\n\u003cp\u003eOnce you've trained the model, you don't actually need the output layer anymore -- all that matters is the hidden layer, which will now act as a \"Lookup Table\" that allows us to quickly get the vector for any given word in the vocabulary. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/new_word2vec_weight_matrix_lookup_table.png\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's the beautiful thing about this lookup table -- when you input a given word, it is passed into the model in a one-hot encoded format. This means that in a vocabulary of 10,000 words, you'll have a \u003ccode\u003e1\u003c/code\u003e at the element that corresponds to the word that we're looking up the word vector for, and \u003ccode\u003e0\u003c/code\u003e for every other element in the vector. If you multiply this one-hot encoded vector by the weight matrix that is our hidden layer, then the vector for every word will be zeroed out, except for the vector that corresponds to the word that you are most interested in!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-using-word2vec/master/images/matrix_mult_w_one_hot.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eUnderstanding the Intuition Behind Word2Vec\u003c/h3\u003e\n\n\u003cp\u003eSo how does the model actually learn the correct weights for each word in a way that captures their semantic context and meaning? The intuition behind Word2Vec is actually quite simple, when you think about the idea of the context window that it's learning to predict. Recall the following quote, which you've seen before:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"You shall know a word by the company it keeps.\"  -- J.R. Firth, Linguist\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn the case of the Word2Vec model, the \"company\" a word keeps are the words surrounding it, and the model is learning to predict these companions! By exploring many different contexts, the model attempts to decipher which words are appropriate in which contexts. For example, consider the sentence \"we have two cats as pets\". You could easily substitute the word \"cats\" for \"dogs\" and the entire sentence would still make perfect sense. While the meaning of the sentence is undoubtedly changed, there is also a lesson regarding the fact that both are nouns and pets. Without even worrying about the embedding space, you can easily understand that words that have similar meanings will likely also be used in many of the same kinds of sentences. The more similar words are, the more sentences in which they are likely to share context windows! This is exactly what the model is learning, and this is why words that are similar end up near each other inside the embedding space. The ways that they are \u003cem\u003enot\u003c/em\u003e similar also helps the model learn to differentiate between them, since there will be patterns here as well. For instance, consider \"ran\" and \"run\", and \"walk\" and \"walked\". They differ only in tense. From the perspective of the sentences present in a large text corpus (models are commonly trained on all of Wikipedia, to give you an idea of the sheer size and scale of most datasets), the model will see numerous examples of how \"ran\" is similar to \"walked\", as well as examples of how the context windows for \"ran\" are different from \"run\" in the same ways that the context windows for \"walked\" are different from \"walk\"! \u003c/p\u003e\n\n\u003ch2\u003eTraining A Word2Vec Model with \u003ccode\u003egensim\u003c/code\u003e\n\u003c/h2\u003e\n\n\u003cp\u003eNow, take look at how you can apply the Word2Vec model using the \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\n\u003cp\u003eTo train a Word2Vec model, you first need to import the model from the \u003ccode\u003egensim\u003c/code\u003e library and instantiate it. Upon instantiation, you'll need to provide the model with certain parameters including:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ethe dataset you'll be training on\u003c/li\u003e\n\u003cli\u003ethe \u003ccode\u003esize\u003c/code\u003e of the word vectors you want to learn \u003c/li\u003e\n\u003cli\u003ethe \u003ccode\u003ewindow\u003c/code\u003e size to use when training the model\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003emin_count\u003c/code\u003e, which corresponds to the minimum number of times a word must be used in the corpus in order to be included in the training (for instance, \u003ccode\u003emin_count=5\u003c/code\u003e would only learn word embeddings for words that appear 5 or more times throughout the entire training set)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eworkers\u003c/code\u003e, the number of threads to use for training, which can speed up processing (\u003ccode\u003e4\u003c/code\u003e is typically used, since most processors nowadays have at least 4 cores). \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOnce you've instantiated the model, you'll still need to call the model's \u003ccode\u003e.train()\u003c/code\u003e method, and pass in the following parameters:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe same dataset that you passed in at instantiation\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etotal_examples\u003c/code\u003e, which is the number of words in the model. You don't need to calculate this manually -- instead, you can just pass in the instantiated model's \u003ccode\u003e.corpus_count\u003c/code\u003e attribute for this parameter.\u003c/li\u003e\n\u003cli\u003eThe number of \u003ccode\u003eepochs\u003c/code\u003e to train the model for. \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe following example demonstrates how to instantiate and train a Word2Vec model:\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"python\"\u003efrom gensim.models import Word2Vec\n\nmodel = Word2Vec(data, size=100, window=5, min_count=1, workers=4)\n\nmodel.train(data, total_examples=model.corpus_count)\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003ch3\u003eExploring the Embedding Space\u003c/h3\u003e\n\n\u003cp\u003eOnce you have trained the model, you can easily explore the embedding space using the built-in methods and functionality provided by gensim's \u003ccode\u003eWord2Vec\u003c/code\u003e class. \u003c/p\u003e\n\n\u003cp\u003eThe actual Word2Vec model itself is quite large. Normally, you only need the actual vectors and the words that correspond to them, which are stored inside of \u003ccode\u003emodel.wv\u003c/code\u003e as a \u003ccode\u003eWord2VecKeyedVectors\u003c/code\u003e object. To save time and space, it's usually easiest to just store the \u003ccode\u003emodel.wv\u003c/code\u003e inside it's own variable, and then work directly with that. You can then use this model for various sorts of functionality, which you'll demonstrate below!\u003c/p\u003e\n\n\u003cpre\u003e\u003ccode class=\"python\"\u003ewv = model.wv\n\nwv.most_similar('Cat')\n\nwv.most_similar(negative='Cat')\n\nwv['Cat']\n\nwv.vectors\n\nwv.most_similar(positive=['king', 'woman'], negative=['man'])\n\u003c/code\u003e\u003c/pre\u003e\n\n\u003cp\u003eIn the next lab, you'll train a Word2Vec model, and then explore the embedding space it has learned. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about how the Word2Vec model actually works, and how you can train and use a Word2Vec model using the \u003ccode\u003egensim\u003c/code\u003e library!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-using-word2vec\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-using-word2vec\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-using-word2vec/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"introduction-to-flask","title":"Introduction to Flask","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-flask-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-flask-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you'll look at a very simple web application using a framework called Flask.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eRecall the client-server model and request-response cycle\u003c/li\u003e\n\u003cli\u003eIdentify the key functionality of a web server\u003c/li\u003e\n\u003cli\u003ePractice running a Flask web server on your local computer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClient-Server Model and Request-Response Cycle\u003c/h2\u003e\n\n\u003cp\u003eLet's review some of the fundamentals of web architecture.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/request_response_cycle.png\" alt=\"request response cycle\"\u003e\u003c/p\u003e\n\n\u003cp\u003e(Icons made by \u003ca href=\"https://www.flaticon.com/authors/freepik\"\u003eFreepik\u003c/a\u003e from \u003ca href=\"http://www.flaticon.com\"\u003ewww.flaticon.com\u003c/a\u003e)\u003c/p\u003e\n\n\u003ch3\u003eClient\u003c/h3\u003e\n\n\u003cp\u003eThe client makes the \u003cstrong\u003erequest\u003c/strong\u003e and waits for the \u003cstrong\u003eresponse\u003c/strong\u003e. Probably the most familiar HTTP client is a web browser. We have also previously used the \u003ccode\u003erequests\u003c/code\u003e library to make a Python code client.\u003c/p\u003e\n\n\u003ch3\u003eServer\u003c/h3\u003e\n\n\u003cp\u003eThe server runs constantly, waiting for requests, and then responds to requests when it receives them. Most of the time as a data scientist you will be interacting with a server that someone else is managing. However in this lesson we'll learn how to run a server of our own!\u003c/p\u003e\n\n\u003ch3\u003eWeb Server\u003c/h3\u003e\n\n\u003cp\u003eIn this lesson we're specifically looking at a \u003cstrong\u003eweb server\u003c/strong\u003e called Flask. Not all servers are web servers (e.g. database servers are a different kind of server), but web servers are a particularly valuable tool because they allow resources and services to be accessed via the Internet.\u003c/p\u003e\n\n\u003cp\u003eWeb servers accept requests and serve responses with an \u003cstrong\u003eHTTP protocol\u003c/strong\u003e. This protocol means that the client and server can operate using totally different languages, and easily interact so long as they use the right HTTP methods, paths, headers, and responses.\u003c/p\u003e\n\n\u003cp\u003eIn this example, we'll set up:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eHTTP \u003ccode\u003eGET\u003c/code\u003e method\n\n\u003cul\u003e\n\u003cli\u003eUsed by clients to request to read some form of data from the server\u003c/li\u003e\n\u003cli\u003eCorresponds to the \u003ccode\u003e.get()\u003c/code\u003e method in the \u003ccode\u003erequests\u003c/code\u003e library\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/\u003c/code\u003e path\n\n\u003cul\u003e\n\u003cli\u003eEssentially asking for the \"home page\" of the website\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eNo particular headers\u003c/li\u003e\n\u003cli\u003eA string response\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eA \"Hello World\" Flask App\u003c/h2\u003e\n\n\u003cp\u003eFor the rest of this lesson we'll be creating a very basic Flask app. Clone this repository and follow along on your local computer, using your preferred local code editor (e.g. VS Code) and your terminal application.\u003c/p\u003e\n\n\u003ch3\u003eSetting up a Flask Environment\u003c/h3\u003e\n\n\u003cp\u003eLet's make a new \u003ccode\u003econda\u003c/code\u003e environment for developing our Flask app.\u003c/p\u003e\n\n\u003cp\u003eRun this code in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e flask-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8.12 pip\nconda activate flask-env\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003eFlask\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.0.3\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTest whether it worked by running this command in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003ewhich flask\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIt should print out a path that includes \u003ccode\u003eflask-env\u003c/code\u003e. If it doesn't, try repeatedly running \u003ccode\u003econda deactivate\u003c/code\u003e until there is no current active conda environment, then \u003ccode\u003econda activate flask-env\u003c/code\u003e again.\u003c/p\u003e\n\n\u003ch3\u003eRunning the Flask Application\u003c/h3\u003e\n\n\u003cp\u003eNow, run the following commands in the terminal, from the root of this repository:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eexport \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_ENV\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003edevelopment\n\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should produce an output that looks something like:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e * Serving Flask app 'app.py' (lazy loading)\n * Environment: development\n * Debug mode: on\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: \u0026lt;PIN\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf this works, your server is now up and running!\u003c/p\u003e\n\n\u003ch4\u003eTroubleshooting Running the Flask Application\u003c/h4\u003e\n\n\u003cp\u003eIf you do not see an output like the one above, here are some things to investigate:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you get \u003ccode\u003eError: Could not import 'app'\u003c/code\u003e, make sure that you are running the above code \u003cem\u003efrom the root of this repository\u003c/em\u003e. \u003ccode\u003eapp.py\u003c/code\u003e needs to be in the same directory where you are running the \u003ccode\u003eflask run\u003c/code\u003e command. Use \u003ccode\u003ecd\u003c/code\u003e until you are in the correct directory, then try again.\u003c/li\u003e\n\u003cli\u003eIf you get an \u003ccode\u003eOSError\u003c/code\u003e such as \u003ccode\u003eAddress already in use\u003c/code\u003e or \u003ccode\u003eAn attempt was made to access a socket in a way forbidden by its access permissions\u003c/code\u003e, that means that there is another program already running on the default port (5000).\n\n\u003cul\u003e\n\u003cli\u003eIf you think there is a chance that the program using port 5000 is another Flask app, but you don't know where that terminal window is, go through the instructions at the bottom of this page under \"What If I Accidentally Closed the Terminal Window?\"\u003c/li\u003e\n\u003cli\u003eIf this is the first time you are running Flask and there is still something using port 5000 (e.g. macOS Monterey appears to use this port for AirPlay), you can tell Flask to use a different port instead. For example, instead of \u003ccode\u003eenv FLASK_APP=app.py flask run\u003c/code\u003e you could run \u003ccode\u003eenv FLASK_APP=app.py flask run --port 5001\u003c/code\u003e. Just make sure you replace \u003ccode\u003e5000\u003c/code\u003e with \u003ccode\u003e5001\u003c/code\u003e in any of the following examples.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eOpening the Flask Application in the Browser\u003c/h4\u003e\n\n\u003cp\u003eLike Jupyter Notebook, this server needs to stay running in the terminal for the application to work. If you want to do something else in the terminal, you will need to open a new window/tab, or shut down the server with control-C.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eDO NOT\u003c/strong\u003e just close the terminal window when you are done running the Flask app. It will keep running in the background and cause problems unless you locate the process ID and terminate it. Always make sure you use control-C.\u003c/p\u003e\n\n\u003cp\u003eUnlike Jupyter notebook, this doesn't open in the browser automatically. You need to copy the URL \u003ccode\u003ehttp://127.0.0.1:5000/\u003c/code\u003e and paste it into a web browser address bar. Once you do that, you should see this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNow, go ahead and shut down the Flask server by typing control-C in the terminal.\u003c/p\u003e\n\n\u003cp\u003e(If you accidentally closed the terminal window, there are troubleshooting steps at the bottom of this page under \"What If I Accidentally Closed the Terminal Window?\")\u003c/p\u003e\n\n\u003ch2\u003eFlask Source Code\u003c/h2\u003e\n\n\u003cp\u003eThis line\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003emeans that the Flask source code is located in a file called \u003ccode\u003eapp.py\u003c/code\u003e. Open up that file in your favorite text editor.\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003eapp.py\u003c/code\u003e looks like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import flask here\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new flask app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# define routes for your new flask app\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat's it, that's the entire web server code! The Flask library does a lot of work for us.\u003c/p\u003e\n\n\u003cp\u003eLet's break down each line of \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch3\u003eImporting Flask\u003c/h3\u003e\n\n\u003cp\u003eFirst, we imported the \u003ccode\u003eFlask\u003c/code\u003e class from the \u003ccode\u003eflask\u003c/code\u003e library:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eflask\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eInstantiating \u003ccode\u003eFlask\u003c/code\u003e Object\u003c/h3\u003e\n\n\u003cp\u003eThen we create a new instance of \u003ccode\u003eFlask\u003c/code\u003e, called \u003ccode\u003eapp\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFlask\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can find more documentation \u003ca href=\"https://flask.palletsprojects.com/en/2.0.x/api/#flask.Flask\"\u003ehere\u003c/a\u003e, including an explanation for the \u003ccode\u003e__name__\u003c/code\u003e parameter.\u003c/p\u003e\n\n\u003ch3\u003eDefining a \u003ccode\u003e/\u003c/code\u003e Route\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eroute\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'/'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emethods\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'GET'\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eindex\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e'Hello, world!'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003e@app.route\u003c/code\u003e is a \u003cem\u003edecorator\u003c/em\u003e that adds the function immediately below it as a route on the Flask app. This particular route uses the HTTP \u003ccode\u003eGET\u003c/code\u003e method and the \u003ccode\u003e/\u003c/code\u003e path.\u003c/p\u003e\n\n\u003cp\u003eThe name of the function, \u003ccode\u003eindex()\u003c/code\u003e, is conventional for the home page (\u003ccode\u003e/\u003c/code\u003e path), but it can be anything you want it to be. The important part is the content of the function.\u003c/p\u003e\n\n\u003cp\u003eIn this case, it simply returns a string. In a more complex Flask app, this might take in additional information from the body of the request or the URL parameters, and would typically return JSON or HTML rather than simply a string like \u003ccode\u003e'Hello, world!'\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eExercises\u003c/h2\u003e\n\n\u003cp\u003ePractice defining a few more routes in \u003ccode\u003eapp.py\u003c/code\u003e.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eDefine a route \u003ccode\u003eGET '/welcome'\u003c/code\u003e which shows the text \u003ccode\u003e'Welcome to an amazing Flask App!'\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eDefine a route \u003ccode\u003eGET '/goodbye'\u003c/code\u003e which shows the text \u003ccode\u003e'Thanks for looking around. Come back again soon!'\u003c/code\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTest these out by running the app again:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003eenv \u003c/span\u003e\u003cspan class=\"nv\"\u003eFLASK_APP\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003eapp.py flask run\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen go to the browser and try:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:5000/welcome\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003ehttp://127.0.0.1:5000/goodbye\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eFinishing Up\u003c/h2\u003e\n\n\u003cp\u003eMake sure you shut down the Flask server by typing control-C in the terminal window where it is running.\u003c/p\u003e\n\n\u003ch2\u003eWhat If I Accidentally Closed the Terminal Window?\u003c/h2\u003e\n\n\u003cp\u003eIt's ok! You will still be able to shut down the Flask server, it will just take more steps. First you need to identify the process ID of your Flask server, then run a command to terminate that process.\u003c/p\u003e\n\n\u003ch3\u003eIdentifying the Process Using the Port\u003c/h3\u003e\n\n\u003cp\u003eFor these examples we will assume that you did not specify a port when you started the Flask server, so it is running on port 5000. If you used a different port (e.g. 5001 due to macOS Monterey) then make sure you replace the port numbers when following these instructions.\u003c/p\u003e\n\n\u003ch4\u003eMac or Linux\u003c/h4\u003e\n\n\u003cp\u003eOn Mac or Linux, you should be able to use the \u003ccode\u003elsof\u003c/code\u003e command. \u003ccode\u003elsof\u003c/code\u003e is short for \"list open files\". Run this in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003elsof \u003cspan class=\"nt\"\u003e-P\u003c/span\u003e \u003cspan class=\"nt\"\u003e-i\u003c/span\u003e :5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eCOMMAND   PID     USER   FD  TYPE             DEVICE SIZE/OFF NODE NAME\nPython  30786 XXXXXXXX   3u  IPv4 0xXXXXXXXXXXXXXXXX      0t0  TCP localhost:5000 (LISTEN)\nPython  30786 XXXXXXXX   4u  IPv4 0xXXXXXXXXXXXXXXXX      0t0  TCP localhost:5000 (LISTEN)\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe process ID is the value in the \u003ccode\u003ePID\u003c/code\u003e column of that output.\u003c/p\u003e\n\n\u003ch4\u003eWindows\u003c/h4\u003e\n\n\u003cp\u003eOn Windows, you should be able to use the \u003ccode\u003enetstat\u003c/code\u003e command. \u003ccode\u003enetstat\u003c/code\u003e is short for \"network statistics\". Run this in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003enetstat \u003cspan class=\"nt\"\u003e-ano\u003c/span\u003e | findstr 5000\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will produce an output like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eProto  Local Address Foreign Address     State   PID\nTCP   127.0.0.1:5000       0.0.0.0:0 LISTENING 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eTerminating the Process\u003c/h3\u003e\n\n\u003cp\u003eIn both of the above examples, the process ID is 30786. Make sure you replace this with the actual process ID that you identified!\u003c/p\u003e\n\n\u003ch4\u003eMac or Linux\u003c/h4\u003e\n\n\u003cp\u003eYou can use the \u003ccode\u003ekill\u003c/code\u003e command to terminate the process in the command line on Mac or Linux.\u003c/p\u003e\n\n\u003cp\u003eFor example, \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003e\u003cspan class=\"nb\"\u003ekill\u003c/span\u003e \u003cspan class=\"nt\"\u003e-9\u003c/span\u003e 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can also use the \"Activity Monitor\" application on Mac if you are more comfortable with a graphical user interface. Just find the process with the relevant ID, click on the process, and click the button with the X.\u003c/p\u003e\n\n\u003ch4\u003eWindows\u003c/h4\u003e\n\n\u003cp\u003eYou can use the \u003ccode\u003etaskkill\u003c/code\u003e command to terminate the process in the command line on Windows.\u003c/p\u003e\n\n\u003cp\u003eFor example,\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003etaskkill /F /PID 30786\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can also use the \"Task Manager\" application on Windows if you are more comfortable with a graphical user interface. If you don't immediately see the process you're looking for, try clicking \"More details\" to see the full list. Select the process you want to terminate and then click \"End task\".\u003c/p\u003e\n\n\u003ch3\u003eChecking Port 5000 Again\u003c/h3\u003e\n\n\u003cp\u003eNow if you re-run the command checking port 5000 (either \u003ccode\u003elsof\u003c/code\u003e or \u003ccode\u003enetstat\u003c/code\u003e), no processes should be displayed. You should now be able to execute the \u003ccode\u003eflask run\u003c/code\u003e command without getting an \u003ccode\u003eOSError\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you reviewed the client-server model and request-response cycle, and saw a specific application of it using a basic Flask app.\u003c/p\u003e","frontPage":false},{"exportId":"short-video-solving-an-eigenvalue-problem","title":"Short Video: Solving an Eigenvalue Problem","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813281?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"topic-32-lesson-priorities-live","title":"Topic 32 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u003cspan\u003eIn the Live program, there is no scheduled lecture on Singular Value Decomposition (SVD); instead there is a recorded video lecture. Take the time to watch the lecture recording if you are interested in a deeper dive into the linear algebra concepts that tie together PCA and recommendation systems.\u003c/span\u003e\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.526%; height: 127px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eSVD\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Recommendation Systems - Introduction\" href=\"pages/recommendation-systems-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/recommendation-systems-introduction\" data-api-returntype=\"Page\"\u003eRecommendation Systems - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Recommendation Systems\" href=\"pages/introduction-to-recommendation-systems\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-recommendation-systems\" data-api-returntype=\"Page\"\u003eIntroduction to Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Collaborative Filtering and Singular Value Decomposition\" href=\"assignments/g935c2c028baa43d2098a808afe5a8065\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12155\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering and Singular Value Decomposition\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Matrix Factorization with Alternating Least Squares\" href=\"assignments/g735d585333f584530e3ffdaf6d72ee19\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12158\" data-api-returntype=\"Assignment\"\u003eMatrix Factorization with Alternating Least Squares\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.713%; height: 130px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eSVD\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eRecommendation Systems\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"SVD Exit Ticket\" href=\"quizzes/ge90739ce01a620cd258817433744522a\"\u003e\u003cstrong\u003eSVD Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Collaborative Filtering with Surprise\" href=\"assignments/ga6a3b7eadae54ca83ed43d893f924a25\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12156\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering with Surprise\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Collaborative Filtering with Surprise - Lab\" href=\"assignments/g8899aaa2ef46cbed887e639d05c7181f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12157\" data-api-returntype=\"Assignment\"\u003eCollaborative Filtering with Surprise - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Recommendation Systems\" href=\"quizzes/g05d801f10914dc65584eb6465ecc0c0f\"\u003eQuiz: Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.713%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eRecommendation Systems\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003cstrong\u003e\u003ca title=\"Recommendation Systems Exit Ticket\" href=\"quizzes/g50cf88f4c370db6969f085cc72c98bb1\"\u003eRecommendation Systems Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 27px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 27px;\"\u003e\u003ca title=\"Recommendation Systems - Recap\" href=\"pages/recommendation-systems-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/recommendation-systems-recap\" data-api-returntype=\"Page\"\u003eRecommendation Systems - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 27px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"graph-theory-introduction","title":"Graph Theory - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll investigate a new data structure: networks! Networks are a useful data structure to map a range of applications from driving directions to social networks.\u003c/p\u003e\n\n\u003ch2\u003eNetwork Graphs\u003c/h2\u003e\n\n\u003cp\u003eNetworks are another way of representing data that you have yet to fully investigate. In their most simple case, a network contains \u003cstrong\u003enodes\u003c/strong\u003e connected by \u003cstrong\u003eedges\u003c/strong\u003e like this:\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-network-introduction/master/images/graph.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNodes represent some object such as people, languages, countries, or tags, to name a few. The relationships between these objects are the edges between them. For example, later in this section you'll investigate the relationship of various technology tags on the popular website \u003ca href=\"stackoverflow.com\"\u003eStackOverflow\u003c/a\u003e. One potential network visualization of this data looks like this:\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-network-introduction/master/images/stackoverflow_clusters.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003ePath Searching\u003c/h2\u003e\n\n\u003cp\u003eAn important concept in network analysis are path searching algorithms. Finding the shortest path between two nodes is a foundational concept for creating a distance metric which can then be used to conduct more advanced analyses. Mapping applications such as Google Maps, Apple Maps, Waze, or Uber are also natural applications for path searching algorithms. In this section, you'll investigate Dijkstra's algorithm for finding the shortest path between two points, coding it from scratch using Python.\u003c/p\u003e\n\n\u003ch2\u003eCentrality\u003c/h2\u003e\n\n\u003cp\u003eOnce you've familiar with the concept of path searching, you'll then go on to investigate properties of nodes and edges. Centrality is a key concept in this, helping to determine which nodes are most influential in a network, or hold pivotal positions in connecting the network.\u003c/p\u003e\n\n\u003ch2\u003eCliques and Clustering\u003c/h2\u003e\n\n\u003cp\u003eMoving from the study of single objects nodes and edges within the network, you'll then start to investigate larger structures. With this, you'll investigate the concept of cliques and clusters in order to subdivide a network into smaller groups. Natural applications of this include sub-setting social networks into groups or categorizing items such as books or languages.\u003c/p\u003e\n\n\u003ch2\u003eRecommendation Systems\u003c/h2\u003e\n\n\u003cp\u003eTo round out this section, you'll investigate how networks can be used to fuel recommendation systems, a popular and exciting topic. With this, you'll work on recommending amazon products to customers.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eGet ready to dive into the exciting realm of networks! In this section, you'll get to play around with a range of datasets from Twitter, Game of Thrones, and the Amazon Marketplace!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-network-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-network-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-network-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"deep-nlp-with-word-embeddings-recap","title":"Deep NLP with Word Embeddings - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eCongratulations! You know have a myriad of powerful NLP tools that you can begin to tap into and further explore. With that, take a minute to review some of the key concepts you were exposed to in this section. \u003c/p\u003e\n\n\u003ch2\u003eRNNs and Word Embeddings\u003c/h2\u003e\n\n\u003cp\u003eRemember that word embeddings are a type of vectorization strategy that computes word vectors from a text corpus. They use similarity metrics, which can reveal how certain words relate to each other, or \"semantic relationships\".\u003c/p\u003e\n\n\u003cp\u003eUnlike TF-IDF vectorization, the size of word embeddings is a tunable parameter, which can help overcoming the curse of dimensionality. Word embeddings can be created using Word2Vec models -- given enough training data. \u003c/p\u003e\n\n\u003cp\u003eSince deep learning is used to create Word2Vec models, training word embeddings can be really time consuming, and when building a predictive model you'd want to avoid spending a lot of time here. Pretrained word vectors are very useful here, and GLoVe is the most commonly used model. When using GLoVe, and moving towards a vector representation for any arbitrarily-sized block of text, mean word embeddings can be used.\u003c/p\u003e\n\n\u003ch2\u003eGRUs and LSTMs\u003c/h2\u003e\n\n\u003cp\u003eBuilding on this, you then took a look at some new architectures for neural nets. Aside from having a temporal aspect as with RNNs, GRUs (Gated Recurrent Units) and LSTMs (Long Short Term Memory Cells) have capabilities for both summarizing important information seen prior and forgetting needless details to free up memory. This acts as an analogy to human memory and allows for improved performance in many tasks. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section you learned about advanced deep network architectures including RNNs, GRUs, and LSTMs. You also saw how to create word embeddings, an alternative methodology for encoding textual data into numerical spaces. With that, you also saw how to use transfer learning to apply Word2Vec models and improve NLP classification algorithms.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-deep-nlp-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-deep-nlp-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"pca-recap","title":"PCA - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-summary\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-summary/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePCA is an \u003cem\u003eunsupervised learning technique\u003c/em\u003e which does not require labeled data \u003c/li\u003e\n\u003cli\u003eIt is also a dimensionality reduction technique which can be used to compress data and experiment with its effects on machine learning algorithms as a preprocessing step \u003c/li\u003e\n\u003cli\u003eThere are four steps to conducting PCA:\n\n\u003cul\u003e\n\u003cli\u003eCenter each feature by subtracting the feature mean\u003c/li\u003e\n\u003cli\u003eCalculate the covariance matrix for your normalized dataset\u003c/li\u003e\n\u003cli\u003eCalculate the eigenvectors/eigenvalues for the covariance matrix\n\n\u003cul\u003e\n\u003cli\u003eReorder your eigenvectors based on their accompanying eigenvalues (in descending order of the eigenvalues)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTake the dot product of the transpose of the eigenvectors with the transpose of the normalized data\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eYou can also easily implement PCA using scikit-learn \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-pca-summary\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-pca-summary\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-pca-summary/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"modeling-time-series-data-recap","title":"Modeling Time Series Data - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-models-section-recap\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA white noise model has a fixed and constant mean and variance, and no correlation over time\u003c/li\u003e\n\u003cli\u003eA random walk model has no specified mean or variance, but has a strong dependence over time\u003c/li\u003e\n\u003cli\u003eThe Pandas \u003ccode\u003e.corr()\u003c/code\u003e method can be used to return the correlation between various time series in the DataFrame\u003c/li\u003e\n\u003cli\u003eAutocorrelation allows us to identify how strongly each time series observation is related to previous observations\u003c/li\u003e\n\u003cli\u003eThe Autocorrelation Function (ACF) is a function that represents autocorrelation of a time series as a function of the time lag\u003c/li\u003e\n\u003cli\u003eThe Partial Autocorrelation Function (or PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags\u003c/li\u003e\n\u003cli\u003eARMA (Autoregressive and Moving Average) modeling is a tool for forecasting time series values by regressing the variable on its own lagged (past) values\u003c/li\u003e\n\u003cli\u003eARMA models assume that you've already detrended your data and that there is no seasonality\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"topic-38-lesson-priorities-live","title":"Topic 38 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.251%; height: 98px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNeural Networks Architecture\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Neural Networks - Introduction\" href=\"pages/neural-networks-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/neural-networks-introduction\" data-api-returntype=\"Page\"\u003eNeural Networks - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Neural Networks \" href=\"assignments/g5cfd415b6c16b8a663492df51792ab17\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187116\" data-api-returntype=\"Assignment\"\u003eIntroduction to Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Introduction to Neural Networks - Lab\" href=\"assignments/gf2f068c1f54bb20d5b59fed69c0b026d\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187117\" data-api-returntype=\"Assignment\"\u003eIntroduction to Neural Networks - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.6255%; height: 261px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNeural Networks Architecture\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eIntro to Keras and TensorFlow\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Neural Network Architecture Exit Ticket\" href=\"quizzes/g019828bafb8113a73d23e631cda07bd3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30661\" data-api-returntype=\"Quiz\"\u003eNeural Network Architecture Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Keras\" href=\"assignments/g0eb3977117857e24bafa2973c6d41fd6\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187113\" data-api-returntype=\"Assignment\"\u003eIntroduction to Keras\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Keras - Lab\" href=\"assignments/gf64a29e6ba56e3918fe4a29949d8110b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187119\" data-api-returntype=\"Assignment\"\u003eKeras - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Deeper Neural Networks\" href=\"assignments/g5593261c5fe164b30874c26e98026d4c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187104\" data-api-returntype=\"Assignment\"\u003eDeeper Neural Networks\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Deeper Neural Networks - Lab\" href=\"assignments/g435e4887d3bebaf536db883d19cdf707\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187105\" data-api-returntype=\"Assignment\"\u003eDeeper Neural Networks - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Image Classification with Multi-Layer Perceptrons\" href=\"pages/image-classification-with-multi-layer-perceptrons\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/image-classification-with-multi-layer-perceptrons\" data-api-returntype=\"Page\"\u003eImage Classification with Multi-Layer Perceptrons\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Image Classification with MLPs - Lab\" href=\"assignments/g41f7a6a6dd480b27090ed07c9767da64\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187110\" data-api-returntype=\"Assignment\"\u003eImage Classification with MLPs - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.626%;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Neural Networks\" href=\"quizzes/ga45ae0602eaec10912652ed52580feb0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30664\" data-api-returntype=\"Quiz\"\u003eQuiz: Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\"\u003e\u003cstrong\u003e\u003cspan style=\"color: #000000;\"\u003e1st\u003c/span\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.5188%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eIntro to Keras and TensorFlow\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.626%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.60015%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Short Video: Regression with a Neural Network\" href=\"pages/short-video-regression-with-a-neural-network\" data-api-endpoint=\"pages/short-video-regression-with-a-neural-network?module_item_id=mastercourse_15802_382_27525315d1cfc0d6bf5ed83471c2f0af\" data-api-returntype=\"Page\"\u003eShort Video: Regression with a Neural Network\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e2nd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Intro to Keras and Tensorflow Exit Ticket\" href=\"quizzes/g0e314f849741298b050a433febfe8e80\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30686\" data-api-returntype=\"Quiz\"\u003eIntro to Keras and Tensorflow Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.626%; height: 29px;\"\u003e\u003ca title=\"Neural Networks - Recap\" href=\"pages/neural-networks-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/neural-networks-recap\" data-api-returntype=\"Page\"\u003eNeural Networks - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.60015%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"classification-with-word-embeddings","title":"Classification with Word Embeddings","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll look at the practical aspects of how you can use word embeddings and Word2Vec models for text classification!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe what an embedding layer is in a neural network \u003c/li\u003e\n\u003cli\u003eUse pretrained word embeddings from popular pretrained models such as GloVe \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll start by reviewing \u003cstrong\u003e\u003cem\u003eTransfer Learning\u003c/em\u003e\u003c/strong\u003e and loading pre-trained word vectors. Then, you'll learn about how to get important word vectors, combine them into \u003cstrong\u003e\u003cem\u003eMean Word Vectors\u003c/em\u003e\u003c/strong\u003e, and streamline this process by writing a custom vectorizer class compatible with scikit-learn pipelines. Finally, you'll end the lesson by examining how to train deep neural networks that include their own word embedding layers, and how you can use Keras to preprocess text data conveniently!\u003c/p\u003e\n\n\u003ch2\u003eUsing Pretrained Word Vectors With GloVe\u003c/h2\u003e\n\n\u003cp\u003ePerhaps the single best way to improve performance for text classification is to make use of weights from a Word2Vec model that has been trained for a very long time on a massive amount of text data. With deep learning, more data is almost always the single best thing that can improve model performance, and the embedded word vectors created by a Word2Vec model are no exception. For this reason, it's almost always a good idea to load one of the top-tier, industry-standard models that been open sourced for this exact purpose. The most common model to use for this is the \u003cstrong\u003e\u003cem\u003eGloVe\u003c/em\u003e\u003c/strong\u003e (short for \u003cstrong\u003e\u003cem\u003eGlobal Vectors for Word Representation\u003c/em\u003e\u003c/strong\u003e) model by the Stanford NLP Group. This model is trained on massive datasets, such as the entirety of Wikipedia, for a very long time on server clusters with multiple GPUs. It would be absolutely impossible for us to train a model of similar quality on our own machines. However, because the model weights are open-source, you don't need to! Instead, you'll simply download the weights and go from there. \u003c/p\u003e\n\n\u003cp\u003eFor text classification purposes, loading the weights precludes the need for us to instantiate or train a Word2Vec model entirely -- instead, you just:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGet the total vocabulary in our dataset\u003c/li\u003e\n\u003cli\u003eDownload and unzip the GloVe file needed from the Stanford NLP Group's website\u003c/li\u003e\n\u003cli\u003eRead the GloVe file, and save only the vectors that correspond to the words that appear in the vocabulary of our dataset \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis can be a fairly involved process, so the code for this is provided for you in the next lab. That said, it's important to take some time and examine this code until you have at least general idea of what's going on!\u003c/p\u003e\n\n\u003ch2\u003eMean Word Embeddings\u003c/h2\u003e\n\n\u003cp\u003eLoading a pretrained model like GloVe may provide you with the most accurate word vectors we could possibly hope, but each vector is still just a single word. This isn't very conducive to classification as is at this stage, because it's highly likely that any text classification will be focused on arbitrarily-sized blobs of text, such as sentences or paragraphs. With that, the question is how to get these sentences and paragraphs into a format that can be used for classification, while making use of the word vectors from GloVe?\u003c/p\u003e\n\n\u003cp\u003eThe answer is to compute a \u003cstrong\u003e\u003cem\u003eMean Word Embedding\u003c/em\u003e\u003c/strong\u003e. The idea behind this is simple. To get the vector representation for any arbitrarily-sized block of text, all you need to do is get the vector for every individual word that appears in that block of text, and average them together! The benefit of this is that no matter how big or small that block of text is, the mean word embedding of that sentence will be the same size as all of the others, because the vectors you're averaging together all have the exact same dimensionality! This makes it a simple matter to get a block of text into a format that we can use with traditional supervised learning models such as Support Vector Machines or Gradient Boosted Trees. \u003c/p\u003e\n\n\u003ch3\u003eWorking With scikit-learn pipelines\u003c/h3\u003e\n\n\u003cp\u003eAs you'll see in the next lab, it's worth the extra bit of work to build a class that works with the requirements of a scikit-learn \u003ccode\u003ePipeline()\u003c/code\u003e class, so that you can pass the data straight in and generate the mean word embeddings on the fly. This way, you don't need to write the same set of code twice to generate mean word embeddings for both the training and test set. This is also important if the dataset is too large to fit into your computer's memory, as it will allow you to partially train models and load in different chunks of the dataset. By building a vectorizer class that handles creating the mean word embeddings rather than just writing the code procedurally, you'll save yourself a lot of work in the long run!\u003c/p\u003e\n\n\u003cp\u003eThe code for the mean embedding vectorizer class is also provided for you in the next lab. As you'll see, the class requires both \u003ccode\u003e.fit()\u003c/code\u003e and \u003ccode\u003e.transform()\u003c/code\u003e methods to be compliant with scikit-learn's \u003ccode\u003ePipeline()\u003c/code\u003e class. Take some time to study this code until you understand what it's doing -- it isn't complex, and understanding how to do this yourself will pay dividends in the long run. After all, writing clean, reusable code always does!\u003c/p\u003e\n\n\u003ch2\u003eDeep Learning \u0026amp; Embedding Layers\u003c/h2\u003e\n\n\u003cp\u003eOne problem you may have noticed with the mean word embedding strategy is that by combining all the words, you lose some information that is contained in the sequence of the words. In natural language, the position and phrasing of words in a sentence can often contain information that we pick up on. This is a downside to this approach, and one of the reasons why \u003cstrong\u003e\u003cem\u003eSequence Models\u003c/em\u003e\u003c/strong\u003e tend to outperform all of the 'shallow' algorithms (note: this term just refers to any machine learning algorithms that do not fall under the umbrella of deep learning -- it doesn't make any judgments about whether they are better or worse, as that is almost always dependent on the situation!). In the next lesson, you'll learn about sequence models including \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e. Moreover, in the next lab, you'll also see a preview example of these, so that you can see how to use \u003cstrong\u003e\u003cem\u003eEmbedding Layers\u003c/em\u003e\u003c/strong\u003e directly within neural networks!\u003c/p\u003e\n\n\u003cp\u003eAn \u003cstrong\u003e\u003cem\u003eEmbedding Layer\u003c/em\u003e\u003c/strong\u003e is just a layer that learns the word embeddings for our dataset on the fly, right there inside the neural network. Essentially, its a way to make use of all the benefits of Word2Vec, without worrying about finding a way to include a separately trained Word2Vec model's output into our neural networks (which are probably already complicated enough!). You'll see an example of an \u003cstrong\u003e\u003cem\u003eEmbedding Layer\u003c/em\u003e\u003c/strong\u003e in the next lab. You should make note of a couple caveats that come with using embedding layers in your neural network -- namely:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe embedding layer must always be the first layer of the network, meaning that it should immediately follow the \u003ccode\u003eInput()\u003c/code\u003e layer \u003c/li\u003e\n\u003cli\u003eAll words in the text should be integer-encoded, with each unique word encoded as it's own unique integer\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eThe size of the embedding layer must always be greater than the total vocabulary size of the dataset! The first parameter denotes the vocabulary size, while the second denotes the size of the actual word vectors\u003c/li\u003e\n\u003cli\u003eThe size of the sequences passed in as data must be set when creating the layer (all data will be converted to padded sequences of the same size during the preprocessing step)\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn the next lab, you'll make use of Keras' text preprocessing tools to convert the data from text to a tokenized format. Then, you'll convert the tokenized sentences to sequences. Finally, you'll pad the sequences, so that they're all the same length. During this step, you'll exclusively make use of the preprocessing tools provided by Keras. Don't worry if this all seems a bit complex right now, as you'll soon see, this is actually the most straightforward part of the next lab!\u003c/p\u003e\n\n\u003cp\u003eFor a full rundown of how to use embedding layers in Keras, see the \u003ca href=\"https://keras.io/layers/embeddings/\"\u003eKeras Documentation for Embedding Layers\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you focused on the practical and pragmatic elements of using Word2Vec and word embeddings for text classification. You learned about how to load professional-quality pretrained word vectors with the Stanford NLP Group's open source GloVe data, as well as how to generate mean word embeddings that work with scikit-learn pipelines, and how to add embedding layers into neural networks with Keras!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-classification-with-word-embeddings\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-classification-with-word-embeddings\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"topic-37-lesson-priorities-live","title":"Topic 37 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.7191%; height: 188px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNLP Pre-Processing\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Natural Language Processing - Introduction\" href=\"pages/natural-language-processing-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/natural-language-processing-introduction\" data-api-returntype=\"Page\"\u003eNatural Language Processing - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP and Word Vectorization\" href=\"pages/nlp-and-word-vectorization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/nlp-and-word-vectorization\" data-api-returntype=\"Page\"\u003eNLP and Word Vectorization\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Word Vectorization - Lab\" href=\"assignments/ga30aa82d071d72e9a33e2fe1c8b59f4a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187174\" data-api-returntype=\"Assignment\"\u003eWord Vectorization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to NLP with NLTK\" href=\"pages/introduction-to-nlp-with-nltk\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-nlp-with-nltk\" data-api-returntype=\"Page\"\u003eIntroduction to NLP with NLTK\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Introduction to Regular Expressions\" href=\"pages/introduction-to-regular-expressions\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-regular-expressions\" data-api-returntype=\"Page\"\u003eIntroduction to Regular Expressions\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Regular Expressions - Codealong\" href=\"assignments/g311caf2ef8d1c4fae0d9dd5602a56818\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187146\" data-api-returntype=\"Assignment\"\u003eRegular Expressions - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8934%; height: 160px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Pre-Processing\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eNLP Vectorization\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Short Video: The Bag of Words Model\" href=\"pages/short-video-the-bag-of-words-model\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-the-bag-of-words-model\" data-api-returntype=\"Page\"\u003eShort Video: The Bag of Words Model\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 37.9688%;\"\u003e\u003cstrong\u003e\u003ca title=\" NL Pre-Processing Exit Ticket\" href=\"quizzes/g00c1d4e4c62cb2f4bcc9a48df38ab1df\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30660\" data-api-returntype=\"Quiz\"\u003e NL Pre-Processing Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Feature Engineering for Text Data\" href=\"pages/feature-engineering-for-text-data\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/feature-engineering-for-text-data\" data-api-returntype=\"Page\"\u003e\u003cstrong\u003eFeature Engineering for Text Data\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Corpus Statistics - Lab\" href=\"assignments/g884dfd7a7c655abeb9864d3e0f37cb7a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187100\" data-api-returntype=\"Assignment\"\u003eCorpus Statistics - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Context-Free Grammars and POS Tagging\" href=\"pages/context-free-grammars-and-pos-tagging\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/context-free-grammars-and-pos-tagging\" data-api-returntype=\"Page\"\u003eContext-Free Grammars and POS Tagging\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Context-Free Grammars - Codealong\" href=\"assignments/g533c9d870df05d068e79cd3996c70b47\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187098\" data-api-returntype=\"Assignment\"\u003eContext-Free Grammars - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 105px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Vectorization\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eNLP Modeling\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Short Video: TF-IDF Vectorization\" href=\"pages/short-video-tf-idf-vectorization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-tf-idf-vectorization\" data-api-returntype=\"Page\"\u003eShort Video: TF-IDF Vectorization\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP Vectorization Exit Ticket\" href=\"quizzes/gc87c99b3ff83367c87ec87311d640eca\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30668\" data-api-returntype=\"Quiz\"\u003eNLP Vectorization Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Text Classification\" href=\"pages/text-classification\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/text-classification\" data-api-returntype=\"Page\"\u003eText Classification\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Natural Language Processing\" href=\"quizzes/ge4eb3dd722fcfcc80f1f9aa87b632443\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30666\" data-api-returntype=\"Quiz\"\u003eQuiz: Natural Language Processing\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 105px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNLP Modeling\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 37.9688%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 9.80977%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"NLP Modeling Exit Ticket\" href=\"quizzes/g272d6ccbdae72e63883d6986cb4fd1fa\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30680\" data-api-returntype=\"Quiz\"\u003eNLP Modeling Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"‚≠êÔ∏è Text Classification - Cumulative Lab\" href=\"quizzes/g11ad01bbe6f79a0e7287e5eb4163a824\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30667\" data-api-returntype=\"Quiz\"\u003e‚≠êÔ∏è Text Classification - Cumulative Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st*\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 37.9688%; height: 29px;\"\u003e\u003ca title=\"Natural Language Processing - Recap\" href=\"pages/natural-language-processing-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/natural-language-processing-recap\" data-api-returntype=\"Page\"\u003eNatural Language Processing - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 9.80977%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e*Cumulative labs may be used for pairing exercises and might not be published yet; contact your instructor if you have questions\u003c/strong\u003e\u003c/p\u003e","frontPage":false},{"exportId":"hierarchical-agglomerative-clustering","title":"Hierarchical Agglomerative Clustering","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-hierarchical-agglomerative-clustering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about another popular class of clustering algorithms -- hierarchical agglomerative clustering!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the process behind hierarchical agglomerative clustering \u003c/li\u003e\n\u003cli\u003eDescribe the three different linkage criteria for hierarchical agglomerative clustering \u003c/li\u003e\n\u003cli\u003eDefine the purpose of a dendrogram \u003c/li\u003e\n\u003cli\u003eCompare and contrast k-means and hierarchical agglomerative clustering methodologies\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eUnderstanding Hierarchical Clustering\u003c/h2\u003e\n\n\u003cp\u003eSo far, we've worked with a non-hierarchical clustering algorithm, k-means clustering. K-means works by taking a set parameter that tells it how many clusters we think exist in the data, and then uses the Expectation-Maximization (EM) algorithm to iteratively shift each cluster centroid to the best possible position by constantly calculating and recalculating the centroid's position by assigning each point to the cluster centroid they are closest to with each new step, and then moving the centroid to the center of all the points currently assigned to that centroid. With non-hierarchical algorithms, there can be no subgroups -- that is, no clusters within clusters.\u003c/p\u003e\n\n\u003cp\u003eThis is where agglomerative clustering algorithms come in. In agglomerative clustering, the algorithm starts with \u003cimg class=\"equation_image\" title=\"n\" src=\"https://learning.flatironschool.com/equation_images/n\" alt=\"{\" data-equation-content=\"n\"\u003e clusters (where \u003cimg class=\"equation_image\" title=\"n\" src=\"https://learning.flatironschool.com/equation_images/n\" alt=\"{\" data-equation-content=\"n\"\u003e is the number of data points) and proceeds by merging the most similar clusters, until some stopping criterion. in \u003ccode\u003escikit-learn\u003c/code\u003e, the stopping criterion that is implemented is \"number of clusters\".  If left alone, the algorithm will work until it has merged every cluster into one giant cluster. We can also set the limit, if we want, to stop when there are only [x] clusters remaining. \u003c/p\u003e\n\n\u003ch3\u003eLinking Similar Clusters Together\u003c/h3\u003e\n\n\u003cp\u003eSeveral linkage criteria that have different definitions for \"most similar clusters\" can be used. The measure is always defined between two existing clusters up until that point, so the later in the algorithms, the bigger the clusters get.\u003c/p\u003e\n\n\u003cp\u003eScikit-learn provides three linkage criteria:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eward\u003c/strong\u003e (default): picks the two clusters to merge in a way that the variance within all clusters increases the least. Generally, this leads to clusters that are fairly equally sized.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eaverage\u003c/strong\u003e: merges the two clusters that have the smallest \u003cstrong\u003e\u003cem\u003eaverage\u003c/em\u003e\u003c/strong\u003e distance between all the points.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003ecomplete\u003c/strong\u003e (or maximum linkage): merges the two clusters that have the smallest \u003cstrong\u003e\u003cem\u003emaximum\u003c/em\u003e\u003c/strong\u003e distance between their points.\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs we'll see in the next lab, these linkage criteria can definitely have an effect on how the clustering algorithm performs. As always seems to be the case, no one of these is \"best\" -- which one you should use often depends on the structure of your data, and/or your own goals. \u003c/p\u003e\n\n\u003ch3\u003eA Visual Example\u003c/h3\u003e\n\n\u003cp\u003eIt's often easier to understand what the HAC algorithm is doing when we look at the decisions it makes at each given step. The following diagram demonstrates the clusters created at each step for a dataset of 16 points. Take a look at the diagram and see if you can figure out what the algorithm is doing at each step as it merges clusters together:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/hac_iterative.png\" alt=\"initialization through step 14 of HAC algorithm\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs we can see from the diagram above, in each step, the algorithm takes the two clusters that are closest together (and remember, we define \"closest together\" according to whichever linkage criteria we choose to use), and then \u003cstrong\u003e\u003cem\u003emerge\u003c/em\u003e\u003c/strong\u003e those two clusters together into a single cluster. We don't move the data points or anything like that -- we just consider them as a single unit, as opposed to two separate ones. This works at every stage because in the beginning, we treat each data point as a unique cluster. \u003c/p\u003e\n\n\u003cp\u003eThis becomes very intuitive when we look at the following gif -- pay attention to the image on the left:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/dendrogram_gif.gif\" alt=\"animation of clusters shown in x-y space on the left and a dendrogram on the right, showing which clusters correspond to which parts of the dendrogram\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAs the dots disappear, the visualization is replacing them with the newly calculated center of that cluster, which will be used for linkage purposes. Now, let's end this lesson by talking about visualizations we can use to interpret results!\u003c/p\u003e\n\n\u003ch3\u003eDendrograms and Clustergrams\u003c/h3\u003e\n\n\u003cp\u003eOne advantage of HAC is that we can easily visualize the results \u003cstrong\u003e\u003cem\u003eat any given step\u003c/em\u003e\u003c/strong\u003e using visualizations such as \u003cstrong\u003e\u003cem\u003eDendrograms\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eClustergrams\u003c/em\u003e\u003c/strong\u003e. Take another look at the gif above, but this time, pay attention to the image on the right.  This is a \u003cem\u003edendrogram,\u003c/em\u003e which is used to visualize the hierarchical relationship between the various clusters that are computed throughout each step. Dendrograms are very useful to decide how clusters change depending on the euclidean distance. If you decide that your intra-cluster euclidean distance should be smaller than 3, you can draw a horizontal line at euclidean distance 3, and define which points belong to which cluster by looking at the dendrogram. For the gif above, this means that there are three clusters: cluster one contains \u003cimg class=\"equation_image\" title=\"p_0\" src=\"https://learning.flatironschool.com/equation_images/p_0\" alt=\"{\" data-equation-content=\"p_0\"\u003e, \u003cimg class=\"equation_image\" title=\"p_1\" src=\"https://learning.flatironschool.com/equation_images/p_1\" alt=\"{\" data-equation-content=\"p_1\"\u003e and \u003cimg class=\"equation_image\" title=\"p_2\" src=\"https://learning.flatironschool.com/equation_images/p_2\" alt=\"{\" data-equation-content=\"p_2\"\u003e, cluster two contains \u003cimg class=\"equation_image\" title=\"p_3\" src=\"https://learning.flatironschool.com/equation_images/p_3\" alt=\"{\" data-equation-content=\"p_3\"\u003e, cluster three contains \u003cimg class=\"equation_image\" title=\"p_4\" src=\"https://learning.flatironschool.com/equation_images/p_4\" alt=\"{\" data-equation-content=\"p_4\"\u003e, \u003cimg class=\"equation_image\" title=\"p_5\" src=\"https://learning.flatironschool.com/equation_images/p_5\" alt=\"{\" data-equation-content=\"p_5\"\u003e and \u003cimg class=\"equation_image\" title=\"p_6\" src=\"https://learning.flatironschool.com/equation_images/p_6\" alt=\"{\" data-equation-content=\"p_6\"\u003e.\u003c/p\u003e\n\n\u003cp\u003eWe can also visualize the same information by drawing lines representing each cluster at each step to create a \u003cem\u003eclustergram\u003c/em\u003e. Take a look at the following diagram below, which shows both a dendrogram and clustergram of the same HAC results:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering/master/images/new_clustergram.png\" alt=\"another view of clusters on the left and dendrogram on the right\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eHow is HAC used?\u003c/h3\u003e\n\n\u003cp\u003eHAC algorithms are used in generally the same way that K-means and other clustering algorithms are used: for tasks such as market segmentation, or for gaining a deeper understanding of a dataset through cluster analysis. However, there are special cases of things that fit quite well in a hierarchical agglomerative structure -- one of the most common use cases you'll see for HAC is the way that smartphones naturally sort photos inside their photos app! Take a look at your photos app on your phone, and the albums that it creates for you -- you'll likely see that the albums are sorted in a \u003cstrong\u003e\u003cem\u003ehierarchical\u003c/em\u003e\u003c/strong\u003e fashion! Perhaps the phone chooses to group photos by date first, and then by location,  or even content! In this way, these can be viewed as natural clusters within clusters, in a way that makes intuitive sense to users. When we browse, we likely want to see photos that were taken around the same time, and then at the same place, and then narrow it down to photos about the same things, to quickly browse and find what we're looking for. This is a great example of HAC being used in the wild!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about how the HAC algorithm derives its clusters, including different linkage criteria that can be used to determine which clusters should be merged at any given point. We also examined some visualizations of HAC algorithms, in the forms of dendrograms and clustergrams!\u003c/p\u003e","frontPage":false},{"exportId":"natural-language-processing-introduction","title":"Natural Language Processing - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson summarizes the topics we'll be covering in this section and why they'll be important to you as a data scientist.\u003c/p\u003e\n\n\u003ch2\u003eFoundations of Natural Language Processing (NLP)\u003c/h2\u003e\n\n\u003cp\u003eIn this section we will be covering Natural Language Processing (NLP), which refers to analytics tasks that deal with natural human language, in the form of text or speech.\u003c/p\u003e\n\n\u003ch3\u003eNatural Language Tool Kit (NLTK)\u003c/h3\u003e\n\n\u003cp\u003eWe'll start by providing more context on the Natural Language Tool Kit (NLTK), one of the most popular NLP libraries used in Python.  This library was developed by researchers at the University of Pennsylvania, and it has quickly become one of the most powerful and complete library of NLP tools available. \u003c/p\u003e\n\n\u003ch3\u003eRegular Expressions\u003c/h3\u003e\n\n\u003cp\u003eData preprocessing is an essential part of NLP, and that's why being very familiar with \u003cstrong\u003eregular expressions\u003c/strong\u003e is extremely important. Regular expressions, or \"Regex\" is extremely useful for NLP. We can use regex to quickly pattern match and filter through text documents. \u003c/p\u003e\n\n\u003ch3\u003eFeature Engineering for Text Data\u003c/h3\u003e\n\n\u003cp\u003eWorking with text data comes with a lot of ambiguity. Feature engineering for NLP is pretty specific, and in this section you'll learn some feature engineering techniques that are essential when working with text data. You'll learn how to remove stop words from your text, as well as how to create frequency distributions, representing histograms that give us an overview of the total number of times each word occurs in a given text corpus. \u003c/p\u003e\n\n\u003cp\u003eAdditionally, you'll learn about stemming and lemmatization, which is the technique of removing suffixes from our words (and can enhance our text insight by creating frequency histograms \u003cem\u003eafter\u003c/em\u003e having performed stemming or lemmatization!). You'll also learn how to create bigrams, which creates an insight on how often two words occur together!\u003c/p\u003e\n\n\u003ch3\u003eContext-Free Grammars and Part-of-Speech (POS) Tagging\u003c/h3\u003e\n\n\u003cp\u003eIn NLP, it is important to understand what context-free grammars and part-of-speech tagging are. Context-free grammars refer to bits of text that are grammatically correct, but feel like complete nonsense when considering the same bit of text on the semantic level. POS tagging refers to the act of helping a computer understand how to interpret a sentence. The context-free grammars (CFG) defines the rules of how sentences can exist. You'll see multiple examples on how to use both CFG and POS tagging, and why they are important!\u003c/p\u003e\n\n\u003ch3\u003eText Classification\u003c/h3\u003e\n\n\u003cp\u003eWe will finish off this section by explaining the general process to set text data up for classification problems.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the foundations of NLP and different techniques to make a computer understand text!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-nlp-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-nlp-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-nlp-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"graph-theory-recap","title":"Graph Theory - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networks-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networks-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you explored a new data structure: networks! While network analysis is a deep topic with many additional topics to explore, you should have a good initial introduction and enough to conduct some preliminary analyses for social networks and building recommendation systems.\u003c/p\u003e\n\n\u003ch2\u003eNetworks\u003c/h2\u003e\n\n\u003cp\u003eYou've seen that networks can represent a range of different underlying data. From directions, social networks, and customer databases, networks are a wonderful way to represent the relationships between individuals. They also make for some snazzy visuals!\u003c/p\u003e\n\n\u003ch2\u003ePaths\u003c/h2\u003e\n\n\u003cp\u003eThe first stop along your journey was paths! Here, you investigated Dijkstra's algorithm to find the shortest path between nodes. This harked back to some of your experience scraping the web when you used recursive functions to perform breadth and depth based search techniques to transverse a json file. While you didn't directly explore this application, networks are also a natural representation for exploring internet traffic and web page structures.\u003c/p\u003e\n\n\u003ch2\u003eCentrality\u003c/h2\u003e\n\n\u003cp\u003eOnce you had a metric to calculate the distance between nodes, you then started to investigate other important concepts of networks such as which nodes were most influential or connected within a graph. You saw how alternative metrics can provide different insights on node structure. As a quick recap:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eDegree-centrality\u003c/strong\u003e: The number of edges attached to a node\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eCloseness-centrality\u003c/strong\u003e: The reciprocal of the sum of the distances to all other nodes in the network \u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eBetweeness-centrality\u003c/strong\u003e: The number of shortest paths between all node pairs the node lies on divided by the maximum number of shortests-paths any one node in the network lies on \u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eEigenvalue-centrality\u003c/strong\u003e: An iterative algorithm which assigns relative influence to a node based on the number and importance of connected nodes. Can be very computationally expensive to compute for large networks. Google's PageRank algorithm is a variation of eigenvalue-centrality \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003eAfter discussing centrality, you then focused on larger structures within a network, breaking apart nodes into clusters to examine subgroups. While this is a common and useful application, it is an ill-defined problem mathematically, often making it difficult to definitively determine an optimal clustering schema. \u003c/p\u003e\n\n\u003ch2\u003eRecommendations\u003c/h2\u003e\n\n\u003cp\u003eFinally, you rounded out the section by investigating how networks can be used to provide recommendations to users. To do this, you investigated a preliminary approach known as collaborative filtering, specifically exploring user-based collaborative filtering in which similar users are identified and their preferences are used to generate recommendations to the user in question. There are many alternative approaches to recommendations systems such as using Singular Value Decomposition. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eA lot was covered in this section! From this, you should have a solid introduction to networks, and some of their applications. Going forward, continue to explore ongoing developments in clustering social networks, and generating recommendations from these fascinating data structures.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-networks-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-networks-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-networks-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"the-aws-ecosystem","title":"The AWS Ecosystem","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-the-aws-ecosystem\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll get set up to use \u003cstrong\u003e\u003cem\u003eAmazon Web Services\u003c/em\u003e\u003c/strong\u003e, and then get to know our way around the platform. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/awscloud.svg\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eSet up an AWS account and explore the Amazon Resource Center \u003c/li\u003e\n\u003cli\u003eExplain what the \"regions\" are in AWS and why it is important to choose the right one\u003c/li\u003e\n\u003cli\u003eExplain the purpose of AWS IAM\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\n\u003cp\u003eBefore we can begin exploring everything AWS has to offer, we'll need to create an account on the platform. To do this, start by following this link to \u003ca href=\"https://aws.amazon.com/\"\u003eAmazon Web Services\u003c/a\u003e. While you're there, you may want to take the time to bookmark it -- chances are this is a website you'll use frequently in your career as a data scientist!\u003c/p\u003e\n\n\u003ch3\u003eWill This Cost Money?\u003c/h3\u003e\n\n\u003cp\u003eAlthough you will need a credit card to register for AWS, working through this section will not cost any money. AWS provides a free tier for learning and prototyping on the platform -- this is the tier we'll use for everything going forward. As long as you correctly register for the free tier, this will not cost you any money. \u003c/p\u003e\n\n\u003ch3\u003eRegister Your Email\u003c/h3\u003e\n\n\u003cp\u003eBegin by clicking the \"Sign Up\" button in the top right-hand corner of the page. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-1.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNext, create an account by adding your email and password. You'll also need to set an \u003cstrong\u003e\u003cem\u003eAWS Account Name\u003c/em\u003e\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-2.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eOn the next screen, enter your contact information. \u003cstrong\u003e\u003cem\u003eMake sure you set your account type to 'Personal'!\u003c/em\u003e\u003c/strong\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-3.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis next page is especially important -- be sure to select the \u003cstrong\u003e\u003cem\u003eBasic Plan\u003c/em\u003e\u003c/strong\u003e! As a reminder, you will be asked to enter a credit card number during the next few steps. Although we will only be making use of the free tier of services for AWS, be aware that you will still need to enter a credit card number in order to complete the registration process. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-4.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNow that you're all signed up, click the \"Sign in to the Console\" button to actually enter the AWS Console. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-5.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eGreat, you've now created an AWS Account! Let's take a look around. \u003c/p\u003e\n\n\u003ch2\u003eThe AWS Console\u003c/h2\u003e\n\n\u003cp\u003eNow that you're signed in, you'll see the \u003cstrong\u003e\u003cem\u003eAWS Console\u003c/em\u003e\u003c/strong\u003e. This is your \"home screen\" for AWS -- it allows you to quickly navigate through the thousands of services offered on AWS to find what you need. The easiest way to find what you need is the \"Find Services\" search bar at the top of the body of the page. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-6.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eYou can also click the \"See All Services\" dropdown to see a full list of services you can use in AWS. There are \u003cstrong\u003ea ton\u003c/strong\u003e of services, but don't let yourself get overwhelmed -- you'll probably never end up using the vast majority of these, as only a few apply to the work of a data scientist.\u003c/p\u003e\n\n\u003ch2\u003eA Note on Regions\u003c/h2\u003e\n\n\u003ch3\u003eAWS Regions\u003c/h3\u003e\n\n\u003cp\u003eAWS has data centers all over the world, and they are \u003cstrong\u003enot\u003c/strong\u003e interchangeable when it comes to your projects. Check out \u003ca href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\"\u003ethis link\u003c/a\u003e to see a list of all of the current AWS regions across the globe. While it typically won't matter for your projects in this program, the different AWS regions vary in terms of latency, cost, legal compliance, and features.\u003c/p\u003e\n\n\u003cp\u003eEach AWS region is a separate geographic area and is designed to be completely isolated from the other regions. This helps achieve the greatest possible fault-tolerance and stability. Communication between regions is possible, but often costs money and/or requires additional security configuration.\u003c/p\u003e\n\n\u003ch3\u003eImplications for Your Projects\u003c/h3\u003e\n\n\u003cp\u003eIt is \u003cstrong\u003e\u003cem\u003every important\u003c/em\u003e\u003c/strong\u003e that you always choose the same region to connect to with your projects. Resources are not automatically replicated across regions! One of the most common mistakes newcomers to AWS make is thinking they've lost their project because they are connected to a different data center and don't realize it. We'll remind you of this again later, but it can't hurt to say it twice: always make sure you're connected to the correct data center! This goes doubly for when you're creating a new project. \u003c/p\u003e\n\n\u003ch2\u003eAWS IAM\u003c/h2\u003e\n\n\u003cp\u003eIAM stands for \u003ca href=\"https://aws.amazon.com/iam/\"\u003eIdentity and Access Management\u003c/a\u003e. AWS allows IT administrators to configure access to different services at a very granular level, which can get intimidating pretty quickly!\u003c/p\u003e\n\n\u003cp\u003eEssentially all you need to know is that access to services requires you to create a \u003cstrong\u003erole\u003c/strong\u003e in IAM, and then set a \u003cstrong\u003epolicy\u003c/strong\u003e for that role's access permissions. In some cases, e.g. you want to run a cloud notebook in \u003ca href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/security-iam.html\"\u003eAWS SageMaker\u003c/a\u003e, that role should be restricted to just you, and you should have permission to take any action. In other cases, e.g. you want to store data in an \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-overview.html\"\u003eS3 bucket\u003c/a\u003e, you might want to allow anyone to download the data, but only allow yourself to upload.\u003c/p\u003e\n\n\u003cp\u003eIn our curriculum examples we'll advise on IAM settings, but you'll likely need to do your own research as you explore beyond these for your own projects. Luckily these are public projects so the risk of leaking data or models is low. In a job setting, make sure you consult with your IT team to make sure that you are not revealing private data.\u003c/p\u003e\n\n\u003ch2\u003eUsing the Amazon Resource Center\u003c/h2\u003e\n\n\u003cp\u003eAs platforms go, you won't find many with more options than AWS. It has an amazing amount of offerings, with more getting added all the time. While AWS is great for basic use cases like hosting a server or a website, it also has all kinds of different offerings in areas such as Databases, Machine Learning, Data Analytics and other areas useful to Data Scientists.\u003c/p\u003e\n\n\u003cp\u003eIt's not possible for us to cover how to use every service in AWS in this section -- but luckily, we don't need to, because Amazon already has! The \u003ca href=\"https://aws.amazon.com/getting-started/\"\u003eGetting Started Resource Center\u003c/a\u003e contains a ton of awesome tutorials, demonstrations, and sample projects for just about everything you would ever want to know about any service on AWS. We \u003cstrong\u003e\u003cem\u003estrongly recommend\u003c/em\u003e\u003c/strong\u003e bookmarking this page, as the tutorials they offer are very high quality, and free!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-the-aws-ecosystem/raw/master/images/aws-7.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we signed up for Amazon Web Services and explored some of the different options on the platform. \u003c/p\u003e","frontPage":false},{"exportId":"topic-35-lesson-priorities-live","title":"Topic 35 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 284px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eTime Series Modeling\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Modeling Time Series Data - Introduction\" href=\"pages/modeling-time-series-data-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/modeling-time-series-data-introduction\" data-api-returntype=\"Page\"\u003eModeling Time Series Data - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Basic Time Series Models\" href=\"assignments/g93c55fdf39a2cc133da1d60ed47dc1d4\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187090\" data-api-returntype=\"Assignment\"\u003eBasic Time Series Models\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Basic Time Series Models - Lab\" href=\"assignments/g1d58818d312c4d5f9f62f3dc6c1b782b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187091\" data-api-returntype=\"Assignment\"\u003eBasic Time Series Models - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Correlation and Autocorrelation in Time Series\" href=\"assignments/g707994093d5da85ab8ed839b66896e84\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187101\" data-api-returntype=\"Assignment\"\u003eCorrelation and Autocorrelation in Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Correlation and Autocorrelation in Time Series - Lab\" href=\"assignments/gff5be975b62dc44dd62d3c3e18377bd7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187102\" data-api-returntype=\"Assignment\"\u003eCorrelation and Autocorrelation in Time Series - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"ARMA Models\" href=\"pages/arma-models\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/arma-models\" data-api-returntype=\"Page\"\u003eARMA Models\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"ARMA Models in statsmodels\" href=\"assignments/gf868208900f3e52add61497dd6c38a20\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187088\" data-api-returntype=\"Assignment\"\u003eARMA Models in statsmodels\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"ARMA Models in statsmodels - Lab\" href=\"assignments/gc3248cd9dd99557b6439eb760221ba01\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187089\" data-api-returntype=\"Assignment\"\u003eARMA Models in statsmodels - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 41.6686%;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Time Series\" href=\"quizzes/g6f491f0e0c0297c3b56e2a98b1f7ec9a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30674\" data-api-returntype=\"Quiz\"\u003eQuiz: Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.4856%; height: 36px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Modeling\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eTime Series Modeling Walkthrough\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Time Series Modeling Exit Ticket\" href=\"quizzes/gfc62258e0fcd6a6f69716d3621e26746\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30682\" data-api-returntype=\"Quiz\"\u003e\u003cstrong\u003eTime Series Modeling Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.5794%; height: 76px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Modeling Walkthrough\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Modeling Walkthrough Exit Ticket\" href=\"quizzes/g1312f4631ddd87855c7283a1939eb895\"\u003eTime Series Modeling Walkthrough Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Modeling Time Series Data - Recap\" href=\"pages/modeling-time-series-data-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/modeling-time-series-data-recap\" data-api-returntype=\"Page\"\u003eModeling Time Series Data - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"nlp-and-word-vectorization","title":"NLP and Word Vectorization","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-nlp-and-word-vectorization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-and-word-vectorization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-and-word-vectorization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about some foundational concepts in Natural Language Processing such as stemming and lemmatization, as well as various strategies for converting text data into word vectors!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain stemming and lemmatization\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eExplain what stop words are and why they are frequently removed \u003c/li\u003e\n\u003cli\u003eDefine tokenization in the context of NLP \u003c/li\u003e\n\u003cli\u003eDefine TF-IDF vectorization and its components \u003c/li\u003e\n\u003cli\u003eDefine count vectorization and its relationship to bag of words \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Natural Language Processing?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eNatural Language Processing\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eNLP\u003c/em\u003e\u003c/strong\u003e, is the study of how computers can interact with humans through the use of human language.  Although this is a field that is quite important to Data Scientists, it does not belong to Data Science alone.  NLP has been around for quite a while, and sits at the intersection of \u003cem\u003eComputer Science\u003c/em\u003e, \u003cem\u003eArtificial Intelligence\u003c/em\u003e, \u003cem\u003eLinguistics\u003c/em\u003e, and \u003cem\u003eInformation Theory\u003c/em\u003e. In the early days of NLP, it mainly consisted of trying to program algorithms that contained many rules borrowed from the field of linguistics. However, in the 1980s, machine learning started to show great success with many NLP tasks, and many of these rule-based methods took a back seat to approaches involving machine learning and AI. Fast forward to now, and NLP has become an area of applied machine learning that Data Scientists all around the globe work in every day. \u003c/p\u003e\n\n\u003ch2\u003eNLP and Bayesian Statistics\u003c/h2\u003e\n\n\u003cp\u003eAs machine learning has come into its own, we've seen NLP products get better and better.  For instance, in just a few decades, we've gone from rule-based chat bots with preprogrammed responses to things like Siri and \u003ca href=\"https://www.youtube.com/watch?v=D5VN56jQMWM\"\u003eGoogle Duplex\u003c/a\u003e (if you aren't familiar with Duplex, take a few minutes to follow that link and watch the demo on YouTube -- you won't be disappointed!). Much of the most exciting advancements currently happening in the field of NLP are due to Deep Learning.  However, we can still do amazing things with machine learning and text data by making use of Bayesian methods. For instance, you may remember a time in the early 2000s when the problem of email spam was bad, and getting worse.  This problem was eventually solved through the application of machine learning -- specifically, \u003cstrong\u003e\u003cem\u003eNaive Bayesian Classification\u003c/em\u003e\u003c/strong\u003e!  For the remainder of this section, we'll focus on how we can apply our newfound knowledge of Bayesian methods to solve real-world NLP tasks such as \u003ca href=\"http://www.paulgraham.com/spam.html\"\u003espam filtering\u003c/a\u003e and text classification. \u003c/p\u003e\n\n\u003ch2\u003eWorking With Text Data\u003c/h2\u003e\n\n\u003cp\u003eWorking with text data comes with a unique set of problems and solutions that other types of datasets don't have.  Often, text data requires more cleaning and preprocessing than normal data, in order to get it into a format where we can use statistical methods or machine learning to work with it. Let's explore some of the things we generally need to do to get text data into a form where we can work with it. \u003c/p\u003e\n\n\u003ch2\u003eCreating a  Bag of Words\u003c/h2\u003e\n\n\u003cp\u003eThe most common approach to working with text is to vectorize it by creating a \u003cstrong\u003e\u003cem\u003eBag of Words\u003c/em\u003e\u003c/strong\u003e.  In this case, the name \"Bag of Words\" is quite descriptive of the final product -- the bag contains information about all the important words in the text individually, but not in any particular order. It's as if we take every word in a \u003cstrong\u003e\u003cem\u003eCorpus\u003c/em\u003e\u003c/strong\u003e and throw them into a bag. With a large enough corpus, we'll often see certain patterns start to emerge -- for instance, a bag of words made out of Shakespeare's \u003cem\u003eHamlet\u003c/em\u003e is probably more similar to a bag of words made out of \u003cem\u003eMacbeth\u003c/em\u003e than it is to something like \u003cem\u003eThe Hunger Games\u003c/em\u003e. The simplest way to create a bag of words is to just count how many times each unique word is used in a given corpus. If we have a number for every word, then we have a way to treat each bag as a \u003cstrong\u003e\u003cem\u003evector\u003c/em\u003e\u003c/strong\u003e, which opens up all kinds of machine learning tools for use.  \u003c/p\u003e\n\n\u003cp\u003eLet's explore some of the steps that must occur before we can fully vectorize a text and work with it.\u003c/p\u003e\n\n\u003ch3\u003eBasic Cleaning and Tokenization\u003c/h3\u003e\n\n\u003cp\u003eOne of the most basic problems seen when working with text data is things like punctuation and capitalization.  Although counting how many times a word appears in a text sounds straightforward at first, it can actually be quite complicated at times, and will almost always require some decisions on our part. For instance, consider the following sentence:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"Apple shareholders have had a great year. Apple's stock price has gone steadily upwards -- Apple even broke a trillion-dollar valuation, continuing the dominance of this tech stock.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIf we were to count how many times each word appears in this sentence, we would likely say that \"Apple\" has a count of three.  However, if we wrote a basic Python script to do this, our algorithm would tell us that the word \"Apple\" only appears twice! To a computer, \"Apple\" and \"Apple's\" are different words.  Capitalization is also a problem -- \"apple\" would also be counted as a different word. Similarly, punctuation is also a problem.  A basic counting algorithm would see \"stock\" and \"stock.\" as two completely different words. \u003c/p\u003e\n\n\u003cp\u003eFirst and foremost, cleaning a text dataset usually means removing punctuation, and lowercasing everything. However, this can be tricky, and require decisions on your part based on the text you're working with and your goals -- for instance, whether or not apostrophes should be removed. \u003c/p\u003e\n\n\u003cp\u003eThe goal of this step is to create word \u003cstrong\u003e\u003cem\u003etokens\u003c/em\u003e\u003c/strong\u003e. The sentence \"Where did you get those coconuts?\", when cleaned and tokenized, would probably look more like \u003ccode\u003e['where', 'did', 'you, 'get', 'those', 'coconuts']\u003c/code\u003e. \u003c/p\u003e\n\n\u003cp\u003eHowever, there are still other important decisions to make during the tokenization stage. For instance, should \"run\" and \"runs\" be counted as the same token, or as different tokens? How about \"ran\", or \"running\"?  \u003c/p\u003e\n\n\u003ch3\u003eStemming, Lemmatization, and Stop Words\u003c/h3\u003e\n\n\u003cp\u003eSometimes, depending on the task, it may be best to leave \"run\" and \"runs\" as different tokens.  However, this often is not the case -- especially with smaller datasets.  NLP methods such as \u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e help us deal with this problem, where we reduce each word token down to its root word.  For cases such as \"run\", \"runs\", \"running\" and \"ran\", they are more similar than different -- we may want our algorithm to treat these as the same word, \"run\".  \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e accomplishes this by removing the ends of words where the end signals some sort of derivational change to the word. For instance, we know that adding an 's' to the end of a word makes it plural -- a stemming algorithm given the word \"cats\" would return \"cat\".  Note that stems do not have to make sense as actual English words. For example, \"ponies\" would be reduced to \"poni\", not \"pony\". Stemming is a more crude, heuristic process that contains rule sets that tells the algorithm how to stem each word, and what it should be stemmed to. The process is more crude than lemmatization, but it's also easier to implement. For instance, take a look at this example subset of stemming rules from the \u003ca href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\"\u003eStanford NLP Group\u003c/a\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-nlp-and-word-vectorization/master/images/new_stemming.png\" alt=\"stemming rules and examples\" width=\"400\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e accomplishes pretty much the same thing as stemming, but does it in a more complex way, by examining the \u003cstrong\u003e\u003cem\u003emorphology\u003c/em\u003e\u003c/strong\u003e of words and attempting to reduce each word to its most basic form, or \u003cstrong\u003e\u003cem\u003elemma\u003c/em\u003e\u003c/strong\u003e.  Note that the results here often end up a bit different than stemming.  See the following table for an example of the differences in results:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: center\"\u003eWord\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eStem\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eLemma\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003eStudies\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudi\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003eStudying\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003eStudy\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eFinally, you may have intuited that many words in a text are pretty much useless and contain little to no actual information. For instance, words such as \"the\" and \"of\".  These are called \u003cstrong\u003e\u003cem\u003eStop Words\u003c/em\u003e\u003c/strong\u003e, and are often removed after tokenization is complete in order to reduce the dimensionality of each corpus down to only the words that contain important information. Popular NLP frameworks and toolkits such as NLTK contain a list of stop words for most languages, which allow us to easily loop through our tokenized corpus and remove any stop words we find. \u003c/p\u003e\n\n\u003ch2\u003eVectorization Strategies\u003c/h2\u003e\n\n\u003cp\u003eOnce we cleaned and tokenized our text data, we can convert it to vectors. However, there are a few different ways we can do this. Depending on our goals and our dataset, some may be more useful than others. \u003c/p\u003e\n\n\u003ch3\u003eCount Vectorization\u003c/h3\u003e\n\n\u003cp\u003eOne of the most basic, but useful ways of vectorizing text data is to simply count the number of times each word appears in the corpus. If working with a single document, we just create a single vector, where each element in the vector corresponds to the count of a unique word in the document. If working with multiple documents, we would store everything in a DataFrame, with each column representing a unique word, while each row represents the count vector for a given document. \u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: center\"\u003eDocument\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eAardvark\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eApple\u003c/th\u003e\n\u003cth\u003e...\u003c/th\u003e\n\u003cth\u003eZebra\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e0\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e3\u003c/td\u003e\n\u003ctd\u003e...\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: center\"\u003e2\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e1\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e2\u003c/td\u003e\n\u003ctd\u003e...\u003c/td\u003e\n\u003ctd\u003e0\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eNote that we do not need to have a column for every word in the English language -- just a column for each word that shows up in the total vocabulary of our document or documents. If we have multiple documents, we just combine the unique words from each document to get the total dimensionality that allows us to represent each. If a word doesn't show up in a given document, that's fine -- that just means the count is 0 for that row and column. \u003c/p\u003e\n\n\u003ch3\u003eTF-IDF Vectorization\u003c/h3\u003e\n\n\u003cp\u003eTF-IDF stands for \u003cstrong\u003e\u003cem\u003eTerm Frequency-Inverse Document Frequency\u003c/em\u003e\u003c/strong\u003e. It is a combination of two individual metrics, which are the TF and IDF, respectively. TF-IDF is used when we have multiple documents. It is based on the idea that rare words contain more information about the content of a document than words that are used many times throughout all the documents. For instance, if we treated every article in a newspaper as a separate document, looking at the amount of times the word \"he\" or \"she\" is used probably doesn't tell us much about what that given article is about -- however, the amount of times \"touchdown\" is used can provide good signal that the article is probably about sports.  \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTerm Frequency\u003c/em\u003e\u003c/strong\u003e is calculated with the following formula:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Term\\ Frequency(t) = \\frac{number\\ of\\ times\\ t\\ appears\\ in\\ a\\ document} {total\\ number\\ of\\ terms\\ in\\ the\\ document} \" src=\"/equation_images/%255Clarge%20Term%255C%20Frequency(t)%20=%20%255Cfrac{number%255C%20of%255C%20times%255C%20t%255C%20appears%255C%20in%255C%20a%255C%20document}%20{total%255C%20number%255C%20of%255C%20terms%255C%20in%255C%20the%255C%20document}\" alt=\"{\" data-equation-content=\"\\large Term\\ Frequency(t) = \\frac{number\\ of\\ times\\ t\\ appears\\ in\\ a\\ document} {total\\ number\\ of\\ terms\\ in\\ the\\ document} \"\u003e\u003c/p\u003e \u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eInverse Document Frequency\u003c/em\u003e\u003c/strong\u003e is calculated with the following formula:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large IDF(t) = log_e(\\frac{Total\\ Number\\ of\\ Documents}{Number\\ of\\ Documents\\ with\\ t\\ in\\ it})\" src=\"/equation_images/%255Clarge%20IDF(t)%20=%20log_e(%255Cfrac{Total%255C%20Number%255C%20of%255C%20Documents}{Number%255C%20of%255C%20Documents%255C%20with%255C%20t%255C%20in%255C%20it})\" alt=\"{\" data-equation-content=\"\\large IDF(t) = log_e(\\frac{Total\\ Number\\ of\\ Documents}{Number\\ of\\ Documents\\ with\\ t\\ in\\ it})\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThe \u003cstrong\u003e\u003cem\u003eTF-IDF\u003c/em\u003e\u003c/strong\u003e value for a given word in a given document is just found by multiplying the two!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about some foundational concepts in Natural Language Processing such as stemming and lemmatization, as well as various strategies for converting text data into word vectors.\u003c/p\u003e","frontPage":false},{"exportId":"neural-networks-introduction","title":"Neural Networks - Introduction","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-neural-nets-intro-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-intro-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-intro-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll be introduced to one of the most advanced machine learning algorithms currently in the world -- neural networks! \u003c/p\u003e\n\n\u003ch2\u003eDeep Learning\u003c/h2\u003e\n\n\u003cp\u003eThe time has come to learn about one of the most exciting and fast-growing areas of data science: Deep Learning! When we talk about deep learning, we are talking about (deep) neural networks. You'll learn all about them in this section. You'll also use Python to build (basic) neural networks from scratch.\u003c/p\u003e\n\n\u003ch3\u003eNeural Networks\u003c/h3\u003e\n\n\u003cp\u003eIn this section, you'll learn what it means when we talk about neural networks. You'll learn about the essential building blocks like \"layers\", \"nodes\", \"arrows\", \"weights\", \"loss\", \"cost function\", etc. You'll learn that a neural network generally consists of several layers, and how a logistic regression model can be represented as a neural network with just one layer. You'll be able to explain what the advantages and disadvantages of using neural networks are, and get an insight of how forward and backward propagation are used in neural networks to minimize the loss and \"optimize\" your neural network.\u003c/p\u003e\n\n\u003ch3\u003eKeras and TensorFlow\u003c/h3\u003e\n\n\u003cp\u003eYou'll be introduced to Keras, a leading open source neural network library in Python, which is now a part of TensorFlow. Keras makes building neural networks surprisingly easy. Before building your first neural network model in Keras, you'll learn about tensors and why they are important when building deep learning models.\u003c/p\u003e\n\n\u003ch3\u003eDeeper Neural Networks\u003c/h3\u003e\n\n\u003cp\u003eYou'll learn why deeper networks sometimes lead to better results, and we'll generalize what you have learned before to get your matrix dimensions right for deep networks. You'll build deeper neural networks from scratch, and also learn how to build these using Keras.\u003c/p\u003e\n\n\u003cp\u003eYou'll learn that deep representations are really good at automating what used to be a tedious and time-consuming process of feature engineering. In this section, you'll see that you can actually build a smaller but deeper neural network with exponentially less hidden units which performs even better than a network with more hidden units. The reason for this is that learning happens in each layer, and adding more layers (even with fewer limits) can lead to very powerful predictions! You'll learn about matrix notation for these deep networks and how to build a network like that from scratch.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the basics of neural networks and how to implement them in Keras!\u003c/p\u003e","frontPage":false},{"exportId":"neural-networks-recap","title":"Neural Networks - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-neural-nets-recap-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-recap-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-neural-nets-recap-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003ch3\u003eNeural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eNeural networks are powerful models that can be customized and tweaked using various amounts of nodes, layers, etc.\u003c/li\u003e\n\u003cli\u003eThe most basic neural networks are single-layer densely connected neural networks, which have very similar properties as logistic regression models\u003c/li\u003e\n\u003cli\u003eCompared to more traditional statistics and ML techniques, neural networks perform particularly well when using unstructured data\u003c/li\u003e\n\u003cli\u003eApart from densely connected networks, other types of neural networks include convolutional neural networks, recurrent neural networks, and generative adversarial neural networks \u003c/li\u003e\n\u003cli\u003eWhen working with image data, it's important to understand how image data is stored when working with them in Python\u003c/li\u003e\n\u003cli\u003eLogistic regression can be seen as a single-layer neural network with a sigmoid activation function\u003c/li\u003e\n\u003cli\u003eNeural networks use loss and cost functions to minimize the \"loss\", which is a function that summarizes the difference between the actual outcome (eg. pictures contain Santa or not) and the model prediction (whether the model correctly identifies pictures with Santa)\u003c/li\u003e\n\u003cli\u003eBackward and forward propagation are used to estimate the so-called \"model weights\"\u003c/li\u003e\n\u003cli\u003eAdding more layers to neural networks can substantially increase model performance\u003c/li\u003e\n\u003cli\u003eSeveral activations can be used in model nodes, you can explore with different types and evaluate how it affects performance\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eDeep Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eDeep neural network representations can lighten the burden and automate certain tasks of heavy data preprocessing\u003c/li\u003e\n\u003cli\u003eDeep representations need exponentially fewer hidden units than shallow networks, to obtain the same performance\u003c/li\u003e\n\u003cli\u003eParameter initialization, forward propagation, cost function evaluation, and backward propagation are again the cornerstones of deep networks\u003c/li\u003e\n\u003cli\u003eTensors are the building blocks of neural networks and a good understanding of them and how to use them in Python is crucial\u003c/li\u003e\n\u003cli\u003eScalars can be seen as 0-D tensors. Vectors can be seen as 1-D tensors, and matrices as 2-D tensors\u003c/li\u003e\n\u003cli\u003eThe usage of tensors reaches beyond matrices: tensors can have N dimensions\u003c/li\u003e\n\u003cli\u003eTensors can be created and manipulated using NumPy\u003c/li\u003e\n\u003cli\u003eKeras makes building neural networks in Python easy, and you learned how to do that in this section\u003c/li\u003e\n\u003cli\u003eYou can use Keras to do some NLP as well, e.g. for tokenization \u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"modeling-time-series-data-introduction","title":"Modeling Time Series Data - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about modeling for time series data. \u003c/p\u003e\n\n\u003ch2\u003eTime Series Modeling\u003c/h2\u003e\n\n\u003cp\u003eIn the previous section, we introduced the idea of time series data and provided some best practices for importing, managing, and visualizing time series data along with a number of techniques for removing trends and/or seasonality from a time series dataset. In this section, we're going to look at various types of models for time series data.\u003c/p\u003e\n\n\u003ch3\u003eBasic Time Series Models\u003c/h3\u003e\n\n\u003cp\u003eWe start off by introducing two basic time series models -- the white noise and random walk models.\u003c/p\u003e\n\n\u003ch3\u003eCorrelation, Autocorrelation, and Partial Autocorrelation\u003c/h3\u003e\n\n\u003cp\u003eWe will then move on to the concept of correlation as it relates to time series datasets, and plot the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) for a time series. \u003c/p\u003e\n\n\u003ch3\u003eARMA Models\u003c/h3\u003e\n\n\u003cp\u003eWe then move on to introduce two other key time series models that are widely used for predicting future values for time series data - the auto regressive (AR) and moving average (MA) models.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eLet's get started! This section wraps up our introduction to time series analysis, giving you the modeling tools required to effectively forecast time series data.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-time-series-models-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-time-series-models-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-time-series-models-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"table-of-contents-live","title":"Table of Contents (Live)","type":"WikiPage","content":"\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 31: Principal Component Analysis\" href=\"modules/g7c67143d69f51335e99562b32712bfd8\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43434\" data-api-returntype=\"Module\"\u003eTopic 31: Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 31 Lesson Priorities (Live)\" href=\"pages/topic-31-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-31-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 31 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 32: Recommendation Systems\" href=\"modules/g0e06344ce8eccc6ff781e3cbbfbb9aa9\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43435\" data-api-returntype=\"Module\"\u003eTopic 32: Recommendation Systems\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 32 Lesson Priorities (Live)\" href=\"pages/topic-32-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-32-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 32 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 33: Clustering\" href=\"modules/gce68bd8eeb6464538bfeaabf4566602f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43436\" data-api-returntype=\"Module\"\u003eTopic 33: Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 33 Lesson Priorities (Live)\" href=\"pages/topic-33-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-33-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 33 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 34: Exploring Time Series Data\" href=\"modules/g7ad5bedda4978b4fa340558c6c6d71ca\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43437\" data-api-returntype=\"Module\"\u003eTopic 34: Exploring Time Series Data\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003e\u003ca title=\"Topic 34 Lesson Priorities (Live)\" href=\"pages/topic-34-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-34-lesson-priorities-live\" data-api-returntype=\"Page\"\u003eTopic 34 Lesson Priorities\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 35: Modeling Time Series Data\" href=\"modules/ge5695df63ab9b4a0c363f3024c5a3cc9\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43438\" data-api-returntype=\"Module\"\u003eTopic 35: Modeling Time Series Data\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 35 Lesson Priorities (Live)\" href=\"pages/topic-35-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-35-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 35 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 36: Big Data and (Py)Spark\" href=\"modules/ga5e985716089f35d6154990b88b1513f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43439\" data-api-returntype=\"Module\"\u003eTopic 36: Big Data and (Py)Spark\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 36 Lesson Priorities (Live)\" href=\"pages/topic-36-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-36-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 36 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 37: Natural Language Processing\" href=\"modules/g42079c4ff48ac0dfe3c3fa1b40ffe628\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43440\" data-api-returntype=\"Module\"\u003eTopic 37: Natural Language Processing\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 37 Lesson Priorities (Live)\" href=\"pages/topic-37-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-37-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 37 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 38: Neural Networks\" href=\"modules/g23a6d31a68ba26c6d7b06ca5047ca55a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43441\" data-api-returntype=\"Module\"\u003eTopic 38: Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 38 Lesson Priorities (Live)\" href=\"pages/topic-38-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-38-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 38 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 39: Tuning Neural Networks\" href=\"modules/g36962a75f13484bc512e7f84c95d4708\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43442\" data-api-returntype=\"Module\"\u003eTopic 39: Tuning Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 39 Lesson Priorities (Live)\" href=\"pages/topic-39-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-39-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 39 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca title=\"Topic 40: Amazon Web Services\" href=\"modules/g0e7370999d9fba80091511a7fa02df15\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43443\" data-api-returntype=\"Module\"\u003eTopic 40: Amazon Web Services\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003ca title=\"Topic 40 Lesson Priorities (Live)\" href=\"pages/topic-40-lesson-priorities-live\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/topic-40-lesson-priorities-live\" data-api-returntype=\"Page\"\u003e\u003cspan style=\"font-size: 10pt;\"\u003eTopic 40 Lesson Priorities\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca title=\"üèÜ Milestones\" href=\"modules/g4ced624eeaf253578a9cdbfadc24c3d5\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43432\" data-api-returntype=\"Module\"\u003eüèÜ Milestones\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca title=\"APPENDIX: More Time Series\" href=\"modules/g9f7eddb4c2ad4c55c1b6f443cdd47aac\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/modules/43444\" data-api-returntype=\"Module\"\u003eAPPENDIX\u003c/a\u003e\u003c/p\u003e","frontPage":true},{"exportId":"phase-4-project-choosing-a-dataset","title":"Phase 4 Project - Choosing a Dataset","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-phase-4-choosing-a-dataset\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e  \u003cp\u003eFor this phase, you will choose a project that relates to one of the following topics:\u003c/p\u003e  \u003cul\u003e \u003cli\u003eTime Series Modeling\u003c/li\u003e \u003cli\u003eRecommendation Systems\u003c/li\u003e \u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e \u003cli\u003eNatural Language Processing\u003c/li\u003e \u003c/ul\u003e  \u003ch2\u003eThe Data\u003c/h2\u003e  \u003cp\u003eWe have provided a dataset suitable to each topic, but you are also welcome to source your own dataset. If you choose your own dataset, \u003cstrong\u003erun the dataset and business problem by your instructor for approval\u003c/strong\u003e before starting your project.\u003c/p\u003e  \u003ch3\u003eHow to Choose a Project\u003c/h3\u003e  \u003cp\u003eWhen choosing a project, consider one of the following approaches:\u003c/p\u003e  \u003col\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eDepth:\u003c/strong\u003e Choose a project that similar to what you want to do for your capstone project (Phase 5). This will allow you to practice those methods in a group setting before needing to use it independently. This will help you build a better Capstone project and a portfolio that demonstrates the ability to deeply learn and implement one modeling approach.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eBreadth:\u003c/strong\u003e Choose a problem that you don't necessarily plan to use in your capstone project. This will allow you to develop applied experience with multiple modeling approaches. This will help you refine your areas of interest and build a portfolio that demonstrates the ability to learn and implement multiple modeling approaches.\u003c/p\u003e\u003c/li\u003e \u003c/ol\u003e  \u003cp\u003eIf you are feeling overwhelmed or behind, we recommend you choose Topic 3: Image Classification with Deep Learning.\u003c/p\u003e  \u003ch3\u003eTopic 1: Time Series Modeling\u003c/h3\u003e  \u003cp\u003eIf you choose the Time Series option, you will be forecasting real estate prices of various zip codes using data from \u003ca href=\"https://www.zillow.com/research/data/\"\u003eZillow Research\u003c/a\u003e. For this project, you will be acting as a consultant for a fictional real-estate investment firm. The firm has asked you what seems like a simple question:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eWhat are the top 5 best zip codes for us to invest in?\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eThis may seem like a simple question at first glance, but there's more than a little ambiguity here that you'll have to think through in order to provide a solid recommendation. Should your recommendation be focused on profit margins only? What about risk? What sort of time horizon are you predicting against?  Your recommendation will need to detail your rationale and answer any sort of lingering questions like these in order to demonstrate how you define \"best\".\u003c/p\u003e  \u003cp\u003eThere are many datasets on the \u003ca href=\"https://www.zillow.com/research/data/\"\u003eZillow Research Page\u003c/a\u003e, and making sure you have exactly what you need can be a bit confusing. For simplicity's sake, we have already provided the dataset for you in this repo -- you will find it in the file \u003ccode\u003etime-series/zillow_data.csv\u003c/code\u003e.\u003c/p\u003e  \u003cp\u003eThe goal of this project is to have you complete a very common real-world task in regard to time series modeling. However, real world problems often come with a significant degree of ambiguity, which requires you to use your knowledge of statistics and data science to think critically about and answer. While the main task in this project is time series modeling, that isn't the overall goal -- it is important to understand that time series modeling is a tool in your toolbox, and the forecasts it provides you are what you'll use to answer important questions.\u003c/p\u003e  \u003cp\u003eIn short, to pass this project, demonstrating the quality and thoughtfulness of your overall recommendation is at least as important as successfully building a time series model!\u003c/p\u003e  \u003ch4\u003eStarter Jupyter Notebook\u003c/h4\u003e  \u003cp\u003eFor this project, you will be provided with a Jupyter notebook, \u003ccode\u003etime-series/starter_notebook.ipynb\u003c/code\u003e, containing some starter code. If you inspect the Zillow dataset file, you'll notice that the datetimes for each sale are the actual column names -- this is a format you probably haven't seen before. To ensure that you're not blocked by preprocessing, we've provided some helper functions to help simplify getting the data into the correct format. You're not required to use this notebook or keep it in its current format, but we strongly recommend you consider making use of the helper functions so you can spend your time working on the parts of the project that matter.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eIn addition to deciding which quantitative metric(s) you want to target (e.g. minimizing mean squared error), you need to start with a definition of \"best investment\".  Consider additional metrics like risk vs. profitability, or ROI yield.\u003c/p\u003e  \u003ch3\u003eTopic 2: Recommendation Systems\u003c/h3\u003e  \u003cp\u003eIf you choose the Recommendation System option, you will be making movie recommendations based on the \u003ca href=\"https://grouplens.org/datasets/movielens/latest/\"\u003eMovieLens\u003c/a\u003e dataset from the GroupLens research lab at the University of Minnesota.  Unless you are planning to run your analysis on a paid cloud platform, we recommend that you use the \"small\" dataset containing 100,000 user ratings (and potentially, only a particular subset of that dataset).\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that provides top 5 movie recommendations to a user, based on their ratings of other movies.\u003c/p\u003e \u003c/blockquote\u003e  \u003cp\u003eThe MovieLens dataset is a \"classic\" recommendation system dataset, that is used in numerous academic papers and machine learning proofs-of-concept.  You will need to create the specific details about how the user will provide their ratings of other movies, in addition to formulating a more specific business problem within the general context of \"recommending movies\".\u003c/p\u003e  \u003ch4\u003eCollaborative Filtering\u003c/h4\u003e  \u003cp\u003eAt minimum, your recommendation system must use collaborative filtering.  If you have time, consider implementing a hybrid approach, e.g. using collaborative filtering as the primary mechanism, but using content-based filtering to address the \u003ca href=\"https://en.wikipedia.org/wiki/Cold_start_(computing)\"\u003ecold start problem\u003c/a\u003e.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eThe MovieLens dataset has explicit ratings, so achieving some sort of evaluation of your model is simple enough.  But you should give some thought to the question of metrics. Since the rankings are ordinal, we know we can treat this like a regression problem.  But when it comes to regression metrics there are several choices: RMSE, MAE, etc.  \u003ca href=\"http://fastml.com/evaluating-recommender-systems/\"\u003eHere\u003c/a\u003e are some further ideas.\u003c/p\u003e  \u003ch3\u003eTopic 3: Image Classification with Deep Learning\u003c/h3\u003e  \u003cp\u003eIf you choose this option, you'll put everything you've learned together to build a deep neural network that trains on a large dataset for classification on a non-trivial task.  In this case, using x-ray images of pediatric patients to identify whether or not they have pneumonia.  The dataset comes from Kermany et al. on \u003ca href=\"https://data.mendeley.com/datasets/rscbjbr9sj/3\"\u003eMendeley\u003c/a\u003e, although there is also a version on \u003ca href=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\"\u003eKaggle\u003c/a\u003e that may be easier to use.\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that can classify whether a given patient has pneumonia, given a chest x-ray image.\u003c/p\u003e \u003c/blockquote\u003e  \u003ch4\u003eAim for a Proof of Concept\u003c/h4\u003e  \u003cp\u003eWith Deep Learning, data is king -- the more of it, the better. However, the goal of this project isn't to build the best model possible -- it's to demonstrate your understanding by building a model that works. You should try to avoid datasets and model architectures that won't run in reasonable time on your own machine. For many problems, this means downsampling your dataset and only training on a portion of it. Once you're absolutely sure that you've found the best possible architecture and other hyperparameters for your model, then consider training your model on your entire dataset overnight (or, as larger portion of the dataset that will still run in a feasible amount of time).\u003c/p\u003e  \u003cp\u003eAt the end of the day, we want to see your thought process as you iterate and improve on a model. A project that achieves a lower level of accuracy but has clearly iterated on the model and the problem until it found the best possible approach is more impressive than a model with high accuracy that did no iteration. We're not just interested in seeing you finish a model -- we want to see that you understand it, and can use this knowledge to try and make it even better!\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eEvaluation is fairly straightforward for this project.  But you'll still need to think about which metric to use and about how best to cross-validate your results.\u003c/p\u003e  \u003ch3\u003eTopic 4: Natural Language Processing (NLP)\u003c/h3\u003e  \u003cp\u003eIf you choose this option, you'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via \u003ca href=\"https://data.world/crowdflower/brands-and-product-emotions\"\u003edata.world\u003c/a\u003e. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\u003c/p\u003e  \u003cp\u003eYour task is to:\u003c/p\u003e  \u003cblockquote\u003e \u003cp\u003eBuild a model that can rate the sentiment of a Tweet based on its content.\u003c/p\u003e \u003c/blockquote\u003e  \u003ch4\u003eAim for a Proof of Concept\u003c/h4\u003e  \u003cp\u003eThere are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\u003c/p\u003e  \u003ch4\u003eEvaluation\u003c/h4\u003e  \u003cp\u003eEvaluating multiclass classifiers can be trickier than binary classifiers because there are multiple ways to mis-classify an observation, and some errors are more problematic than others. Use the business problem that your NLP project sets out to solve to inform your choice of evaluation metrics.\u003c/p\u003e  \u003ch3\u003eSourcing Your Own Data\u003c/h3\u003e  \u003cp\u003eSourcing new data is a valuable skill for data scientists, but it requires a great deal of care. An inappropriate dataset or an unclear business problem can lead you spend a lot of time on a project that delivers underwhelming results. The guidelines below will help you complete a project that demonstrates your ability to engage in the full data science process.\u003c/p\u003e  \u003cp\u003eYour dataset must be...\u003c/p\u003e  \u003col\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eAppropriate for one of this phase's models.\u003c/strong\u003e These are time series, recommendation systems, image classification, or natural language processing.   \u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eUsable to solve a specific business problem.\u003c/strong\u003e This solution must rely on your model.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eSomewhat complex.\u003c/strong\u003e It should contain thousands of rows and features that require creativity to use.\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eUnfamiliar.\u003c/strong\u003e It can't be one we've already worked with during the course or that is commonly used for demonstration purposes (e.g. MNIST).\u003c/p\u003e\u003c/li\u003e \u003cli\u003e\u003cp\u003e\u003cstrong\u003eManageable.\u003c/strong\u003e Stick to datasets that you can model using the techniques introduced in Phase 4.\u003c/p\u003e\u003c/li\u003e \u003c/ol\u003e  \u003ch4\u003eProblem First, or Data First?\u003c/h4\u003e  \u003cp\u003eThere are two ways that you can source your own dataset: \u003cstrong\u003e\u003cem\u003eProblem First\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003eData First\u003c/em\u003e\u003c/strong\u003e. The less time you have to complete the project, the more strongly we recommend a Data First approach to this project.\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003e\u003cem\u003eProblem First\u003c/em\u003e\u003c/strong\u003e: Start with a problem that you are interested in that you could potentially solve with a classification model. Then look for data that you could use to solve that problem. This approach is high-risk, high-reward: Very rewarding if you are able to solve a problem you are invested in, but frustrating if you end up sinking lots of time in without finding appropriate data. To mitigate the risk, set a firm limit for the amount of time you will allow yourself to look for data before moving on to the Data First approach.\u003c/p\u003e  \u003cp\u003e\u003cstrong\u003e\u003cem\u003eData First\u003c/em\u003e\u003c/strong\u003e: Take a look at some of the most popular internet repositories of cool data sets we've listed below. If you find a data set that's particularly interesting for you, then it's totally okay to build your problem around that data set.\u003c/p\u003e  \u003ch4\u003ePotential Data Sources\u003c/h4\u003e  \u003cp\u003eThere are plenty of amazing places that you can get your data from. We recommend you start looking at data sets in some of these resources first:\u003c/p\u003e  \u003cul\u003e \u003cli\u003e\u003ca href=\"https://archive.ics.uci.edu/ml/datasets.php\"\u003eUCI Machine Learning Datasets Repository\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://www.kaggle.com/datasets\"\u003eKaggle Datasets\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://github.com/awesomedata/awesome-public-datasets\"\u003eAwesome Datasets Repo on Github\u003c/a\u003e\u003c/li\u003e \u003cli\u003eLocal data portals for state and local government resources  \u003cul\u003e \u003cli\u003eExamples: \u003ca href=\"https://opendata.cityofnewyork.us/\"\u003eNYC\u003c/a\u003e, \u003ca href=\"http://data.houstontx.gov/\"\u003eHouston\u003c/a\u003e, \u003ca href=\"https://data.seattle.gov/\"\u003eSeattle\u003c/a\u003e, \u003ca href=\"https://data.ca.gov/\"\u003eCalifornia\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"http://insideairbnb.com/\"\u003eInside AirBNB\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://data.fivethirtyeight.com/\"\u003eFiveThirtyEights data portal\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0\"\u003eData is Plurals Archive Spreadsheet\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"https://www.reddit.com/r/datasets/\"\u003eDatasets Subreddit\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e","frontPage":false},{"exportId":"phase-4-project-description","title":"Phase 4 Project Description","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-phase-4-project-v2-3\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-project-v2-3\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-phase-4-project-v2-3/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eFinal phase down -- you're absolutely crushing it! You've made it all the way through one of the toughest phases of this course. You must have an amazing brain in your head!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-phase-4-project-v2-3/main/images/brain.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eYou have one last project to complete before the Capstone!\u003c/p\u003e\n\u003cp\u003eIn this project description, we will cover:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProject Overview\u003c/li\u003e\n\u003cli\u003eDeliverables\u003c/li\u003e\n\u003cli\u003eGrading\u003c/li\u003e\n\u003cli\u003eGetting Started\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eFor this project, you will engage in an \u003cstrong\u003eadvanced supervised modeling process\u003c/strong\u003e from start to finish, solving either a classification or a regression problem using an advanced dataset.\u003c/p\u003e\n\u003ch3\u003eBusiness Problem and Data\u003c/h3\u003e\n\u003cp\u003eSimilar to the Phase 3 project, you are responsible for choosing a dataset as well as defining a stakeholder and business problem. In addition to these choices, you can choose between any of the four advanced supervised modeling techniques covered in Phase 4:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTime Series Modeling\u003c/li\u003e\n\u003cli\u003eRecommendation System\u003c/li\u003e\n\u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e\n\u003cli\u003eNatural Language Processing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor complete details, see \u003ca href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\"\u003ePhase 4 Project - Choosing a Dataset\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003eKey Points\u003c/h3\u003e\n\u003ch3\u003eAdvanced Data Types and Modeling\u003c/h3\u003e\n\u003cp\u003eThe purpose of this project is to demonstrate that you have mastered the basics of some type of modeling technique beyond the techniques introduced in Phase 3. This is your chance to tailor your work to a \u003cstrong\u003edata science audience\u003c/strong\u003e in particular, with a clear notebook narrative that illustrates your process. The resulting presentation slides will be substantially similar to a Phase 3 presentation, but someone reading your notebook should be able to see your grasp of the specific advanced modeling technique.\u003c/p\u003e\n\u003ch3\u003eValidation Strategy\u003c/h3\u003e\n\u003cp\u003eA \u003cstrong\u003evalidation strategy\u003c/strong\u003e means a strategy to demonstrate that your model will actually perform well on unseen data. In Phase 3 this was relatively straightforward to accomplish with the \u003ccode\u003etrain_test_split\u003c/code\u003e function from scikit-learn. This may or may not be appropriate for the project you select. Make sure that you are thinking about this strategy from the start and incorporating it into your notebook narrative.\u003c/p\u003e\n\u003ch3\u003eChoosing a Dataset\u003c/h3\u003e\n\u003cp\u003eWe've given you a lot of choices - don't get stuck spending too much time choosing which project to do. Give yourself a firm time limit for picking a project (e.g. 2 hours) so you can get on with making something great. Don't worry about picking the perfect project - remember that you will get to do a new, larger Capstone project very soon!\u003c/p\u003e\n\u003ch2\u003eThe Deliverables\u003c/h2\u003e\n\u003cp\u003eThere are three deliverables for this project:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003enon-technical presentation\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003eJupyter Notebook\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003eGitHub repository\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe checklist of requirements is the same for Phase 4 as it was in Phase 3. This will also be the checklist for Capstone!\u003c/p\u003e\n\u003ch3\u003eNon-Technical Presentation\u003c/h3\u003e\n\u003cp\u003eThe non-technical presentation should be very similar to the presentation you gave in Phase 3. You can feel free to mention the specific models and metrics you used, but make sure you translate everything for an audience who is not familiar with data science.\u003c/p\u003e\n\u003ch3\u003eJupyter Notebook\u003c/h3\u003e\n\u003cp\u003eThe notebook will have the same checklist elements as in Phase 3. However, \u003cstrong\u003ethis time around the Communication rubric element will focus on the technical notebook\u003c/strong\u003e. A data science professional reading your notebook should be able to understand all of your data preparation and modeling decisions.\u003c/p\u003e\n\u003ch3\u003eGitHub Repository\u003c/h3\u003e\n\u003cp\u003eThe GitHub repository should also be very similar to the Phase 3 repository.\u003c/p\u003e\n\u003cp\u003eThe main additional element to consider is \u003cstrong\u003ereproducibility\u003c/strong\u003e, since many of the dataset options are too large to be saved directly in a GitHub repository. Make sure you include clear instructions for how someone would reproduce your modeling process, potentially including any scripts you used to organize data into directories.\u003c/p\u003e\n\u003ch2\u003eGrading\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTo pass this project, you must pass each rubric objective.\u003c/em\u003e\u003c/strong\u003e The project rubric objectives for Phase 4 are:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAttention to Detail\u003c/li\u003e\n\u003cli\u003eAdvanced ML Communication\u003c/li\u003e\n\u003cli\u003eAdvanced Data Preparation\u003c/li\u003e\n\u003cli\u003eAdvanced ML Modeling\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eAttention to Detail\u003c/h3\u003e\n\u003cp\u003eOnce again, the Attention to Detail standard has increased. \u003cstrong\u003e\u003cem\u003eIn Phase 4, you need to complete 90% (9 out of 10) or more of the checklist elements in order to pass the Attention to Detail objective.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNOTE THAT THE PASSING BAR IS HIGHER IN PHASE 4 THAN IT WAS IN PHASE 3!\u003c/strong\u003e\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003e100% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003e90% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003e80% of the project checklist items are complete\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003e70% or fewer of the project checklist items are complete\u003c/p\u003e\n\u003ch3\u003eAdvanced ML Communication\u003c/h3\u003e\n\u003cp\u003eOnce again, you are expected to communicate the results of an ML modeling process. Just like in Phase 3, we are looking for \u003cem\u003erationale, results, limitations, and recommendations.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn Phase 4, the emphasis is on the \u003cstrong\u003eJupyter Notebook\u003c/strong\u003e. The notebook should include a \u003cstrong\u003esummary\u003c/strong\u003e at the beginning that briefly and accurately describes your process. The summary should be approximately 250 words -- about the size of a research paper abstract.\u003c/p\u003e\n\u003cp\u003eSummary elements:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBusiness and data understanding: \u003cem\u003ewhat kind of data are you using, and what makes it well-suited for the business problem?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eYou do not need to include any data visualizations in your summary, but consider including relevant descriptive statistics\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eData preparation: \u003cem\u003ewhy did you choose the data preparation steps that you did, and what was the result?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eThis should be specific to the kind of data you are working with. For example, if you are doing an NLP project, what did you decide to do with stopwords?\u003c/li\u003e\n\u003cli\u003eBe sure to list the packages/libraries used to prepare the data, and why\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eModeling: \u003cem\u003ewhat modeling package(s) did you use, which model(s) within the package(s), and what tuning steps did you take?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eFor some projects there may be only one applicable package; you should still briefly explain why this was the appropriate choice\u003c/li\u003e\n\u003cli\u003eFor neural networks projects, be sure to describe your model architecture choices\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEvaluation: \u003cem\u003ehow well did your final model perform?\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eInclude one or more relevant metrics\u003c/li\u003e\n\u003cli\u003eBe sure to briefly describe your validation approach\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eCommunicates advanced modeling summary as well as a narrative throughout the notebook text that demonstrates mastery of an advanced topic\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDecisions should be justified and outcomes evaluated in Markdown throughout the notebook\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully communicates a summary of an advanced modeling technique including business and data understanding, data preparation, modeling, and evaluation\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIt is possible to meet this bar with just a summary and not a narrative throughout the notebook, so long as the steps taken are justifiable and free of major errors. See the Approaching Objective section for an explanation of what a \"major error\" means.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003eCommunicates advanced modeling summary with at least one major error\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA major error means that one of the required elements of the summary was missing, or some aspect of the communication was fundamentally incorrect. For example, if you stated that you performed \"deep learning\" when you actually used \u003ccode\u003eCountVectorizer\u003c/code\u003e and \u003ccode\u003eMultinomialNB\u003c/code\u003e from scikit-learn, that would be a major error. Another example would be if you described a regression task as a classification task, or if you described supervised learning as unsupervised learning.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not communicate advanced modeling summary\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMarkdown headings and occasional narrative text throughout the notebook are not sufficient in this phase, even if they were in previous phases. You need to include a summary at the beginning of your notebook.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eAdvanced Data Preparation\u003c/h3\u003e\n\u003cp\u003eOnce again, this objective is very similar to Phase 3, although the complexity has increased.\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eGoes above and beyond with data preparation, such as feature engineering, using pipelines, or using unsupervised techniques\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSupervised learning is the core of this project, but feel free to use unsupervised techniques for data analysis or preparation\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully prepares data for modeling, using at least one Python package other than scikit-learn\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYour final model does not need to use anything other than scikit-learn, but you should explore other tools during your modeling process\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003ePrepares some data successfully, but has at least one major error\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not prepare data for modeling\u003c/p\u003e\n\u003ch3\u003eAdvanced ML Modeling\u003c/h3\u003e\n\u003cp\u003eThis is your real opportunity to flex those new Phase 4 skills!\u003c/p\u003e\n\u003ch4\u003eExceeds Objective\u003c/h4\u003e\n\u003cp\u003eGoes above and beyond in the modeling process, such as using models from multiple different packages or model explainability tools\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eYou are encouraged but not required to use models from multiple different packages. The feasibility of this depends on your choice of project. For time series, this might mean trying both StatsModels and Prophet. For image classification, this might mean using TensorFlow with and without transfer learning.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://christophm.github.io/interpretable-ml-book/lime.html\"\u003ethis book chapter\u003c/a\u003e for an introduction to LIME for model explainability\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eMeets Objective (Passing Bar)\u003c/h4\u003e\n\u003cp\u003eSuccessfully builds and evaluates multiple models using an appropriate model validation technique\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAs noted previously, the \u003ccode\u003etrain_test_split\u003c/code\u003e from scikit-learn may or may not be appropriate for your modeling task. Be sure to investigate appropriate techniques so you are confident in the performance of your final model on unseen data\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch4\u003eApproaching Objective\u003c/h4\u003e\n\u003cp\u003eBuilds multiple models with at least one major error\u003c/p\u003e\n\u003ch4\u003eDoes Not Meet Objective\u003c/h4\u003e\n\u003cp\u003eDoes not build multiple models\u003c/p\u003e\n\u003ch2\u003eGetting Started\u003c/h2\u003e\n\u003cp\u003ePlease start by reviewing the contents of this project description. If you have any questions, please ask your instructor ASAP.\u003c/p\u003e\n\u003cp\u003eOnce you are ready to begin the project, you will need to complete the \u003cstrong\u003e\u003cem\u003e\u003ca title=\"Phase 4 Project Proposal\" href=\"quizzes/g1daef7be675ef2b7bc60c9ddf372ac38\"\u003eProject Proposal\u003c/a\u003e\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eRecall that more information is available in \u003ca href=\"https://github.com/learn-co-curriculum/dsc-phase-4-choosing-a-dataset\"\u003ePhase 4 Project - Choosing a Dataset\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo get started with project development, create a new repository on GitHub. For this project, we recommend that you do not fork the template repository, but rather that you make a new repository from scratch, starting by going to \u003ca href=\"https://github.com/new\"\u003egithub.com/new\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eThis project is your chance to show off your data science prowess with some advanced machine learning algorithms. Now that you've gone through all of the core course content, we're excited to see what you are able to do!\u003c/p\u003e","frontPage":false},{"exportId":"topic-34-lesson-priorities-live","title":"Topic 34 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 145px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eTime Series Data Manipulation\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Exploring Time Series Data - Introduction\" href=\"pages/exploring-time-series-data-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/exploring-time-series-data-introduction\" data-api-returntype=\"Page\"\u003eExploring Time Series Data - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Time Series\" href=\"assignments/g5e241006fa4fc3b20c656f2ced7fe4dc\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12160\" data-api-returntype=\"Assignment\"\u003eIntroduction to Time Series\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Managing Time Series Data - Lab\" href=\"assignments/g98648f0b58736379c0de5fe10e862048\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12161\" data-api-returntype=\"Assignment\"\u003eManaging Time Series Data - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Visualizing Time Series Data - Lab\" href=\"assignments/g38a7acb7ef18eec76d012e036a33d576\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12162\" data-api-returntype=\"Assignment\"\u003eVisualizing Time Series Data - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 220px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Data Manipulation\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eTime Series Trends and Stationarity\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Data Manipulation Exit Ticket\" href=\"quizzes/gf0c7c18a3e0636816c6aca490f3e1d3b\"\u003eTime Series Data Manipulation Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Types of Trends\" href=\"assignments/ga5806767e1d56323adbce5fd975ead09\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12163\" data-api-returntype=\"Assignment\"\u003eTypes of Trends\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Testing for Trends - Lab\" href=\"assignments/gba1d403ececda39a33c1783ccce4f999\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12164\" data-api-returntype=\"Assignment\"\u003eTesting for Trends - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Removing Trends\" href=\"assignments/g119393ced24c88150154a7658ec60f95\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12165\" data-api-returntype=\"Assignment\"\u003eRemoving Trends\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Removing Trends - Lab\" href=\"assignments/ga1d0e819649ad5a415863e9dd8cd00b2\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12166\" data-api-returntype=\"Assignment\"\u003eRemoving Trends - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Time Series Decomposition\" href=\"assignments/g03cc9745b85a37c968dfdc957e36819b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12167\" data-api-returntype=\"Assignment\"\u003eTime Series Decomposition\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 78px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eTime Series Trends and Stationarity\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.6686%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 11.7125%; height: 29px; text-align: center;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Time Series Trends and Stationarity Exit Ticket\" href=\"quizzes/ga61f46194e766cc2c8f25e2acb45d00b\"\u003eTime Series Trends and Stationarity Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.6686%; height: 29px;\"\u003e\u003ca title=\"Exploring Time Series Data - Recap\" href=\"pages/exploring-time-series-data-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/exploring-time-series-data-recap\" data-api-returntype=\"Page\"\u003eExploring Time Series Data - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 11.7125%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"topic-40-lesson-priorities-live","title":"Topic 40 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100%; height: 196px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eCloud Services\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 36.7893%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.3512%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Amazon Web Services - Introduction\" href=\"pages/amazon-web-services-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-web-services-introduction\" data-api-returntype=\"Page\"\u003eAmazon Web Services - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003cstrong\u003e\u003ca title=\"Cloud Computing\" href=\"pages/cloud-computing\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/cloud-computing\" data-api-returntype=\"Page\"\u003eCloud Computing\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"The AWS Ecosystem\" href=\"pages/the-aws-ecosystem\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/the-aws-ecosystem\" data-api-returntype=\"Page\"\u003eThe AWS Ecosystem\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Amazon Simple Storage Service (S3)\" href=\"pages/amazon-simple-storage-service-s3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-simple-storage-service-s3\" data-api-returntype=\"Page\"\u003eAmazon Simple Storage Service (S3)\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 22px;\"\u003e\u003ca title=\"Introduction to Amazon SageMaker\" href=\"pages/introduction-to-amazon-sagemaker\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-amazon-sagemaker\" data-api-returntype=\"Page\"\u003eIntroduction to Amazon SageMaker\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 22px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Data Science and Machine Learning Engineering\" href=\"pages/data-science-and-machine-learning-engineering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/data-science-and-machine-learning-engineering\" data-api-returntype=\"Page\"\u003eData Science and Machine Learning Engineering\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Introduction to Flask\" href=\"pages/introduction-to-flask\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/introduction-to-flask\" data-api-returntype=\"Page\"\u003eIntroduction to Flask\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Deploying a Model with Flask\" href=\"pages/deploying-a-model-with-flask\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/deploying-a-model-with-flask\" data-api-returntype=\"Page\"\u003eDeploying a Model with Flask\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Introduction to Dash\" href=\"pages/introduction-to-dash\"\u003eIntroduction to Dash\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 36.7893%;\"\u003e\u003ca title=\"Deploying a Model with Dash\" href=\"pages/deploying-a-model-with-dash\"\u003eDeploying a Model with Dash\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; text-align: center;\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Productionizing a Model with Docker and SageMaker\" href=\"assignments/ge49973b1f11da2d1d2ab006198d397c0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12386\" data-api-returntype=\"Assignment\"\u003eProductionizing a Model with Docker and SageMaker\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8934%; height: 80px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eCloud Services\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 36.7893%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.3512%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Cloud Services Exit Ticket\" href=\"quizzes/ge4dfe6dffe72ccc8d79792139640e029\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/quizzes/11295\" data-api-returntype=\"Quiz\"\u003eCloud Services Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 36.7893%; height: 29px;\"\u003e\u003ca title=\"Amazon Web Services - Recap\" href=\"pages/amazon-web-services-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/amazon-web-services-recap\" data-api-returntype=\"Page\"\u003eAmazon Web Services - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.3512%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"image-classification-with-multi-layer-perceptrons","title":"Image Classification with Multi-Layer Perceptrons","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-image-classification-with-mlps\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll learn why deeper networks sometimes lead to better results, and we'll generalize what you have learned before to get your matrix dimensions right in deep networks.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what is meant by \"deep representations\" of images \u003c/li\u003e\n\u003cli\u003eMathematically represent forward and back propagation in a deep neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhy deep representations?\u003c/h2\u003e\n\n\u003cp\u003eDeep representations are really good at automating what used to be a tedious process of feature engineering. Not only would modelers need to have complex programming and analytical skills, they would also often require domain knowledge in order to manually build features that would then be passed on to a regression or classification algorithm. With deep representations, this time consuming process is often severely diminished. \u003c/p\u003e\n\n\u003cp\u003eFor example, the deep layers of a neural network for computer might look like this:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efirst layer detects edges in pictures\u003c/li\u003e\n\u003cli\u003esecond layer groups edges together and starts to detect different parts\u003c/li\u003e\n\u003cli\u003emore layers: group even bigger parts together, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eor in the case of audio:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003efirst layer: low lever wave features\u003c/li\u003e\n\u003cli\u003esecond layer: basic units of sounds, \"phonemes\" \u003c/li\u003e\n\u003cli\u003ethird: word recognition\u003c/li\u003e\n\u003cli\u003efourth: sentence recognition\n-...\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe general idea is shallow networks detect \"simple\" things, and the deeper you go, the more complex things can be detected. \u003c/p\u003e\n\n\u003cp\u003eYou can build a smaller but deeper neural network that needs exponentially less hidden units but performs better, because learning happens in each layer!\u003c/p\u003e\n\n\u003ch2\u003eDeep Network Architecture and Notation\u003c/h2\u003e\n\n\u003cp\u003eLet's try to generalize all the notation to get things straight and know the dimensions of all matrices we'll be working with. Let's have a look at this 3-layer network:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-image-classification-with-mlps/master/images/new_classwmips.png\" alt=\"neural network with input layer, first hidden layer, second hidden layer, output layer\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eImagine that there are 300 cases, or observations (m = 300). What do our matrices look like? \u003c/p\u003e\n\n\u003cp\u003eLet's start with \u003cimg class=\"equation_image\" title=\" Z^{[1]} = W^{[1]} X +b^{[1]}\" src=\"/equation_images/%20Z^{[1]}%20=%20W^{[1]}%20X%20+b^{[1]}\" alt=\"{\" data-equation-content=\" Z^{[1]} = W^{[1]} X +b^{[1]}\"\u003e.  \u003c/p\u003e\n\n\u003cp\u003eWhile not shown above in the diagram, Z is the output of the linear part of one of our hidden layers.  \u003c/p\u003e\n\n\u003cp\u003eBreaking this down, we have:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"W^{[1]}\" src=\"/equation_images/W^{[1]}\" alt=\"{\" data-equation-content=\"W^{[1]}\"\u003e is the weights matrix with dimensions (4 x 2)\u003c/li\u003e\n\u003cli\u003eIf we look at all our samples, \u003cimg class=\"equation_image\" title=\"x\" src=\"https://learning.flatironschool.com/equation_images/x\" alt=\"{\" data-equation-content=\"x\"\u003e is a (2 x 300)-matrix \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"Z^{[1]}\" src=\"/equation_images/Z^{[1]}\" alt=\"{\" data-equation-content=\"Z^{[1]}\"\u003e is a (4 x 300)-matrix \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"b^{[1]}\" src=\"/equation_images/b^{[1]}\" alt=\"{\" data-equation-content=\"b^{[1]}\"\u003e is a (4 x 1)-matrix. Due to broadcasting in Python, this matrix will be duplicated into a (4 x 300)-matrix \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSimilarly, the second hidden layer also has a linear function attached.\u003c/p\u003e\n\n\u003cp\u003eIn \u003cimg class=\"equation_image\" title=\" Z^{[2]} = W^{[2]} A^{[1]} +b^{[2]}\" src=\"/equation_images/%20Z^{[2]}%20=%20W^{[2]}%20A^{[1]}%20+b^{[2]}\" alt=\"{\" data-equation-content=\" Z^{[2]} = W^{[2]} A^{[1]} +b^{[2]}\"\u003e\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe dimension of \u003cimg class=\"equation_image\" title=\"A^{[1]}\" src=\"/equation_images/A^{[1]}\" alt=\"{\" data-equation-content=\"A^{[1]}\"\u003e is the same as the dimension of \u003cimg class=\"equation_image\" title=\"Z^{[1]}\" src=\"/equation_images/Z^{[1]}\" alt=\"{\" data-equation-content=\"Z^{[1]}\"\u003e: (4 x 300)\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"W^{[2]}\" src=\"/equation_images/W^{[2]}\" alt=\"{\" data-equation-content=\"W^{[2]}\"\u003e is the weights matrix with dimensions (3 x 4)\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"Z^{[2]}\" src=\"/equation_images/Z^{[2]}\" alt=\"{\" data-equation-content=\"Z^{[2]}\"\u003e is a (3 x 300)-matrices \u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"b^{[2]}\" src=\"/equation_images/b^{[2]}\" alt=\"{\" data-equation-content=\"b^{[2]}\"\u003e is a (3 x 1)-matrix. Due to broadcasting in Python, this matrix will be duplicated into a (3 x 300)-matrix \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eGeneralizing Notation\u003c/h2\u003e\n\n\u003cp\u003eFrom here, we wish to generalize our notation to a deep network with \u003cimg class=\"equation_image\" title=\"L\" src=\"https://learning.flatironschool.com/equation_images/L\" alt=\"{\" data-equation-content=\"L\"\u003e layers as opposed to 2. For each of these layers, we have parameters associated with the linear transformation of the layer, and parameters associated with the activation function applied to the output of this linear transformation.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eParameters for the linear transformation:\u003c/strong\u003e  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"W^{[l]}: (n^{[l]}, n^{[l-1]})\" src=\"/equation_images/W^{[l]}:%20(n^{[l]},%20n^{[l-1]})\" alt=\"{\" data-equation-content=\"W^{[l]}: (n^{[l]}, n^{[l-1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"b^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/b^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\"b^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"dW^{[l]}: (n^{[l]}, n^{[l-1]})\" src=\"/equation_images/dW^{[l]}:%20(n^{[l]},%20n^{[l-1]})\" alt=\"{\" data-equation-content=\"dW^{[l]}: (n^{[l]}, n^{[l-1]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"db^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/db^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\"db^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eParameters for the activation function:\u003c/strong\u003e  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" a^{[l]}, z^{[l]}: (n^{[l]}, 1)\" src=\"/equation_images/%20a^{[l]},%20z^{[l]}:%20(n^{[l]},%201)\" alt=\"{\" data-equation-content=\" a^{[l]}, z^{[l]}: (n^{[l]}, 1)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" Z^{[l]}, A^{[l]}: (n^{[l]}, m)\" src=\"/equation_images/%20Z^{[l]},%20A^{[l]}:%20(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\" Z^{[l]}, A^{[l]}: (n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)\" src=\"/equation_images/%20dZ^{[l]},%20dA^{[l]}:%20(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\" dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eForward Propagation\u003c/h2\u003e\n\n\u003cp\u003eRecall that deep networks work by performing forward propagation; evaluating a cost function associated with the output of the neural network by successively calculating the output of each layer given initial parameter values, and passing this output on to the next layer until a finalized output has been calculated and the cost function can then be evaluated.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eInput is \u003cimg class=\"equation_image\" title=\"a^{[l-1]}\" src=\"/equation_images/a^{[l-1]}\" alt=\"{\" data-equation-content=\"a^{[l-1]}\"\u003e\u003c/li\u003e\n\u003cli\u003eOutput \u003cimg class=\"equation_image\" title=\"a^{[l]}\" src=\"/equation_images/a^{[l]}\" alt=\"{\" data-equation-content=\"a^{[l]}\"\u003e, save \u003cimg class=\"equation_image\" title=\"z^{[l]}, w^{[l]}, b^{[l]}, a^{[l-1]} \" src=\"/equation_images/z^{[l]},%20w^{[l]},%20b^{[l]},%20a^{[l-1]}\" alt=\"{\" data-equation-content=\"z^{[l]}, w^{[l]}, b^{[l]}, a^{[l-1]} \"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHere's some more details about how the forward propagation calculation is performed:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Z^1\" src=\"/equation_images/Z^1\" alt=\"{\" data-equation-content=\"Z^1\"\u003e is the output of the linear transformation of the initial input \u003cimg class=\"equation_image\" title=\"A^1\" src=\"/equation_images/A^1\" alt=\"{\" data-equation-content=\"A^1\"\u003e (the observations). In successive layers, \u003cimg class=\"equation_image\" title=\"A^l\" src=\"/equation_images/A^l\" alt=\"{\" data-equation-content=\"A^l\"\u003e is the output from the previous hidden layer. In all of these cases, \u003cimg class=\"equation_image\" title=\"W^l\" src=\"/equation_images/W^l\" alt=\"{\" data-equation-content=\"W^l\"\u003e is a matrix of weights to be optimized to minimize the cost function. \u003cimg class=\"equation_image\" title=\"b^l\" src=\"/equation_images/b^l\" alt=\"{\" data-equation-content=\"b^l\"\u003e is also optimized but is a vector as opposed to a matrix.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"g^l\" src=\"/equation_images/g^l\" alt=\"{\" data-equation-content=\"g^l\"\u003e is the activation function which takes the output of this linear transformation and yields the input to the next hidden layer.  \u003c/p\u003e\n\n\u003cp\u003eMathematically we have:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}\" src=\"/equation_images/%20Z^{[l]}=%20W^{[l]}%20A^{[l-1]}%20+%20b^{[l]}\" alt=\"{\" data-equation-content=\" Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" A^{[l]}= g^{[l]} ( Z^{[l]})\" src=\"/equation_images/%20A^{[l]}=%20g^{[l]}%20(%20Z^{[l]})\" alt=\"{\" data-equation-content=\" A^{[l]}= g^{[l]} ( Z^{[l]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003ehere, \u003cimg class=\"equation_image\" title=\" Z^{[l]}, A^{[l]}\" src=\"/equation_images/%20Z^{[l]},%20A^{[l]}\" alt=\"{\" data-equation-content=\" Z^{[l]}, A^{[l]}\"\u003e both have a shape of \u003cimg class=\"equation_image\" title=\"(n^{[l]}, m)\" src=\"/equation_images/(n^{[l]},%20m)\" alt=\"{\" data-equation-content=\"(n^{[l]}, m)\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eBackward Propagation\u003c/h2\u003e\n\n\u003cp\u003eOnce an output for the neural network given the current parameter weights has been calculated, we must back propagate to calculate the gradients of layer parameters with respect to the cost function. This will allow us to apply an optimization algorithm such as gradient descent in order to make small adjustments to the parameters in order to minimize our cost (and improve our predictions).\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eInput: \u003cimg class=\"equation_image\" title=\"da ^{[l]}\" src=\"/equation_images/da%20^{[l]}\" alt=\"{\" data-equation-content=\"da ^{[l]}\"\u003e\u003c/li\u003e\n\u003cli\u003eOutput:  \u003cimg class=\"equation_image\" title=\"da^{[l-1]}\" src=\"/equation_images/da^{[l-1]}\" alt=\"{\" data-equation-content=\"da^{[l-1]}\"\u003e, \u003cimg class=\"equation_image\" title=\"dW^{[l]}, db^{[l]}\" src=\"/equation_images/dW^{[l]},%20db^{[l]}\" alt=\"{\" data-equation-content=\"dW^{[l]}, db^{[l]}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn terms of formulas, the gradients for our respective parameters in each activation layer are given by:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})\" src=\"/equation_images/%20dZ^{[l]}=%20dA%20^{[l]}%20*%20g^{[l]'}%20(Z^{[l]})\" alt=\"{\" data-equation-content=\" dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}\" src=\"/equation_images/%20dW^{[l]}%20=%20%255Cdfrac{1}{m}%20dZ^{[l]}*%20A^{[l-1]T}\" alt=\"{\" data-equation-content=\" dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)\" src=\"/equation_images/%20db^{[l]}%20=%20%255Cdfrac{1}{m}%20np.sum(dZ^{[l]},%20axis=1,%20keepdims=True)\" alt=\"{\" data-equation-content=\" db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\" dA^{[l-1]} = W^{[l]T}*dZ^{[l]}\" src=\"/equation_images/%20dA^{[l-1]}%20=%20W^{[l]T}*dZ^{[l]}\" alt=\"{\" data-equation-content=\" dA^{[l-1]} = W^{[l]T}*dZ^{[l]}\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eProcess Overview\u003c/h2\u003e\n\n\u003cp\u003eTo summarize the process once more, we begin by defining a model architecture which includes the number of hidden layers, activation functions, and the number of units in each of these.   \u003c/p\u003e\n\n\u003cp\u003eWe then initialize parameters for each of these layers (typically randomly). After the initial parameters are set, forward propagation evaluates the model giving a prediction, which is then used to evaluate a cost function. Forward propagation involves evaluating each layer and then piping this output into the next layer. \u003c/p\u003e\n\n\u003cp\u003eEach layer consists of a linear transformation and an activation function. The parameters for the linear transformation in \u003cstrong\u003eeach\u003c/strong\u003e layer include \u003cimg class=\"equation_image\" title=\"W^l\" src=\"/equation_images/W^l\" alt=\"{\" data-equation-content=\"W^l\"\u003e and \u003cimg class=\"equation_image\" title=\"b^l\" src=\"/equation_images/b^l\" alt=\"{\" data-equation-content=\"b^l\"\u003e. The output of this linear transformation is represented by \u003cimg class=\"equation_image\" title=\"Z^l\" src=\"/equation_images/Z^l\" alt=\"{\" data-equation-content=\"Z^l\"\u003e. This is then fed through the activation function (again, for each layer) giving us an output \u003cimg class=\"equation_image\" title=\"A^l\" src=\"/equation_images/A^l\" alt=\"{\" data-equation-content=\"A^l\"\u003e which is the input for the next layer of the model.  \u003c/p\u003e\n\n\u003cp\u003eAfter forward propagation is completed and the cost function is evaluated, back propogation is used to calculate gradients of the initial parameters with respect to this cost function. Finally, these gradients are then used in an optimization algorithm, such as gradient descent, to make small adjustments to the parameters and the entire process of forward propagation, back propagation, and parameter adjustments is repeated until the modeller is satisfied with the results.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations\"\u003ehttps://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this brief lesson, we gave an intuitive justification behind using deep network structures and reviewed the architecture for neural nets in general. In upcoming lessons, we will begin to extend our previous work in creating a single layer neural network in order to build a deeper more powerful model.\u003c/p\u003e","frontPage":false},{"exportId":"arma-models","title":"ARMA Models","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eYou've seen two basic time series models now, the random walk and white noise models. In this lesson, you'll learn about two other very important time series models that are widely used to understand and predict future values in stochastic processes: the Autoregressive (AR) and Moving Average (MA) models.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\n- Explain what autoregressive means in an autoregressive model \n- Explain what a moving average model means \n- Describe how AR and MA can be combined to form an ARMA model \u003c/p\u003e\n\n\u003ch2\u003eThe Autoregressive Model\u003c/h2\u003e\n\n\u003cp\u003eAn autoregressive (AR) model is when a value from a time series is regressed on previous values from the same time series.\u003c/p\u003e\n\n\u003cp\u003eIn words, the mathematical idea is the following:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\text{Today = constant + slope} \\times \\text{yesterday + noise} \" src=\"/equation_images/%20%255Ctext{Today%20=%20constant%20+%20slope}%20%255Ctimes%20%255Ctext{yesterday%20+%20noise}\" alt=\"{\" data-equation-content=\" \\text{Today = constant + slope} \\times \\text{yesterday + noise} \"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eOr, mathematically:\n\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\" src=\"/equation_images/%255Clarge%20Y_t%20=%20%255Cmu%20+%20%255Cphi%20*%20Y_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eSome notes based on this formula:\n- If the slope is 0, the time series is a white noise model with mean \u003cimg class=\"equation_image\" title=\"\\mu\" src=\"https://learning.flatironschool.com/equation_images/%255Cmu\" alt=\"{\" data-equation-content=\"\\mu\"\u003e\n- If the slope is not 0, the time series is autocorrelated\n- Bigger slope means bigger autocorrelation\n- When there is a negative slope, the time series follows an oscillatory process\u003c/p\u003e\n\n\u003cp\u003eWe simulated some time series below. Have a look at them, and make sure this follows your intuition looking at the formula.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_model.png\" alt=\"autoregressive model\"\u003e\u003c/p\u003e\n\n\u003cp\u003eNote that simply having a value for \u003cem\u003ephi\u003c/em\u003e ( \u003cimg class=\"equation_image\" title=\"\\phi\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi\" alt=\"{\" data-equation-content=\"\\phi\"\u003e ) slightly bigger than 1, the time series clearly goes in one direction. Note the scale of the y-axis, where the y-axis scale for all the other processes is between -10 and 10, the last time series goes down to values of -100.\u003c/p\u003e\n\n\u003cp\u003eLet's look at the autocorrelation plots as well.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_ACF.png\" alt=\"autoregressive autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThe oscillatory process of the time series with \u003cimg class=\"equation_image\" title=\"\\phi=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.9\" alt=\"{\" data-equation-content=\"\\phi=0.9\"\u003e is reflected in the autocorrelation function, returning an oscillatory autocorrelation function as well. \u003cimg class=\"equation_image\" title=\"\\phi=0.2\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.2\" alt=\"{\" data-equation-content=\"\\phi=0.2\"\u003e leads to a very low, insignificant,  autocorrelation. \u003cimg class=\"equation_image\" title=\"\\phi=0.8\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=0.8\" alt=\"{\" data-equation-content=\"\\phi=0.8\"\u003e leads to a strong autocorrelation for the first few lags and then incurs a steep decline. Having a \u003cimg class=\"equation_image\" title=\"\\phi=1.02\" src=\"https://learning.flatironschool.com/equation_images/%255Cphi=1.02\" alt=\"{\" data-equation-content=\"\\phi=1.02\"\u003e (just slightly bigger than 1) leads to strong and long-lasting autocorrelation.\u003c/p\u003e\n\n\u003cp\u003eNext, let's look at the partial autocorrelation plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/AR_PACF.png\" alt=\"autogregressive partial autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFor each of these PACFs, we notice a high value for 1 lag, then autocorrelations of 0, except for the second one. This is no big surprise, as the slope parameter is fairly small, so the relationship between a value and the next one is fairly limited.\u003c/p\u003e\n\n\u003ch2\u003eThe  Moving Average Model\u003c/h2\u003e\n\n\u003cp\u003eThe Moving Average model can be described as the weighted sum of today's and yesterday's noise.\u003c/p\u003e\n\n\u003cp\u003eIn words, the mathematical idea is the following:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} \" src=\"/equation_images/%20%255Ctext{Today%20=%20Mean%20+%20Noise%20+%20Slope}%20%255Ctimes%20%255Ctext{yesterday's%20noise}\" alt=\"{\" data-equation-content=\" \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} \"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eOr, mathematically:\n\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\" src=\"/equation_images/%255Clarge%20Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta%20*%20%255Cepsilon_{t-1}\" alt=\"{\" data-equation-content=\"\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eSome notes based on this formula:\n- If the slope is 0, the time series is a white noise model with mean \u003cimg class=\"equation_image\" title=\"\\mu\" src=\"https://learning.flatironschool.com/equation_images/%255Cmu\" alt=\"{\" data-equation-content=\"\\mu\"\u003e\n- If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n- Bigger slope means bigger autocorrelation\n- When there is a negative slope, the time series follow an oscillatory process\u003c/p\u003e\n\n\u003cp\u003eFor the Moving Average Model we also simulated some time series with varying parameters below.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_model.png\" alt=\"moving average model\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen there is a positive \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e there is a certain persistence in level, meaning that each observation is generally close to its neighbors. This is more pronounced for higher values of \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e. MA series with negative coefficients, however, show oscillatory patterns. Recall that when \u003cimg class=\"equation_image\" title=\"\\theta=0\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=0\" alt=\"{\" data-equation-content=\"\\theta=0\"\u003e, the process is a true white noise process! \u003c/p\u003e\n\n\u003cp\u003eLet's look at the ACF plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_ACF.png\" alt=\"moving average autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRemember that MA processes have autocorrelations, but because of the structure of the MA formula (regressing it on the noise term of the previous observation) there is only a dependence for one period, and the autocorrelation is zero for lags 2 and higher.\u003c/p\u003e\n\n\u003cp\u003eIf \u003cimg class=\"equation_image\" title=\"\\theta \u003e0\" src=\"/equation_images/%255Ctheta%20\u003e0\" alt=\"{\" data-equation-content=\"\\theta \u003e0\"\u003e the lag one autocorrelation is positive, if \u003cimg class=\"equation_image\" title=\"\\theta \u003c0\" src=\"/equation_images/%255Ctheta%20\u003c0\" alt=\"{\" data-equation-content=\"\\theta \u003c0\"\u003e the lag one autocorrelation is negative.\u003c/p\u003e\n\n\u003cp\u003eNext, let's look at the partial autocorrelation plots.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-arma-models/master/images/MA_PACF.png\" alt=\"moving average partial autocorrelation functions\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFor PACFs, a typical structure is that  there is a strong correlation with the 1-period lag (strength depending on \u003cimg class=\"equation_image\" title=\"\\theta\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta\" alt=\"{\" data-equation-content=\"\\theta\"\u003e), and then the PACF gradually tails off. You can particularly observe this for \u003cimg class=\"equation_image\" title=\"\\theta=0.9\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=0.9\" alt=\"{\" data-equation-content=\"\\theta=0.9\"\u003e and \u003cimg class=\"equation_image\" title=\"\\theta=-0.95\" src=\"https://learning.flatironschool.com/equation_images/%255Ctheta=-0.95\" alt=\"{\" data-equation-content=\"\\theta=-0.95\"\u003e.\u003c/p\u003e\n\n\u003ch2\u003eHigher-order AR and MA models\u003c/h2\u003e\n\n\u003cp\u003eLet's look at the formulas of AR and MA again:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAR: \u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi%20*%20Y_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t\"\u003e\u003c/li\u003e\n\u003cli\u003eMA: \u003cimg class=\"equation_image\" title=\"Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta%20*%20%255Cepsilon_{t-1}\" alt=\"{\" data-equation-content=\"Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNote that these models are constructed in a way that processes only depend directly on the previous observation in the process. These are known as \"1st order models\", and denoted by AR(1) and MA(1) processes respectively. Let's look at AR(2) and MA(2).\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAR(2): \u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi_1%20*%20Y_{t-1}+%255Cphi_2%20*%20Y_{t-2}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t\"\u003e\u003c/li\u003e\n\u003cli\u003eMA(2): \u003cimg class=\"equation_image\" title=\"Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%255Cepsilon_t%20+%20%255Ctheta_1%20*%20%255Cepsilon_{t-1}+%20%255Ctheta_2%20*%20%255Cepsilon_{t-2}\" alt=\"{\" data-equation-content=\"Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNeedless to say, this can be extended to higher-orders as well! Generally, the order of an AR model is denoted \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e, and the order of an MA model is denoted \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e.\u003c/p\u003e\n\n\u003ch2\u003eACF and PACF intuition for AR(p) and MA(q)\u003c/h2\u003e\n\n\u003cp\u003eA quick overview of how higher order models affect the ACF and PACF: \u003c/p\u003e\n\n\u003ch3\u003eAR(p)\u003c/h3\u003e\n\n\u003cp\u003eConsidering a time series that was generated by an autoregression (AR) process with an order of \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e, we would expect the ACF plot for the AR(p) time series to be strong to a lag of \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e and remain stagnant for subsequent lag values, trailing off at some point as the effect is weakened. The PACF, on the other hand, describes the direct relationship between an observation and its lag. This generally leads to no correlation for lag values beyond \u003cimg class=\"equation_image\" title=\"p\" src=\"https://learning.flatironschool.com/equation_images/p\" alt=\"{\" data-equation-content=\"p\"\u003e.\u003c/p\u003e\n\n\u003ch3\u003eMA(q)\u003c/h3\u003e\n\n\u003cp\u003eWith a time series generated by a moving average (MA) process with an order \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e, we would expect the ACF for the MA(q) process to show a strong correlation with recent values up to the lag of \u003cimg class=\"equation_image\" title=\"q\" src=\"https://learning.flatironschool.com/equation_images/q\" alt=\"{\" data-equation-content=\"q\"\u003e, then an immediate decline to minimal or no correlation. For the PACF, we would expect the plot to show a strong relationship to the lag and then a tailing off to no correlation from the lag onwards.\u003c/p\u003e\n\n\u003ch2\u003eARMA models\u003c/h2\u003e\n\n\u003cp\u003eNow that we've seen AR and MA models, it is important to note that \u003cstrong\u003ethere is no reason why AR and MA models would not coexist\u003c/strong\u003e. That's where ARMA models come in, which basically means that in this model, a regression on past values takes place (AR part) and also that the error term is modeled as a linear combination of error terms of the recent past (MA part). Generally, one denotes ARMA as ARMA(p, q).\u003c/p\u003e\n\n\u003cp\u003eAn ARMA(2,1) model is given by:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t\" src=\"/equation_images/Y_t%20=%20%255Cmu%20+%20%255Cphi_1%20Y_{t-1}+%255Cphi_2%20Y_{t-2}+%20%255Ctheta%20%255Cepsilon_{t-1}+%255Cepsilon_t\" alt=\"{\" data-equation-content=\"Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eA short table to summarize ACF and PACF for AR(p), MA(q), and ARMA(p, q):\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eAR(p)\u003c/th\u003e\n\u003cth\u003eMA(q)\u003c/th\u003e\n\u003cth\u003eARMA(p, q)\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eACF\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003ctd\u003eCuts off after lag q\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePACF\u003c/td\u003e\n\u003ctd\u003eCuts off after lag p\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003ctd\u003eTails off\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003ch2\u003eNote on modeling\u003c/h2\u003e\n\n\u003cp\u003eSeeing the table above, you might get an idea of why ACF and PACF are so useful when modeling! What you generally will try to do for any time series analysis is:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDetrend your time series using differencing. ARMA models represent stationary processes, so we have to make sure there are no trends in our time series\u003c/li\u003e\n\u003cli\u003eLook at ACF and PACF of the time series\u003c/li\u003e\n\u003cli\u003eDecide on the AR, MA, and order of these models\u003c/li\u003e\n\u003cli\u003eFit the model to get the correct parameters and use for prediction\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eAdditional resources\u003c/h2\u003e\n\n\u003cp\u003eTo learn more about AR, MA, and ARMA, have a look at lessons 1 and 2 \u003ca href=\"https://online.stat.psu.edu/stat510/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eGreat! Now that you have learned the basics of AR, MA, and ARMA models, let's look at some time series and how to model them in the next lesson!\u003c/p\u003e","frontPage":false},{"exportId":"big-data-and-py-spark-introduction","title":"Big Data and (Py)Spark - Introduction","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-pyspark-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you will be introduced to the idea of big data and the tools data scientists use to manage it.\u003c/p\u003e\n\n\u003ch2\u003eBig Data\u003c/h2\u003e\n\n\u003cp\u003eBig data is undoubtedly one of the most hyped terms in data science these days. Big data analytics involves dealing with data that is large in volume and high in variety and velocity, making it challenging for data scientists to run their routine analysis activities. In this section, you'll learn the basics of dealing with big data through parallel and distributed computing.\u003c/p\u003e\n\n\u003ch3\u003eParallel and Distributed Computing with MapReduce\u003c/h3\u003e\n\n\u003cp\u003eWe start this section by providing more context on the ideas of parallel and distributed computing and \u003cstrong\u003eMapReduce\u003c/strong\u003e. When talking about distributed and parallel computing, we refer to the fact that complex (and big) data science tasks can be executed over a cluster of interconnected computers instead of on just one machine. You'll learn that MapReduce allows us to convert these big datasets into sets of tuples as key:value pairs, as we'll cover in more detail in this section.\u003c/p\u003e\n\n\u003ch2\u003eApache Spark and PySpark\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003eApache Spark\u003c/strong\u003e is an open-source distributed cluster-computing framework that makes it easier (and feasible) to use huge amounts of data! It was developed in response to limitations of MapReduce and written using the Scala programming language. Fortunately for Python developers, there is also a Python interface for Spark called \u003cstrong\u003ePySpark\u003c/strong\u003e. Throughout these lessons we will use the terms \"Spark\" and \"PySpark\" fairly interchangeably, though technically \"Spark\" is the underlying framework and \"PySpark\" is the Python library we'll be using.\u003c/p\u003e\n\n\u003ch3\u003eInstalling and Configuring PySpark with Docker\u003c/h3\u003e\n\n\u003cp\u003ePySpark was not part of the original environment setup you completed. While the interface is in Python, Spark relies on an underlying Java virtual machine (JVM) that can be challenging to install. Therefore we will provide instructions for installing PySpark with and without \u003cstrong\u003eDocker\u003c/strong\u003e, a container system that uses an \"image\" to handle a lot of the configuration for you.\u003c/p\u003e\n\n\u003ch2\u003eSpark Unstructured API\u003c/h2\u003e\n\n\u003cp\u003eFirst we'll look at the fundamental low-level data structures used by Spark: SparkContext and RDDs.\u003c/p\u003e\n\n\u003ch3\u003eRDDs (Resilient Distributed Datasets)\u003c/h3\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDDs) are the core concept in PySpark. RDDs are immutable distributed collections of data objects. Each dataset in RDD is divided into logical partitions, which may be computed on different computers (so-called \"nodes\") in the Spark cluster. In this section, you'll learn how RDDs in Spark work. Additionally, you'll learn that RDD operations can be split into actions and transformations. \u003c/p\u003e\n\n\u003ch3\u003eWord Count with MapReduce\u003c/h3\u003e\n\n\u003cp\u003eYou'll use MapReduce with Spark RDDs to solve a basic NLP task where you compare the attributes of different authors of various texts.\u003c/p\u003e\n\n\u003ch2\u003eSpark Structured API\u003c/h2\u003e\n\n\u003cp\u003eThen we'll look at the modern use of Spark: SparkSession, Spark DataFrames, and MLlib.\u003c/p\u003e\n\n\u003ch3\u003eSpark DataFrames\u003c/h3\u003e\n\n\u003cp\u003eSpark DataFrames are built on top of RDDs, but have a more intuitive and performant data structure. They are also what we'll use for machine learning with Spark.\u003c/p\u003e\n\n\u003ch3\u003eMachine Learning with Spark\u003c/h3\u003e\n\n\u003cp\u003eAfter you've solved a basic MapReduce problem, you will learn about employing the machine learning modules of PySpark. You will perform both a regression and classification problem and get the chance to build a full parallelizable data science pipeline that can scale to work with big data.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn the foundations of Big Data and how to manage it with Apache Spark!\u003c/p\u003e","frontPage":false},{"exportId":"data-science-and-machine-learning-engineering","title":"Data Science and Machine Learning Engineering","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-data-science-and-machine-learning-engineering\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-data-science-and-machine-learning-engineering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-data-science-and-machine-learning-engineering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about how the role of Machine Learning Engineer fits into the broader data science job market.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the difference between a Data Scientist and a Machine Learning Engineer\u003c/li\u003e\n\u003cli\u003eExplain the difference between deploying models and productionizing models\u003c/li\u003e\n\u003cli\u003eThink about how your skillset fits into the data science job market\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eData Scientist vs. Machine Learning Engineer\u003c/h2\u003e\n\n\u003cp\u003eAt large, established tech companies, data-related roles have specialized into separate Data Scientist and Machine Learning Engineer categories.\u003c/p\u003e\n\n\u003cp\u003eData Scientists typically run experiments and train models until they have found a solution that works. Once they have trained and validated the model, they typically then hand off productionization of the model to \u003cstrong\u003e\u003cem\u003eMachine Learning Engineers\u003c/em\u003e\u003c/strong\u003e. Whereas the Data Scientist creates the basic prototype, the Machine Learning Engineer's job is to put that model into a production system in a performant and maintainable manner. Whereas Data Scientists at large companies focus on the \"big picture\" by finding solutions to business problems, Machine Learning Engineers focus on the details, implementing the solutions created by the Data Scientists in the best way possible. Data Scientists focus more on analytics and statistics, whereas Machine Learning Engineers will have a stronger command of backend engineering, data structures and algorithms, and software engineering overall. The following diagram lays out the relationship between different technical roles well:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/data-careers-venn-diagram.png\" height=\"80%\" width=\"80%\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eDeploying vs. Productionizing\u003c/h2\u003e\n\n\u003cp\u003eIf we think back to the CRISP-DM process model, Deployment is the final step. We have previously discussed model pickling and how to ensure that data science processes are reproducible, as part of the deployment process:\u003c/p\u003e\n\n\u003cp\u003e\u003ca title=\"Kenneth Jensen, CC BY-SA 3.0 \u003chttps://creativecommons.org/licenses/by-sa/3.0\u003e, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:CRISP-DM_Process_Diagram.png\"\u003e\u003cimg width=\"512\" alt=\"CRISP-DM Process Diagram\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/512px-CRISP-DM_Process_Diagram.png\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eSo, if a Data Scientist toolkit already includes deployment, what additional skills and techniques play into the \u003cstrong\u003eproductionizing\u003c/strong\u003e of models that Machine Learning Engineers perform?\u003c/p\u003e\n\n\u003cp\u003eThere is no bright-line distinction between deploying and productionizing, but in general deploying focuses on the bare minimum to get a model into a context where it is usable for the client, whereas productionizing considers broader factors such as scaling, maintenance, and security. A deployed model might be manually re-trained on the latest data once a month, whereas a productionized model might be continuously re-training as new data comes in. Productionized models might also have test coverage, metric tracking, and \u003ca href=\"https://ml-ops.org/\"\u003emore\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2\u003eData Science Skills and the Job Market\u003c/h2\u003e\n\n\u003cp\u003eAs you start to look at job postings, you probably notice that \u003cstrong\u003ea \"Data Scientist\" job can mean many, many different things\u003c/strong\u003e. In some companies, it means a data analyst or a DBA focused on databases or data pipelines. In others, it means someone with a scientific mindset skilled with running A/B tests. Yet others may be highly specialized machine learning roles in areas like NLP, Computer Vision, or Deep Learning -- and these roles may break down further into specializations focused on either research or implementation. As a Junior Data Scientist entering the workforce, it's most likely that you'll land in a generalist role, spending the first few years of your career working on various tasks that focus on all of these areas at least a little bit. Specialization happens later in your career. Out of the gate, the best thing that you can be is a \u003cstrong\u003estrong generalist\u003c/strong\u003e, with the demonstrated ability to contribute to many different sorts of projects that might be expected of a Data Science team.\u003c/p\u003e\n\n\u003ch3\u003eBeing a 'Scrappy' Data Scientist\u003c/h3\u003e\n\n\u003cp\u003eLarge companies with official Machine Learning Engineer roles are typically only looking for more-advanced candidates. For example, a Machine Learning Engineer posting from Amazon we found lists these required qualifications:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e¬∑ 3+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. \u003cbr\u003e\n¬∑ 4+ years of non-internship professional software development, data engineering, or machine learning experience \u003cbr\u003e\n¬∑ Bachelor‚Äôs degree in Electrical Engineering, Computer Sciences, Mathematics or equivalent work experience \u003cbr\u003e\n¬∑ Experience deploying and running services in AWS and in engineering big-data solutions using technologies like Glue, S3, and Spark \u003cbr\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn companies like that, there is less need for anyone in a Data Scientist role to have model productionizing skillsets, since the size of their data teams allows for this kind of specialization.\u003c/p\u003e\n\n\u003cp\u003eWith small and medium-sized companies, it's much less likely that a role like this will exist. Data Scientists in smaller organizations are expected to be a bit more independent, and will likely have to \"wear more hats\".\u003c/p\u003e\n\n\u003cp\u003eFor a data science role at a startup, it's a common expectation for their ata scientists to handle every part of a data science project. This means starting by interviewing key stakeholders and identifying the problem to be solved, followed by rapidly prototyping a solution until you've trained/tuned/validated a model that meets your standards, followed by actually putting that model in production!\u003c/p\u003e\n\n\u003cp\u003eThis means that it's very important to be 'scrappy', and be able to handle anything that's thrown at you as a Data Scientist. Smaller companies often don't have the funds or the infrastructure for a separate Machine Learning Engineering team to handle the details of implementation. In this respect, being able to productionize a machine learning model can make you a much more attractive candidate to employers, and give you a competitive advantage!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about the similarities and differences between Data Scientists and Machine Learning Engineers. We also learned why the ability to productionize a machine learning model is a crucial skill for data scientists at small companies, as well as how this skill can provide a competitive advantage when applying for jobs!\u003c/p\u003e","frontPage":false},{"exportId":"tuning-neural-networks-recap","title":"Tuning Neural Networks - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-recap-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-recap-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-recap-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003ch3\u003eTuning Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eValidation and test sets are used when iteratively building deep neural networks\u003c/li\u003e\n\u003cli\u003eLike traditional machine learning models, we need to watch out for the bias variance trade-off when building deep learning models\u003c/li\u003e\n\u003cli\u003eExamples of alternatives for gradient descent are: RMSprop, Adam, Gradient Descent with Momentum, etc.\u003c/li\u003e\n\u003cli\u003eHyperparameter tuning is of crucial importance when working with deep learning models, as setting the parameters right can lead to great improvements in model performance\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eRegularization\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eSeveral regularization techniques can help us limit overfitting: L1 Regularization, L2 Regularization, Dropout Regularization, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eNormalization\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eTraining of deep neural networks can be sped up by using normalized inputs\u003c/li\u003e\n\u003cli\u003eNormalized inputs can also help mitigate a common issue of vanishing or exploding gradients\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eConvolutional Neural Networks\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eCNNs are a useful model for image recognition due to their ability to recognize visual patterns at varying scales\u003c/li\u003e\n\u003cli\u003eThe essence of a CNN is a convolutional operation, where a window is slid across the image based on a stride size\u003c/li\u003e\n\u003cli\u003ePadding can be used to prevent shrinkage and make sure pixels at the edge of an image receive the necessary attention\u003c/li\u003e\n\u003cli\u003eMax pooling is typically used between convolutional layers to reduce the dimensionality\u003c/li\u003e\n\u003cli\u003eAfter developing the convolutional and pooling layers to form a base, the end of the network architecture still connects back to a densely connected network to perform classification\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"semi-supervised-learning-and-look-alike-models","title":"Semi-Supervised Learning and Look-Alike Models","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about some unsupervised learning techniques we can use to supplement our supervised learning techniques.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify appropriate use cases for semi-supervised learning \u003c/li\u003e\n\u003cli\u003eIdentify appropriate use cases for look-alike models \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCombining Supervised and Unsupervised Learning\u003c/h2\u003e\n\n\u003cp\u003eFor the majority of this section, we've focused exclusively on popular unsupervised learning techniques and their most common use cases. However, in the real world, there are also plenty of examples where it works to our advantage to bring supervised and unsupervised learning algorithms together to supplement each other. In this lesson, we'll look at two common areas combining supervised and unsupervised learning algorithms that allow us to be more effective than just using them on their own. \u003c/p\u003e\n\n\u003ch2\u003eUse Case 1: Look-Alike Models\u003c/h2\u003e\n\n\u003cp\u003eAs we've learned when working with clustering algorithms, one of their most common use cases is for market segmentation. A more advanced, but similar use case is to then use these market segments to create \u003cstrong\u003e\u003cem\u003elook-alike models\u003c/em\u003e\u003c/strong\u003e to help us identify more customers or market segments that we can plausibly assume are equally valuable, due to their similarity with valuable customers or market segments we've already identified. \u003c/p\u003e\n\n\u003cp\u003eTake a look at the following infographic that provides a visual representation of look-alike modeling:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/master/images/new_look-alike-model.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the example above, the dark blue smiley faces represent customer segments that we already know are valuable. These are customers that we have identified in our data, and know for a fact have been good for us. Under normal circumstances, this would mean that we can divide our customers (or, more often, potential customers) into two groups: the group we know is valuable, and everyone else, who are all unknown to us. \u003c/p\u003e\n\n\u003cp\u003eThis is where \u003cem\u003elook-alike modeling\u003c/em\u003e comes in. A look-alike model uses a distance metric of our choice to rate the similarity of each customer in our group of unknowns to customers in our known, valuable group. For customers that look extremely similar to customers in own known valuable group, we can assume with a very high likelihood that these customers will also be valuable, and should direct resources at capturing them! We'll likely also see customers that are only somewhat similar to our valuable group, which tells us that they \u003cem\u003ecould possibly be valuable\u003c/em\u003e, but we aren't sure. And finally, customers that look nothing like our known valuable customers segment, should probably be left alone.  \u003c/p\u003e\n\n\u003cp\u003eIf this sounds suspiciously like clustering to you, you are absolutely correct! Although this could also be framed as a classification or regression problem, it's quite common to see clustering used to help determine similarity. After all, if we want to build a supervised learning model to predict if an unknown customer looks like our known valuable customers, then we need plenty of labeled examples, and we don't always have that luxury! \u003c/p\u003e\n\n\u003cp\u003eIn the real-world, using look-alike models to find other customers that could potentially be valuable to us is often referred to as \u003cstrong\u003e\u003cem\u003eprospecting\u003c/em\u003e\u003c/strong\u003e. Viewed in terms of the infographic above, we would choose direct resources to market to the customers that look like our valuable customers to increase our \u003cstrong\u003e\u003cem\u003etop-of-funnel\u003c/em\u003e\u003c/strong\u003e, meaning that we are trying to increase the number of potential customers that haven't shown interest in our product or company yet but are likely to, due to their similarity to customers that already have. \u003c/p\u003e\n\n\u003ch2\u003eUse Case 2: Semi-Supervised Learning\u003c/h2\u003e\n\n\u003cp\u003eThe second use case we'll talk about combines supervised and unsupervised learning to allow us access to more (pseudo) labeled data so that we can better train our supervised learning models. This technique is called \u003cstrong\u003e\u003cem\u003esemi-supervised learning\u003c/em\u003e\u003c/strong\u003e.  You may also hear it commonly referred to as \u003cstrong\u003e\u003cem\u003eweakly supervised learning\u003c/em\u003e\u003c/strong\u003e, but it means the same thing. \u003c/p\u003e\n\n\u003cp\u003ePicture the following scenario: \u003c/p\u003e\n\n\u003cp\u003eWe are trying to build a supervised learning model, and we have 100,000 observations in our dataset. However, labels are exceedingly expensive, so only 5,000 of these 100,000 observations are labeled. In traditional supervised learning, this means that in a practical sense, we really only have a dataset of 5,000 observations, because we can't do anything with the 95,000 unlabeled examples -- or can we?\u003c/p\u003e\n\n\u003cp\u003eThe main idea behind \u003cem\u003esemi-supervised learning\u003c/em\u003e is to generate \u003cstrong\u003e\u003cem\u003epseudo-labels\u003c/em\u003e\u003c/strong\u003e that are possibly correct (at least better than random chance). To do this, we don't usually use clustering algorithms -- instead, we use our supervised learning algorithms in an unsupervised way. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/master/images/new_semi-supervised.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSupervised learning typically follows a set pattern:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eTrain your model on your labeled training data\u003c/em\u003e\u003c/strong\u003e. In the case of our example above, we would build the best model possible with our tiny dataset of 5,000 labeled examples. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eUse your trained model to generate pseudo-labels for your unlabeled data\u003c/em\u003e\u003c/strong\u003e. This means having our trained model make predictions on our 95,000 unlabeled examples. Since our trained model does better than random chance, this means that our generated pseudo-labels will be at least somewhat more correct than random chance. We can even put a number to this, by looking at the performance our trained model had on the test set. For example, if our trained model had an accuracy of ~70%, then we can assume that ~70% of the pseudo-labels will be correct, ~30% will be incorrect. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCombine your labeled data and your pseudo-labeled data into a single, new dataset.\u003c/em\u003e\u003c/strong\u003e. This means that we concatenate all our labeled data of 5,000 examples with the 95,000 pseudo-labeled examples. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRetrain your model on the new dataset\u003c/em\u003e\u003c/strong\u003e. Although some of the pseudo-labeled data will certainly be wrong, it's likely that the amount that is correct will be more useful, and the signal that these correctly pseudo-labeled examples provide will outweigh the incorrectly labeled ones, thereby resulting in better overall model performance. \u003c/p\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3\u003eBenefits and Drawbacks of Semi-Supervised Learning\u003c/h3\u003e\n\n\u003cp\u003eIf semi-supervised learning sounds a bit risky to you, you're not wrong. When done correctly, semi-supervised learning can increase overall model performance by opening up access to much more data than we would have access to, and more data almost always results in better performance, but without the exorbitant costs of paying to have humans generate labels for the data needed. \u003c/p\u003e\n\n\u003cp\u003eHowever, there are definitely some problems that can arise from using a semi-supervised learning approach, if we're not careful and thoughtful throughout.\u003c/p\u003e\n\n\u003ch4\u003eFeedback Loops and Self-Fulfilling Prophecies\u003c/h4\u003e\n\n\u003cp\u003eSemi-supervised learning tends to work fairly well in many use cases and has become quite a popular technique in the field of Deep Learning, which requires massive amounts of labeled data that is often very expensive to obtain. But what happens when our dataset is extremely noisy to begin with? In that case, our incorrect pseudo-labels may skew the model by introducing more \"noise\" than \"signal\". This is partially because we can end up in a feedback loop of sorts. Think about an example where the model has generated an incorrect pseudo-label. If a model trained only on the real data with no pseudo-labels got this example wrong, then what happens when you train the model on the same example, but this time provide a pseudo-label that \"confirms\" this incorrect belief? When done correctly, we can hope that the signal provided by all the correctly pseudo-labeled examples will generalize to help the model correct its mistakes on the ones it got wrong. However, if the dataset is noisy, or the original model wasn't that good to begin with (or both), then it can be quite likely that we are introducing even more incorrect information than correct information, moving the model in the wrong direction.\u003c/p\u003e\n\n\u003cp\u003eSo how do we make sure that we're not making these mistakes when using a semi-supervised approach? \u003cstrong\u003e\u003cem\u003eUse a holdout set!\u003c/em\u003e\u003c/strong\u003e You should definitely have a test set that the model has never seen before to check the performance of your semi-supervised model. Obviously, make sure that your test set only contains actual, ground-truth labeled examples, no pseudo-labels allowed! Also, the noisier your dataset or more complicated your problem, the more likely you are to run into trouble with semi-supervised learning. When possible, try to structure your tasks as binary classification tasks, rather than multi-categorical, and make sure that your dataset is as clean as possible before attempting semi-supervised learning. Although it seems risky, there's a reason companies that are heavy into deep learning and AI research such as Google, Microsoft, and Facebook make heavy use of semi-supervised learning -- when done correctly, it works wonders, without costing an arm and a leg to pay for labeling!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about two popular methodologies for using unsupervised learning in applied, focused ways to help companies generate more revenue, get more customers, or increase model performance without paying for more labeled training data!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-semi-supervised-learning-and-look-alike-models\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-semi-supervised-learning-and-look-alike-models\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-semi-supervised-learning-and-look-alike-models/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"introduction-to-amazon-sagemaker","title":"Introduction to Amazon SageMaker","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about \u003cstrong\u003e\u003cem\u003eAmazon SageMaker\u003c/em\u003e\u003c/strong\u003e, and explore some of the common use cases it covers for data scientists. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the use cases of Amazon SageMaker \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is SageMaker?\u003c/h2\u003e\n\n\u003cp\u003eSageMaker is a platform created by Amazon to centralize all the various services related to Data Science and Machine Learning. If you're a data scientist working on AWS, chances are that you'll be spending most (if not all) of your time in SageMaker getting things done. You can get to SageMaker by just searching for \"SageMaker\" inside the spotlight search bar in the AWS Console. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/sagemaker.png\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSageMaker Use Cases\u003c/h2\u003e\n\n\u003cp\u003eWhen you visit the page for SageMaker, you'll notice that the following graphic highlighting the various use cases SageMaker can help with:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/use_cases.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eYou'll also notice these same categories on the sidebar on the left side of the screen, with more detailed links to services that fall under each category:\n\u003cbr\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/sidebar.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHere's a brief explanation of what each of these service areas are used for in a professional data science setting.\u003c/p\u003e\n\n\u003ch3\u003eGround Truth\u003c/h3\u003e\n\n\u003cp\u003eOne of the hardest, most expensive, and most tedious parts of data science is getting the labels needed for supervised learning projects. For projects inside companies, it's quite common to start by gathering the proprietary data needed in order to train a model that can answer the business question and/or provide the service your company needs. One of the major use cases SageMaker provides is a well-structured way to manage data labeling projects. \u003cstrong\u003e\u003cem\u003eSageMaker GroundTruth\u003c/em\u003e\u003c/strong\u003e allows you to manage private teams, in case your information is sensitive, or to manage public teams by leveraging \u003cstrong\u003e\u003cem\u003eAWS Mechanical Turk\u003c/em\u003e\u003c/strong\u003e, which crowdsources labels from an army of public contractors that have signed up and are paid by the label. \u003c/p\u003e\n\n\u003cp\u003eRecently, Amazon launched an automated labeling service that makes use of machine learning models to generate labels in a human-in-the-loop format, where only labels that are above a particular confidence threshold (which you set yourself) are auto-generated by the model. This allows your contractors to focus only on the tough examples, and saves you from having to pay as much for labels for the easy examples which a model can handle. \u003c/p\u003e\n\n\u003ch3\u003eNotebooks\u003c/h3\u003e\n\n\u003cp\u003eThese are exactly what they sound like -- cloud-based jupyter notebooks, a data scientist's 'bread and butter'!  SageMaker notebooks are just like regular jupyter notebooks, with a bit more added functionality. For instance, it's quite easy to choose from a bunch of pre-configured kernels to select which version of Python/TensorFlow/etc. you want to use. You can start a notebook from scratch inside SageMaker and do all of your work in the cloud, or you can upload preexisting notebooks into SageMaker, allowing you to do you work on a local machine and move it over to the cloud when you're ready for training!\u003c/p\u003e\n\n\u003cp\u003eWe strongly recommend you take a minute to poke around inside a SageMaker notebook to get a feel for what it looks like and what it can do. They're pretty amazing!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/master/images/notebook.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eTraining\u003c/h3\u003e\n\n\u003cp\u003eSageMaker's training services allow you to easily leverage cloud computing with AWS's specialized GPU and TPU servers, allowing you to train massive models that simply wouldn't be possible on a local machine. There are a ton of configuration options, and you can easily set budgets, limits, training times, and even auto-tune your hyperparameters! Although this is outside the scope of our lessons on AWS, Amazon provides some pretty amazing (and fast!) tutorials about how to use more specific services like cloud training or \u003ca href=\"https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/\"\u003emodel tuning\u003c/a\u003e once you've completed this section! \u003c/p\u003e\n\n\u003ch3\u003eInference\u003c/h3\u003e\n\n\u003cp\u003eArguably the most important part of the data science pipeline, \u003cstrong\u003e\u003cem\u003eInference\u003c/em\u003e\u003c/strong\u003e services focus on allowing you to create endpoints so that people can consume your models over the internet! One of the most handy parts of SageMaker's approach to inference is the fact that you can productionize your own model, or just use one of theirs! While there are certainly times where you'll need to create, train, and host your own model, AWS has made things simple by allowing you to use their own models and charging you on a per-use basis. For instance, let's say that you needed to make some time series forecasts. While you could go down the very complicated route of training your own model, you could also just make use of AWS SageMaker's \u003cem\u003eDeepAR\u003c/em\u003e model, which uses the most cutting-edge time series model available to make forecasts on your data. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about Amazon SageMaker, and explored some of the common use cases it covers for data scientists!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-introduction-to-aws-sagemaker\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-introduction-to-aws-sagemaker\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-aws-sagemaker/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"exploring-time-series-data-recap","title":"Exploring Time Series Data - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-section-recap\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you import time series data into Pandas, make sure to use the time/date information as index values using either a Pandas \u003ccode\u003etimestamp\u003c/code\u003e or Python \u003ccode\u003edatetime\u003c/code\u003e data type\u003c/li\u003e\n\u003cli\u003eThere are a range of built-in methods in Pandas for easily downsampling or upsampling time series data\u003c/li\u003e\n\u003cli\u003eLine plots and dot plots can be useful for getting a sense of how a time series dataset changes over time\u003c/li\u003e\n\u003cli\u003eHistograms and density plots can be useful for getting a sense of the time-independent distribution of a time series\u003c/li\u003e\n\u003cli\u003eBox and whisker plots per year (or other seasonality period - day, week, month, etc) can be a great way to easily see trends in the distribution of time series data over time\u003c/li\u003e\n\u003cli\u003eHeat maps can also be useful for comparing changes of time series data across a couple of dimensions. For example, with months on one axis and years on another, they can be a great way to see both seasonality and year on year trends\u003c/li\u003e\n\u003cli\u003eA time series is said to be stationary if its statistical properties such as mean and variance remain constant over time\u003c/li\u003e\n\u003cli\u003eMost time series models work on the assumption that the time series are stationary (assumption of homoscedasticity)\u003c/li\u003e\n\u003cli\u003eMany time series datasets \u003cem\u003edo\u003c/em\u003e have trends, violating the assumption of homoscedasticity\u003c/li\u003e\n\u003cli\u003eCommon examples are trends that include linear (straight line over time), exponential, and periodic. Some datasets also have increasing (or decreasing) variance over time\u003c/li\u003e\n\u003cli\u003eAny given dataset may exhibit multiple trends (e.g. linear, periodic, and reduction of variance)\u003c/li\u003e\n\u003cli\u003eRolling statistics can be used to test for trends to see whether the centrality and/or dispersion of time series changes over time\u003c/li\u003e\n\u003cli\u003eThe Dickey-Fuller test is a common test for determining whether a time series contains trends\u003c/li\u003e\n\u003cli\u003eCommon approaches for removing trends and seasonality include taking a log-transform, subtracting the rolling mean, and differencing\u003c/li\u003e\n\u003cli\u003eDecomposing allows you to separately view \u003cem\u003eseasonality\u003c/em\u003e (which could be daily, weekly, annual, etc), \u003cem\u003etrend\u003c/em\u003e, and \u003cem\u003erandom\u003c/em\u003e, which is the variability in time series after removing the effects of the seasonality and trend\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"pca-introduction","title":"PCA - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about principal component analysis, or PCA, one of the most famous \u003cem\u003eUnsupervised Learning Techniques\u003c/em\u003e. PCA is a dimensionality reduction technique. It allows you to compress a dataset into a lower dimensional space with fewer features while maintaining as much of the original information as possible.\u003c/p\u003e\n\n\u003ch2\u003eThe Curse of Dimensionality\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is a general mathematical problem relating to the exploding size of space as you continue to add additional dimensions. This can be particularly problematic when dealing with large datasets. The more features you have, the more data you have about the scenario, but the more difficult it might be to exhaustively explore combinations of these features.\u003c/p\u003e\n\n\u003ch2\u003ePCA Use Cases\u003c/h2\u003e\n\n\u003cp\u003eThe curse of dimensionality is certainly one motivating factor for PCA. If you can't process all of the information at your disposal, then an alternative path around is necessary. Dimensionality reduction techniques such as PCA can be essential in such situations. PCA can also help improve regression and classification algorithms in many cases. In particular, algorithms are less prone to overfitting when the underlying data itself has first been compressed, reducing noise or other anomalies. Finally, PCA can also be helpful for visualizing the structure of large datasets. After all, you are limited to 2 or 3 dimensions when visualizing data. As such, reducing a dataset to 2 or 3 primary features is monumental in creating a visualization.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll explore PCA in depth using scikit-learn, and coding your own version from scratch using NumPy. Throughout this section, keep in mind use cases for PCA such as the curse of dimensionality.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-pca-introduction\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-pca-introduction\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-pca-introduction/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"introduction-to-graph-theory","title":"Introduction to Graph Theory","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-intro-graph-theory\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-intro-graph-theory\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-intro-graph-theory/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll get an introduction to some basic terminology regarding graphs and graph theory. To start, here's a graph!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph1.png\"\u003e\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain what nodes and edges are in graph theory\u003c/li\u003e\n\u003cli\u003eExplain the difference between directed and undirected graphs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eNodes and Edges: The Building Blocks of Graphs\u003c/h2\u003e\n\u003cp\u003eTo start, graphs are composed of two primary objects: \u003cstrong\u003enodes\u003c/strong\u003e and \u003cstrong\u003eedges\u003c/strong\u003e. In the picture above, the nodes are the circles, while the lines that connect them are edges. Typically, nodes represent some entity such as a person, businesses, places, or webpages. In turn, edges then represent the relationships between these entities. For example, you might have a graph of a social network in which each node represents a person, and each edge represents whether those two individuals are connected or friends within the network.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph2.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, Jen is a well connected character in this scenario: she has a connecting edge with literally every other node in the graph! On the other hand, Jake is the least connected. He has no other connections other than Jen.\u003c/p\u003e\n\u003ch2\u003eDirected vs Undirected Graphs\u003c/h2\u003e\n\u003cp\u003eAnother important concept in graph theory is the difference between directed and undirected graphs. The previous two examples have demonstrated undirected graphs. As the name implies, the edges in an undirected graph represent a mutual connection between two nodes. For example, the previous undirected graph could represent a mutual relationship such as \"Friends\" on Facebook or \"Connections\" on LinkedIn. In contrast, a direct graph looks like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-intro-graph-theory/master/images/graph3.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, each of the edges now has an arrow indicating a direction. This scenario could represent an alternative type of social network such as Twitter in which individual's relationships are not necessarily mutual. Instead, Twitter users can follow other users to stay up to date with their activity. In the graph depicted above, Sally isn't following anyone. However, both Bob and Jen are following Sally. There is also one mutual relationship depicted: Jake is following Jen and she is also following him.\u003c/p\u003e\n\u003ch2\u003eConnectedness\u003c/h2\u003e\n\u003cp\u003eConnectedness aims to quantify the number of edges attached to a node. In the graphs above, Jen is undoubtedly the most connected of the individuals depicted. In the undirected graph, she was connected to everyone. Similarly, if your goal is to become an \u003cem\u003einfluencer\u003c/em\u003e, you're going to need to develop quite the following and become a very connected node. You'll explore more details in how connectedness is quantified in the upcoming lessons. For now, take some time to think about other implications of connectedness. For example, how might you be able to use connectedness to determine friend circles or cliques in social networks?\u003c/p\u003e\n\u003ch2\u003ePath Searching\u003c/h2\u003e\n\u003cp\u003ePath searching algorithms aim to find the shortest distance between any two nodes. This can then be used as a distance metric between nodes. Additionally, this can have interesting implications. For example, in a graph network of a website, a path searching algorithm might outline how many steps are required for a customer to move from the homepage, to browsing for an item, all the way through completing their purchase at checkout. You've actually already seen some basic examples of path searching algorithms in your work with traversing JSON files. There, you took a look at developing breadth-first versus depth-first recursive procedures to create an outline of the structure of an arbitrary JSON file.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you got a brief introduction to graph theory, including some basic definitions and foundational concepts. Remember that graphs are composed of primary objects called nodes and the relationships between those objects, known as edges. Additionally, graphs can be directed or undirected depending on the nature of the edges and the relationships between nodes.\u003c/p\u003e","frontPage":false},{"exportId":"tuning-neural-networks-introduction","title":"Tuning Neural Networks - Introduction","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-intro-v2-4\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-intro-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-intro-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have a general sense of the architecture of neural networks and some of their underlying concepts, its time to further investigate how to properly tune a model for optimal performance.\u003c/p\u003e\n\n\u003ch2\u003eRegularization\u003c/h2\u003e\n\n\u003cp\u003eYou've seen regularization before in many other models including linear regression. For example, recall the L1 and L2 penalties which modify ordinary linear regression. These updated loss functions can help tune models so they do not overfit to the training data. For neural networks, you'll use a surprisingly similar process in order to achieve well trained models that are neither overfit nor underfit.\u003c/p\u003e\n\n\u003ch2\u003eNormalization\u003c/h2\u003e\n\n\u003cp\u003eAnother modeling problem occurs when one gets trapped into a local minimum when searching for an optimal solution using an iterative approach such as gradient descent. One technique for counteracting this scenario is normalizing features. Normalization in deep learning models can drastically decrease computation time, mitigate common issues such as vanishing or exploding gradients, and increase model performance.\u003c/p\u003e\n\n\u003ch3\u003eOptimization\u003c/h3\u003e\n\n\u003cp\u003eYou'll also look at alternative optimization algorithms. These are of primary interest when one encounters local minimum. Knowing when one has hit such a pitfall can be challenging and typically requires experimenting with different optimization approaches and learning rates.\u003c/p\u003e\n\n\u003ch2\u003eConvolutional Neural Networks\u003c/h2\u003e\n\n\u003cp\u003eThere are several issues when using densely connected neural networks on image data. Firstly, dense layers learn global patterns rather than local patterns, and densely connected networks can really grow very big if we have high resolution images. In this section, you'll see why Convolutional Neural Networks are often preferred over densely connected networks for image processing. Additionally, you'll learn what a convolution operation is, the different building blocks of convolutional neural networks (including filters, padding schemes, strided convolutions, etc.), and the types of network layers that are part of your convolutional neural networks.\u003c/p\u003e\n\n\u003ch3\u003eBuilding a CNN from Scratch\u003c/h3\u003e\n\n\u003cp\u003eOnce you understand how CNNs work, you'll practice building one from scratch. You'll learn how to preprocess your image data so your model can be trained using Keras. Just like with densely connected networks, Keras provides an extremely user-friendly tool to build CNNs.\u003c/p\u003e\n\n\u003ch3\u003eVisualizing Intermediate Activations\u003c/h3\u003e\n\n\u003cp\u003eAs with densely connected networks, CNNs are complicated networks that are considered a \"black box\" tool with little insight in what's happening in the network layers. However, when using CNNs, you're essentially changing your image through filters in every layer. You'll learn to get some insight in your black box models by visualizing the intermediate layers in your CNNs!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll extend your deep learning knowledge by learning about regularization, normalization, and convolutional neural networks.\u003c/p\u003e","frontPage":false},{"exportId":"lstms-and-grus","title":"LSTMs and GRUs","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-lstms-and-grus\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-lstms-and-grus\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-lstms-and-grus/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about two advanced types of neurons that typically outperform basic RNNs, \u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eGated Recurrent Units\u003c/em\u003e\u003c/strong\u003e! You'll explore the problems they solve that increase their effectiveness compared to traditional vanilla RNNs, and compare and contrast the two neurons types to get a feel for what exactly they do and how they do it!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExplain why vanishing and exploding gradients exist when training RNNs\u003c/li\u003e\n\u003cli\u003eDescribe the basic architecture and function of a GRU\u003c/li\u003e\n\u003cli\u003eDescribe the architecture and function of an LSTM cell\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eRNNs and Gradient Problems\u003c/h2\u003e\n\u003cp\u003eOne of the biggest problems with standard Recurrent Neural Networks is that they get \u003cstrong\u003e\u003cem\u003eSaturated\u003c/em\u003e\u003c/strong\u003e. The problem with this it that they use a sigmoid or tanh activation function, and there are large areas of each function where the derivative is very, very close to 0. When the derivatives are low, this means the weight updates are small, which means that the \"learning\" of the model slows to a crawl! This happens because after many, many weight updates, many weights will have been pushed into an extremely positive or extremely negative value. All you have to do is get past -5 or +5 to get to very small values.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_vanishing_gradient.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWhen gradients are close to 0 because the values are extremely low, this is called \u003cstrong\u003e\u003cem\u003eVanishing Gradient\u003c/em\u003e\u003c/strong\u003e. Similarly, networks can also get to the point where the gradients are much, much large, resulting in massive weight updates that cause the model to thrash between 1 extremely wrong answer and another. When this happens, it is called \u003cstrong\u003e\u003cem\u003eExploding Gradient\u003c/em\u003e\u003c/strong\u003e. In practice, you can easily solve exploding gradients by just \"clipping\" the weight updates by bounding them at a maximum value. However, there's no good solution for vanishing gradients!\u003c/p\u003e\n\u003cp\u003eAn intuitive way to think of this in terms of Information Theory -- the network is trying to encapsulate too much information from all of the time steps. Take a look at the following diagram, which you saw in the previous lesson. Pay attention to the colors that represent each word:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/unrolled.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eNotice how the further along the sequence goes, the less overall area the navy blue color (for the first word, \"What\") gets. As each new word in the sequence gets processed, the amount of \"room\" the RNN has to remember things gets saturated. It turns out, remembering too many things is a pretty surefire way to get your model to crash and burn. This makes it hard for dealing with long-term dependencies in the data. For instance, consider the following sentence:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\"Marilyn studied in France during the summer and fall semesters of college in 2016. As a result, she speaks fluent {_}\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eIf you were to use a traditional RNN to predict the next word in this sentence, it would likely have trouble figuring out the answer because of the number of time steps between the word to predict and the word that contains the information necessary to make a prediction, \"France\".\u003c/p\u003e\n\u003ch2\u003eRemembering and Forgetting\u003c/h2\u003e\n\u003cp\u003eThis is where the modern versions of RNNs come in. In practice, when building models for sequence data, people rarely use traditional RNN architectures anymore. Instead they make use of \u003cstrong\u003e\u003cem\u003eLSTMs\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eGRUs\u003c/em\u003e\u003c/strong\u003e. Both of these models can be thought of as special types of neurons that can be used in an RNN. Although they work a little differently, they have the same strength -- the ability to \u003cstrong\u003e\u003cem\u003eforget information\u003c/em\u003e\u003c/strong\u003e! By constantly updating their internal state, they can learn what is important to remember, and when it is okay to forget it.\u003c/p\u003e\n\u003cp\u003eConsider the word prediction example you just looked at. You clearly need to remember the word \"France\", but there are plenty of words in between France and the word you need to predict that aren't that important, and you can safely ignore, such as \"during the\", \"and\", \"of\", etc. Furthermore, let's assume that the model learns enough to answer this question, but the next thousand words in the sequence is about something completely different. Do you really still need to hold on to the information about where Marilyn studied? How can you tell when you need to remember something and when you need to forget something? This is where GRUs and LSTMs have different approaches. Let's take a quick look at how they both work.\u003c/p\u003e\n\u003ch2\u003eGated Recurrent Units (GRUs)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eGated Recurrent Units\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eGRUs\u003c/em\u003e\u003c/strong\u003e, are a special type of cell that passes along it's internal state at each time step. However, not every part of the internal state is passed along, but only the important stuff! GRUs make use of two \"gate\" functions: a \u003cstrong\u003e\u003cem\u003eReset Gate\u003c/em\u003e\u003c/strong\u003e, which determines what should be removed from the cell's internal state before passing itself along to the next time step, and an \u003cstrong\u003e\u003cem\u003eUpdate Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the state from the previous time step should be used in the current time step.\u003c/p\u003e\n\u003cp\u003eThe following technical diagram shows the internal operations of how a GRU cell works. Don't worry about trying to understand what every part of this diagram means. Internally, its just some equations for the update and reset operations, coupled with matrix multiplication and sigmoid functions. Instead, focus on the the \u003cimg src=\"https://render.githubusercontent.com/render/math?math=S_t\"\u003e line, which moves from left to right and denotes the state being updated and passed onto the next layer.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_gru.png\" width=\"400\"\u003e\u003c/p\u003e\n\u003ch2\u003eLong Short Term Memory Cells (LSTMs)\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLong Short Term Memory Cells\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eLSTMs\u003c/em\u003e\u003c/strong\u003e, are another sort of specialized neurons for use in RNNs that are able to effectively learn what to remember and what to forget in sequence models.\u003c/p\u003e\n\u003cp\u003eLSTMs are generally like GRUs, except that they use three gates instead of two. LSTMs have:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ean \u003cstrong\u003e\u003cem\u003eInput Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the cell state that was passed along should be kept\u003c/li\u003e\n\u003cli\u003ea \u003cstrong\u003e\u003cem\u003eForget Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the current state should be forgotten\u003c/li\u003e\n\u003cli\u003ean \u003cstrong\u003e\u003cem\u003eOutput Gate\u003c/em\u003e\u003c/strong\u003e, which determines how much of the current state should be exposed to the next layers in the network\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs you can see, they essentially accomplish the same thing as GRUs, but they do it in a slightly different way. Both models do a great job learning patterns from sequences, even when they are long and extremely complex! You'll find a diagram of a LSTM cell below. Just like with GRUs, don't worry about what the symbols mean or the math behind it. You can always pick that up later if you're curious. Instead, try to focus on how the information flows through this diagram from left to right, and where the various gates are for each function performed!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-lstms-and-grus/master/images/new_LSTM3_chain.png\" width=\"800\"\u003e\u003c/p\u003e\n\u003cp\u003eThere's no good answer yet as to whether GRUs or LSTMs are superior to one another. In practice, GRUs tend to have a slight advantage in many use cases, but this is far from guaranteed. The best thing to do is to build a model with each and see which one does better.\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about how LSTMs and GRUs can help the models avoid problems such as vanishing and exploding gradients when working with large sequences of data. You also learned about the structure of LSTMs and GRUs, and how they are able to \"forget\" information!\u003c/p\u003e","frontPage":false},{"exportId":"amazon-simple-storage-service-s3","title":"Amazon Simple Storage Service (S3)","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-aws-s3\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-aws-s3\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-aws-s3/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAmazon Simple Storage Service (S3) is one of the flagship services from AWS. In this lesson we'll discuss how you might use it as a data scientist!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe use cases for S3 buckets in data science\u003c/li\u003e\n\u003cli\u003eCreate S3 buckets and upload data\u003c/li\u003e\n\u003cli\u003eAccess data in S3 buckets with Python code\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eS3 Buckets in Data Science\u003c/h2\u003e\n\n\u003ch3\u003eLimitations of GitHub\u003c/h3\u003e\n\n\u003cp\u003eAt this point in the program, you might have encountered an error message like this more than once:\u003c/p\u003e\n\n\u003cpre style=\"color:red\"\u003eremote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com\nremote: error: Trace: 08740bd2fb02f980041be67b73e715a9\nremote: error: See http://git.io/iEPt8g for more information.\nremote: error: File is 218.83 MB; this exceeds GitHub's file size limit of 100.00 MB\n! [remote rejected] master -\u0026gt; master (pre-receive hook declined)\nerror: failed to push some refs\n\u003c/pre\u003e\n\n\u003cp\u003eThis happens when you try to push a file that exceeds GitHub's \u003ca href=\"https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github\"\u003efile size limits\u003c/a\u003e. The file might contain data in CSV or JSON format, or maybe a pickled ML model.\u003c/p\u003e\n\n\u003cp\u003eThe short-term workaround is to use \u003ccode\u003e.gitignore\u003c/code\u003e so that the file or files just stay on your computer and are not pushed to GitHub. But that has some limitations:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you want someone else to be able to \u003cstrong\u003ereproduce\u003c/strong\u003e your project and one or more files are too big for GitHub, how do they get the file(s)? You would need to provide very detailed instructions to make this possible\u003c/li\u003e\n\u003cli\u003eIf you want to \u003cstrong\u003etrain your model in the cloud\u003c/strong\u003e and your data is too big for GitHub, how will your code access the data?\u003c/li\u003e\n\u003cli\u003eIf you want to \u003cstrong\u003eproductionize your model\u003c/strong\u003e and your pickled model is too big for GitHub, how will your code access the model?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis problem is also not limited to GitHub. Some cloud notebooks do not support standard file systems at all, and some deployment approaches have file size limitations that are much more restrictive than GitHub's!\u003c/p\u003e\n\n\u003cp\u003eFortunately, while these tools might not be optimized for larger files, S3 buckets are a great alternative.\u003c/p\u003e\n\n\u003ch3\u003eRecommended S3 Setup for Data Science\u003c/h3\u003e\n\n\u003cp\u003eFor your projects, let's assume you are:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eWorking from a Jupyter notebook locally\u003c/li\u003e\n\u003cli\u003eNot concerned about access or keeping data private\u003c/li\u003e\n\u003cli\u003eNot needing to dynamically upload data (e.g. allow users to upload photos)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTherefore we recommend that you follow this S3 setup:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eSet up an S3 bucket where objects are all publicly readable\u003c/li\u003e\n\u003cli\u003eWhen you encounter or create a file that is too big for GitHub, \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html\"\u003eupload files to S3\u003c/a\u003e\n\n\u003col\u003e\n\u003cli\u003eFor files below 160 GB, use the AWS Console (web browser interface)\u003c/li\u003e\n\u003cli\u003eFor files between 160 GB and 5 TB, use \u003ccode\u003eboto3\u003c/code\u003e (the AWS Python SDK)\u003c/li\u003e\n\u003c/ol\u003e\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003eboto3\u003c/code\u003e in your Python code to access data in your bucket\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eNow we will go over all of these steps!\u003c/p\u003e\n\n\u003ch2\u003eCreating and Configuring S3 Buckets\u003c/h2\u003e\n\n\u003cp\u003eIn some software applications, S3 buckets are created dynamically based on application context. For data science, projects don't typically need to be quite so dynamic, so we can create our S3 buckets using the more-intuitive AWS console interface rather than using code.\u003c/p\u003e\n\n\u003cp\u003eGo to the \u003cstrong\u003eS3 management console\u003c/strong\u003e. This can be accessed by searching for \"s3\" in the \u003ca href=\"https://aws.amazon.com/console/\"\u003eAWS Management Console\u003c/a\u003e or by going directly to \u003ca href=\"https://s3.console.aws.amazon.com/s3/home\"\u003ethis link\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eClick on \u003cstrong\u003e\"Create Bucket\"\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eGive your bucket a \u003cstrong\u003eunique name\u003c/strong\u003e:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you're working on a specific project, try giving the bucket a name that relates to the project\u003c/li\u003e\n\u003cli\u003eDO NOT include any private/secret information in the bucket name\u003c/li\u003e\n\u003cli\u003eIf someone else has already used a bucket name, you will not be able to use it\n\n\u003cul\u003e\n\u003cli\u003eIf you're feeling stuck brainstorming a name, try adding today's date to it. That will be less likely to already be in use\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eScroll down and \u003cstrong\u003eun-check \"Block all public access\"\u003c/strong\u003e. AWS assumes that you want your data to be private, but we are moving forward with the assumption that public data access is not a problem. You will also need to check the box next to \u003cstrong\u003eI acknowledge that the current settings might result in this bucket and the objects within becoming public\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eScroll the rest of the way down and click \u003cstrong\u003eCreate Bucket\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eNow you should have a bucket set up where objects can be public!\u003c/p\u003e\n\n\u003ch2\u003eUploading Data to S3 Buckets\u003c/h2\u003e\n\n\u003ch3\u003eAWS Console Approach\u003c/h3\u003e\n\n\u003cp\u003eFor files below 160 GB, you can use the AWS Management Console. Go to the \u003cstrong\u003eS3 management console\u003c/strong\u003e and click on the name of your bucket.\u003c/p\u003e\n\n\u003cp\u003eBy default, you should see the \"Objects\" tab. Click on \u003cstrong\u003eUpload\u003c/strong\u003e. Click \u003cstrong\u003eAdd Files\u003c/strong\u003e and use the file picker to select a file or multiple files on your computer.\u003c/p\u003e\n\n\u003cp\u003eScroll down to \u003cstrong\u003ePermissions\u003c/strong\u003e and click to expand. Under \"Predefined ACLs\", click \u003cstrong\u003eGrant public-read access\u003c/strong\u003e and then check the box next to \u003cstrong\u003eI understand the risk of granting public-read access to the specified objects\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eScroll to the bottom and click \u003cstrong\u003eUpload\u003c/strong\u003e. You will be taken to an upload status page while the file is being uploaded, then you can click \u003cstrong\u003eClose\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eChecking for Successful Upload and Configuration\u003c/h3\u003e\n\n\u003cp\u003eNow your data should be publicly hosted on S3! Try clicking on the file name in the \"Objects\" tab to see all of the information about it.\u003c/p\u003e\n\n\u003cp\u003eTo test whether the file permissions were successfully set to be public, you can click on either the \"Open\" button in the upper right, or the \"Object URL\" link inside the \"Object Overview\" panel.\u003c/p\u003e\n\n\u003ch4\u003eSuccessful Upload\u003c/h4\u003e\n\n\u003cp\u003eIf your file is downloaded, that means the settings are correct. (If it is a very large file, feel free to stop the download to save time and space -- you already have the file on your computer!)\u003c/p\u003e\n\n\u003ch4\u003eUnsuccessful Upload\u003c/h4\u003e\n\n\u003cp\u003eIf you see a message like this:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThis XML file does not appear to have any style information associated with it. The document tree is shown below.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e\u0026lt;Error\u0026gt;\n\u0026lt;Code\u0026gt;AccessDenied\u0026lt;/Code\u0026gt;\n\u0026lt;Message\u0026gt;Access Denied\u0026lt;/Message\u0026gt;\n\u0026lt;RequestId\u0026gt;XXXXXXXXXXXXXXXX\u0026lt;/RequestId\u0026gt;\n\u0026lt;HostId\u0026gt;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\u0026lt;/HostId\u0026gt;\n\u0026lt;/Error\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat means that you did not configure the permissions correctly. Go back through and make sure that:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe bucket settings are configured so that objects can be public\n\n\u003cul\u003e\n\u003cli\u003eIf you look at the bucket from the \u003ca href=\"https://s3.console.aws.amazon.com/s3/home\"\u003eS3 management console\u003c/a\u003e, you should see the text \"Objects can be public\" in the \"Access\" column\u003c/li\u003e\n\u003cli\u003eIf you do not see that, click on the bucket, go to the \u003cstrong\u003ePermissions\u003c/strong\u003e tab, scroll down to \u003cstrong\u003eBlock public access (bucket settings)\u003c/strong\u003e, and click \u003cstrong\u003eEdit\u003c/strong\u003e. Un-check \u003cstrong\u003eBlock all public access\u003c/strong\u003e, check \u003cstrong\u003eI acknowledge that the current settings might result in this bucket and the objects within becoming public\u003c/strong\u003e, and click \u003cstrong\u003eSave Changes\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eThe object settings are configured so that the public can access them\n\n\u003cul\u003e\n\u003cli\u003eIf you click on the bucket name, then click on the name of the file (e.g. \u003ccode\u003etest.csv\u003c/code\u003e), then go to the \u003cstrong\u003ePermissions\u003c/strong\u003e tab, you should see \"Read\" in the \"Object\" column next to \"Everyone (public access)\"\u003c/li\u003e\n\u003cli\u003eIf you do not see that, click on \u003cstrong\u003eEdit\u003c/strong\u003e next to \"Access control list (ACL)\". Locate the row that says \"Everyone (public access)\" and the column that says \"Objects\", and click the checkbox next to \u003cstrong\u003eRead\u003c/strong\u003e. Scroll down and click the checkbox next to \u003cstrong\u003eI understand the effects of these changes on this object\u003c/strong\u003e, then click \u003cstrong\u003eSave changes\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003ePython Approach\u003c/h3\u003e\n\n\u003cp\u003eFor files from 160 GB to 5 TB, you'll need a more sophisticated approach. Check out \u003ca href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\"\u003ethis documentation\u003c/a\u003e for an overview of the multi-part upload process.\u003c/p\u003e\n\n\u003cp\u003eFortunately you can use \u003ccode\u003eboto3\u003c/code\u003e, the same package we'll use in the later examples in this lesson, in order to achieve this. First, use \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html#configuration\"\u003ethis documentation\u003c/a\u003e to configure a file on your computer to give \u003ccode\u003eboto3\u003c/code\u003e the credentials it needs to upload. Then follow the documentation \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_multipart_upload\"\u003ehere\u003c/a\u003e to create the actual upload.\u003c/p\u003e\n\n\u003ch2\u003eAccessing Data in S3 Buckets\u003c/h2\u003e\n\n\u003cp\u003eAs demonstrated above, one way to access the data in your S3 bucket is simply to navigate the the relevant web address and download the file. However, our main goal is to make the data accessible in \u003cstrong\u003ePython code\u003c/strong\u003e, not using a web browser. To achieve that, we'll use the \u003ccode\u003eboto3\u003c/code\u003e library!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/boto3.png\" alt=\"boto3\"\u003e\u003c/p\u003e\n\n\u003cp\u003eBoto 3 is a library that allows Python developers to access many different Amazon web services, not just S3. You can find the full list \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/index.html\"\u003ehere\u003c/a\u003e. But we'll focus on using S3 with \u003ccode\u003eboto3\u003c/code\u003e because that is one of the most common use cases for data scientists.\u003c/p\u003e\n\n\u003cp\u003e(The name \"boto\" is a type of dolphin that is native to the Amazon river. \u003ca href=\"https://github.com/boto/boto3/issues/1023#issuecomment-287127647\"\u003eAccording to its developer\u003c/a\u003e, \"I wanted something short, unusual, and with at least some kind of connection to Amazon\".)\u003c/p\u003e\n\n\u003ch3\u003eInstalling \u003ccode\u003eboto3\u003c/code\u003e\u003c/h3\u003e\n\n\u003cp\u003eThis library is not part of \u003ccode\u003elearn-env\u003c/code\u003e as of this writing. If you are working on a project, we recommend activating that project \u003ccode\u003econda\u003c/code\u003e environment. Or if you're just wanting to learn about \u003ccode\u003eboto3\u003c/code\u003e, you can un-comment this line of code to install it in your current environment:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install boto3 -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMake sure this cell runs successfully before proceeding:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eboto3\u003c/span\u003e\n\u003cspan class=\"n\"\u003es3\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eboto3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eresource\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"s3\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eConnecting to an Example S3 Bucket\u003c/h3\u003e\n\n\u003cp\u003eFor the purposes of this curriculum, we have loaded some example files into an S3 bucket for you! Let's go through those examples, starting with a text file.\u003c/p\u003e\n\n\u003ch4\u003eText File\u003c/h4\u003e\n\n\u003cp\u003eWe'll instantiate an instance of the \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html?highlight=s3.object#S3.Object\"\u003e\u003ccode\u003eObject\u003c/code\u003e class\u003c/a\u003e by passing in those string values. The first one, \u003ccode\u003ebucket_name\u003c/code\u003e, is the name of the bucket. The second, \u003ccode\u003ekey\u003c/code\u003e, is the name of the object (file) inside that bucket.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/data/zen_of_python.txt\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003es3.Object(bucket_name='curriculum-content', key='data-science/data/zen_of_python.txt')\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis object is used kind of like a request in the \u003ccode\u003erequests\u003c/code\u003e library. You call the \u003ca href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html?highlight=s3.object#S3.Object.get\"\u003e\u003ccode\u003eget\u003c/code\u003e method\u003c/a\u003e to initiate an HTTP \u003ccode\u003eGET\u003c/code\u003e request.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etxt_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003e{'ResponseMetadata': {'RequestId': 'JR1N0QAM82W3ETVW',\n  'HostId': 'J2J6MiFzynwLLLlOXBSTgYyFOPcDpoofyc165VnBbB+nNEH2cbovo7p4+MGMYXiT0mfD8acVZ2o=',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amz-id-2': 'J2J6MiFzynwLLLlOXBSTgYyFOPcDpoofyc165VnBbB+nNEH2cbovo7p4+MGMYXiT0mfD8acVZ2o=',\n   'x-amz-request-id': 'JR1N0QAM82W3ETVW',\n   'date': 'Thu, 10 Mar 2022 20:58:09 GMT',\n   'last-modified': 'Thu, 10 Mar 2022 19:17:44 GMT',\n   'etag': '\"760dcb2a44c5b0553ee12ea8cca057b8\"',\n   'x-amz-server-side-encryption': 'AES256',\n   'accept-ranges': 'bytes',\n   'content-type': 'binary/octet-stream',\n   'server': 'AmazonS3',\n   'content-length': '858'},\n  'RetryAttempts': 0},\n 'AcceptRanges': 'bytes',\n 'LastModified': datetime.datetime(2022, 3, 10, 19, 17, 44, tzinfo=tzutc()),\n 'ContentLength': 858,\n 'ETag': '\"760dcb2a44c5b0553ee12ea8cca057b8\"',\n 'ContentType': 'binary/octet-stream',\n 'ServerSideEncryption': 'AES256',\n 'Metadata': {},\n 'Body': \u0026lt;botocore.response.StreamingBody at 0x10ad09128\u0026gt;}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe actual data for the object is contained in the \"Body\" of the response. Let's extract that key and read out the data:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003etxt_body\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etxt_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"n\"\u003edecode\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etxt_body\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eMore-Complex Files: \u003ccode\u003eBytesIO\u003c/code\u003e\u003c/h4\u003e\n\n\u003cp\u003eIf we have a file type where we want to do something other than just print out its contents (e.g. images, pickled models, CSVs), we need to add one more step: creating a virtual file with \u003ccode\u003eBytesIO\u003c/code\u003e (a class in the built-in \u003ca href=\"https://docs.python.org/3/library/io.html\"\u003ePython \u003ccode\u003eio\u003c/code\u003e module\u003c/a\u003e). Then we can send that virtual file to a library like Pillow, \u003ccode\u003ejoblib\u003c/code\u003e, or \u003ccode\u003epandas\u003c/code\u003e.\u003c/p\u003e\n\n\u003ch4\u003eImage File\u003c/h4\u003e\n\n\u003cp\u003e\u003ccode\u003elearn-env\u003c/code\u003e already has Pillow, but un-comment the following line if you need to install it in the environment you're currently using to look at this example. Or you can feel free to skip this example and go down to the next one!\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install pillow -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ePIL\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eImage\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Getting the same boto3 image that appears earlier in this lesson\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/images/boto3.png\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eimg_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into a BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Display the image using Pillow\n\u003c/span\u003e\u003cspan class=\"n\"\u003eimage\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eImage\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nb\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edisplay\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eimage\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"index_files/index_18_0.png\" alt=\"png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is a bit silly example (displaying image data in a Jupyter notebook) but the same approach could be used for loading data into an image classification tool! Check out \u003ca href=\"https://medium.com/analytics-vidhya/custom-keras-generator-fetching-images-from-s3-to-train-neural-network-4e98694de8ee\"\u003ethis blog post\u003c/a\u003e for an example.\u003c/p\u003e\n\n\u003ch4\u003ePickled Model\u003c/h4\u003e\n\n\u003cp\u003eSome model algorithms (e.g. Random Forest, Neural Networks) produce very large pickled models that don't easily fit into GitHub. And in some cases, your deployment approach will not have a file system available, so you'll need to use a cloud storage technique regardless of the model size. Below we show an example of a fairly simple linear regression model that has been stored in S3, but the same concept can easily apply to larger, more-complex models:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \n\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.linear_model\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eLinearRegression\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ejoblib\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Initialize S3 object\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/models/regression_model.pkl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epkl_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Load the data using joblib\n\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epkl_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Loaded model is y = \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecoef_\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003ex + \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eintercept_\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eloaded_model\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epredict\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e12\u003c/span\u003e\u003cspan class=\"p\"\u003e]])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight plaintext\"\u003e\u003ccode\u003eLoaded model is y = 1.0x + 1.0\n\n\n\n\n\narray([11., 12., 13.])\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003eCSV File\u003c/h4\u003e\n\n\u003cp\u003eCSV data is a more realistic file type you might be working with. The below example reads a CSV file from an S3 bucket, then loads it into \u003ccode\u003epandas\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Initialize S3 object\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_obj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"curriculum-content\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"data-science/data/test.csv\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Get the response\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_resp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecsv_obj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Read the data into a BytesIO object\n\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_bytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_resp\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eread\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Load the data with pandas\n\u003c/span\u003e\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread_csv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecsv_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv\u003e\n\u003cstyle\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eid\u003c/th\u003e\n      \u003cth\u003ebattery_power\u003c/th\u003e\n      \u003cth\u003eblue\u003c/th\u003e\n      \u003cth\u003eclock_speed\u003c/th\u003e\n      \u003cth\u003edual_sim\u003c/th\u003e\n      \u003cth\u003efc\u003c/th\u003e\n      \u003cth\u003efour_g\u003c/th\u003e\n      \u003cth\u003eint_memory\u003c/th\u003e\n      \u003cth\u003em_dep\u003c/th\u003e\n      \u003cth\u003emobile_wt\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003epc\u003c/th\u003e\n      \u003cth\u003epx_height\u003c/th\u003e\n      \u003cth\u003epx_width\u003c/th\u003e\n      \u003cth\u003eram\u003c/th\u003e\n      \u003cth\u003esc_h\u003c/th\u003e\n      \u003cth\u003esc_w\u003c/th\u003e\n      \u003cth\u003etalk_time\u003c/th\u003e\n      \u003cth\u003ethree_g\u003c/th\u003e\n      \u003cth\u003etouch_screen\u003c/th\u003e\n      \u003cth\u003ewifi\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1043\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e193\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e16\u003c/td\u003e\n      \u003ctd\u003e226\u003c/td\u003e\n      \u003ctd\u003e1412\u003c/td\u003e\n      \u003ctd\u003e3476\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e841\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e61\u003c/td\u003e\n      \u003ctd\u003e0.8\u003c/td\u003e\n      \u003ctd\u003e191\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e746\u003c/td\u003e\n      \u003ctd\u003e857\u003c/td\u003e\n      \u003ctd\u003e3895\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1807\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e2.8\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1366\u003c/td\u003e\n      \u003ctd\u003e2396\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1546\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e96\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e20\u003c/td\u003e\n      \u003ctd\u003e295\u003c/td\u003e\n      \u003ctd\u003e1752\u003c/td\u003e\n      \u003ctd\u003e3893\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e1434\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e49\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e108\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e749\u003c/td\u003e\n      \u003ctd\u003e810\u003c/td\u003e\n      \u003ctd\u003e1773\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e995\u003c/th\u003e\n      \u003ctd\u003e996\u003c/td\u003e\n      \u003ctd\u003e1700\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e54\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e170\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e644\u003c/td\u003e\n      \u003ctd\u003e913\u003c/td\u003e\n      \u003ctd\u003e2121\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e996\u003c/th\u003e\n      \u003ctd\u003e997\u003c/td\u003e\n      \u003ctd\u003e609\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e13\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e1152\u003c/td\u003e\n      \u003ctd\u003e1632\u003c/td\u003e\n      \u003ctd\u003e1933\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e997\u003c/th\u003e\n      \u003ctd\u003e998\u003c/td\u003e\n      \u003ctd\u003e1185\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e80\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e477\u003c/td\u003e\n      \u003ctd\u003e825\u003c/td\u003e\n      \u003ctd\u003e1223\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e998\u003c/th\u003e\n      \u003ctd\u003e999\u003c/td\u003e\n      \u003ctd\u003e1533\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e50\u003c/td\u003e\n      \u003ctd\u003e0.4\u003c/td\u003e\n      \u003ctd\u003e171\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e38\u003c/td\u003e\n      \u003ctd\u003e832\u003c/td\u003e\n      \u003ctd\u003e2509\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e999\u003c/th\u003e\n      \u003ctd\u003e1000\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e35\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e140\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e457\u003c/td\u003e\n      \u003ctd\u003e608\u003c/td\u003e\n      \u003ctd\u003e2828\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e1000 rows √ó 21 columns\u003c/p\u003e\n\u003c/div\u003e\n\n\u003ch4\u003eAvoiding \u003ccode\u003eBytesIO\u003c/code\u003e by Installing S3Fs\u003c/h4\u003e\n\n\u003cp\u003eIf you are using \u003ccode\u003epandas\u003c/code\u003e and you want to avoid having to use \u003ccode\u003eBytesIO\u003c/code\u003e, there is a library called \u003ca href=\"https://s3fs.readthedocs.io/en/latest/\"\u003eS3Fs (S3 Filesystem)\u003c/a\u003e that can help you shorten the above code by treating S3 URLs as regular file system URLs. You just need to start the file path with \u003ccode\u003e\"s3://\"\u003c/code\u003e!\u003c/p\u003e\n\n\u003cp\u003e(S3Fs is used \"under the hood\" by \u003ccode\u003epandas\u003c/code\u003e and does not require a separate import for this type of use.)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# !conda install s3fs -c conda-forge -y\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eHere is the same example as above, using S3Fs to shorten the code:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eread_csv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"s3://curriculum-content/data-science/data/test.csv\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003edf\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv\u003e\n\u003cstyle\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eid\u003c/th\u003e\n      \u003cth\u003ebattery_power\u003c/th\u003e\n      \u003cth\u003eblue\u003c/th\u003e\n      \u003cth\u003eclock_speed\u003c/th\u003e\n      \u003cth\u003edual_sim\u003c/th\u003e\n      \u003cth\u003efc\u003c/th\u003e\n      \u003cth\u003efour_g\u003c/th\u003e\n      \u003cth\u003eint_memory\u003c/th\u003e\n      \u003cth\u003em_dep\u003c/th\u003e\n      \u003cth\u003emobile_wt\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003epc\u003c/th\u003e\n      \u003cth\u003epx_height\u003c/th\u003e\n      \u003cth\u003epx_width\u003c/th\u003e\n      \u003cth\u003eram\u003c/th\u003e\n      \u003cth\u003esc_h\u003c/th\u003e\n      \u003cth\u003esc_w\u003c/th\u003e\n      \u003cth\u003etalk_time\u003c/th\u003e\n      \u003cth\u003ethree_g\u003c/th\u003e\n      \u003cth\u003etouch_screen\u003c/th\u003e\n      \u003cth\u003ewifi\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1043\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e193\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e16\u003c/td\u003e\n      \u003ctd\u003e226\u003c/td\u003e\n      \u003ctd\u003e1412\u003c/td\u003e\n      \u003ctd\u003e3476\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e841\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e61\u003c/td\u003e\n      \u003ctd\u003e0.8\u003c/td\u003e\n      \u003ctd\u003e191\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e746\u003c/td\u003e\n      \u003ctd\u003e857\u003c/td\u003e\n      \u003ctd\u003e3895\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1807\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e2.8\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1366\u003c/td\u003e\n      \u003ctd\u003e2396\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1546\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e96\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e20\u003c/td\u003e\n      \u003ctd\u003e295\u003c/td\u003e\n      \u003ctd\u003e1752\u003c/td\u003e\n      \u003ctd\u003e3893\u003c/td\u003e\n      \u003ctd\u003e10\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e1434\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e49\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e108\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e18\u003c/td\u003e\n      \u003ctd\u003e749\u003c/td\u003e\n      \u003ctd\u003e810\u003c/td\u003e\n      \u003ctd\u003e1773\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e7\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e995\u003c/th\u003e\n      \u003ctd\u003e996\u003c/td\u003e\n      \u003ctd\u003e1700\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1.9\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e54\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e170\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e17\u003c/td\u003e\n      \u003ctd\u003e644\u003c/td\u003e\n      \u003ctd\u003e913\u003c/td\u003e\n      \u003ctd\u003e2121\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e996\u003c/th\u003e\n      \u003ctd\u003e997\u003c/td\u003e\n      \u003ctd\u003e609\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e13\u003c/td\u003e\n      \u003ctd\u003e0.9\u003c/td\u003e\n      \u003ctd\u003e186\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e1152\u003c/td\u003e\n      \u003ctd\u003e1632\u003c/td\u003e\n      \u003ctd\u003e1933\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e997\u003c/th\u003e\n      \u003ctd\u003e998\u003c/td\u003e\n      \u003ctd\u003e1185\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1.4\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e8\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e80\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e477\u003c/td\u003e\n      \u003ctd\u003e825\u003c/td\u003e\n      \u003ctd\u003e1223\u003c/td\u003e\n      \u003ctd\u003e5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e14\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e998\u003c/th\u003e\n      \u003ctd\u003e999\u003c/td\u003e\n      \u003ctd\u003e1533\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e50\u003c/td\u003e\n      \u003ctd\u003e0.4\u003c/td\u003e\n      \u003ctd\u003e171\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e12\u003c/td\u003e\n      \u003ctd\u003e38\u003c/td\u003e\n      \u003ctd\u003e832\u003c/td\u003e\n      \u003ctd\u003e2509\u003c/td\u003e\n      \u003ctd\u003e15\u003c/td\u003e\n      \u003ctd\u003e11\u003c/td\u003e\n      \u003ctd\u003e6\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e999\u003c/th\u003e\n      \u003ctd\u003e1000\u003c/td\u003e\n      \u003ctd\u003e1270\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e4\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e35\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003e140\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e457\u003c/td\u003e\n      \u003ctd\u003e608\u003c/td\u003e\n      \u003ctd\u003e2828\u003c/td\u003e\n      \u003ctd\u003e9\u003c/td\u003e\n      \u003ctd\u003e2\u003c/td\u003e\n      \u003ctd\u003e3\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e1000 rows √ó 21 columns\u003c/p\u003e\n\u003c/div\u003e\n\n\u003ch3\u003eConnecting to Your S3 Bucket\u003c/h3\u003e\n\n\u003cp\u003eIn the cell below, replace the string values with the names of your S3 bucket and the file you want to read:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003ebucket_name\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003cspan class=\"n\"\u003eobject_name\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we'll attempt to load your object using \u003ccode\u003eboto3\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eobj\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003es3\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eObject\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebucket_name\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eobject_name\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003eobj\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eobj\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(If you get a \u003ccode\u003eNoCredentialError\u003c/code\u003e here, that means that you either have the wrong bucket or object name, or you did not set the permissions on the bucket or object correctly. Double-check that the steps above are working as expected.)\u003c/p\u003e\n\n\u003cp\u003eNow you can continue with whatever next steps are appropriate for your use case!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we introduced the use cases for S3 in data science: typically data scientists use S3 for storing files that are too big for GitHub, but still need to be accessible from Python code for the purposes of reproducibility, using certain cloud services, or deployment. These can include many types of files, including text, images, pickled models, and data files such as CSV.\u003c/p\u003e\n\n\u003cp\u003eWe recommend that you use the AWS console to upload content to a bucket and configure the access permissions, then use the \u003ccode\u003eboto3\u003c/code\u003e Python library to access this content from the context of Python code.\u003c/p\u003e","frontPage":false},{"exportId":"short-video-regression-with-a-neural-network","title":"Short Video: Regression with a Neural Network","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713813950?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"introduction-to-nlp-with-nltk","title":"Introduction to NLP with NLTK","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll discuss a general overview of Natural Language Processing, and the popular Python library for NLP, \u003cstrong\u003e\u003cem\u003eNatural Language Tool Kit\u003c/em\u003e\u003c/strong\u003e (NLTK).\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify ways we can use NLTK to simplify and accelerate common preprocessing tasks for text data\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Natural Language Processing?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eNatural Language Processing\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eNLP\u003c/em\u003e\u003c/strong\u003e, refers to analytics tasks that deal with natural human language, in the form of text or speech. These tasks usually involve some sort of machine learning, whether for text classification or for feature generation, but NLP isn't just machine learning. Tasks such as text preprocessing and cleaning also fall under the NLP umbrella. \u003c/p\u003e\n\n\u003cp\u003eThe most common Python library used for NLP tasks is \u003cstrong\u003e\u003cem\u003eNatural Language Tool Kit\u003c/em\u003e\u003c/strong\u003e, or NLTK for short. This library was developed by researchers at the University of Pennsylvania, and quickly became the most powerful and complete library of NLP tools available. \u003c/p\u003e\n\n\u003ch2\u003eUsing NLTK\u003c/h2\u003e\n\n\u003cp\u003eNLTK is a sort of \"one-stop shop\" for all things NLP. It contains many sample corpora, with everything from full texts from Project Gutenberg to transcripts of State of the Union speeches from US Presidents. This library contains functions and tools for everything from data cleaning and preprocessing, to linguistic analysis, to feature generation and extraction. NLTK even contains its own Bayesian classifiers for quick testing (although realistically, you'll likely want to continue using scikit-learn for these sorts of tasks). \u003c/p\u003e\n\n\u003cp\u003eNLP is unique in that in addition to statistics and math, it also relies heavily on the field of \u003cstrong\u003e\u003cem\u003eLingustics\u003c/em\u003e\u003c/strong\u003e. Many of the concepts you'll run into will be grounded in linguistics. Some of them will seem a bit foreign to you if you haven't studied languages or grammar yet, but don't worry! The reality of it all is that you don't need deep expertise in linguistics to work with text data, because NLTK was built by professionals to make it easier for everyone to access the linguistic tools and methods needed for working with text data. Although a linguist knows how to manually generate something like a \u003cstrong\u003e\u003cem\u003eParse Tree\u003c/em\u003e\u003c/strong\u003e for a sentence, NLTK provides this functionality for you in just a few lines of code. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eA sample Parse Tree created with NLTK\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-nltk/master/images/new_parse_tree.png\" width=\"750\"\u003e \n\n\u003ch2\u003eWorking With Text, Simplified\u003c/h2\u003e\n\n\u003cp\u003eGenerally, projects that work with text data follow the same overall pattern as any other projects. The main difference is that text projects usually require a bit more cleaning and preprocessing than regular data, in order to get the text into a format that's usable for modeling. \u003c/p\u003e\n\n\u003cp\u003eHere are some of the ways that NLTK can make our lives easier when working with text data:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStop Word Removal\u003c/em\u003e\u003c/strong\u003e: NLTK contains a full library of stop words, making it easy to remove the words that don't matter from our data.    \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eFiltering and Cleaning\u003c/em\u003e\u003c/strong\u003e: NLTK provides simple, easy ways to create and filter frequency distributions, as well providing multiple ways to clean, stem, lemmatize, or tokenize datasets.   \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e\u003cem\u003eFeature Selection and Feature Engineering\u003c/em\u003e\u003c/strong\u003e: NLTK contains tools to quickly generate features such as bigrams and n-grams. It also contains major libraries such as the \u003cstrong\u003e\u003cem\u003ePenn Tree Bank\u003c/em\u003e\u003c/strong\u003e to allow quick feature engineering, such as generating part-of-speech tags, or sentence polarity. \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAgain, don't worry if you're not sure what things like 'lemmatize' mean yet -- we'll cover all of that soon! With effective use of NLTK, we can quickly process and work with text data, allowing us to quickly get our data into the shape needed for tasks we're familiar with, such as classification!\u003c/p\u003e\n\n\u003cp\u003eFor the remainder of this section, we're going to spend some time getting comfortable with NLTK, while also learning about foundational concepts of linguistics that underpin many of the tasks in NLP. We'll learn to effectively use NLTK to clean and preprocess data in a variety of ways. We'll gain some practice filtering data with regular expressions, generate text statistics to compare text documents, and quickly engineer features to help us better train classifiers for text classification!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about what NLP is, and how the NLTK package can save us time and make us more effective when working with text data. \u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-introduction-to-nltk\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-introduction-to-nltk\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-nltk/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"cloud-computing","title":"Cloud Computing","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-cloud-computing\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-cloud-computing\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-cloud-computing/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFor most of this curriculum, we have focused on techniques that you can apply on your own computer. In a production setting, you will likely need to go beyond your computer and utilize cloud services! This lesson gives an overview of what that means and what your options are.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the general concept of \"the cloud\"\u003c/li\u003e\n\u003cli\u003eIdentify some of the most popular cloud platforms\u003c/li\u003e\n\u003cli\u003eIdentify the key use cases of cloud platforms\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eThe Cloud\u003c/h2\u003e\n\n\u003cp\u003e\u003ca title=\"ÁôæÊ•ΩÂÖé, CC BY-SA 3.0 \u003chttps://creativecommons.org/licenses/by-sa/3.0\u003e, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Cloud_computing_icon.svg\"\u003e\u003cimg width=\"256\" alt=\"Cloud computing icon\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Cloud_computing_icon.svg/256px-Cloud_computing_icon.svg.png\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eCloud computing\u003c/em\u003e\u003c/strong\u003e is originally an IT infrastructure term, which is contrasted with \u003cem\u003eon-premises\u003c/em\u003e computing. In traditional IT infrastructure, specialized computers (servers) would be purchased and set up at the company to do things like store customer data in a database, or serve the company's website. The problem with this setup is that it's less flexible (leaving resources unused at low-traffic times, running the risk of servers being overloaded at high-traffic times) and requires on-site server maintenance expertise. Some small or niche organizations still use 100% on-premises computing (e.g. because of special security needs), but nowadays most have moved to using some kind of cloud platform.\u003c/p\u003e\n\n\u003cp\u003eOn a cloud platform, server resources are typically available \"on-demand\", meaning that the amount of storage space or CPU time scales based on user needs, and the user pays accordingly. This allows for better agility, performance, and monitoring than traditional on-premises setups.\u003c/p\u003e\n\n\u003ch3\u003ePopular Cloud Platforms\u003c/h3\u003e\n\n\u003cp\u003e\u003cstrong\u003eAmazon Web Services (AWS)\u003c/strong\u003e emerged in the early 21st Century as the first modern cloud platform. Previously there had been time-sharing approaches and virtual private network (VPN) services, but AWS also introduced the concept of virtual private servers. Two early AWS products, Simple Storage Service (S3) and Elastic Compute Cloud (EC2), were released in 2006 and are still very popular today.\u003c/p\u003e\n\n\u003cp\u003eOther major tech companies soon followed with their own cloud platforms, to compete with AWS and also offer novel products and services. The two major competitors to AWS are Microsoft's \u003cstrong\u003eAzure\u003c/strong\u003e and \u003cstrong\u003eGoogle Cloud\u003c/strong\u003e. For most typical cloud computing use cases, all three of these companies offer comparable services, although one particular offering might be best for your company's needs in terms of pricing or specifications.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://www.flexera.com/blog/wp-content/uploads/2021/03/Picture9.png\" alt=\"public cloud adoption for enterprises\"\u003e\nFrom \u003ca href=\"https://www.flexera.com/blog/cloud/cloud-computing-trends-2021-state-of-the-cloud-report/\"\u003e\u003cem\u003eCloud Computing Trends: 2021 State of the Cloud Report\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eBecause AWS is the most popular cloud platform, we'll take some time later to discuss the AWS ecosystem and specific AWS services that you may find useful in your projects or future career.\u003c/p\u003e\n\n\u003ch2\u003eHardware Acceleration\u003c/h2\u003e\n\n\u003cp\u003eYou're already familiar with software libraries like NumPy and Spark that can help your computer perform at its best, but ultimately your personal computer (laptop or desktop) was probably not designed specifically for high-powered machine learning tasks.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eHardware acceleration\u003c/strong\u003e is useful when you need to train models or make predictions more quickly. As a general concept, \u003ca href=\"https://www.omnisci.com/learn/resources/technical-glossary/hardware-acceleration\"\u003ehardware acceleration\u003c/a\u003e means using purpose-built hardware rather than general-purpose hardware.\u003c/p\u003e\n\n\u003cp\u003eIn the case of machine learning, this typically means running your code on a \u003cstrong\u003eGPU\u003c/strong\u003e, rather than a CPU.  A CPU \u003cem\u003ecan\u003c/em\u003e do everything that a GPU can do, but it is not optimized for it, so it will likely take more time.  \u003ca href=\"https://towardsdatascience.com/maximize-your-gpu-dollars-a9133f4e546a\"\u003eThis blog\u003c/a\u003e argues that a CPU is to a GPU as a horse and buggy is to a car.\u003c/p\u003e\n\n\u003cp\u003eThe easiest way to get started with utilizing a GPU is by using a \u003cstrong\u003ecloud notebook\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCloud Notebooks\u003c/h3\u003e\n\n\u003cp\u003eA cloud notebook means that you can work in a familiar notebook interface, while at the same time using more-powerful computational resources. You usually don't have to install or configure anything -- you can just start coding in a super-powerful cloud environment. Sometimes these cloud environments even have built-in GitHub integration, so you can complete the entire development process in the cloud! Some past Flatiron students have found cloud notebooks to be extremely helpful for building the kinds of models they wanted to build in the time they had.\u003c/p\u003e\n\n\u003cp\u003eThere are also some downsides to cloud notebooks to be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSometimes you don't have precise control over the available \u003cstrong\u003ePython packages\u003c/strong\u003e and their versions. So, for example, you might want to use the latest version of TensorFlow, but the service you're using might not support it yet.\u003c/li\u003e\n\u003cli\u003ePaid tools (including the AWS and Google Cloud Platform tools listed below) can quickly get very \u003cstrong\u003eexpensive\u003c/strong\u003e. In particular be very careful about completing tutorials or running other people's projects, because it's easy to use up a lot of compute resources. You will typically get some free credits when signing up for these services, and we recommend that you save them for your own portfolio projects. Also make sure you always shut down your notebook instance when you're not using it.\u003c/li\u003e\n\u003cli\u003eSome of these notebooks don't work with a straightforward \u003cstrong\u003efile system\u003c/strong\u003e like you do on your everyday DS setup. Instead of simply being able to call \u003ccode\u003epd.read_csv\u003c/code\u003e to open a file, you'll likely need to interact with a web API to pull in your data from a storage bucket or other virtual storage location.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSome popular cloud notebooks include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html\"\u003eAWS SageMaker\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eProfessional-grade cloud JupyterLab instances (paid service, some free credits may be available)\u003c/li\u003e\n\u003cli\u003eWe'll also have more lessons on this later in the curriculum\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/vertex-ai/docs/workbench/user-managed?hl=en_US\"\u003eGoogle Cloud Notebooks\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eProfessional-grade cloud JupyterLab instances (paid service, some free credits may be available)\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://research.google.com/colaboratory/\"\u003eGoogle Colab\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eMore like the \"Google Docs\" of notebooks: not quite the same as a Jupyter notebook, and doesn't have access to a file system, but very fast to get started and 100% free\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.kaggle.com/code\"\u003eKaggle Kernels\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eNot exactly a Jupyter notebook, but a similar interface from Kaggle. Great if you're using a dataset from Kaggle\u003c/li\u003e\n\u003cli\u003eFree, although you're limited to \u003ca href=\"https://www.kaggle.com/page/GPU-tips-and-tricks\"\u003e30 hours per week\u003c/a\u003e of GPU time\u003c/li\u003e\n\u003cli\u003eGo \u003ca href=\"https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu\"\u003ehere\u003c/a\u003e for instructions on how to set up a GPU, \u003ca href=\"https://www.kaggle.com/docs/notebooks\"\u003ehere\u003c/a\u003e for full documentation\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://databricks.com/product/faq/community-edition\"\u003eDatabricks Community Edition\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eNot exactly a Jupyter notebook, but a similar interface from Databricks\u003c/li\u003e\n\u003cli\u003eFree cloud Spark cluster functionality\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eCloud Instances/Containers\u003c/h3\u003e\n\n\u003cp\u003eSometimes you want to be able to run a full-fledged cloud computer, not just a notebook. With cloud instances, you can provision the necessary compute resources for completing essentially any task! You get root access to the file system and can run long-running scripts without overheating your personal computer. With Docker, you can even develop the code locally then deploy it online to speed up processing times.\u003c/p\u003e\n\n\u003cp\u003eThere are also some downsides of cloud instances to be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSimilar to cloud notebooks, paid cloud instances can get very \u003cstrong\u003eexpensive\u003c/strong\u003e. Pay particular attention to the amount of storage you are using, since a storage-specific solution might be a lot cheaper than a general-purpose cloud instance.\u003c/li\u003e\n\u003cli\u003eCloud instances require some \u003cstrong\u003esystems administration\u003c/strong\u003e skills. You'll likely need to configure access permissions and ports. Most containers are Linux-based so you'll need to be comfortable navigating and installing things using the terminal.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSome popular cloud instances include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/ec2/\"\u003eAWS EC2\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGo \u003ca href=\"https://aws.amazon.com/blogs/machine-learning/train-deep-learning-models-on-gpus-using-amazon-ec2-spot-instances/\"\u003ehere\u003c/a\u003e for instructions on training deep learning models with GPUs on EC2\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/compute/docs\"\u003eGoogle Cloud Compute Engine\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGo \u003ca href=\"https://cloud.google.com/ai-platform/training/docs/using-gpus\"\u003ehere\u003c/a\u003e for instructions on using GPUs for training models with Google Cloud Platform\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/en-us/azure/virtual-machines/\"\u003eAzure Virtual Machines\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eBecause this is made by Microsoft, they're one of the few places that offers Windows virtual machines\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oracle.com/cloud/\"\u003eOracle Cloud Infrastructure\u003c/a\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerous free tier\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCloud Storage\u003c/h2\u003e\n\n\u003cp\u003eIt's annoying to have huge data files taking up space on your laptop, and if you want to train your model in the cloud, your data also needs to be in the cloud. But for reasons related to hardware acceleration, it can get pretty expensive to store large datasets in general-purpose cloud services like an EC2 instance or a cloud VM. That's when cloud storage services become useful.\u003c/p\u003e\n\n\u003cp\u003eThere are many different kinds of cloud storage tools, but they fall roughly into three categories: \u003cstrong\u003efile storage\u003c/strong\u003e systems, cloud storage \u003cstrong\u003ebuckets\u003c/strong\u003e, and cloud \u003cstrong\u003edatabases\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eCloud File Storage\u003c/h3\u003e\n\n\u003cp\u003eThis type of cloud storage is probably most familiar to you already. Cloud file storage includes something like Dropbox or Google Drive, where files are stored in directories that can be navigated in a way that is similar to the file system on your local computer.\u003c/p\u003e\n\n\u003cp\u003eWhile there are professional-grade cloud tools for this such as \u003ca href=\"https://aws.amazon.com/efs/\"\u003eAWS Elastic File System (EFS)\u003c/a\u003e, \u003ca href=\"https://azure.microsoft.com/en-us/services/storage/files/\"\u003eAzure Files\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/filestore\"\u003eGoogle Cloud Filestore\u003c/a\u003e, the main takeaway you should have is the contrast between file storage and the storage approaches described below.\u003c/p\u003e\n\n\u003ch3\u003eCloud Storage Buckets\u003c/h3\u003e\n\n\u003cp\u003eAlso known as \u003cstrong\u003eobject storage\u003c/strong\u003e services, cloud storage buckets are great for storing raw files, e.g. folders full of images, CSVs, or JSONs. Unlike cloud file storage, files are not stored in directories. Instead, all data is stored in a \"flat\" system where it can be retrieved by name. This lack of hierarchy makes cloud storage buckets faster to use and more cost efficient than traditional file storage.\u003c/p\u003e\n\n\u003cp\u003eTypically these services are not free, although they are fairly cheap (2-5 cents per GB per month) and typically come with some free credits.\u003c/p\u003e\n\n\u003cp\u003eSome major providers of cloud storage buckets include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/s3/getting-started/\"\u003eAWS S3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cloud.google.com/storage/\"\u003eGoogle Cloud Storage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.microsoft.com/en-us/azure/storage/common/storage-introduction\"\u003eAzure Storage\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAWS S3 is the oldest and tends to have the most integration support with other platforms, although you may need to use Google storage if you're using other Google products or Azure storage if you're using other Azure products. Google Cloud Functions, for example, rely on source code being stored in Google Cloud Storage.\u003c/p\u003e\n\n\u003ch3\u003eCloud Databases\u003c/h3\u003e\n\n\u003cp\u003eDatabases are a familiar concept, but thus far we have mainly practiced using SQLite. If you're working with production-scale SQL data, it's best not to save it in a SQLite file but rather to store it on a database server.\u003c/p\u003e\n\n\u003cp\u003eMost likely your projects in this program will not require you to use a production-scale database, but this is an opportunity to practice if you want to prepare for on-the-job tasks.\u003c/p\u003e\n\n\u003cp\u003eSome major providers of cloud databases include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.heroku.com/postgres\"\u003eHeroku Postgres\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.mongodb.com/cloud/atlas\"\u003eMongoDB Atlas\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/rds/aurora/\"\u003eAWS Aurora\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/rds/\"\u003eAWS RDS\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we discussed the definition of \"cloud services\" and walked through several use cases. In summary, most cloud services can be described as either being used for \u003cem\u003ehardware acceleration\u003c/em\u003e, including cloud notebooks and cloud instances, and \u003cem\u003ecloud storage\u003c/em\u003e, including cloud file storage, cloud storage buckets, and cloud databases.\u003c/p\u003e","frontPage":false},{"exportId":"transfer-learning-recap","title":"Transfer Learning - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you learned how you can adapt pretrained models to improve the performance of neural networks when limited training data is available. While you specifically investigated CNNs and the VGG-19 model, these concepts are also applicable to other domains as well. For example, GloVe (Global Vectors for Word Representation) is a pretrained model that can be useful in a variety of natural language processing tasks.\u003c/p\u003e\n\n\u003cp\u003eRemember that the general process for transfer learning begins by taking a pretrained model like VGG-19 and freezing the weights so that they remain constant. From there, you can then append a standard densely connected classifier to perform the task at hand. In essence, the pretrained model acts as a form of feature engineering applied to the underlying dataset. \u003c/p\u003e\n\n\u003cp\u003eAfter the classifier is trained with the frozen pretrained model, a few of the top layers from the pretrained model can be unfrozen for fine tuning. Remember that you should only do this after training the classifier on top of the fully frozen model. Unfreezing parts of the pretrained model earlier is prone to overwriting any useful feature weights encoded in the pretrained model as there will be large gradients in forward and backward propagation passes until the densely connected layers converge to a stable solution. Also, remember that little is to be gained by unfreezing more than a few of the top layers from a pretrained model. Base layers of models such as VGG-19 will pick up very granular features such as colors or edges in image recognition. As such, these base layers are typically well formulated features across many domains. Unfreezing top layers has far more impact on tuning as these final layers often pick up domain specific features, so when adopting a model to a new problem domain such as predicting flower species instead of predicting animal kingdoms, these top layers can often be more impactful if retrained to the specific application.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you got an overview of transfer learning and how to adapt pretrained models. From here, you'll continue to learn about other neural network architectures and build upon your growing deep learning knowledge.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-transfer-learning-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-transfer-learning-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-transfer-learning-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"lecture-singular-value-decomposition-svd","title":"üé¨ Lecture: Singular Value Decomposition (SVD)","type":"WikiPage","content":"\u003cdiv style=\"padding: 56.25% 0 0 0; position: relative;\"\u003e\u003ciframe style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\" title=\"Singular Value Decomposition (SVD)\" src=\"https://player.vimeo.com/video/575551378?badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\u0026amp;h=bae89cb853\" allowfullscreen=\"allowfullscreen\" allow=\"autoplay; fullscreen; picture-in-picture\"\u003e\u003c/iframe\u003e\u003c/div\u003e\n\u003cp\u003e\n\n\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eIn this lecture, Greg Damico introduces the idea of Singular Value Decomposition or SVD. Topics discussed in this lecture include: what is SVD, the relationship between SVD and Eigendecomposition, the relationship between SVD and PCA, diagonalization, dimensionality reduction, least-squares problem, and optimizing problem.\u003c/p\u003e\n\u003cp\u003eThe repository for this lecture can be found here: \u003ca class=\"inline_disabled\" style=\"color: #3598db;\" href=\"https://github.com/flatiron-school/ds-singular_value_decomposition-kvo32\"\u003eSingular Value Decomposition (SVD) Lecture Repository\u003c/a\u003e\u003c/p\u003e","frontPage":false},{"exportId":"topic-39-lesson-priorities-live","title":"Topic 39 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 186px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eNetwork Evaluation and Regularization\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Tuning Neural Networks - Introduction\" href=\"pages/tuning-neural-networks-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-introduction\" data-api-returntype=\"Page\"\u003eTuning Neural Networks - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Regularization\" href=\"pages/tuning-neural-networks-with-regularization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-with-regularization\" data-api-returntype=\"Page\"\u003e\u003cstrong\u003eTuning Neural Networks with Regularization\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Regularization - Lab\" href=\"assignments/g44969ffff4b33b816b9daba862417b65\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12382\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks with Regularization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Normalization\" href=\"pages/tuning-neural-networks-with-normalization\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-with-normalization\" data-api-returntype=\"Page\"\u003eTuning Neural Networks with Normalization\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks with Normalization - Lab\" href=\"assignments/g3f1caffeac6631bd5eec966c32c523dd\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12384\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks with Normalization - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks from Start to Finish - Lab\" href=\"assignments/g499e8e49f89e304b98ba1a620123f8a3\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/assignments/12385\" data-api-returntype=\"Assignment\"\u003eTuning Neural Networks from Start to Finish - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 203px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eNetwork Evaluation and Regularization\u003c/em\u003e Lecture, Before \u003cem\u003eConvolutional Neural Networks\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Network Regularization and Evaluation Exit Ticket\" href=\"quizzes/g4298ef63270d7a1a95ee2a490732081d\"\u003eNetwork Regularization and Evaluation Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Convolutional Neural Networks\" href=\"pages/convolutional-neural-networks\"\u003eConvolutional Neural Networks\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Convolutional Neural Networks - Codealong\" href=\"assignments/g546a70919f77202cb729711ea35833d7\"\u003eConvolutional Neural Networks - Codealong\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Building a CNN from Scratch\" href=\"assignments/gc0c371179354c474eb62d3e35ada83d6\"\u003eBuilding a CNN from Scratch\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Visualizing Intermediate Activations\" href=\"assignments/g133398f3cf3addbcc4503103ffaa1031\"\u003eVisualizing Intermediate Activations\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Visualizing Activation Functions - Lab\" href=\"assignments/gcd231132357b7197c79a1dd8aa04b47c\"\u003eVisualizing Activation Functions - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center; height: 29px;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 80px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eConvolutional Neural Networks\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 41.8821%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.81268%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"CNNs Exit Ticket\" href=\"quizzes/g8714088b2a6bd1ad813141f7a91f909c\"\u003e\u003cstrong\u003eCNNs Exit Ticket\u003c/strong\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 41.8821%; height: 29px;\"\u003e\u003ca title=\"Tuning Neural Networks - Recap\" href=\"pages/tuning-neural-networks-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/tuning-neural-networks-recap\" data-api-returntype=\"Page\"\u003eTuning Neural Networks - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.81268%; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e\u003cspan style=\"color: #000000;\"\u003e3rd\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"convolutional-neural-networks","title":"Convolutional Neural Networks","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-convolutional-neural-networks\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eConvolutional Neural Networks (CNNs), build upon the fully connected neural networks you've seen to date. Since detailed images can have incredibly high dimensions based on the number of pixels, CNNs provide an alternative formulation for analyzing groups of pixels. Without the convolutional operation, fitting neural networks to medium to large images would be infeasible for all but the most powerful computers. For example, given a color image with 500 x 500 pixels, you would have 500 x 500 x 3 = 750,000 input features, \u003cimg class=\"equation_image\" title=\"(x_1,...,x_{750,000})\" src=\"/equation_images/(x_1,...,x_{750,000})\" alt=\"{\" data-equation-content=\"(x_1,...,x_{750,000})\"\u003e. \nFrom there, even having 2000 hidden units (3% of the input), in the first hidden layer, would result in roughly 1.5 billion parameters!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine what a convolution is, as it relates to CNNs \u003c/li\u003e\n\u003cli\u003eExplain how convolutions work using RGB images \u003c/li\u003e\n\u003cli\u003eDescribe what a pooling layer is in a neural network \u003c/li\u003e\n\u003cli\u003eExplain how padding works with convolution layers of a neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCNNs\u003c/h2\u003e\n\n\u003cp\u003eCNNs have certain features that identify patterns in images because of \"convolution operation\" including:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eDense layers learn global patterns in their input feature space\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eConvolution layers learn local patterns, and this leads to the following interesting features:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUnlike with densely connected networks, when a convolutional neural network recognizes a pattern in one region, these insights can be shared and applied to other regions.\u003c/li\u003e\n\u003cli\u003eDeeper convolutional neural networks can learn spatial hierarchies. A first layer will learn small local patterns, a second layer will learn larger patterns using features of the first layer patterns, etc. \u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBecause of these properties, CNNs are great for tasks like: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImage classification\u003c/li\u003e\n\u003cli\u003eObject detection in images\u003c/li\u003e\n\u003cli\u003ePicture neural style transfer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eBuilding CNNs in Keras\u003c/h2\u003e\n\n\u003cp\u003eBuilding a CNN in Keras is very similar to the previous neural networks that you've built to date. To start, you will initialize a sequential model as before and go on adding layers. However, rather then simply adding additional dense layers or dropouts between them, we will now start to investigate other potential layer architectures including convolutional layers.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/Image_158CNN.png\" alt=\"input image, convolutions, pooling, fully connected\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eThe Convolution Operation\u003c/h2\u003e\n\n\u003cp\u003eThe idea behind the convolutional operation is to detect complex building blocks, or features, that can aid in the larger task such as image recognition. For example, we'll detect vertical or horizontal edges present in the image. Let's look at what horizontal edge detection would look like: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/conv.png\" alt=\"one 5 by 5 grid, one 3 by 3 grid containing 1 1 1 0 0 0 -1 -1 -1\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is a simplified 5 x 5 pixel image (grayscale!). You use a so-called \"filter\" (denoted on the right) to perform a convolution operation. This particular filter operation will detect horizontal edges. The matrix in the left should have number in it (from 1-255, or let's assume we rescaled it to number 1-10). The output is a 3 x 3 matrix. (\u003cem\u003eThis example is for computational clarity, no clear edges\u003c/em\u003e)\u003c/p\u003e\n\n\u003cp\u003eIn Keras, function for the convolution step is \u003ccode\u003eConv2D\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe convolutional operation applies this filter (typically 3x3 or 5x5) to each possible 3x3 or 5x5 region of the original image. The graphic below demonstrates this process.  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/convolution-layer-a.png\" alt=\"animation of filter operation across an image to create a smaller matrix output\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://stanford.edu/%7Eshervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\"\u003egif courtesy of Stanford University\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003ePadding\u003c/h2\u003e\n\n\u003cp\u003eThere are some issues with using filters on images including: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eThe image shrinks with each convolution layer: you're throwing away information in each layer! For example:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStarting from a 5 x 5 matrix, and using a 3 x 3 matrix, you end up with a 3 x 3 image\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eStarting from a 10 x 10 matrix, and using a 3 x 3 matrix, you end up with a 8 x 8 image, etc. \u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe pixels around the edges are used much less in the outputs due to the filter   \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor example, if you apply 3x3 filters to a 5x5 image, the original 5x5 image contains 25 pixels, but tiling the 3x3 filter only has 9 possible locations. Here's the 4 of the 9 possible locations for the 3x3 filter on a 5x5 image:  \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_1.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_2.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_3.jpeg\" width=\"200\"\u003e\n\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-convolutional-neural-networks/master/images/5by5_3by3_4.jpeg\" width=\"200\"\u003e\u003c/p\u003e\n\n\u003cp\u003eFortunately, padding solves both of these problems! Just one layer of pixels around the edges preserves the image size when having a 3 x 3 filter. We can also use bigger filters, but generally the dimensions are odd!\u003c/p\u003e\n\n\u003cp\u003eSome further terminology regarding padding that you should be aware of includes:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\"Valid\" - no padding\u003c/li\u003e\n\u003cli\u003e\"Same\" - padding such that output is same as the input size\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eBy adding padding to our 5x5 image, (now a 6x6 image by adding a border of pixels) we can add padding so that each pixel of our original 5x5 image can be the center of a 3x3 convolution window filter.\u003c/p\u003e\n\n\u003ch2\u003eStrided convolutions\u003c/h2\u003e\n\n\u003cp\u003eAnother method to change the output of your convolutions is to change the stride. The stride is how the convolution filter is moved over the original image. In our above example, we moved the filter one pixel to the right starting from the upper left hand corner, and then began to do this again after moving the filter one pixel down. Alternatively, by changing the stride, we could move our filter by 2 pixels each time, resulting in a smaller number of possible locations for the filter.  \u003c/p\u003e\n\n\u003cp\u003eStrided convolutions are rarely used in practice but a good feature to be aware of for some models.\u003c/p\u003e\n\n\u003ch2\u003eConvolutions on RGB images\u003c/h2\u003e\n\n\u003cp\u003eInstead of 5 x 5 grayscale, imagine a 7 x 7 RGB image, which boils down to having a 7 x 7 x 3 tensor. (The image itself is compromised by a 7 by 7 matrix of pixels, each with 3 numerical values for the RGB values.) From there, you will need to use a filter that has the third dimension equal to 3 as well, let's say, 3 x 3 x 3 (a 3D \"cube\"). \u003c/p\u003e\n\n\u003cp\u003eThis allows you to detect horizontal edges in the blue channel.\u003c/p\u003e\n\n\u003cp\u003eThen, in each layer, you can convolve with several 3D filters. Afterwards, you stack every output of the result together, giving you a matrix of shape 5 x 5 x \u003ccode\u003enumber_of_filters\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eIf you think of it, the filter plays the same role as the w^{[1]} in our densely connected networks.\u003c/p\u003e\n\n\u003cp\u003eThe advantage is, while your image may be huge, the amount of parameters you have still only depends on how many filters you're using!\u003c/p\u003e\n\n\u003cp\u003eImagine 20 (3 x 3 x 3) --\u0026gt; 20 * 27 + a bias for each filter (1* 20) = 560 parameters.\u003c/p\u003e\n\n\u003cp\u003eNotation:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e = size of the filter\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"p^{[l]}\" src=\"/equation_images/p^{[l]}\" alt=\"{\" data-equation-content=\"p^{[l]}\"\u003e = padding\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\"s^{[l]}\" src=\"/equation_images/s^{[l]}\" alt=\"{\" data-equation-content=\"s^{[l]}\"\u003e = amount of stride\u003c/li\u003e\n\u003cli\u003e\u003cimg class=\"equation_image\" title=\" n_c^{[l]}\" src=\"/equation_images/%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_c^{[l]}\"\u003e = number of filters\u003c/li\u003e\n\u003cli\u003e\u003cp\u003efilter: \u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e x \u003cimg class=\"equation_image\" title=\"f^{[l]}\" src=\"/equation_images/f^{[l]}\" alt=\"{\" data-equation-content=\"f^{[l]}\"\u003e x \u003cimg class=\"equation_image\" title=\" n_c^{[l-1]}\" src=\"/equation_images/%20n_c^{[l-1]}\" alt=\"{\" data-equation-content=\" n_c^{[l-1]}\"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eInput = \u003cimg class=\"equation_image\" title=\" n_h^{[l-1]} * n_w^{[l-1]} * n_c^{[l-1]} \" src=\"/equation_images/%20n_h^{[l-1]}%20*%20n_w^{[l-1]}%20*%20n_c^{[l-1]}\" alt=\"{\" data-equation-content=\" n_h^{[l-1]} * n_w^{[l-1]} * n_c^{[l-1]} \"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eOutput = \u003cimg class=\"equation_image\" title=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \" src=\"/equation_images/%20n_h^{[l]}%20*%20n_w^{[l]}%20*%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \"\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHeight and width are given by:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"n_h^{[l]}= \\Bigr\\lfloor\\dfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\" src=\"/equation_images/n_h^{[l]}=%20%255CBigr%255Clfloor%255Cdfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1%255CBigr%255Crfloor\" alt=\"{\" data-equation-content=\"n_h^{[l]}= \\Bigr\\lfloor\\dfrac{n_h^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg class=\"equation_image\" title=\"n_w^{[l]}= \\Bigr\\lfloor\\dfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\" src=\"/equation_images/n_w^{[l]}=%20%255CBigr%255Clfloor%255Cdfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1%255CBigr%255Crfloor\" alt=\"{\" data-equation-content=\"n_w^{[l]}= \\Bigr\\lfloor\\dfrac{n_w^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\Bigr\\rfloor\"\u003e\u003c/p\u003e\n\n\u003cp\u003eActivations: \u003cimg class=\"equation_image\" title=\"a^{[l]}\" src=\"/equation_images/a^{[l]}\" alt=\"{\" data-equation-content=\"a^{[l]}\"\u003e is of dimension \u003cimg class=\"equation_image\" title=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \" src=\"/equation_images/%20n_h^{[l]}%20*%20n_w^{[l]}%20*%20n_c^{[l]}\" alt=\"{\" data-equation-content=\" n_h^{[l]} * n_w^{[l]} * n_c^{[l]} \"\u003e\u003c/p\u003e\n\n\u003ch2\u003ePooling layer\u003c/h2\u003e\n\n\u003cp\u003eThe last element in a CNN architecture (before fully connected layers as we have previously discussed in other neural networks) is the pooling layer. This layer is meant to substantially downsample the previous convolutional layers. The idea behind this is that the previous convolutional layers will find patterns such as edges or other basic shapes present in the pictures. From there, pooling layers such as Max pooling (the most common) will take a summary of the convolutions from a larger section. In practice, Max pooling (taking the max of all convolutions from a larger area of the original image) works better than average pooling as we are typically looking to detect whether a feature is present in that region. Downsampling is essential in order to produce viable execution times in the model training.\u003c/p\u003e\n\n\u003cp\u003eMax pooling has some important hyperparameters:\n- \u003cimg class=\"equation_image\" title=\"f\" src=\"https://learning.flatironschool.com/equation_images/f\" alt=\"{\" data-equation-content=\"f\"\u003e (filter size)\n- \u003cimg class=\"equation_image\" title=\"S\" src=\"https://learning.flatironschool.com/equation_images/S\" alt=\"{\" data-equation-content=\"S\"\u003e (stride)\u003c/p\u003e\n\n\u003cp\u003eCommon hyperparameters include: \u003ccode\u003ef=2\u003c/code\u003e, \u003ccode\u003es=2\u003c/code\u003e and \u003ccode\u003ef=3\u003c/code\u003e, \u003ccode\u003es=2\u003c/code\u003e, this shrinks the size of the representations.\u003c/p\u003e\n\n\u003cp\u003eIf a feature is detected anywhere in the quadrants, a high number will appear, so max pooling preserves this feature.\u003c/p\u003e\n\n\u003ch2\u003eFully Connected Layers in CNN\u003c/h2\u003e\n\n\u003cp\u003eOnce you have added a number of convolutional layers and pooling layers, you then will add fully connected (dense) layers as we did before in previous neural network models. This now allows the network to learn a final decision function based on these transformed informative inputs generating from the convolutional and pooling layers.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you learned about the basic concepts behind CNNs including their use cases and general architecture. In the upcoming lab, you'll begin to look at how you can build these models in Python using Keras.\u003c/p\u003e","frontPage":false},{"exportId":"parallel-and-distributed-computing-with-mapreduce","title":"Parallel and Distributed Computing with MapReduce","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-parallel-and-distributed-computing-with-mapreduce\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eMapReduce is a programming paradigm that enables the ability to scale across hundreds or thousands of servers for big data analytics. The underlying concept can be somewhat difficult to grasp, because this paradigm differs from the traditional programming practices. This lesson aims to present a simple yet intuitive account of MapReduce that we shall put into practice in upcoming labs. \u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eIn a nutshell, the term \"MapReduce\" refers to two distinct tasks. The first is the \u003cstrong\u003eMap\u003c/strong\u003e job, which takes one set of data and transforms it into another set of data, where individual elements are broken down into tuples \u003cstrong\u003e(key/value pairs)\u003c/strong\u003e, while the \u003cstrong\u003eReduce\u003c/strong\u003e job takes the output from a map as input and combines those data tuples into a smaller set of tuples.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eWe'll see this with help of some simple examples in this lesson.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain how the MapReduce paradigm works and how it differs from traditional programming approaches \u003c/li\u003e\n\u003cli\u003eExplain what is meant by distributed and parallel processing \u003c/li\u003e\n\u003cli\u003eUse MapReduce with a simple word count example \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eParallel and Distributed Processing\u003c/h2\u003e\n\n\u003cp\u003eThe MapReduce programming paradigm is designed to allow \u003cstrong\u003eparallel and distributed processing\u003c/strong\u003e  of large sets of data (also known as big data). MapReduce allows us to convert such big datasets into sets of \u003cstrong\u003etuples\u003c/strong\u003e as \u003cstrong\u003ekey:value\u003c/strong\u003e pairs, as we'll see shortly. These pairs are analogous to the data structures we saw with dictionaries and JSON files etc. These tuples are \u003cstrong\u003emapped\u003c/strong\u003e and \u003cstrong\u003ereduced\u003c/strong\u003e in a computational environment to allow distributed execution of complex tasks on a group (cluster) of interconnected computers. \u003c/p\u003e\n\n\u003cp\u003eSo in simpler terms, \u003cem\u003eMapReduce uses parallel distributed computing to turn big data into regular data.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's first see what we mean by parallel and distributed processing below. \u003c/p\u003e\n\n\u003ch3\u003eDistributed Processing Systems\u003c/h3\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eA distributed processing system is a group of computers in a network working in tandem to accomplish a task\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhen computers are in a distributed system, they do not share hard drive memory or processing memory; they communicate with one other through messages, which are transferred over a network. The individual computers in this network are referred to as \u003cstrong\u003enodes\u003c/strong\u003e. As you've seen before, computers can send requests as well as packets of data to one another.\u003c/p\u003e\n\n\u003cp\u003eThe two most common ways of organizing computers into a distributed system are the client-server system and peer-to-peer system.\u003c/p\u003e\n\n\u003cp\u003eThe client-server architecture has nodes that make requests to a central server. The server will then decide to accept or reject these requests and send additional methods out to the outer nodes.\u003c/p\u003e\n\n\u003cp\u003ePeer-to-peer systems allow nodes to communicate with one another directly without requiring approval from a server.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/types_of_network.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eParallel Processing Systems\u003c/h3\u003e\n\n\u003cp\u003eThese networks are useful for many applications all over the web, but they are generally ill-suited for dealing with the processing power required for very large sets of data and complex problems.\u003c/p\u003e\n\n\u003cp\u003eJust like in the workplace, whenever there is an extremely complex task, it is best to divide and conquer. In the world of big data, if the data is \"big\" enough, it is generally better to take the approach of splitting up the larger task into smaller pieces.\u003c/p\u003e\n\n\u003cp\u003eEven though individual processors are getting faster (remember \u003ca href=\"https://en.wikipedia.org/wiki/Moore%27s_law\"\u003eMoore's Law\u003c/a\u003e), they will never have the ability to keep up with the amount of data we are able to produce. The best solution computer scientists have developed has been to use the power of \u003cstrong\u003emultiple processors\u003c/strong\u003e to put them to the same task. When using a well-developed distributed system, multiple processors can accomplish tasks at a fraction of the time it would take for a single processor to accomplish. As noted in the picture below, if you can divide the work between multiple processors, everything will be more efficient. \u003c/p\u003e\n\n\u003cp\u003eWith parallel computing:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ea larger problem is broken up into smaller pieces\u003c/li\u003e\n\u003cli\u003eevery part of the problem follows a series of instructions\u003c/li\u003e\n\u003cli\u003eeach one of the instructions is executed simultaneously on different processors\u003c/li\u003e\n\u003cli\u003eall of the answers are collected from the small problems and combined into one final answer\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn the image below, you can see a simple example of a process being broken up and completed both sequentially and in parallel.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/parallel.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eOf course, not all problems can be parallelized, but there are some that are formally called \u003ca href=\"https://en.wikipedia.org/wiki/Embarrassingly_parallel\"\u003eembarrassingly parallel\u003c/a\u003e problems that require hardly any effort to ensure that a certain task is able to easily parallelizable. One example of something that would be embarrassingly parallelizable would be password cracking. Another example would be a movie production company trying to calculate the total profit they made from all of the movies they released in a given year. Let's think about all of the components that go into determining whether or not a movie is profitable.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003estory rights\u003c/li\u003e\n\u003cli\u003eproducer\u003c/li\u003e\n\u003cli\u003edirector\u003c/li\u003e\n\u003cli\u003ecast\u003c/li\u003e\n\u003cli\u003eproduction costs\u003c/li\u003e\n\u003cli\u003evisual effects\u003c/li\u003e\n\u003cli\u003emusic\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eand of course\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ebox office revenue\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eHere is what this would look like if it was calculated sequentially.\u003c/p\u003e\n\n\u003cp\u003eIf a movie studio was to compute each one it's movie's profits sequentially, it would take far more time than if it calculated each movie's profit and combined them in parallel.\u003c/p\u003e\n\n\u003cp\u003eHere is a diagram of what parallel processing looks like in action: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/parallel_movies_.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSo how can we make all these nodes communicate with one another? By using a programming paradigm called MapReduce!\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eMapReduce\u003c/strong\u003e is a software framework developed for processing datasets that qualify as \"Big Data\", in a \u003cstrong\u003edistributed and parallel\u003c/strong\u003e processing environment over several computers/nodes connected to each other as part of a \u003cstrong\u003ecluster\u003c/strong\u003e. It is a specific instance of the generalized split-apply-combine technique used to perform different data analyses.\u003c/p\u003e\n\n\u003cp\u003eWe will soon look into a simple example that is shown to introduce MapReduce,  \u003cstrong\u003eThe Word Count Problem\u003c/strong\u003e. The overall concept of MapReduce is very simple yet very powerful as:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eSomehow, all data can be mapped to \u003cstrong\u003ekey:value\u003c/strong\u003e pairs \u003c/li\u003e\n\u003cli\u003eKeys and values themselves can be of ANY data type \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFor our example, let's say a national association of zoos wants to determine the total number of species of animals in the country. After receiving responses from every zoo in the country, a data scientist receives a large file that has a different zoo located on each line with the species at that location. \u003c/p\u003e\n\n\u003cp\u003eHere are the first five zoos the data scientist reads over in the data document they receive:\u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eAnimals\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003elion tiger bear\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003elion giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egiraffe penguin\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epenguin lion giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekoala giraffe\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eLet's now look at how you would use the MapReduce framework in this simple word count example that could be generalized to much more data.\u003c/p\u003e\n\n\u003cp\u003eWe'll take a look at an image of this process in action and determine what's actually going on.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-parallel-and-distributed-computing-with-mapreduce/raw/master/images/word_count.png\"\u003e\u003c/p\u003e\n\n\u003ch3\u003e1. MAP Task (Splitting \u0026amp; Mapping)\u003c/h3\u003e\n\n\u003cp\u003eThe dataset that needs processing must first be transformed into \u003cstrong\u003ekey:value\u003c/strong\u003e pairs and split into fragments, which are then assigned to map tasks. Each computing cluster is assigned a number of map tasks, which are subsequently distributed among its nodes. In this example, let's assume that we are using 5 nodes (a server with 5 different workers).\u003c/p\u003e\n\n\u003cp\u003eFirst, split the data from one file or files into however many nodes are being used.\u003c/p\u003e\n\n\u003cp\u003eWe will then use the map function to create key:value pairs represented by:\u003cbr\u003e\n\u003cem\u003e{animal}\u003c/em\u003e , \u003cem\u003e{# of animals per zoo}\u003c/em\u003e \u003c/p\u003e\n\n\u003cp\u003eAfter processing of the original key:value pairs, some \u003cstrong\u003eintermediate\u003c/strong\u003e key:value pairs are generated. The intermediate key:value pairs are \u003cstrong\u003esorted by their key values\u003c/strong\u003e to create a new list of key:value pairs.\u003c/p\u003e\n\n\u003ch3\u003e2. Shuffling\u003c/h3\u003e\n\n\u003cp\u003eThis list from the map task is divided into a new set of fragments that sorts and shuffles the mapped objects into an order or grouping that will make it easier to reduce them. \u003cstrong\u003eThe number of these new fragments will be the same as the number of the reduce tasks\u003c/strong\u003e. \u003c/p\u003e\n\n\u003ch3\u003e3. REDUCE Task (Reducing)\u003c/h3\u003e\n\n\u003cp\u003eNow, every properly shuffled segment will have a reduce task applied to it. After the task is completed, the final output is written onto a file system. The underlying file system is usually HDFS (Hadoop Distributed File System). \u003c/p\u003e\n\n\u003cp\u003eIt's important to note that MapReduce will generally only be powerful when dealing with large amounts of data. When working with a small dataset, it will be faster not to perform operations in the MapReduce framework.\u003c/p\u003e\n\n\u003cp\u003eThere are two groups of entities in this process to ensuring that the MapReduce task gets done properly:\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eJob Tracker\u003c/strong\u003e: a \"master\" node that informs the other nodes which map and reduce jobs to complete\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eTask Tracker\u003c/strong\u003e: the \"worker\" nodes that complete the map and reduce operations\u003c/p\u003e\n\n\u003cp\u003eThere are different names for these components depending on the technology used, but there will always be a master node that informs worker nodes what tasks to perform.\u003c/p\u003e\n\n\u003cp\u003eA general pseudocode for a word count map and reduce tasks would look like \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# Count word frequency\n\u003c/span\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003emap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003edoc\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eword\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003edoc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esplit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"s\"\u003e' '\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eemit\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003eword\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ereduce\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ekey\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eemit\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003ekey\u003c/span\u003e \u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003esum\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e \u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSimilarly, we can discuss combining several MapReduce jobs in order to complete a given task. This means that once the first MapReduce job is finished, the output will become an input for the second MapReduce job and that output could be the final result (or fed into another MapReduce job). \u003c/p\u003e\n\n\u003cp\u003eLet's assume that we would like to extend the word count program and we would like to count all words in a given Twitter dataset. The first MapReduce will read our twitter data and extract the tweets' text. The second MapReduce is the word count Map-Reduce which will analyze the Twitter dataset and produce the statistics about it. So it is simply chaining together multiple jobs. \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eInputFile -\u0026gt; Map-1 -\u0026gt; Reduce-1 -\u0026gt; output-1 -\u0026gt; Map-2 - \u0026gt; Reduce-2 -\u0026gt; output-2 -\u0026gt; ... Map-x -\u0026gt; Reduce-x\u003c/strong\u003e  \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLater we are going to look at Apache Spark, which adds extra features of security and fault tolerance to its MapReduce offering, making it an industry standard. We will also look at programming for the aforementioned word count problem.\u003c/p\u003e\n\n\u003ch2\u003eAdditional Resources\u003c/h2\u003e\n\n\u003cp\u003eVisit following external links to read about the previous descriptions and examples in more detail. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.tutorialspoint.com/map_reduce/map_reduce_introduction.htm\"\u003eMapReduce Introduction\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.guru99.com/introduction-to-mapreduce.html\"\u003eWhat is MapReduce? How it Works\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we looked at how MapReduce allows a programming paradigm quite different than traditional programming practices, yet very powerful and effective towards processing large amounts of data.\u003c/p\u003e","frontPage":false},{"exportId":"introduction-to-regular-expressions","title":"Introduction to Regular Expressions","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-regular-expressions\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-regular-expressions\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-regular-expressions/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll learn about how we can use \u003cstrong\u003e\u003cem\u003eRegular Expressions\u003c/em\u003e\u003c/strong\u003e for pattern matching and filtering when working with text data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIdentify common use cases where regular expressions are useful \u003c/li\u003e\n\u003cli\u003eCreate regex code to capture meaningful patterns found in text \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat Are Regular Expressions?\u003c/h2\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eRegular Expressions\u003c/em\u003e\u003c/strong\u003e are a type of pattern that describe some text. We can use these regular expressions to quickly match patterns and filter through text documents. Regular Expressions (or regex, for short) are an important tool anytime we need to pull information from a larger text document without manually reading the entire thing. For data scientists, regex is extremely useful for data gathering. With regex, we can quickly scrape webpages by using regex to search through the html and find the info needed. \u003c/p\u003e\n\n\u003ch3\u003eUse Cases for NLP\u003c/h3\u003e\n\n\u003cp\u003eRegex is especially useful for Natural Language Processing. By definition, just about any text document you work with on an NLP task is going to be one that contains a large amount of text. One of the more common NLP-specific use cases for regex is to use regex during the tokenization stage to define the rules for where we should split strings into separate tokens. As an example, NLTK's basic \u003ccode\u003eword_tokenize()\u003c/code\u003e function would split a word that contains an apostrophe into 3 separate tokens -- \u003ccode\u003e'they're'\u003c/code\u003e gets broken into \u003ccode\u003e[\"they\", \"'\", \"re\"]\u003c/code\u003e. This is because the word tokenizer has instructions to just grab sequences of letters as the basic tokens, and an apostrophe isn't a letter. When preprocessing text data, it's quite common to use some small regex patterns to create a more intelligent tokenization scheme to avoid problems like this, so that our tokenizer treats words like \u003ccode\u003e'they're'\u003c/code\u003e as a single token. \u003c/p\u003e\n\n\u003ch2\u003eCreating Basic Patterns\u003c/h2\u003e\n\n\u003cp\u003eRegex is only as good as the \u003cstrong\u003e\u003cem\u003ePatterns\u003c/em\u003e\u003c/strong\u003e we create. We can use these patterns to find, or to replace text. There are many, many things we can do with regex, and covering them all is outside the scope of this lesson. Instead, we'll just focus on some of the more useful, basic patterns that allow us to begin using regex to work with text data. \u003c/p\u003e\n\n\u003cp\u003eLet's take a look at a basic regex pattern, to get a feel for what they look like. \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ere\u003c/span\u003e\n\u003cspan class=\"n\"\u003esentence\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'he said that she said \"hello\".'\u003c/span\u003e\n\u003cspan class=\"n\"\u003epattern\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e'he'\u003c/span\u003e\n\u003cspan class=\"n\"\u003ep\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ere\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nb\"\u003ecompile\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esentence\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ep\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efindall\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"c1\"\u003e# Output will be ['he', 'he, 'he']\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe define a pattern by a Python string. We can then use the regular expressions library, \u003ccode\u003ere\u003c/code\u003e, to compile this pattern. Once we have a compiled pattern, we just need to pass in a string and the pattern will find every instance of that pattern in the string. \u003c/p\u003e\n\n\u003cp\u003eFor people new to regex, the results from the pattern above might be surprising at first. The pattern successfully matches the word 'he', but it also matches the letters 'he' that are found inside of the words 'she' and 'hello'.  Subsequences inside of larger sequences are fair game to regex. If we just wanted to match the word 'he', we would need to specify that the pattern needs to start and end with a space, or use of \u003cstrong\u003e\u003cem\u003eanchors\u003c/em\u003e\u003c/strong\u003e for things like word boundaries. \u003c/p\u003e\n\n\u003ch2\u003eRanges, Groups, and Quantifiers\u003c/h2\u003e\n\n\u003cp\u003eObviously, we don't want to have to explicitly type every valid match for any search into our pattern. That would defeat the purpose. Luckily, we don't have to type every possible uppercase letter to match on uppercase letters. Instead, we can use a \u003cstrong\u003e\u003cem\u003eRange\u003c/em\u003e\u003c/strong\u003e such as \u003ccode\u003e[A-Z]\u003c/code\u003e. This will match any uppercase letter. Ranges are always inside of square brackets. We can put many things inside of ranges at the same time, and regex will match on any of them. For instance, if we wanted to find any uppercase letter, lowercase letter, or digit, we could use \u003ccode\u003e[A-Za-z0-9]\u003c/code\u003e. \u003c/p\u003e\n\n\u003ch3\u003eCharacter Classes\u003c/h3\u003e\n\n\u003cp\u003eCharacter classes are a special case of ranges. Since it's quite a common task to use ranges to do things like match on words or numbers, regex actually includes character classes as a shortcut. For instance, we could use \u003ccode\u003e\\d\u003c/code\u003e to match any digit -- this is equivalent to using \u003ccode\u003e[0-9]\u003c/code\u003e. We could also use \u003ccode\u003e\\w\u003c/code\u003e to match on any word. In the same vein, we can use \u003ccode\u003e\\D\u003c/code\u003e to get anything that \u003cem\u003eisn't\u003c/em\u003e a digit, or \u003ccode\u003e\\W\u003c/code\u003e to match on everything that isn't a word. There are a few other types of character classes as well. For a full list, check out the cheat sheet below!\u003c/p\u003e\n\n\u003ch3\u003eGroups and Quantifiers\u003c/h3\u003e\n\n\u003cp\u003eGroups are kind of like ranges, but they specify an exact pattern to match on. Groups are denoted by parentheses. Whereas \u003ccode\u003e[A-Z0-9]\u003c/code\u003e matches on any uppercase letter or any digit, \u003ccode\u003e(A-Z0-9)\u003c/code\u003e will only match on the sequence \u003ccode\u003e'A-Z0-9'\u003c/code\u003e exactly. This becomes much more useful when paired with \u003cstrong\u003e\u003cem\u003eQuantifiers\u003c/em\u003e\u003c/strong\u003e, which allows us to specify how many times a group should happen in a row. If we want to specify an exact number of times, we can use curly braces. For instance, a group followed by \u003ccode\u003e{3}\u003c/code\u003e will only match on patterns that have that group repeated exactly 3 times. The most common quantifiers are usually:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e*\u003c/code\u003e (0 or more times)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e+\u003c/code\u003e (1 or more times)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e?\u003c/code\u003e (0 or 1 times)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn this way, we can fill a grouping with any pattern, tell and specify the number of times we can expect to see that pattern. When we include things like ranges, groupings, and quantifiers together, it becomes easy to write a pattern that can match complex things, like email addresses -- take a look at the example provided below, and see if you can figure out how it works!\u003c/p\u003e\n\n\u003cp\u003e\u003ccode\u003e'([A-Za-z]+)@([A-Za-z]+)\\.com'\u003c/code\u003e \u003c/p\u003e\n\n\u003cp\u003eThis pattern matches basic email addresses like '\u003ca href=\"mailto:joe@gmail.com\"\u003ejoe@gmail.com\u003c/a\u003e', but not '\u003ca href=\"mailto:john.doe@gmail.com\"\u003ejohn.doe@gmail.com\u003c/a\u003e', or '\u003ca href=\"mailto:joe@stanford.edu\"\u003ejoe@stanford.edu\u003c/a\u003e'. Take a look at the pattern again -- how would you need to modify the pattern in order for it to match either of those, as well?\u003c/p\u003e\n\n\u003ch2\u003eAlways Keep A Cheat Sheet Handy\u003c/h2\u003e\n\n\u003cp\u003eRegex is confusing, but it gets easier. With that being said, don't worry about trying to memorize all of the different symbols and metacharacters. Instead, focus on how patterns work, and just look up the symbols when you need them. The internet is filled with great regex cheatsheets. Here's an easy one to keep on hand for future reference:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-introduction-to-regular-expressions/master/images/regex_cheat_sheet.png\" alt=\"regex cheat sheet\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about what regular expressions are, how they are used in NLP for specific tasks, and some common patterns and tools in regex. \u003c/p\u003e","frontPage":false},{"exportId":"feature-engineering-for-text-data","title":"Feature Engineering for Text Data","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-feature-engineering-for-text-data\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-feature-engineering-for-text-data\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-feature-engineering-for-text-data/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll examine some common approaches to feature engineering for text data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what stop words are and why they are frequently removed \u003c/li\u003e\n\u003cli\u003eExplain stemming and lemmatization\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eDefine bigrams and n-grams \u003c/li\u003e\n\u003cli\u003eDefine mutual information in the context of NLP \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eCommon Approaches to NLP Feature Engineering\u003c/h2\u003e\n\n\u003cp\u003eAs you've likely noticed by now, working with text data comes with \u003cstrong\u003e\u003cem\u003ea lot\u003c/em\u003e\u003c/strong\u003e of ambiguity. When all we start with is an arbitrarily-sized string of words, there's no clear answer as to what sorts of features we should engineer, or even where we should start! The goal of this lesson is to provide a framework for working with text data, and help us figure out exactly what sorts of features we should create when working with text data. \u003c/p\u003e\n\n\u003cp\u003eIn this lesson, we'll focus on the following topics:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eStopword Removal\u003c/li\u003e\n\u003cli\u003eFrequency Distributions\u003c/li\u003e\n\u003cli\u003eStemming and Lemmatization\u003c/li\u003e\n\u003cli\u003eBigrams, N-grams, and Mutual Information Score\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eRemoving Stop Words\u003c/h2\u003e\n\n\u003cp\u003eWhen working with text data, one of the first steps to try is to remove the \u003cstrong\u003e\u003cem\u003eStop Words\u003c/em\u003e\u003c/strong\u003e from the text. One common feature of text data (regardless of language!) is the inclusion of stop words for grammatical structure. Words such as \"a\", \"and\", \"but\", and \"or\" are examples of stop words. While a sentence would be both grammatically incorrect and hard to understand without them, from a modeling standpoint, stop words provide little to no actual value. If we create a \u003cstrong\u003e\u003cem\u003eFrequency Distribution\u003c/em\u003e\u003c/strong\u003e to see the number of times each word is used in a corpus, we'll almost always find that the top spots are dominated by stop words, which tell us nothing about the actual content of the corpus. Removing stop words allows us to reduce the overall dimensionality of our dataset (which is always a good thing), while also distilling the overall vocabulary of our bag-of-words down only to the words that really matter. \u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eNLTK\u003c/em\u003e makes it extremely easy to remove stopwords. The library includes a full corpus of all stopwords for all the languages NLTK supports. Since we usually only want the stopwords relevant to the language our text data is in, NLTK even makes it easy to filter out the unneeded stop words and grab only the ones that pertain to our problem. \u003c/p\u003e\n\n\u003cp\u003eThe following example shows how we can get all the stopwords for English from NLTK:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk.corpus\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords\u003c/span\u003e\n\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003estring\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# Get all the stop words in the English language\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewords\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'english'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# It is generally a good idea to also remove punctuation\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Now we have a list that includes all english stopwords, as well as all punctuation\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"nb\"\u003elist\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003estring\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epunctuation\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce we have a list of stopwords, we can easily remove them from our text data after we've tokenized our data. Recall that we can easily tokenize text data using NLTK's \u003ccode\u003eword_tokenize()\u003c/code\u003e function. Once we have a list of word tokens, all we need to do is use a list comprehension, and omit any tokens that can be found in our stopwords list.  For example:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eword_tokenize\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eword_tokenize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esome_text_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# It is usually a good idea to lowercase all tokens during this step, as well\n\u003c/span\u003e\u003cspan class=\"n\"\u003estopped_tokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ew\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elower\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ew\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003etokens\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ew\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003estopwords_list\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eFrequency Distributions\u003c/h2\u003e\n\n\u003cp\u003eOnce we have tokenized our data and removed all the stop words, the next step is usually to explore our text data through a \u003cstrong\u003e\u003cem\u003eFrequency Distribution\u003c/em\u003e\u003c/strong\u003e. This is just a fancy way of saying that we create a histogram that tells us the total number of times each word is used in a given corpus. \u003c/p\u003e\n\n\u003cp\u003eOnce we have tokenized our text data, we can use NLTK to easily create a frequency distribution using \u003ccode\u003enltk.FreqDist()\u003c/code\u003e. A frequency distribution is analogous to a Python dictionary, with a few more bells and whistles attached to make it easier to use for NLP tasks. Each key is a word token, and each value is the corresponding number of times that token appeared in the tokenized corpus given to the \u003ccode\u003eFreqDist\u003c/code\u003e object at instantiation. \u003c/p\u003e\n\n\u003cp\u003eWe can easily filter a \u003ccode\u003eFreqDist()\u003c/code\u003e object to see the most common words by using the \u003ccode\u003e.most_common()\u003c/code\u003e built-in method, as seen below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e  \u003cspan class=\"nn\"\u003enltk\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eFreqDist\u003c/span\u003e\n\u003cspan class=\"n\"\u003efreqdist\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eFreqDist\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etokens\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# get the 200 most common words \n\u003c/span\u003e\u003cspan class=\"n\"\u003emost_common\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efreqdist\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emost_common\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce we have the most common words, we can easily use this to filter out the text and reduce the dimensionality of particularly large datasets, as needed. \u003c/p\u003e\n\n\u003ch2\u003eStemming and Lemmatization\u003c/h2\u003e\n\n\u003cp\u003eConsider the words 'run', 'running', 'ran', and 'runs'. If we create a basic frequency distribution, each of these words will be treated as a separate token. After all, they are different words. However, we know that they pretty much mean the same thing. Counting these words as individual separate tokens can sometimes hurt our model by needlessly increasing dimensionality, and hiding important information from our model. Although we instinctively know that those four words are all talking about the same action, our model will default to thinking that they are four completely different concepts. The way we deal with this is to remove suffixes through techniques such as \u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003ePeople often get stemming and lemmatization confused, because they are extremely similar. They generally accomplish the same task, but they use different means to do so. \u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eStemming\u003c/em\u003e\u003c/strong\u003e follows a predetermined set of rules to reduce a word to its \u003cem\u003estem\u003c/em\u003e.  Words like 'running' and 'runs' will be reduced down to 'run', because the stemmer contains rules that understands how to deal with suffixes such as '-ing' and '-s'. The best stemmer currently available is the \u003cstrong\u003e\u003cem\u003ePorter Stemmer\u003c/em\u003e\u003c/strong\u003e. For code samples demonstrating how to use it, check out NLTK's documentation for the \u003ca href=\"http://www.nltk.org/howto/stem.html\"\u003ePorter Stemmer\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eLemmatization\u003c/em\u003e\u003c/strong\u003e differs from stemming in that it reduces each word down to a linguistically valid \u003cstrong\u003e\u003cem\u003elemma\u003c/em\u003e\u003c/strong\u003e, or root word. It does this through stored linguistic mappings. Lemmatization is generally more complex, but also more accurate. This is because the rules that guide things like the Porter Stemmer are good, but far from perfect. For example, stemmers commonly deal with the suffix \u003ccode\u003e-ed\u003c/code\u003e by just  dropping it from the word. This usually works, until it runs into an edge case like the word 'agreed'. When stemmed, 'agreed' becomes 'agre'. Lemmatization does not make this mistake, because it contains a mapping for the word that tells it what 'agreed' should be reduced down to. Generally, most lemmatizers make use of the famous \u003cstrong\u003e\u003cem\u003eWordNet\u003c/em\u003e\u003c/strong\u003e lexical database. \u003c/p\u003e\n\n\u003cp\u003eNLTK makes it quite easy to make use of lemmatization, as demonstrated below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003enltk.stem.wordnet\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eWordNetLemmatizer\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eWordNetLemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'feet'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# foot\n\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elemmatize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'running'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"c1\"\u003e# run\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eBigrams and Mutual Information Score\u003c/h2\u003e\n\n\u003cp\u003eAnother alternative to tokenization is to instead create \u003cstrong\u003e\u003cem\u003eBigrams\u003c/em\u003e\u003c/strong\u003e out of the text. A bigram is just a pair of adjacent words, treated as a single unit. \u003c/p\u003e\n\n\u003cp\u003eConsider the sentence \"the dog played outside\". If we created bigrams out of this sentence, we would get \u003ccode\u003e('the', 'dog'), ('dog', 'played'), ('played', 'outside')\u003c/code\u003e. From a modeling perspective, this can be quite useful, because sometimes pairs of words are greater than the sum of their parts. Note that bigrams are just a special case of \u003cstrong\u003e\u003cem\u003en-grams\u003c/em\u003e\u003c/strong\u003e -- we can choose any number of words for a sequence. Alternatively, it's quite common to create n-grams at the character level, rather than the word level. \u003c/p\u003e\n\n\u003cp\u003eOne handy feature of bigrams is that we can apply a frequency filter to only keep bigrams that show up more than a set number of times. In this way, we can get rid of all bigrams that only occur because of random chance, and keep the bigrams that must mean something, because they occur together multiple times. How strict your frequency filter should be depends on a number of factors, and generally, it's something you'll have to experiment with to get right. However, most experts tend to apply a minimum frequency filter of 5. \u003c/p\u003e\n\n\u003cp\u003eAnother way we can make use of bigrams is to calculate their \u003cstrong\u003e\u003cem\u003ePointwise Mutual Information Score\u003c/em\u003e\u003c/strong\u003e. This is a statistical measure from information theory that generally measures the mutual dependence between two words. In plain english, this measures how much information the bigram itself contains by computing the dependence between the two words in the bigram. For instance, the bigram \u003ccode\u003e('San', 'Francisco')\u003c/code\u003e would likely have a high mutual information score, because when these tokens appear in the text, it is highly likely that they appear together, and unlikely that they appear next other words. \u003c/p\u003e\n\n\u003cp\u003eIn practice, you don't need to worry too much about how to calculate mutual information, because NLTK provides an easy way to do this for us. We'll explore this in detail in the next lab. Instead, your main takeaway on this topic should be that mutual information scores are a type of feature that you can engineer for text data that may provide good information for you when it comes to exploring the text data or fitting a model to it. \u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we learned about various types of feature engineering we can perform on text data, and what each one means!\u003c/p\u003e","frontPage":false},{"exportId":"exploring-time-series-data-introduction","title":"Exploring Time Series Data - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you will learn about working with an important and ever-present type of data: time series! Stock market prices, weather, and economic indicators like GDP are a few examples of time series data.\u003c/p\u003e\n\n\u003ch2\u003eTime Series Data\u003c/h2\u003e\n\n\u003cp\u003e\"Time series\" data refers to datasets where the progress of time is an important dimension in the dataset. For example, working with the changes in stock prices, oil flow through a pipeline or even climate data over time requires an understanding of how to work with time series data. We introduce the concept of time series data, look at how to manage and visualize time series data, introduce the types of trends and the idea of \"time series decomposition\". In the next section, we'll introduce techniques for modeling time series data.\u003c/p\u003e\n\n\u003ch3\u003eIntroduction to Time Series\u003c/h3\u003e\n\n\u003cp\u003eWe start by importing daily minimum temperatures for Melbourne, Australia and introduce the importance of using dates as index values when importing time series data into Pandas. We then go through how to downsample and upsample a dataset and show some of the built-in methods for easily selecting and slicing time series data. We also provide an introduction to some of the most common plots for time series such as a line plot and a dot plot, and approaches to grouping and visualizing time series data.\u003c/p\u003e\n\n\u003cp\u003eWe also introduce the use of time series histograms and density plots for visualizing the distribution of the values without considering the times at which the values were measured and suggest time series box and whisker plots on a per-year basis to get a sense of trends over time. Finally, we introduce time series heat maps which can be a great way of getting a sense of how time series data changes across a couple of dimensions (e.g. month to month and year to year).\u003c/p\u003e\n\n\u003ch3\u003eTypes of Trends\u003c/h3\u003e\n\n\u003cp\u003eBasic regression tests are often not capable of capturing and predicting time-dependent patterns, so we introduce the concept of trends and stationarity, and explain the Dickey-Fuller test for performing statistical testing for time series stationarity.\u003c/p\u003e\n\n\u003ch3\u003eRemoving Trends\u003c/h3\u003e\n\n\u003cp\u003eMost time series modeling techniques assume stationarity, so we look at some of the techniques available for removing (or reducing) trends and/or seasonality using techniques such as a log transformation, rolling means, and differencing.\u003c/p\u003e\n\n\u003ch3\u003eTime Series Decomposition\u003c/h3\u003e\n\n\u003cp\u003eFinally, we end the section by introducing the concept of decomposition - another approach to removing trends and seasonality from a time series dataset.\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eThis section will provide you with the foundational knowledge for loading and working with time series data, so you'll have the skills required to start to perform time series modeling!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-time-series-section-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-time-series-section-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-time-series-section-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"short-video-sklearn-to-pyspark","title":"Short Video: sklearn to pyspark","type":"WikiPage","content":"\u003cdiv style=\"padding:62.5% 0 0 0;position:relative;\"\u003e\u003ciframe src=\"https://player.vimeo.com/video/713814441?h=fdecdbfde4\u0026amp;badge=0\u0026amp;autopause=0\u0026amp;player_id=0\u0026amp;app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen=\"\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"one-hot_encoding_phase2_gd\"\u003e\u003c/iframe\u003e\u003c/div\u003e","frontPage":false},{"exportId":"amazon-web-services-recap","title":"Amazon Web Services - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAWS is a \u003cstrong\u003e\u003cem\u003eCloud-Computing Platform\u003c/em\u003e\u003c/strong\u003e which we can use for a variety of use cases in data science.\u003c/li\u003e\n\u003cli\u003eIn this section, we learned about how to sign up for AWS, and how to make sure that we have the right region selected when working in AWS.\u003c/li\u003e\n\u003cli\u003eAmazon has centralized all of the major data science services inside \u003cstrong\u003e\u003cem\u003eAmazon SageMaker\u003c/em\u003e\u003c/strong\u003e. SageMaker provides numerous services for things such as:\n\n\u003cul\u003e\n\u003cli\u003eData Labeling\u003c/li\u003e\n\u003cli\u003eCloud-based Notebooks\u003c/li\u003e\n\u003cli\u003eTraining and Model Tuning\u003c/li\u003e\n\u003cli\u003eInference\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWe can set up our own models, or use the preexisting models provided by AWS. Similarly, we can set up our own inference endpoints, or make use of preexisting endpoints created by AWS. \u003c/li\u003e\n\u003cli\u003eCreating our own endpoint requires us to use a Docker instance, as we saw in the previous codealong. Much of the work required to create an endpoint for our own model is boilerplate, and we can use it again and again across multiple projects. \u003c/li\u003e\n\u003c/ul\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-productionizing-machine-learning-models-section-recap\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-productionizing-machine-learning-models-section-recap\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-productionizing-machine-learning-models-section-recap/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"topic-31-lesson-priorities-live","title":"Topic 31 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u003cspan style=\"font-size: 24pt;\"\u003eWelcome to Phase 4!\u003c/span\u003e\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 101.369%; height: 307px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003ePCA\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA - Introduction\" href=\"pages/pca-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/pca-introduction\" data-api-returntype=\"Page\"\u003ePCA - Introduction\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Unsupervised Learning\" href=\"pages/unsupervised-learning\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/unsupervised-learning\" data-api-returntype=\"Page\"\u003eUnsupervised Learning\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"The Curse of Dimensionality\" href=\"pages/the-curse-of-dimensionality\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/the-curse-of-dimensionality\" data-api-returntype=\"Page\"\u003eThe Curse of Dimensionality\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Curse of Dimensionality - Lab\" href=\"assignments/g27ff2fdc813a820fe3664cf8e0538f87\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187103\" data-api-returntype=\"Assignment\"\u003eCurse of Dimensionality - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"PCA in scikit-learn\" href=\"assignments/gc0f03e96ae12b9559a73a7a051856f69\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187135\" data-api-returntype=\"Assignment\"\u003ePCA in scikit-learn\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA in scikit-learn - Lab\" href=\"assignments/g62781b0f81600caf7cf0ef404029b642\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187136\" data-api-returntype=\"Assignment\"\u003ePCA in scikit-learn - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Integrating PCA in Pipelines - Lab\" href=\"assignments/g9f909bbb881f8a8f09562043a774c457\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187112\" data-api-returntype=\"Assignment\"\u003eIntegrating PCA in Pipelines - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA and Digital Image Processing\" href=\"assignments/g565911fd864b7ec0428d04864ab03532\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187132\" data-api-returntype=\"Assignment\"\u003ePCA and Digital Image Processing\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003csup\u003e1\u003c/sup\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA and Digital Image Processing - Lab\" href=\"assignments/g9e3a49e6940910d53bc3684917edf480\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187133\" data-api-returntype=\"Assignment\"\u003ePCA and Digital Image Processing - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003csup\u003e1\u003c/sup\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA Background: Covariance Matrix and Eigendecomposition\" href=\"assignments/g228826ed11f4a16c8e008a66f71ae8d1\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187134\" data-api-returntype=\"Assignment\"\u003ePCA Background: Covariance Matrix and Eigendecomposition\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Performing Principal Component Analysis\" href=\"assignments/g6747449b9e6df2c0c494613e6764ddf7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187137\" data-api-returntype=\"Assignment\"\u003ePerforming Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Performing Principal Component Analysis - Lab\" href=\"assignments/g5977d47bef596d1748bef4a87eeec33a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187138\" data-api-returntype=\"Assignment\"\u003ePerforming Principal Component Analysis - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Principal Component Analysis\" href=\"quizzes/g3edf2c8c948b9f818582eb3cc62d6ce0\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30676\" data-api-returntype=\"Quiz\"\u003eQuiz: Principal Component Analysis\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003csup\u003e1\u003c/sup\u003eThese two lessons use PCA as part of a supervised learning process with SVM. If you haven't gotten to going through the SVM lessons don't worry about the specifics of the algorithm.\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.808%; height: 86px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003ePCA\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003cth style=\"width: 35.9709%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 6.66307%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"Short Video: Solving an Eigenvalue Problem\" href=\"pages/short-video-solving-an-eigenvalue-problem\" data-api-endpoint=\"pages/short-video-solving-an-eigenvalue-problem?module_item_id=mastercourse_15802_382_3377812da0221f6c1688458fea6a2c96\" data-api-returntype=\"Page\"\u003eShort Video: Solving an Eigenvalue Problem\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"PCA Exit Ticket\" href=\"quizzes/g0ce7341539dd4023f20501b0ece6ef8e\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30659\" data-api-returntype=\"Quiz\"\u003ePCA Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\" href=\"quizzes/gd4bb2a176d75638f44ca8a45af7b753e\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30662\" data-api-returntype=\"Quiz\"\u003e‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003csup\u003e2\u003c/sup\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 29px;\"\u003e\n\u003ctd style=\"width: 35.9709%; height: 29px;\"\u003e\u003ca title=\"PCA - Recap\" href=\"pages/pca-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/pca-recap\" data-api-returntype=\"Page\"\u003ePCA - Recap\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 6.66307%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;Low priority\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e\u003csup\u003e2\u003c/sup\u003eCumulative labs may be used for pairing exercises and might not be published yet; contact your instructor if you have questions\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"context-free-grammars-and-pos-tagging","title":"Context-Free Grammars and POS Tagging","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll explore the concept of context-free grammars, and the role they play in linguistics and NLP, particularly in relation to part-of-speech tagging.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe how you might manually create rules related to context-free grammar \u003c/li\u003e\n\u003cli\u003eDefine context-free grammars \u003c/li\u003e\n\u003cli\u003eExplain parts of speech (POS) tagging, and why it is important in NLP \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is a Context-Free Grammar?\u003c/h2\u003e\n\n\u003cp\u003eConsider the following sentence: \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"Colorless green ideas sleep furiously.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis is a sentence dreamed up by the famous linguist \u003ca href=\"https://en.wikipedia.org/wiki/Noam_Chomsky\"\u003eNoam Chomsky\u003c/a\u003e. This sentence, while correct at the \u003cstrong\u003e\u003cem\u003egrammatical\u003c/em\u003e\u003c/strong\u003e or \u003cstrong\u003e\u003cem\u003esyntactic\u003c/em\u003e\u003c/strong\u003e level, is just a bunch of nonsense when we consider it at the \u003cstrong\u003e\u003cem\u003esemantic\u003c/em\u003e\u003c/strong\u003e level. The sentence follows all the proper rules for a sentence in English, although in reality, it's complete nonsense. This was one of Chomsky's big ideas -- that speech contains an underlying \"deep structure\" that we recognize, regardless of the actual content of the sentence. We don't need any context about what the sentence is actually about to determine if the grammar is correct -- hence the name, \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e, which we'll refer to as 'CFG' for short, for the remainder of this lesson. \u003c/p\u003e\n\n\u003cp\u003eIn order to understand CFGs, we first need to back up and gain a little background knowledge about linguistics. According to linguistics, there are five different levels of language:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/new_LevelsOfLanguage-Graph.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen talking about CFGs, we're focusing on the \u003cstrong\u003e\u003cem\u003esyntactic level\u003c/em\u003e\u003c/strong\u003e. This level worries only about the structure of the sentence, not the informational content. \u003c/p\u003e\n\n\u003cp\u003eSo why do CFGs matter to us? For starters, they are an important part of computer science as a whole, as any code we write gets fed through a parser to determine what we want the computer to actually do. For NLP specifically, they are important because they describe a way that we can write a grammar to interpret sentences at the syntactic level. This is an approach that can be used when we want to generate \u003cstrong\u003e\u003cem\u003ePart-Of-Speech (POS) Tags\u003c/em\u003e\u003c/strong\u003e. Consider the word \"run\". This word can be interpreted as either a noun or a verb. As a noun, we may be talking about the concept of going for a jog, or a run scored in a baseball game. As a verb, we may be talking about the action of running. On its own, we don't know this. Part of the way we know which meaning to interpret for the word is our understanding of where the word fits into the sentence, and the part of speech it occupies in that sentence -- we implicitly recognize that the sentence \"I run in the mornings\" uses run as a verb, while the sentence \"The Yankees scored a run\" uses it as a noun, all based on it's placement in the sentence. \u003c/p\u003e\n\n\u003cp\u003eThis brings us to the concept of \u003cstrong\u003e\u003cem\u003eParse Trees\u003c/em\u003e\u003c/strong\u003e. \u003c/p\u003e\n\n\u003ch2\u003eParse Trees and Sentence Structure\u003c/h2\u003e\n\n\u003cp\u003eIn English, sentences consist of a \u003cstrong\u003e\u003cem\u003eNoun Phrase\u003c/em\u003e\u003c/strong\u003e followed by a \u003cstrong\u003e\u003cem\u003eVerb Phrase\u003c/em\u003e\u003c/strong\u003e, which may optionally be followed by a \u003cstrong\u003e\u003cem\u003ePrepositional Phrase\u003c/em\u003e\u003c/strong\u003e. This seems simple, but it gets more tricky when we realize that there is a recursive structure to these phrases. A noun phrase may consist of multiple smaller noun phrases, and in some cases, even a verb phrase. Similarly, a verb phrase can consist of multiple smaller verb phrases and noun phrases, which can themselves be made up of smaller noun phrases and verb phrases. \u003c/p\u003e\n\n\u003cp\u003eThis leads levels of \u003cstrong\u003e\u003cem\u003eambiguity\u003c/em\u003e\u003c/strong\u003e that can be troublesome for computers. NLTK's documentation explains this by examining the classic Groucho Marx joke:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\"While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\"\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThere are two different ways that we can interpret the first sentence. The common way that we interpret it is that a person shot an elephant while wearing pajamas. However, the alternative interpretation that is still correct (and the source of Marx's timeless punchline) is that Marx shot an elephant that was actually \u003cem\u003ein\u003c/em\u003e his pajamas. While we humans immediately understand the correct interpretation of the sentence (and hopefully get the joke), a computer has no way of knowing which of the two is the correct interpretation. \u003c/p\u003e\n\n\u003cp\u003eThe difference between the two interpretations can be most easily understood by comparing the \u003cstrong\u003e\u003cem\u003eParse Tree\u003c/em\u003e\u003c/strong\u003e for each. Take a look at this diagram from the \u003ca href=\"https://www.nltk.org/book/ch08.html\"\u003eNLTK Book's chapter on analyzing sentence structure\u003c/a\u003e:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/parse_tree.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's break these diagrams down piece by piece. The first, most natural interpretation of the phrase \"I shot an elephant in my pajamas\" breaks down the sentence as such:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNoun phrase: \u003ccode\u003e['I']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eVerb phrase: \u003ccode\u003e['shot', 'an', 'elephant']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ePrepositional phrase: \u003ccode\u003e['in', 'my', 'pajamas']\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis is the basic sentence structure that we are used to hearing. The noun phrase tells us the subject of the sentence, the verb phrase tells us what the subject did, and the prepositional phrase offers more information about the circumstances of the action, e.g. where, when, how, etc. Note that the verb phrase here is made up of a verb ('shot'), followed by a noun phrase ('an elephant'), much in the same way that the prepositional phrase consists of a preposition ('in'), followed by a noun phrase ('my pajamas'). This nested structure is \u003cstrong\u003e\u003cem\u003erecursive\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eHowever, the ambiguity that Marx plays off of uses the second parse tree's structure:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eNoun phrase: \u003ccode\u003e['I']\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eVerb phrase: \u003ccode\u003e['shot', 'an', 'elephant', 'in', 'my', 'pajamas']\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIf we compare the two parse trees visually, the difference becomes clear. Whereas in the first interpretation, the verb phrase consists of a verb phrase and a prepositional phrase, the second interpretation is different, treating the prepositional phrase as part of a noun phrase, which is, in turn, part of the noun phrase contained within that verb phrase. If all the grammar terms are making your head spin a little, don't worry, that's normal! The simple explanation here is that the first interpretation treats 'elephant' and 'in my pajamas' as belonging to different things, while the second treats 'elephant in my pajamas' as a single phrase. \u003c/p\u003e\n\n\u003ch2\u003eWhy Does This Matter?\u003c/h2\u003e\n\n\u003cp\u003eYou may be wondering why any of this actually matters to a Data Scientist. At a glance, it mostly just seems like a rehashing of a bunch of grade-school grammar rules. The answer is that using parse trees to understand sentence structure can help us determine meaning when working with human speech. It also helps highlight why this is such a complicated task -- computers do not have the ability to judge the meaning of a sentence based on things like semantic context like we do. Put simply, we know what an elephant is, what pajamas are, and understand that it's highly unlikely that an elephant could fit in pajamas. This helps us determine how we understand that sentence on the fly -- computers don't have this luxury, so they don't know which to choose!\u003c/p\u003e\n\n\u003ch2\u003ePOS Tagging and CFGs\u003c/h2\u003e\n\n\u003cp\u003eThis brings us to part of speech tagging. One way that we can help a computer understand how to interpret a sentence is to create a CFG for it to use when parsing. The CFG defines the rules of how sentences can exist. We do this by labeling different word tokens as their grammatical types, and then defining which combinations of grammatical types are valid examples of verb phrases, noun phrases, etc. \u003c/p\u003e\n\n\u003cp\u003eLet's take a look at the example CFG from the NLTK link provided above:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/master/images/cfg.png\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's break down this CFG, and see if we can understand it a bit better. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eS -\u0026gt; NP VP\u003c/code\u003e A sentence (S) consists of a Noun Phrase (NP) followed by a Verb Phrase (VP).\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ePP -\u0026gt; P NP\u003c/code\u003e A Prepositional Phrase (PP) consists of a Preposition (P) followed by a Noun Phrase (NP)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eNP -\u0026gt; Det N | Det N PP | 'I'\u003c/code\u003e A Noun Phrase (NP) can consist of:\n\n\u003cul\u003e\n\u003cli\u003ea Determiner (Det) followed by a Noun (N), or (as denoted by \u003ccode\u003e|\u003c/code\u003e) \u003c/li\u003e\n\u003cli\u003ea Determiner (Det) followed by a Noun (N), followed by a Prepositional Phrase (PP), or\u003c/li\u003e\n\u003cli\u003eThe token \u003ccode\u003e'I'\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eVP -\u0026gt; V NP | VP PP\u003c/code\u003e A Verb Phrase can consist of:\n\n\u003cul\u003e\n\u003cli\u003ea Verb (V) followed by a Noun Phrase (NP) or\u003c/li\u003e\n\u003cli\u003ea Verb Phrase (VP) followed by a Prepositional Phrase (PP)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eDet -\u0026gt; 'an' | 'my'\u003c/code\u003e Determiners are the tokens 'an' or 'my'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eN -\u0026gt; 'elephant' | 'pajamas'\u003c/code\u003e Nouns are the tokens 'elephant' or 'pajamas'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eV -\u0026gt; 'shot'\u003c/code\u003e Verbs are the token 'shot'\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eP -\u0026gt; 'in'\u003c/code\u003e Prepositions are the token 'in'\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs we can see, the CFG provides explicit rules as to both:\n1. How sentences, noun phrases, verb phrases, and prepositional phrases may be structured\n2. What parts of speech each token belongs to \u003c/p\u003e\n\n\u003cp\u003eThis defines a very small CFG that allows the parser to successfully generate parse trees for the Groucho Marx's sentence. Note that both the parse trees seen above are valid, according to the rules defined in this grammar. Even though this grammar is quite explicit, both of them work. \u003c/p\u003e\n\n\u003cp\u003eSo what happens if this CFG runs across a sentence structure it doesn't understand, or a token that it doesn't have a POS label for? It fails! True CFGs are quite complex. This was a toy example. \u003c/p\u003e\n\n\u003cp\u003eIn the next lab, we'll gain some practice writing some toy CFGs for a few target sentences. We'll also learn how we can skip all this fun stuff and get existing POS tags for our tokens straight from NLTK whenever we need them, thanks to databases such as the \u003cstrong\u003e\u003cem\u003ePenn Tree Bank\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we dove into linguistics to understand the concept of a \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e, and explored how they can be used to create parse trees for sentences.\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-context-free-grammars-and-POS-tagging\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-context-free-grammars-and-POS-tagging\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-and-POS-tagging/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"common-problems-with-clustering-algorithms","title":"Common Problems with Clustering Algorithms","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-common-problems-with-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-common-problems-with-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we'll discuss some of the common problems often seen when attempting clustering with k-means or hierarchical agglomerative clustering.\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIdentify the problems that can arise from bad centroid initializations in k-means and bad initial groups in HAC\u003c/li\u003e\n\u003cli\u003eCompare and contrast k-means and hierarchical agglomerative clustering methodologies\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCommon Problems with Clustering\u003c/h2\u003e\n\u003cp\u003eWhen working with clustering algorithms, there are certain problems that we should always be aware of in order to help us prevent situations where we unknowingly accept the results of a bad clustering. Understanding the potential problems that can arise with each clustering algorithm also tends to provide greater insight into how each algorithm works.\u003c/p\u003e\n\u003cp\u003eThe most common issue is one that is applicable to all forms of clustering -- we have no way of verifying if the results of the cluster analysis are correct or not! Always try to keep this in mind when working with clustering algorithms, and never make the mistake of treating the results of a cluster analysis as ground-truth.\u003c/p\u003e\n\u003cp\u003eTo further drive this point home, let's spend some time looking at common problems with the two kinds of clustering algorithms we've talked about so far so that we can gain insight into the situations where clustering algorithms fall short.\u003c/p\u003e\n\u003ch2\u003eAdvantages \u0026amp; Disadvantages of K-Means Clustering\u003c/h2\u003e\n\u003cp\u003eThe advantages of the k-means clustering approach are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eVery easy to implement!\u003c/li\u003e\n\u003cli\u003eWith many features, k-means is usually faster than HAC (as long as \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e is reasonably small)\u003c/li\u003e\n\u003cli\u003eObjects are locked into the cluster they are first assigned to and can change as the centroids move around\u003c/li\u003e\n\u003cli\u003eClusters are often tighter than those formed by HAC\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, this algorithm often comes with several disadvantages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQuality of results depends on picking the right value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e . This can be a problem when we don't know how many clusters to expect in our dataset\u003c/li\u003e\n\u003cli\u003eScaling our dataset will completely change the results\u003c/li\u003e\n\u003cli\u003eInitial start points of each centroid have a very strong impact on our final results. A bad start point can cause sub-optimal clusters (see example below)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-common-problems-with-clustering/master/images/bad-centroid-start.gif\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://shabal.in/visuals/kmeans/right.gif\"\u003egif courtesy of Andrey A. Shabalin\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe animation above shows what can happen when we get a bad centroid initialization. Because of the random points that the centroids were initialized at, this led to one centroid cluster containing no points, while another cluster centroid has combined two clusters by being located in between them! Even though we had the correct value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e (since we have 4 centroids, and data clearly contains 4 clusters), we ended up with incorrect results.\u003c/p\u003e\n\u003cp\u003eSince every dataset is different, and centroids are generated randomly, there is no way to make sure that we have good centroid initialization every time. One way to deal with this is to run a clustering algorithm multiple times, and keep track of how many times the same results come up. The good news here is that bad centroid initializations are typically much less likely than good centroid initializations, so the chances of getting bad results due to poor centroid initialization multiple times in a row are somewhat unlikely.\u003c/p\u003e\n\u003cp\u003eNow, let's take a look at HAC.\u003c/p\u003e\n\u003ch2\u003eAdvantages \u0026amp; Disadvantages of HAC\u003c/h2\u003e\n\u003cp\u003eHAC is useful as a clustering algorithm because:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIt produces an ordered relationship between clusters, which can be useful when visualized\u003c/li\u003e\n\u003cli\u003eSmaller clusters are created. This allows us to get a very granular understanding of our dataset, and zoom in at the level where the clusters make the most sense to us (note the coloration of the lines in the example dendrogram above)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHowever, this algorithm is also built on some assumptions which can be disadvantages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eResults are usually dependent upon the distance metric used\u003c/li\u003e\n\u003cli\u003eObjects can be grouped 'incorrectly' early on, with no way to relocate them. For instance, consider two points that belong to separate clusters, but are both nearer to each other than the center of the cluster they actually belong to (both are near the \"boundary\" between their cluster and the opposing cluster). These will be incorrectly grouped as a cluster, which will throw off the clustering of the groups they actually belong to, as well\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet's look at an example. Consider the circled points in the following plot:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-common-problems-with-clustering/master/images/new_bad-hac.png\" width=\"600\"\u003e\u003c/p\u003e\n\u003cp\u003eThe two points circled are from different clusters. However, they are right on the boundary between the two clusters, which has significant overlap between them. Because of this, there is a good chance that the clusters will meet the linkage criteria, and the HAC algorithm will group them together. The centroid of this new (incorrect) cluster is also close to many points on the boundary, meaning that it is quite likely that those points will be merged and the incorrect cluster will grow bigger. Early mistakes with the HAC algorithm tend to act as a bit of a slippery slope, and since HAC doesn't constantly reassign points like k-means does, this means that things can go from bad to worse if mistakes are made early on.\u003c/p\u003e\n\u003ch2\u003eA Note on Visualization\u003c/h2\u003e\n\u003cp\u003eSo far, we've checked our work by looking at visualizations of the clusters and using our eyes and our judgment to check if we agree with the results of the algorithm. However, it's worth remembering that this is highly unlikely to be an option on real-world data since we can't visualize any data with more than 3 dimensions. Because of this, it's often much harder to tell when a clustering algorithm has made a mistake, because we aren't able to use our eyes to confirm or deny the results!\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, we learned about some of the challenges that come with clustering, and the relative advantages and disadvantages of k-means and hierarchical agglomerative clustering.\u003c/p\u003e","frontPage":false},{"exportId":"tuning-neural-networks-with-regularization","title":"Tuning Neural Networks with Regularization","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-regularization\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've learned about neural networks and some streamlined methods for building such models, it's time to further explore how to tune and optimize the performance of these networks. One important aspect is reducing the time and resources needed to train these models. In previous lessons, when importing the Santa images, you immediately reduced each image to an extremely pixelated 64x64 representation. On top of that, you further down-sampled the dataset to reduce the number of observations. This was because training neural networks is resource intensive and is often a time consuming process as a result. Typically you also want to improve the accuracy and performance of these models. In this lesson, you will begin to examine various techniques related to these goals, beginning with the discussion of validation sets.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the relationship between bias and variance in neural networks\u003cbr\u003e\u003c/li\u003e\n\u003cli\u003eExplain how regularization affects the nodes of a neural network \u003c/li\u003e\n\u003cli\u003eExplain L1, L2, and dropout regularization in a neural network \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eHyperparameters and iterative deep learning\u003c/h2\u003e\n\n\u003cp\u003eFirst, there are many hyperparameters you can tune. These include: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003enumber of hidden units\u003c/li\u003e\n\u003cli\u003enumber of layers\u003c/li\u003e\n\u003cli\u003elearning rate ( \u003cimg class=\"equation_image\" title=\"\\alpha\" src=\"https://learning.flatironschool.com/equation_images/%255Calpha\" alt=\"{\" data-equation-content=\"\\alpha\"\u003e )\u003c/li\u003e\n\u003cli\u003eactivation function\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe question then becomes, how do you choose these parameters? One primary method is to develop validation sets to strike a balance between specificity and generalization. \u003c/p\u003e\n\n\u003ch2\u003eTraining, Validation, and Test Sets\u003c/h2\u003e\n\n\u003cp\u003eWhen tuning neural networks it typically helps to split the data into three distinct partitions as follows:\n- You train algorithms on the training set\n- You'll use a validation set to decide which one will be your final model after parameter tuning\n- After having chosen the final model (and having evaluated long enough), you'll use the test set to get an unbiased estimate of the classification performance (or whatever your evaluation metric will be)  \u003c/p\u003e\n\n\u003cp\u003eRemember that it is \u003cstrong\u003eVERY IMPORTANT\u003c/strong\u003e to make sure that the holdout (validation) and test samples come from the same distribution: e.g. same resolution of Santa pictures. \u003c/p\u003e\n\n\u003ch2\u003eBias and Variance in Deep Learning\u003c/h2\u003e\n\n\u003cp\u003eFinding a balance between generalization and specificity is at the heart of the bias-variance trade off. To further examine this process for tuning neural networks, let's return to a simple example you've seen before. \u003c/p\u003e\n\n\u003ch3\u003eThe Circles Example\u003c/h3\u003e\n\n\u003cp\u003eIn classical machine learning, you often need to consider \"bias-variance trade-off\". You'll investigate these concepts here, and see how deep learning is slightly different and a trade-off isn't always present!\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eBias = underfitting\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eHigh variance = overfitting\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eGood fit --\u0026gt; somewhere in between \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTo start, take another look at the two circles data, the data looked like this: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/example.png\" alt=\"scatter plot showing two concentric circles\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRecall that you fit a logistic regression model to the data here. You got something that looked like the picture below. The model didn't do a particularly good job at discriminating between the yellow and purple dots. You could say this is a model with a \u003cstrong\u003ehigh bias\u003c/strong\u003e, the model is \u003cstrong\u003eunderfitting\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/underfitting.png\" alt=\"graph with concentric circles, this time partitioned in two by a single diagonal line\"\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen using a neural network, what you reached in the end was a pretty good decision boundary, a circle discriminating between the yellow and purple dots: \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/good.png\" alt=\"the same graph, this time with an inner circle and outer area partition\"\u003e\u003c/p\u003e\n\n\u003cp\u003eAt the other end of the spectrum, you might experience \u003cstrong\u003eoverfitting\u003c/strong\u003e, where you create a circle which is super sensitive to small deviations of the colored dots, like the example below. You can also call this a model with \u003cstrong\u003ehigh variance\u003c/strong\u003e. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/overfitting.png\" alt=\"the same graph, this time with an inner and outer circle with more wiggly lines\"\u003e\u003c/p\u003e\n\n\u003ch2\u003eThe Santa Example\u003c/h2\u003e\n\n\u003cp\u003e\n \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/S_4.jpg\" alt=\"Santa image\" style=\"height: 220px;\"\u003e \n \u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/NS_1.jpg\" alt=\"Not Santa image\" style=\"height: 220px;\"\u003e \n \u003c/p\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eHigh variance\u003c/th\u003e\n\u003cth\u003eHigh bias\u003c/th\u003e\n\u003cth\u003eHigh variance \u0026amp; bias\u003c/th\u003e\n\u003cth\u003eLow variance and bias\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003etrain set error\u003c/td\u003e\n\u003ctd\u003e12%\u003c/td\u003e\n\u003ctd\u003e26%\u003c/td\u003e\n\u003ctd\u003e26%\u003c/td\u003e\n\u003ctd\u003e12%\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003evalidation set error\u003c/td\u003e\n\u003ctd\u003e25%\u003c/td\u003e\n\u003ctd\u003e28%\u003c/td\u003e\n\u003ctd\u003e40%\u003c/td\u003e\n\u003ctd\u003e13%\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003cp\u003eAssume that our best model can get to a validation set accuracy of 87%. Note that \"high\" and \"low\" are relative! Also, in deep learning there is less of a bias variance trade-off! \u003c/p\u003e\n\n\u003ch2\u003eRules of Thumb Regarding Bias / Variance\u003c/h2\u003e\n\n\u003ctable\u003e\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eHigh Bias? (training performance)\u003c/th\u003e\n\u003cth\u003eHigh variance? (validation performance)\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eUse a bigger network\u003c/td\u003e\n\u003ctd\u003eMore data\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTrain longer\u003c/td\u003e\n\u003ctd\u003eRegularization\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLook for other existing NN architectures\u003c/td\u003e\n\u003ctd\u003eLook for other existing NN architectures\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\n\u003ch2\u003eRegularization\u003c/h2\u003e\n\n\u003cp\u003eUse regularization when the model overfits to the data. \u003c/p\u003e\n\n\u003ch3\u003eL1 and L2 regularization\u003c/h3\u003e\n\n\u003ch4\u003eIn logistic regression\u003c/h4\u003e\n\n\u003cp\u003eLet's look back at the logistic regression example with lambda, a regularization parameter (another hyperparameter you have to tune).\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" J (w,b) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}||w||_2^2\" src=\"/equation_images/%20J%20(w,b)%20=%20%255Cdfrac{1}{m}%20%255Csum^m_{i=1}%255Cmathcal{L}(%255Chat%20y^{(i)},%20y^{(i)})+%20%255Cdfrac{%255Clambda}{2m}||w||_2^2\" alt=\"{\" data-equation-content=\" J (w,b) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}||w||_2^2\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"||w||\u003cem\u003e2^2 = \\sum^{n_x}\u003c/em\u003e{j=1}w_j^2= w^Tw\" src=\"/equation_images/||w||\u003cem\u003e2^2%20=%20%255Csum^{n_x}\u003c/em\u003e{j=1}w_j^2=%20w^Tw\" alt=\"{\"\u003e2^2 = \\sum^{n_x}{j=1}w_j^2= w^Tw}' data-equation-content='||w||\u003cem\u003e2^2 = \\sum^{n_x}\u003c/em\u003e{j=1}w_j^2= w^Tw' /\u0026gt;\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThis is called L2-regularization. You can also add a regularization term for \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e, but \u003cimg class=\"equation_image\" title=\"b\" src=\"https://learning.flatironschool.com/equation_images/b\" alt=\"{\" data-equation-content=\"b\"\u003e is just one parameter. L2-regularization is the most common type of regularization.\u003c/p\u003e\n\n\u003cp\u003eL1-regularization is where you just add a term:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" \\dfrac{\\lambda}{m}||w||_1\" src=\"/equation_images/%20%255Cdfrac{%255Clambda}{m}||w||_1\" alt=\"{\" data-equation-content=\" \\dfrac{\\lambda}{m}||w||_1\"\u003e\u003c/p\u003e (could also be 2 in the denominator)\u003cp\u003e\u003c/p\u003e\n\n\u003ch4\u003eIn a neural network\u003c/h4\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\" J (w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}\\sum^L_{l=1}||w^{[l]}||^2\" src=\"/equation_images/%20J%20(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]})%20=%20%255Cdfrac{1}{m}%20%255Csum^m_{i=1}%255Cmathcal{L}(%255Chat%20y^{(i)},%20y^{(i)})+%20%255Cdfrac{%255Clambda}{2m}%255Csum^L_{l=1}||w^{[l]}||^2\" alt=\"{\" data-equation-content=\" J (w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}\\sum^L_{l=1}||w^{[l]}||^2\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"||w^{[l]}||^2 = \\sum^{n^{[l-1]}}\u003cem\u003e{i=1} \\sum^{n^{[l]}}\u003c/em\u003e{j=1} (w_{ij}^{[l]})^2\" src=\"/equation_images/||w^{[l]}||^2%20=%20%255Csum^{n^{[l-1]}}\u003cem\u003e{i=1}%20%255Csum^{n^{[l]}}\u003c/em\u003e{j=1}%20(w_{ij}^{[l]})^2\" alt=\"{\"\u003e{i=1} \\sum^{n^{[l]}}{j=1} (w_{ij}^{[l]})^2}' data-equation-content='||w^{[l]}||^2 = \\sum^{n^{[l-1]}}\u003cem\u003e{i=1} \\sum^{n^{[l]}}\u003c/em\u003e{j=1} (w_{ij}^{[l]})^2' /\u0026gt;\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eThis matrix norm is called the \"Frobenius norm\", also referred to as \u003cimg class=\"equation_image\" title=\"||w^{[l]}||^2 _F\" src=\"/equation_images/||w^{[l]}||^2%20_F\" alt=\"{\" data-equation-content=\"||w^{[l]}||^2 _F\"\u003e\u003c/p\u003e\n\n\u003cp\u003eHow does backpropagation change now?\u003c/p\u003e\n\n\u003cp\u003eWhichever expression you have from the backpropagation, and add \u003cimg class=\"equation_image\" title=\"\\dfrac{\\lambda}{m} w^{[l]}\" src=\"/equation_images/%255Cdfrac{%255Clambda}{m}%20w^{[l]}\" alt=\"{\" data-equation-content=\"\\dfrac{\\lambda}{m} w^{[l]}\"\u003e.\nSo,\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"dw^{[l]} = \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\" src=\"/equation_images/dw^{[l]}%20=%20%255Ctext{[backpropagation%20derivatives]%20}+%20%255Cdfrac{%255Clambda}{m}%20w^{[l]}\" alt=\"{\" data-equation-content=\"dw^{[l]} = \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\"\u003e\u003c/p\u003e \u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eAfterwards, \u003cimg class=\"equation_image\" title=\"w^{[l]}\" src=\"/equation_images/w^{[l]}\" alt=\"{\" data-equation-content=\"w^{[l]}\"\u003e is updated again as \u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\alpha dw^{[l]} \" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Calpha%20dw^{[l]}\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\alpha dw^{[l]} \"\u003e\u003c/p\u003e\n\n\u003cp\u003eL2-regularization is called weight decay, because regularization will make your load smaller:\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\alpha \\bigr( \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\\bigr)\" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Calpha%20%255Cbigr(%20%255Ctext{[backpropagation%20derivatives]%20}+%20%255Cdfrac{%255Clambda}{m}%20w^{[l]}%255Cbigr)\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\alpha \\bigr( \\text{[backpropagation derivatives] }+ \\dfrac{\\lambda}{m} w^{[l]}\\bigr)\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cimg class=\"equation_image\" title=\"w^{[l]}:= w^{[l]} - \\dfrac{\\alpha\\lambda}{m}w^{[l]} - \\alpha \\text{[backpropagation derivatives]}\" src=\"/equation_images/w^{[l]}:=%20w^{[l]}%20-%20%255Cdfrac{%255Calpha%255Clambda}{m}w^{[l]}%20-%20%255Calpha%20%255Ctext{[backpropagation%20derivatives]}\" alt=\"{\" data-equation-content=\"w^{[l]}:= w^{[l]} - \\dfrac{\\alpha\\lambda}{m}w^{[l]} - \\alpha \\text{[backpropagation derivatives]}\"\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\n\u003cp\u003eHence your weights will become smaller by a factor \u003cimg class=\"equation_image\" title=\"\\bigr(1- \\dfrac{\\alpha\\lambda}{m}\\bigr)\" src=\"/equation_images/%255Cbigr(1-%20%255Cdfrac{%255Calpha%255Clambda}{m}%255Cbigr)\" alt=\"{\" data-equation-content=\"\\bigr(1- \\dfrac{\\alpha\\lambda}{m}\\bigr)\"\u003e.\u003c/p\u003e\n\n\u003cp\u003eIntuition for regularization: the weight matrices will be penalized from being too large. Actually, the network will be forced to almost be simplified.\u003c/p\u003e\n\n\u003cp\u003eAlso: e.g., \u003cem\u003etanh\u003c/em\u003e function, if \u003cimg class=\"equation_image\" title=\"w\" src=\"https://learning.flatironschool.com/equation_images/w\" alt=\"{\" data-equation-content=\"w\"\u003e is small, the activation function will be mostly operating in the linear region and not \"explode\" as easily.\u003c/p\u003e\n\n\u003ch2\u003eDropout Regularization\u003c/h2\u003e\n\n\u003cp\u003eWhen you apply the Dropout technique, a random subset of nodes (also called the units) in a layer are ignored (their weights set to zero) during each phase of training. Below is an image from the \u003ca href=\"http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\"\u003eoriginal paper\u003c/a\u003e that introduced this technique. \u003c/p\u003e\n\n\u003cp\u003eOn the left you can see a standard neural network with four layers (one input layer, two hidden layers, and an output layer). On the right, you can see the network after Dropout is applied during one step of training. This technique is very effective because it allows us to train neural networks on different parts of the data, thus ensuring that our model is not overly sensitive noise in the data. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization/master/images/dropout.png\" alt=\"Left: a standard neural net with 2 hidden layers. Right: An example of a thinned net produced by applying dropout to the network on the left.\"\u003e \u003c/p\u003e\n\n\u003cp\u003eIn Keras, you specify \u003cem\u003eDropout\u003c/em\u003e using the \u003ccode\u003eDropout\u003c/code\u003e layer, which is applied to input and hidden layers. The \u003ccode\u003eDropout\u003c/code\u003e layers requires one argument, \u003ccode\u003erate\u003c/code\u003e, which specifies the fraction of units to drop, usually between 0.2 and 0.5. \u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emodels\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSequential\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'relu'\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einput_shape\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,)))\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Dropout applied to the input layer\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDropout\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'relu'\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# Dropout applied to the hidden layer\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDropout\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.3\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eadd\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elayers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDense\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eactivation\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e'sigmoid'\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn different iterations through the training set, different nodes will be zeroed out!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you began to explore how to further tune and optimize out of the box neural networks built with Keras. This included regularization analogous to previous machine learning work you've seen, as well dropout regularization, which can be used to further prune your networks. In the upcoming lab you'll get a chance to experiment with these concepts in practice and observe their effect on your models outputs. \u003c/p\u003e","frontPage":false},{"exportId":"clustering-recap","title":"Clustering - Recap","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThere are two main types of clustering algorithms: non-hierarchical clustering (k-means) and hierarchical agglomerative clustering\u003c/li\u003e\n\u003cli\u003eYou can quantify the performance of a clustering algorithm using metrics such as variance ratios\u003c/li\u003e\n\u003cli\u003eWhen working with the k-means clustering algorithm, it is useful to create elbow plots to find an optimal value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e\n\u003c/li\u003e\n\u003cli\u003eWhen using hierarchical agglomerative clustering, different linkage criteria can be used to determine which clusters should be merged and at what point\u003c/li\u003e\n\u003cli\u003eDendrograms and clustergrams are very useful visual tools in hierarchical agglomerative clustering\u003c/li\u003e\n\u003cli\u003eAdvantages of k-means clustering include easy implementation and speed, whereas the main disadvantage is that it isn't always straightforward how to pick the \"right\" value for \u003cimg src=\"https://render.githubusercontent.com/render/math?math=k\"\u003e\n\u003c/li\u003e\n\u003cli\u003eAdvantages of hierarchical agglomerative clustering include easy visualization and intuitiveness, whereas the main disadvantage is that the result is very distance-metric-dependent\u003c/li\u003e\n\u003cli\u003eYou can use supervised and unsupervised learning together in a few different ways. Applications of this are look-alike models in market segmentation and semi-supervised learning\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"big-data-and-py-spark-recap","title":"Big Data and (Py)Spark - Recap","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-pyspark-recap\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-recap\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-pyspark-recap/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eKey Takeaways\u003c/h2\u003e\n\n\u003cp\u003eThe key takeaways from this section include:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBig Data usually refers to datasets that grow so large that they become awkward to work with using traditional database management systems and analytical approaches\u003c/li\u003e\n\u003cli\u003eBig data refers to data that is terabytes (TB) to petabytes (PB) in size\u003c/li\u003e\n\u003cli\u003eMapReduce can be used to split big datasets up in smaller sets to be distributed over several machines to deal with Big Data Analytics \u003c/li\u003e\n\u003cli\u003ePySpark can be installed directly on your computer using \u003ccode\u003econda\u003c/code\u003e or in a Docker container\u003c/li\u003e\n\u003cli\u003eWhen you start working with PySpark, you have to create a \u003ccode\u003eSparkContext\u003c/code\u003e or \u003ccode\u003eSparkSession\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eThe creation or RDDs is essential when working with PySpark\u003c/li\u003e\n\u003cli\u003eExamples of actions and transformations include \u003ccode\u003ecollect()\u003c/code\u003e, \u003ccode\u003ecount()\u003c/code\u003e, \u003ccode\u003efilter()\u003c/code\u003e, \u003ccode\u003efirst()\u003c/code\u003e, \u003ccode\u003etake()\u003c/code\u003e, and \u003ccode\u003ereduce()\u003c/code\u003e \u003c/li\u003e\n\u003cli\u003eMachine Learning on the scale of big data can be done with Spark using the \u003ccode\u003eml\u003c/code\u003e library\u003c/li\u003e\n\u003c/ul\u003e","frontPage":false},{"exportId":"introduction-to-dash","title":"Introduction to Dash","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-dash-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dash-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have learned how to build a basic web application using Flask, you'll learn about a web framework called Dash! Dash is built on top of Flask and allows you to build interactive web applications with minimal HTML and no JavaScript.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine the difference between a static and a dynamic web page\u003c/li\u003e\n\u003cli\u003eRun a Dash app directly within Jupyter Notebook\u003c/li\u003e\n\u003cli\u003eIteratively build a Dash app that contains a layout made of components as well as a callback\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eStatic vs. Dynamic Web Pages\u003c/h2\u003e\n\n\u003ch3\u003eStatic Web Pages\u003c/h3\u003e\n\n\u003cp\u003eRecall our simple Flask app home page (from the \u003ccode\u003e/\u003c/code\u003e route):\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png\" alt=\"hello world page\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThat home page is able to display information, but the interface is fundamentally \u003cstrong\u003e\u003cem\u003estatic\u003c/em\u003e\u003c/strong\u003e. In other words, the content served by the backend server is always the same. It also doesn't matter whether the user clicks anywhere on the page; the page will always just say \u003ccode\u003e\"Hello, world!\"\u003c/code\u003e. Static web pages are built using \u003cstrong\u003eHTML\u003c/strong\u003e and \u003cstrong\u003eCSS\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch3\u003eDynamic Web Pages\u003c/h3\u003e\n\n\u003cp\u003eWhen we developed our \u003ccode\u003e/predict\u003c/code\u003e route, we made an API interface that could dynamically generate results, but that interface was only accessible through code. What if we want an interface where a user can specify the values being used for prediction?\u003c/p\u003e\n\n\u003cp\u003eTo do that, we'll make a \u003cstrong\u003e\u003cem\u003edynamic\u003c/em\u003e\u003c/strong\u003e web page. The user can change values using familiar web form inputs (text boxes, drop-downs, checkboxes, sliders, etc.) and the model's predictions will automatically appear on the page. This kind of interface is much easier and more intuitive than using the \u003ccode\u003erequests\u003c/code\u003e library, and looks great in a data science portfolio!\u003c/p\u003e\n\n\u003cp\u003eDynamic web pages are built using \u003cstrong\u003eJavaScript\u003c/strong\u003e in addition to HTML and CSS. JavaScript is able to attach \u003cstrong\u003e\u003cem\u003ecallbacks\u003c/em\u003e\u003c/strong\u003e to the HTML elements (e.g. triggered by clicking on a button), which can optionally interact with the backend server before ultimately making some change to the page's HTML and/or CSS.\u003c/p\u003e\n\n\u003cp\u003eLearning JavaScript can be complicated. Some of the constructs are similar to Python (e.g. first-class functions) but the syntax and error behavior are fairly different. Luckily with \u003cstrong\u003eDash\u003c/strong\u003e we can create \u003cstrong\u003e\u003cem\u003ecomponents\u003c/em\u003e\u003c/strong\u003e and callbacks just using Python, and they will be translated into the appropriate HTML, CSS, and JavaScript code by Dash!\u003c/p\u003e\n\n\u003ch2\u003eA \"Hello World\" Dash App\u003c/h2\u003e\n\n\u003cp\u003eDash is built on top of Flask, and therefore has a similar setup. Once you have the appropriate libraries installed and imported, you instantiate an \u003ccode\u003eapp\u003c/code\u003e, then you can specify properties of that app before running the web server.\u003c/p\u003e\n\n\u003ch3\u003eSetting up a Dash Environment\u003c/h3\u003e\n\n\u003cp\u003eClone this repository locally so you can work through these examples!\u003c/p\u003e\n\n\u003cp\u003eLet's make a new \u003ccode\u003econda\u003c/code\u003e environment for developing our Dash app.\u003c/p\u003e\n\n\u003cp\u003eRun this code in the terminal:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight shell\"\u003e\u003ccode\u003econda create \u003cspan class=\"nt\"\u003e--name\u003c/span\u003e dash-env \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.8.12 pip\nconda activate dash-env\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003enotebook\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003eWerkzeug\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e2.0.3\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003ejupyter-dash\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.4\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003edash-bootstrap-components\u003cspan class=\"o\"\u003e==\u003c/span\u003e1.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003epandas\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e1.4\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003e\u003cspan class=\"nv\"\u003ejoblib\u003c/span\u003e\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.17.0\npip \u003cspan class=\"nb\"\u003einstall \u003c/span\u003escikit-learn\u003cspan class=\"o\"\u003e==\u003c/span\u003e0.23.2\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow, launch this notebook using \u003ccode\u003ejupyter notebook\u003c/code\u003e\u003c/p\u003e\n\n\u003ch3\u003eRunning the Dash Application\u003c/h3\u003e\n\n\u003cp\u003eUnlike with Flask alone, there is functionality to run a Dash app directly within a Jupyter Notebook!\u003c/p\u003e\n\n\u003cp\u003eWe'll run a basic Dash app below, and when you run the cell containing \u003ccode\u003eapp.run_server\u003c/code\u003e, the dynamic web page should appear directly below the cell:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import jupyter notebook version of dash framework\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ejupyter_dash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eJupyterDash\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# import html elements for dash\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to include a single \u0026lt;p\u0026gt; tag containing \"Hello, World!\"\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Hello, World!\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003ewarnings\u003c/span\u003e\n\u003cspan class=\"n\"\u003ewarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efilterwarnings\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e'ignore'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e150\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf this works, you have now run a Dash app! That was easier than running a Flask app!\u003c/p\u003e\n\n\u003ch4\u003eTroubleshooting\u003c/h4\u003e\n\n\u003cp\u003eIf the above code didn't work, make sure you read the error message.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIf you get a \u003ccode\u003eModuleNotFoundError\u003c/code\u003e that means that something went wrong with either installing the dependencies or pointing Jupyter Notebook to the right environment\n\n\u003cul\u003e\n\u003cli\u003eTroubleshooting dependency installation:\u003c/li\u003e\n\u003cli\u003eGo to the terminal and make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003ewhich python\u003c/code\u003e and make sure that it prints out a path that includes \u003ccode\u003edash-env\u003c/code\u003e. If it doesn't, run \u003ccode\u003econda deactivate\u003c/code\u003e then \u003ccode\u003econda remove --name dash-env --all\u003c/code\u003e and start over with the instructions to create \u003ccode\u003edash-env\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eLaunch a Python shell by running \u003ccode\u003epython\u003c/code\u003e in the terminal. Then test out the import statements there, and see if you get a \u003ccode\u003eModuleNotFoundError\u003c/code\u003e. If you get the error, that means you should try again with \u003ccode\u003epip install\u003c/code\u003eing the required packages. If you don't get the error, it means that your problem is probably with pointing Jupyter Notebook to the right environment\u003c/li\u003e\n\u003cli\u003eTroubleshooting Jupyter Notebook environment:\u003c/li\u003e\n\u003cli\u003eGo to the terminal and make sure you have \u003ccode\u003edash-env\u003c/code\u003e activated\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003epython -m ipykernel install --user --name dash-env --display-name \"Python (dash-env)\"\u003c/code\u003e to install this conda environment as an IPython kernel\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003ejupyter notebook\u003c/code\u003e, then select the \u003cstrong\u003eKernel\u003c/strong\u003e --\u0026gt; \u003cstrong\u003eChange kernel\u003c/strong\u003e menu option. \u003ccode\u003ePython (dash-env)\u003c/code\u003e should be one of the options. Select it. Now you should be able to run the above cells successfully.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003cli\u003eIf you get an \u003ccode\u003eOSError\u003c/code\u003e such as \u003ccode\u003eAddress already in use\u003c/code\u003e or \u003ccode\u003eAn attempt was made to access a socket in a way forbidden by its access permissions\u003c/code\u003e, that's the same issue as with Flask, where something else is running on port 5000 on your computer\n\n\u003cul\u003e\n\u003cli\u003eIn \u003ccode\u003eapp.run_server\u003c/code\u003e, change the value of the \u003ccode\u003eport\u003c/code\u003e argument to something other than 5000 (e.g. 5001). This should resolve the \u003ccode\u003eOSError\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eUtilizing Components in Our Dash App Layout\u003c/h2\u003e\n\n\u003cp\u003eRight now the only thing in our app is the text \"Hello, World!\". Let's make it a bit more interesting!\u003c/p\u003e\n\n\u003ch3\u003eMarkdown Components\u003c/h3\u003e\n\n\u003cp\u003ePreviously we used an HTML \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag to display the \"Hello, World!\" text. In Dash, this is instantiated using \u003ccode\u003ehtml.P\u003c/code\u003e. You can find documentation for this component and all other Dash HTML components \u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eHowever as a data scientist who has typically been working in a Jupyter Notebook, you are probably more familiar with Markdown than HTML. Luckily there is a Markdown component we can use that will translate Markdown into HTML for us. This is the \u003ccode\u003edcc.Markdown\u003c/code\u003e component (\u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003edocumentation here\u003c/a\u003e). Usage is fairly straightforward; you just specify the Markdown as a string argument (typically a triple-quoted multi-line string):\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# import dash core components\n\u003c/span\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to an extended markdown example\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Welcome to the Home Page\n\n## Introduction\n\nHello, World! Here is some **bold** and *italic* text, a `code snippet`,\n and a [hyperlink](https://www.google.com/).\n\n## Some Lists\n\n* Unordered list item 1\n* Unordered list item 2\n\n1. Ordered list item 1\n2. Ordered list item 2\n\n## This Is Much Better than the Old Home Page\n\nBelow is an image embedded using Markdown, showing the old home page.\n\n![hello world page](https://curriculum-content.s3.amazonaws.com/data-science/images/flask_hello_world.png)\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003eDataTable Components\u003c/h3\u003e\n\n\u003cp\u003eFor a data science app, it is often useful to be able to display tabular data. Let's go ahead and load in the Iris Dataset from scikit-learn:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003epandas\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\n\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003esklearn.datasets\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eload_iris\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"n\"\u003eX\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataFrame\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecolumns\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efeature_names\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003ey\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSeries\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epd\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econcat\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ey\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eaxis\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWhat if we wanted to display this data in our web page? Enter the DataTable component (\u003ca href=\"https://dash.plotly.com/datatable\"\u003edocumentation here\u003c/a\u003e). This is a Dash component designed for just this purpose!\u003c/p\u003e\n\n\u003cp\u003eLet's go ahead and display a random sample of 10 records from the dataset:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to a data table\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e350\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eGreat!\u003c/p\u003e\n\n\u003ch3\u003eCombining Multiple Components\u003c/h3\u003e\n\n\u003cp\u003eSo far, we have reassigned the \u003ccode\u003elayout\u003c/code\u003e attribute of our app each time, so that it originally was a \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag containing \"Hello, World!\", then it was a Markdown component with various headings and other content, then it was a DataTable with data from the Iris Dataset.\u003c/p\u003e\n\n\u003cp\u003eIf we want to use more than one component in the same web page?\u003c/p\u003e\n\n\u003cp\u003eThe most straightforward way is to use multiple nested Div components (\u003ca href=\"https://dash.plotly.com/dash-html-components/div\"\u003edocumentation here\u003c/a\u003e). Div components for Dash are represented as HTML \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e tags, which are generic HTML container elements.\u003c/p\u003e\n\n\u003cp\u003eThe example below combines some Markdown text with the DataTable with data from the Iris Dataset.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create new dash app here\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# declaring our individual components\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# creating an app layout with these components as children\n\u003c/span\u003e\n\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"450\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we have both Markdown and DataTable components in the same web page!\u003c/p\u003e\n\n\u003ch3\u003eStyling Our Components\u003c/h3\u003e\n\n\u003cp\u003eThis is an optional step, but it makes the components look a bit better together. If you know how to work with CSS, you can define your own custom styles and follow \u003ca href=\"https://dash.plotly.com/external-resources\"\u003ethese instructions\u003c/a\u003e, but for now we'll just use the recommended style sheet from Dash.\u003c/p\u003e\n\n\u003cp\u003eStyle sheets are added when the \u003ccode\u003eapp\u003c/code\u003e is instantiated. Then we can add our Markdown and DataTable elements and see them with their new styles:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e# create a list of external stylesheets, with just one CSS file (for now)\n\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e'https://codepen.io/chriddyp/pen/bWLwgP.css'\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e450\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNot a huge change, but the look and feel is more polished with the stylesheet than without it.\u003c/p\u003e\n\n\u003ch2\u003eCallbacks\u003c/h2\u003e\n\n\u003cp\u003eSo far, we have used Dash components to avoid writing HTML and CSS directly, but we still fundamentally have a static page. Let's add a callback to create some dynamic, interactive functionality!\u003c/p\u003e\n\n\u003ch3\u003eHTML and JavaScript Background: Element \u003ccode\u003eid\u003c/code\u003es\u003c/h3\u003e\n\n\u003cp\u003eOne of the strategies for connecting HTML and JavaScript logic uses the \u003ccode\u003eid\u003c/code\u003e attribute of the HTML elements. In properly-formatted HTML, the \u003ccode\u003eid\u003c/code\u003e attribute is a unique identifier that only applies to a single element on the page. When the \u003ccode\u003eid\u003c/code\u003e has been declared, then JavaScript can locate the element using that \u003ccode\u003eid\u003c/code\u003e in order to specify callback behavior.\u003c/p\u003e\n\n\u003cp\u003eLet's start with a simple HTML page, consisting of a \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e containing a \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag and a \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight html\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e\u0026lt;div\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;button\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003eClick here\u003cspan class=\"nt\"\u003e\u0026lt;/button\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;p\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003eThe button has not been clicked\u003cspan class=\"nt\"\u003e\u0026lt;/p\u0026gt;\u003c/span\u003e\n\u003cspan class=\"nt\"\u003e\u0026lt;/div\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAnd let's say that when we click on that \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag, we want the text of the \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag to change to say \"The button was clicked!\" instead of saying \"The button has not been clicked\".\u003c/p\u003e\n\n\u003cp\u003eTo do that in JavaScript, the code would look something like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight javascript\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ebutton\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003edocument\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003egetElementById\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003ebtn\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kd\"\u003econst\u003c/span\u003e \u003cspan class=\"nx\"\u003ep\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003edocument\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003egetElementById\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003ep\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"nx\"\u003ebutton\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eaddEventListener\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003eclick\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nx\"\u003ee\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"nx\"\u003ep\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003einnerText\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"s2\"\u003eThe button was clicked!\u003c/span\u003e\u003cspan class=\"dl\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eDon't worry too much about the specific syntax here. The main takeaway is that:\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eJavaScript code is able to locate HTML elements by their \u003ccode\u003eid\u003c/code\u003e property\u003c/li\u003e\n\u003cli\u003eOnce JavaScript has located the HTML element, it can add \"event listeners\" that define what should happen when an event (e.g. clicking) happens\u003c/li\u003e\n\u003cli\u003eOnce JavaScript has located the HTML element, it can modify the attributes of the element (e.g. setting the inner text)\u003c/li\u003e\n\u003cli\u003eSteps 2 and 3 are often combined together, so that an event can trigger the modification of the attributes of one or more HTML element\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3\u003eA Simple Callback\u003c/h3\u003e\n\n\u003cp\u003eLet's implement the HTML and JavaScript code above using Dash instead. We'll need a layout consisting of a Div component for the \u003ccode\u003e\u0026lt;div\u0026gt;\u003c/code\u003e tag, a Button component (\u003ca href=\"https://dash.plotly.com/dash-html-components/button\"\u003edocumentation here\u003c/a\u003e) for the \u003ccode\u003e\u0026lt;button\u0026gt;\u003c/code\u003e tag, a P component for the \u003ccode\u003e\u0026lt;p\u0026gt;\u003c/code\u003e tag, a function that modifies the component's text, and a decorator that connects the click event to the text modification.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003edash\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# set the layout to our simple html page with id attributes\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eButton\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Click here\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eP\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e \n\n\u003cspan class=\"c1\"\u003e# attach a callback so that when n_clicks of the Button changes,\n# the children text of the P changes\n\u003c/span\u003e\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"p\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"btn\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"n_clicks\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003eset_text\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003en_clicks\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003en_clicks\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"bp\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"The button has not been clicked\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"s\"\u003e\"The button was clicked!\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you have worked with JavaScript callbacks before, note that the setup with Dash is \u003cstrong\u003edifferent from a typical JavaScript control flow\u003c/strong\u003e. Instead of being event-driven, where clicking the Button \u003cstrong\u003e\u003cem\u003etriggers\u003c/em\u003e\u003c/strong\u003e the change to the P text, the callback function in Dash essentially means that the Button and P components are \u003cstrong\u003e\u003cem\u003esynchronized\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eThis synchronization means that properties of the P component (in this case, the \u003ccode\u003echildren\u003c/code\u003e attribute, which specifies the inner contents) can be automatically connected to properties of the Button component (in this case, the \u003ccode\u003en_clicks\u003c/code\u003e attribute, which counts how many times the button has been clicked).\u003c/p\u003e\n\n\u003cp\u003eThis is more like a spreadsheet cell that calculates a value based on the value of another cell; the calculation occurs as soon as the page loads, rather than waiting for a particular user interaction. This also works similarly to socket programming.\u003c/p\u003e\n\n\u003ch2\u003eBringing It All Together\u003c/h2\u003e\n\n\u003cp\u003eLet's take our Markdown + DataTable example from earlier and make it interactive!\u003c/p\u003e\n\n\u003cp\u003eSpecifically we'll add a Modal component (essentially like a pop-up, although it is part of the same HTML page) that displays additional information about a record in our DataTable when the user clicks on the table.\u003c/p\u003e\n\n\u003cp\u003eInside that Modal component, we'll display a photo of the iris type as well as a list of all attributes of the selected record.\u003c/p\u003e\n\n\u003cp\u003eThere are a lot of nested components in use here; feel free to look up more information in the \u003ca href=\"https://dash.plotly.com/dash-html-components\"\u003eDash HTML Components documentation\u003c/a\u003e and the \u003ca href=\"https://dash-bootstrap-components.opensource.faculty.ai/docs/components/\"\u003eDash Bootstrap Components documentation\u003c/a\u003e but don't worry too much about the details. The main goal is to showcase the complex layout functionality you can achieve with only about 70 lines of Python code (not counting comments)!\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eIf you have some background in front-end web development and are already familiar with Bootstrap CSS styling, you can apply that knowledge here! The same CSS styles should work here, and if you want to specify a CSS class, you can use the component attribute called \u003ccode\u003eclassName\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e########## IMPORTS ##########\n\u003c/span\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003edash_bootstrap_components\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## SETTING UP THE APP ##########\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# this time use bootstrap styles instead of Dash recommended styles\n\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethemes\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBOOTSTRAP\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create new dash app that uses the stylesheet list\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eDash\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e__name__\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eexternal_stylesheets\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## DECLARING LAYOUT COMPONENTS ##########\n\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e# markdown component is almost identical to before, we just added a line\n# telling the user to select a record\n\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edcc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\"\"\n# Iris Dataset\n\nBelow is a DataTable showing a sample of 20 records from the\n [Iris Dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\nSelect any record to view more information!\n\"\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003etable\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edash_table\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDataTable\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003efull_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003erandom_state\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eto_dict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eorient\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"records\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# we want the user to be able to select a row\n\u003c/span\u003e    \u003cspan class=\"n\"\u003erow_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"single\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# suppress default cell selection styling (we are selecting by row, not cell)\n\u003c/span\u003e    \u003cspan class=\"n\"\u003ecell_selectable\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# set an id so we can make attributes of this table into callback inputs\n\u003c/span\u003e    \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# create a modal (has built-in functionality for user to close it)\n\u003c/span\u003e\u003cspan class=\"n\"\u003emodal\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# modal header will always be the same\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalTitle\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Iris Information\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e# modal body will depend on what was clicked\n\u003c/span\u003e    \u003cspan class=\"c1\"\u003e# set and id so we can make this component's children a callback output\n\u003c/span\u003e    \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModalBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e],\u003c/span\u003e\n                  \u003cspan class=\"c1\"\u003e# set an id so we can make the modal's open/closed status\n\u003c/span\u003e                  \u003cspan class=\"c1\"\u003e# a callback output\n\u003c/span\u003e                  \u003cspan class=\"nb\"\u003eid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                  \u003cspan class=\"c1\"\u003e# by default, the modal is not open; it opens when a row\n\u003c/span\u003e                  \u003cspan class=\"c1\"\u003e# in the data table is selected\n\u003c/span\u003e                  \u003cspan class=\"n\"\u003eis_open\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n                 \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e# similar layout to before, just adding the modal to the end\n\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elayout\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emarkdown\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etable\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emodal\u003c/span\u003e\n\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## HELPER FUNCTIONS ##########\n\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Helper function that takes in a dictionary of data\n    and returns a formatted list component\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroup\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eListGroupItem\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003ev\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ek\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ev\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eitems\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    Helper function that takes in a dictionary of data\n    and returns a card with the relevant iris image and name\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"s\"\u003e\"class\"\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris setosa \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"n\"\u003eiris_class\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris versicolor \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_versicolor_3.jpg\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Iris virginica \"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"https://commons.wikimedia.org/wiki/File:Iris_virginica.jpg\"\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCard\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardImg\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_url\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCardBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eEm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n            \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSmall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eA\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"(image source)\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehref\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eimg_source\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"blank_\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e########## CALLBACKS ##########\n\u003c/span\u003e\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"is_open\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003etoggle_modal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    When the `selected_rows` attribute of the data table (id=\"tbl\") changes,\n    set the `is_open` attribute of the modal (id=\"modal\") to True\n\n    `selected_rows` is None when the page first loads, then is a list of\n    row indices that have been selected by the user\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eTrue\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"bp\"\u003eFalse\u003c/span\u003e\n\n\u003cspan class=\"o\"\u003e@\u003c/span\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecallback\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eOutput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"modal-body\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"children\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"derived_virtual_data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003eInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"tbl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"selected_rows\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)])\u003c/span\u003e\n\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erender_information\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e\"\"\"\n    When the `selected_rows` attribute of the data table (id=\"tbl\") changes,\n    set the `children` attribute of the modal body (id=\"modal-body\") to display\n    data about the selected info\n\n    We have a list of two inputs rather than just one this time, because we\n    need to know the actual contents of the row's data, not just the selected\n    index:\n      1) The `derived_virtual_data` attribute of the data table is a list of\n         dictionaries that represent the data currently being shown in the\n         table. The reason we don't just use the original dataframe that we\n         passed in to create the table is that Dash data tables can allow the\n         user to filter, edit, and delete data. We don't have these settings\n         turned on right now, but feel free to explore them!\n         For the sake of simplicity, we map the `derived_virtual_data`\n         attribute onto a parameter called `rows`.\n      2) The `selected_rows` attribute of the data table is a list of index\n         values (i.e. integers). The values in this list correspond to the\n         indices of `derived_virtual_data`.\n    \"\"\"\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"c1\"\u003e# selection is set to \"single\" so there will be exactly 1 selected row\n\u003c/span\u003e        \u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_rows\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]]\u003c/span\u003e\n\n        \u003cspan class=\"c1\"\u003e# set up a layout with one row and two columns\n\u003c/span\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003ehtml\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDiv\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRow\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003echildren\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# left column is a picture + name of the iris class\n\u003c/span\u003e            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_image_card\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e)),\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e# right column is a list of all the attributes and their values\n\u003c/span\u003e            \u003cspan class=\"n\"\u003edbc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCol\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_list_group\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eselected_row_data\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e]))\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight python\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eapp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erun_server\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"inline\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eheight\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e500\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"localhost\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e5000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we introduced the Dash library, which is built on top of Flask. Unlike Flask, Dash has functionality to render web pages directly within a Jupyter Notebook! Dash also lets us create HTML and JavaScript functionality, just by writing Python code. HTML and CSS functionality is generally created using Dash \u003cem\u003ecomponents\u003c/em\u003e, whereas JavaScript functionality is generally created using Dash \u003cem\u003ecallbacks\u003c/em\u003e. Particularly with the Dash Bootstrap Components, it is possible to create sophisticated, dynamic web pages with relatively few lines of Python code.\u003c/p\u003e","frontPage":false},{"exportId":"clustering-introduction","title":"Clustering - Introduction","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-clustering-intro\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-clustering-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn about a useful unsupervised learning technique: clustering. This lesson summarizes the topics you'll be covering in this section.\u003c/p\u003e\n\n\u003ch2\u003eClustering\u003c/h2\u003e\n\n\u003cp\u003eClustering techniques are very powerful when you want to group data with similar characteristics together, but have no pre-specified labels. The main goal of clustering is to create clusters that have a high similarity between the data belonging to one cluster while aiming for minimal similarity between clusters.  \u003c/p\u003e\n\n\u003ch3\u003eK-Means Clustering\u003c/h3\u003e\n\n\u003cp\u003eWe start by providing a basic intuition of the K-means clustering algorithm. When using the K-means clustering algorithm, the number of clusters that you want to obtain is specified upfront and the algorithm aims at the most \"optimal\" cluster centers, given that there are \u003cem\u003eK\u003c/em\u003e clusters.\u003c/p\u003e\n\n\u003ch3\u003eHierarchical Agglomerative Clustering\u003c/h3\u003e\n\n\u003cp\u003eA second branch of clustering algorithms is hierarchical agglomerative clustering. Using hierarchical clustering, unlike K-means clustering, you don't decide on the number of clusters beforehand. Instead, you start with \u003cem\u003en\u003c/em\u003e clusters, where \u003cem\u003en\u003c/em\u003e is the number of data points, and at each step you join two clusters. You stop joining clusters when a certain criterion is reached.\u003c/p\u003e\n\n\u003ch3\u003eSemi-Supervised Learning\u003c/h3\u003e\n\n\u003cp\u003eSemi-supervised learning techniques, which are increasingly popular in machine learning, combine both concepts of supervised and unsupervised learning.\u003c/p\u003e\n\n\u003ch3\u003eMarket Segmentation with Clustering\u003c/h3\u003e\n\n\u003cp\u003eA very common and useful application of clustering is market segmentation. You'll practice your clustering skills on a market segmentation dataset!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll learn how to use clustering techniques which are very useful for finding patterns and grouping unlabeled data together.\u003c/p\u003e","frontPage":false},{"exportId":"topic-33-lesson-priorities-live","title":"Topic 33 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 97px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete Before \u003cem\u003eK-Means Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Short Video: Calculating a Silhouette Coefficient\" href=\"pages/short-video-calculating-a-silhouette-coefficient\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/short-video-calculating-a-silhouette-coefficient\" data-api-returntype=\"Page\"\u003eShort Video: Calculating a Silhouette Coefficient\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Clustering - Introduction\" href=\"pages/clustering-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/clustering-introduction\" data-api-returntype=\"Page\"\u003eClustering - Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"K-means Clustering\" href=\"pages/k-means-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/k-means-clustering\" data-api-returntype=\"Page\"\u003eK-means Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"K-Means Clustering - Lab\" href=\"assignments/ge8a1cb59b882d6b7be9e15aeb4718b6a\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187120\" data-api-returntype=\"Assignment\"\u003eK-Means Clustering - Lab\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.9064%; height: 168px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eK-Means Clustering\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eHierarchical Agglomerative Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.4187%;\"\u003e\u003cstrong\u003e\u003ca title=\"k-Means Clustering Exit Ticket\" href=\"quizzes/g8cb1c0407af1052fa6e18a30712ec5ec\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30671\" data-api-returntype=\"Quiz\"\u003ek-Means Clustering Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Hierarchical Agglomerative Clustering\" href=\"pages/hierarchical-agglomerative-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/hierarchical-agglomerative-clustering\" data-api-returntype=\"Page\"\u003eHierarchical Agglomerative Clustering\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Common Problems with Clustering Algorithms\" href=\"pages/common-problems-with-clustering-algorithms\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/common-problems-with-clustering-algorithms\" data-api-returntype=\"Page\"\u003eCommon Problems with Clustering Algorithms\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Semi-Supervised Learning and Look-Alike Models\" href=\"pages/semi-supervised-learning-and-look-alike-models\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/semi-supervised-learning-and-look-alike-models\" data-api-returntype=\"Page\"\u003eSemi-Supervised Learning and Look-Alike Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Clustering\" href=\"quizzes/g5dfff80ace5a749b059276ee443dd711\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30669\" data-api-returntype=\"Quiz\"\u003eQuiz: Clustering\u003c/a\u003e\u0026nbsp;\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8127%; height: 138px;\" border=\"1\"\u003e\u003ccaption\u003ePriorities to Complete After \u003cem\u003eHierarchical Agglomerative Clustering\u003c/em\u003e Lecture\u003c/caption\u003e\n\u003ctbody\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003cth style=\"width: 42.4187%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n\u003cth style=\"width: 8.50094%; text-align: center; height: 30px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"width: 42.4187%;\"\u003e\u003ca title=\"Short Video: Calculating a Silhouette Coefficient\" href=\"pages/short-video-calculating-a-silhouette-coefficient\"\u003eShort Video: Calculating a Silhouette Coefficient\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; text-align: center;\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003cstrong\u003e\u003ca title=\"Hierarchical Clustering Exit Ticket\" href=\"quizzes/g8638d28fb34d210eaaac9b6fa0ecde05\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30675\" data-api-returntype=\"Quiz\"\u003eHierarchical Clustering Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Market Segmentation with Clustering\" href=\"pages/market-segmentation-with-clustering\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/market-segmentation-with-clustering\" data-api-returntype=\"Page\"\u003eMarket Segmentation with Clustering\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Market Segmentation with Clustering - Lab\" href=\"assignments/gab7e93076acfc2552dcf83a0c4d8c33c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187124\" data-api-returntype=\"Assignment\"\u003eMarket Segmentation with Clustering - Lab\u003c/a\u003e\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cspan\u003e2nd*\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr style=\"height: 30px;\"\u003e\n\u003ctd style=\"width: 42.4187%; height: 30px;\"\u003e\u003ca title=\"Clustering - Recap\" href=\"pages/clustering-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/clustering-recap\" data-api-returntype=\"Page\"\u003eClustering - Recap\u003c/a\u003e\u0026nbsp;\u003c/td\u003e\n\u003ctd style=\"width: 8.50094%; height: 30px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e*This lab may be used for a pairing exercise and might not be published yet; contact your instructor if you have questions\u003c/p\u003e","frontPage":false},{"exportId":"topic-36-lesson-priorities-live","title":"Topic 36 Lesson Priorities (Live)","type":"WikiPage","content":"\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 99.8857%; height: 95px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete Before \u003cem\u003eBig Data Introduction\u003c/em\u003e Lecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Big Data and (Py)Spark - Introduction\" href=\"pages/big-data-and-py-spark-introduction\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/big-data-and-py-spark-introduction\" data-api-returntype=\"Page\"\u003eBig Data and (Py)Spark - Introduction\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Introduction to Big Data\" href=\"pages/introduction-to-big-data\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/introduction-to-big-data\" data-api-returntype=\"Page\"\u003eIntroduction to Big Data\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 53px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 10px;\"\u003e\u003ca title=\"Parallel and Distributed Computing with MapReduce\" href=\"pages/parallel-and-distributed-computing-with-mapreduce\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/parallel-and-distributed-computing-with-mapreduce\" data-api-returntype=\"Page\"\u003eParallel and Distributed Computing with MapReduce\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 10px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd style=\"width: 35.11%;\"\u003e\u003cstrong\u003e\u003ca title=\"(Py)Spark Basics\" href=\"pages/py-spark-basics\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/py-spark-basics\" data-api-returntype=\"Page\"\u003e(Py)Spark Basics\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.229%; height: 242px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete After \u003cem\u003eBig Data Introduction\u003c/em\u003e Lecture, Before\u0026nbsp;\u003cem\u003eSpark\u0026nbsp;\u003c/em\u003eLecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd style=\"width: 35.11%;\"\u003e\u003cstrong\u003e\u003ca title=\"Big Data 1 Exit Ticket\" href=\"quizzes/g188723d464955f60bb59d6ca8d4ecbe7\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30679\" data-api-returntype=\"Quiz\"\u003eBig Data 1 Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Installing and Configuring PySpark with Docker\" href=\"pages/installing-and-configuring-pyspark-with-docker\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/installing-and-configuring-pyspark-with-docker\" data-api-returntype=\"Page\"\u003eInstalling and Configuring PySpark with Docker\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e2nd*\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Understanding SparkContext - Codealong\" href=\"assignments/g294b94461ee6e9572f786a2e6bb0659b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187165\" data-api-returntype=\"Assignment\"\u003eUnderstanding SparkContext - Codealong\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 53px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 10px;\"\u003e\u003ca title=\"Resilient Distributed Datasets (RDDs) - Lab\" href=\"assignments/g2f77863d15f7cdaae1efb4cd6c8dd382\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187149\" data-api-returntype=\"Assignment\"\u003eResilient Distributed Datasets (RDDs) - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 10px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Word Count with MapReduce - Lab\" href=\"assignments/gda1b3b7f840139ea7429bdb7e29b0a3f\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187173\" data-api-returntype=\"Assignment\"\u003eWord Count with MapReduce - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 29px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Spark DataFrames\" href=\"assignments/gbb401e4ed8174cf280ef12f218168b8b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187152\" data-api-returntype=\"Assignment\"\u003eSpark DataFrames\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; text-align: center; height: 29px;\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Machine Learning with Spark\" href=\"assignments/geb081d1079ab27f821ff41228da6e22b\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187121\" data-api-returntype=\"Assignment\"\u003eMachine Learning with Spark\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Machine Learning with Spark -  Lab\" href=\"assignments/ga40052b34f7e3efc7a91e89bac792750\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187122\" data-api-returntype=\"Assignment\"\u003eMachine Learning with Spark - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;2nd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Quiz: Big Data in PySpark\" href=\"quizzes/g9c577f9088ef666a272048004754cb3c\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30673\" data-api-returntype=\"Quiz\"\u003eQuiz: Big Data in PySpark\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e*Installing PySpark is important if you want to use it for your project, or to follow along with lecture content on your local machine. If you just want to go through the lessons and labs, you can do so on IllumiDesk without any additional installation steps.\u003c/p\u003e\n\u003ctable style=\"border-collapse: collapse; width: 100.229%; height: 84px;\" border=\"1\"\u003e\n    \u003ccaption\u003ePriorities to Complete After \u003cem\u003eSpark\u003c/em\u003e\u0026nbsp;Lecture\u003c/caption\u003e\n    \u003ctbody\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003cth style=\"width: 35.11%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003eLesson\u003c/strong\u003e\u003c/th\u003e\n            \u003cth style=\"width: 8.61899%; text-align: center; height: 29px;\" scope=\"col\"\u003e\u003cstrong\u003ePriority\u003c/strong\u003e\u003c/th\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Short Video: sklearn to pyspark\" href=\"pages/short-video-sklearn-to-pyspark\" data-api-endpoint=\"pages/short-video-sklearn-to-pyspark?module_item_id=mastercourse_15802_382_11deed98de38e4b0d2396caeee891876\" data-api-returntype=\"Page\"\u003eShort Video: sklearn to pyspark\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n      \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003cstrong\u003e\u003ca title=\"Spark Exit Ticket\" href=\"quizzes/g7eef4fe2befd6ecccfbf8cdd086abbaa\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/quizzes/30684\" data-api-returntype=\"Quiz\"\u003eSpark Exit Ticket\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;1st\u0026quot;}\"\u003e\u003cstrong\u003e1st\u003c/strong\u003e\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Building a Recommendation System in PySpark - Lab\" href=\"assignments/g45c3dc138b3452c222b28c9ae7968aea\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/assignments/187093\" data-api-returntype=\"Assignment\"\u003eBuilding a Recommendation System in PySpark - Lab\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e2nd\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr style=\"height: 30px;\"\u003e\n            \u003ctd style=\"width: 35.11%; height: 29px;\"\u003e\u003ca title=\"Big Data and (Py)Spark - Recap\" href=\"pages/big-data-and-py-spark-recap\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/5827/pages/big-data-and-py-spark-recap\" data-api-returntype=\"Page\"\u003eBig Data and (Py)Spark - Recap\u003c/a\u003e\u003c/td\u003e\n            \u003ctd style=\"width: 8.61899%; height: 29px; text-align: center;\" data-sheets-value=\"{\u0026quot;1\u0026quot;:2,\u0026quot;2\u0026quot;:\u0026quot;3rd\u0026quot;}\"\u003e3rd\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e","frontPage":false},{"exportId":"deep-nlp-with-word-embeddings-introduction","title":"Deep NLP with Word Embeddings - Introduction","type":"WikiPage","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this section you'll strengthen your deep learning and natural language processing skills by learning about word embeddings! Word embeddings are a unique coding schema for text corpora that preserve many underlying features, allowing for interesting geometric relations in this hyperspace. Specifically, you'll look at how similarity metrics can represent how two words relate to each other, and these transformations can be applied to multiple word pairs. For example, a similarity metric could encapsulate analogies like \"man is to woman as king is to ____\". \u003c/p\u003e\n\n\u003ch3\u003eWord Embeddings\u003c/h3\u003e\n\n\u003cp\u003eIn this section, you'll learn about the concept of word embeddings, and how you can use them to model the semantic meanings of words in a high-dimensional embedding space! Word embeddings use similarity metrics to represent how two words relate to each other. This way, we can understand the words in our corpus to a bigger extent. A typical example is the example of \"Man\" vs \"woman\" and \"king\" vs \"queen\": word embeddings can capture that the word \"man\" relates to the word \"woman\" the same way the word \"king\" relates to \"queen\"!\u003c/p\u003e\n\n\u003ch3\u003eUsing Word2Vec\u003c/h3\u003e\n\n\u003cp\u003eCreating word embeddings is not an easy task. Word embeddings can be created using so-called \"Word2Vec\" models that are  given enough training data. At its core, Word2Vec is just another deep neural network, that looks at sequences of words and words that are often used in similar contexts (or \u003cem\u003eclose\u003c/em\u003e to each other in sentences). In this section you'll learn how to train a Word2Vec model, and you'll explore the embedding space.\u003c/p\u003e\n\n\u003ch3\u003eClassification with Word Embeddings\u003c/h3\u003e\n\n\u003cp\u003eTo wrap up this section, we'll focus on the practical aspects of how Word2Vec and word embeddings can be used to improve our text classification models. We'll start by learning how transfer learning can be used by loading pre-trained word vectors into our Word2Vec model. Then, we'll learn about how we can get the word vectors we need and combine them into mean word vectors, and how we can streamline this process by writing our own vectorizer class that is compatible with scikit-learn pipelines. Next, we'll see how deep neural networks with their own embedding layers can be trained, and how Keras preprocesses the text data to make everything run smoothly!\u003c/p\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this section, you'll dive deeper into NLP and get better classification results using word embeddings!\u003c/p\u003e\n\u003cfooter class=\"fis-footer\" style=\"visibility: hidden;\"\u003e\u003cdiv class=\"fis-feedback\"\u003e\n\u003ch5\u003eHow do you feel about this lesson?\u003c/h5\u003e\n\u003cimg id=\"thumbs-up\" data-repository=\"dsc-deep-nlp-intro\" title=\"Thumbs up!\" alt=\"thumbs up\"\u003e\u003cimg id=\"thumbs-down\" data-repository=\"dsc-deep-nlp-intro\" title=\"Thumbs down!\" alt=\"thumbs down\"\u003e\n\u003c/div\u003e\n\u003ch5\u003eHave specific feedback? \u003ca href=\"https://github.com/learn-co-curriculum/dsc-deep-nlp-intro/issues/new\"\u003eTell us here!\u003c/a\u003e\n\u003c/h5\u003e\u003c/footer\u003e","frontPage":false},{"exportId":"introduction-to-big-data","title":"Introduction to Big Data","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-big-data-introduction\"\u003e\u003c/div\u003e\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn the information age, data in huge quantities has become available to analysts and decision-makers. Due to a vast increase in the amount of such data in recent times, a number of specialized platforms and development paradigms have been developed that can handle big data. Using such specialist approaches allows data scientists to gain valuable insights from complex data, ranging from daily transactions to customer interactions and social network data.\u003c/p\u003e\n\n\u003cp\u003eThis section aims to focus on some of the different analytical approaches and tools data scientists apply to big data in order to gain valuable insights that aid business decision making. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the domain areas where big data is particularly useful \u003c/li\u003e\n\u003cli\u003eList the technologies associated with big data \u003c/li\u003e\n\u003cli\u003eDescribe the 3 V's of big data and how they differentiate big data from routine data \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eWhat is Big Data\u003c/h2\u003e\n\n\u003cp\u003eThe topic of \"big data\" has received a lot of hype lately, accompanied by a huge amount of interest from big businesses as it can potentially provide them data-driven decision-making abilities. Big data is one of the most discussed topics in business today across industry sectors, although it was barely known a few years ago. This lesson will focus on what big data is, why it is important, and the benefits it brings. \u003c/p\u003e\n\n\u003cp\u003eBig data is no different than normal data that we have seen so far; it's only \"bigger.\" This changes the analytical landscape that must be used as the huge size increase of the data requires specialized tools, techniques, and platforms. It helps us solve new problems and find improved ways to find answers to old problems. \u003c/p\u003e\n\n\u003ch3\u003eDefining Big Data\u003c/h3\u003e\n\n\u003cp\u003eDespite all the hype around this topic, there is no clear consensus on how to define  \u003cstrong\u003ebig data\u003c/strong\u003e. The term often gets related to business analytics and data mining for identifying relationships and associations present in huge amounts of transaction data.  \u003c/p\u003e\n\n\u003cp\u003eIn the data science domain, big data usually refers to datasets that grow so large that they become awkward to work with using traditional database management systems and analytical approaches. They are datasets whose size is beyond the ability of commonly used software tools and storage systems to capture, store, manage, as well as process the data within a tolerable elapsed time.\u003c/p\u003e\n\n\u003ch4\u003eHow Big is \"Big\" Data?\u003c/h4\u003e\n\n\u003cp\u003eBig data sizes are constantly increasing, currently ranging from a few terabytes (TB) to many petabytes (PB) of data in a single dataset. Consequently, some of the difficulties related to big data include capturing, storing, searching, sharing, analyzing, and visualizing. Today, enterprises are exploring large volumes of highly detailed data to discover trends and pieces of information considered incapable of being captured before. \u003c/p\u003e\n\n\u003cp\u003eHere are some of the examples of big data:  \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eWeb traffic data: Data points such as number of page views, previous web page, user information, advertisement click-through rate, pages per visit, average visit duration  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eText data: Emails, tweets, news reports, voice recordings, and text gathered from crawling the web can make massive datasets that are valuable to data scientists  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eLocation and time data: GPS data helps Google determine which roads have higher traffic and which businesses will be busier at certain hours  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eSocial network data: Using the information of relationships between users on Facebook, LinkedIn, Twitter, Reddit, and countless other websites and apps  \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eSmart grid and sensor data: With the advent of the Internet of Things (IoT), more and more devices are able to record data at all times, making it possible to gather lots of data instantaneously  \u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003e3 V's of Big Data\u003c/h2\u003e\n\n\u003cp\u003eDoug Laney published a \u003ca href=\"https://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf\"\u003epaper\u003c/a\u003e on three defining characteristics of big data. Three main features characterize big data: volume, variety, and velocity, or the three V‚Äôs. The volume of the data is its size, and how enormous it is. Velocity refers to the rate with which data is changing, or how often it is created. Finally, variety includes the different formats and types of data, as well as the different kinds of uses and ways of analyzing the data:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/3_components.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eLet's look a bit deeper into what these 3 V's refer to:\u003c/p\u003e\n\n\u003ch3\u003eVOLUME\u003c/h3\u003e\n\n\u003cp\u003eVolume refers to the \u003cstrong\u003eamount of data\u003c/strong\u003e generated through websites, portals, and online applications in a data-driven business. Especially for online retailers, volume encompasses the available data that are out there and need to be assessed for relevance. \u003c/p\u003e\n\n\u003cp\u003eConsider the following:\u003c/p\u003e\n\n\u003cp\u003eAs of 2019, Facebook has 2.32 billion users, Youtube: 1.9 billion users, WhatsApp: 1.6 billion users and Instagram: 1 billion users. Every day, these users contribute to billions of images, posts, videos, tweets, etc. You can now imagine the insanely large amount (or \u003cstrong\u003ev\u003c/strong\u003eolume) of data that is generated every minute around the world.\nData volume is the primary attribute of big data. Big data can be quantified by size in Terabytes (TBs) or Petabytes (PBs), as well as even the number of records, transactions, tables, or files. Additionally, one of the things that makes big data really big is that it‚Äôs coming from a greater variety of sources than ever before, including logs, clickstreams, and social media as we will see below. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/rank_users.png\" width=\"650\"\u003e\u003c/p\u003e\n\n\u003ch3\u003eVELOCITY\u003c/h3\u003e\n\n\u003cp\u003eVelocity refers to the speed with which data is generated, and as internet speeds have increased and the number of users has increased, the velocity has also increased substantially.\u003c/p\u003e\n\n\u003cp\u003eThe following image created by \u003ca href=\"https://www.allaccess.com/merge/archive/29580/2019-this-is-what-happens-in-an-internet-minute\"\u003eLori Lewis and Chadd Callahan\u003c/a\u003e shows what happens on major social media platforms in one minute. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/internet_minute.jpg\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eVelocity is basically the frequency of data generation or the frequency of data delivery. The leading edge of\nbig data is streaming data, which is collected in real-time from the websites. \u003c/p\u003e\n\n\u003cp\u003eTools within the big data stack help companies hold this explosion in velocity, accept the incoming flow of data, and at the same time process it quickly enough so that it does not create bottlenecks.\u003c/p\u003e\n\n\u003ch3\u003eVARIETY\u003c/h3\u003e\n\n\u003cp\u003eVariety in big data refers to all the structured and unstructured data that has the possibility of getting generated either by humans or by machines. Structured data is whatever data you could store in a spreadsheet. It can easily be cataloged and summary statistics can be calculated for it. Unstructured data are raw things like texts, tweets, pictures, videos, emails, voice mails, hand-written text, ECG readings, and audio recordings. Humans can only make sense of data that is structured, and it is usually up to data scientists to create some organization and structure to unstructured data.\u003c/p\u003e\n\n\u003cp\u003eVariety is all about the ability to classify the incoming data into various categories and turn unstructured data into something with more structure.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/unstructured_data.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eThis leads us to the most widely used definition in the industry by Gartner: \u003c/p\u003e\n\n\u003ch3\u003e\u003cem\u003eBig data is high-volume, high-velocity and/or high-variety information assets that demand cost-effective, innovative forms of information processing that enable enhanced insight, decision making, and process automation\u003c/em\u003e.\u003c/h3\u003e\n\n\u003cp\u003eAny data sources that fall under those 3 Vs are sources of big data, no matter how you define it.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eNOTE\u003c/strong\u003e: \u003cem\u003eSome researchers have discussed the addition of a fourth V, or \u003cstrong\u003eVeracity\u003c/strong\u003e. Veracity focuses on the quality of the data. This characterizes big data quality as good, bad, or undefined due to data inconsistency, incompleteness, ambiguity, latency, deception, and approximations\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eThe important thing to remember from this three-pronged definition of Big Data is that there is not a single component that makes data \"big\" or not. It is also a futile effort to try and make a definition of what the threshold is to make something \"big data\" rather than normal data. As technologies evolve and new distributed algorithms are created, what was once big data will no longer be big, and we will raise the bar.\u003c/p\u003e\n\n\u003ch2\u003eBig Data Analytics\u003c/h2\u003e\n\n\u003cp\u003eWith the evolution of technology and the increased amounts of data, as discussed above, the need for faster and more efficient ways of analyzing such data has also grown exponentially. Having big data \u003cstrong\u003ealone\u003c/strong\u003e is no longer enough to make efficient decisions at the right time. As we mentioned above, Big Data cannot be easily analyzed with traditional data management and analysis techniques and infrastructures. Therefore, there arises a need for new\ntools and methods specialized for big data analytics, as well as the required architectures for storing and managing such data. Accordingly, the emergence of big data has an effect on everything from the data itself to its collection, analysis, and visualization, as well as the final extracted decisions.\u003c/p\u003e\n\n\u003cp\u003eThe image below shows the technology stack, or the key tools and platforms being heavily employed in big data analytics today. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/tech_stack.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eExplaining each one of these tools/platforms etc. is outside the scope of this lesson. You are, however, encouraged to look up these technologies and see their role in big data analytics. Such a stack maps the different big data storage, management, analytics tools/methods, visualization, and evaluation tools to the different phases of the decision-making process. \u003c/p\u003e\n\n\u003cp\u003eThe key activities associated with big data analytics are reflected in four main areas: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBig data warehousing and distribution\u003c/li\u003e\n\u003cli\u003eBig data storage\u003c/li\u003e\n\u003cli\u003eBig data computational platforms\u003c/li\u003e\n\u003cli\u003eBig data analyses, visualization, and evaluation\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSuch a framework can be applied for knowledge discovery and informed decision-making in big data-driven organizations.\u003c/p\u003e\n\n\u003ch3\u003eExample Business Applications of Big Data Analytics\u003c/h3\u003e\n\n\u003cp\u003eAlong with some of the most common advanced data analytics methods such as regression analysis, association rules, clustering, and classification, some additional analyses have become common with big data.\u003c/p\u003e\n\n\u003cp\u003eFor example, social media has recently become important for social networking and content sharing. Yet, the content that is generated from social media websites is enormous and remains largely unexploited. However, social media analytics can be used to analyze such data and extract useful information and predictions.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/social_media.png\" width=\"600\"\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSocial media analytics\u003c/strong\u003e is based on developing and evaluating informatics frameworks and tools in order to collect, monitor, summarize, analyze, as well as visualize social media data. \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSocial media analytics facilitates understanding the reactions and conversations between people in online communities, as well as extracting useful patterns and intelligence from their interactions and what they share on social media websites.\u003c/p\u003e\n\n\u003cp\u003eOn the other hand, \u003cstrong\u003etext mining\u003c/strong\u003e and \u003cstrong\u003eNLP\u003c/strong\u003e techniques are used to analyze a document or set of documents in order to understand the content within and the meaning of the information contained. Text mining has become very important nowadays since much of the information stored consists of text - in the form of emails, SMS texts, social media feeds, blogs, etc. While data mining deals with structured data, text presents special characteristics which basically follow a non-relational form and require wisely thought-out schemas to grant it more structure.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/nlp.png\" width=\"200\"\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eSentiment analysis/opinion mining\u003c/strong\u003e is also becoming more and more important as online opinion data, such as blogs, product reviews, forums, and social data from social media sites, like Twitter and Facebook, grow tremendously. \u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSentiment Analysis\u003c/strong\u003e focuses on analyzing and understanding emotions from subjective text patterns and is enabled through text mining. It identifies the opinions and attitudes of individuals towards certain topics, and it is useful in classifying viewpoints as positive or negative. \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/sentiment_2.png\" width=\"500\"\u003e\u003c/p\u003e\n\n\u003cp\u003eSentiment analysis uses NLP and text analytics in order to identify and extract information by finding words that are indicative of certain sentiments, as well as relationships between words so that sentiments can be accurately identified.\u003c/p\u003e\n\n\u003cp\u003eAnd finally, one of the leading applications in big data analytics is \u003cstrong\u003erecommendation systems\u003c/strong\u003e. Powerful recommendation engines can be built for anything from movies and videos to music, books, and products as offered by Netflix, Pandora, or Amazon. As customers of an online retailer browse through products, the Recommendation system offers recommendations of products they might be interested in. In our daily online browsing and shopping routine, most of us often come across messages like the one shown below. This is a recommendation system doing its job. \u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"https://github.com/learn-co-curriculum/dsc-big-data-introduction/raw/master/images/rec.png\" width=\"800\"\u003e\u003c/p\u003e\n\n\u003cp\u003eRecommendation systems have been immensely beneficial for both businesses and consumers. Big data is the driving force behind recommendation systems. A typical recommendation system cannot do its job without sufficient data and big data supplies plenty of user data such as past purchases, browsing history, and feedback for the recommendation systems to provide relevant and effective recommendations. In a nutshell, even the most advanced recommendations cannot be effective without big data.\u003c/p\u003e\n\n\u003ch3\u003eSo what's next?\u003c/h3\u003e\n\n\u003cp\u003eAfter this quick introduction, we will look at MapReduce, a distributed computation platform designed to incorporate big data analytics and how it is used by Hadoop/Apache Spark development environments to analyze big data. \u003c/p\u003e\n\n\u003ch2\u003eAdditional Reading\u003c/h2\u003e\n\n\u003cp\u003eBig data is a huge subject and incorporates a lot of underlying technologies and principles. You are advised to visit the following resources and read up on big data to develop a sound and holistic understanding of the domain. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=0cizsKDn3TI\"\u003eYoutube: Big Data Trap\u003c/a\u003e - Highly recommended, an excellent lecture on the social dimension of big data.\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.educba.com/big-data-vs-data-science/\"\u003eBig Data vs Data Science\u003c/a\u003e - How to relate big data analytics to routine analytics that we have so far!\u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://pdfs.semanticscholar.org/d392/0f02dbb15da19b04d782fc0546ef113e0bf7.pdf\"\u003eBig Data Analytics\u003c/a\u003e - A great paper summarizing big-data-related terms, ideas, etc. \u003c/p\u003e\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://web.archive.org/web/20200214174508/https://www.ntnu.no/iie/fag/big/lessons/lesson2.pdf\"\u003eIntroduction to Big Data\u003c/a\u003e - A paper discussing the basics of big data\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this introductory lesson on big data, we looked at what data qualifies as \"big data\". We looked at how it is hard to come up with a standard definition of big data due to the variety of its applications and use cases. Up next, we will get into how we actually make parallelizable applications that are efficient with big data. \u003c/p\u003e","frontPage":false},{"exportId":"sequence-model-use-cases","title":"Sequence Model Use Cases","type":"WikiPage","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-sequence-model-use-cases\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sequence-model-use-cases\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sequence-model-use-cases/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you'll learn about \u003cstrong\u003e\u003cem\u003eSequence Models\u003c/em\u003e\u003c/strong\u003e, and what makes them different from traditional multi-layer perceptrons. You'll also examine some of the common things sequence models can be used for!\u003c/p\u003e\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDefine a Sequence Model\u003c/li\u003e\n\u003cli\u003eList some of the use cases for Sequence Models\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eWhat is a Sequence Model?\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003e\u003cem\u003eSequence Model\u003c/em\u003e\u003c/strong\u003e is a general term for a special class of deep neural networks that work with time series of data as input (or any data where you want the model to consider the data one point at a time, in order). This means that they are great for problems where the order of the data matters - for instance, stock price data or text. In both cases, the data only makes sense in order. For instance, scrambling the words in a sentence destroys the meaning of the sentence, and it's impossible to predict if a stock price is going to go up or down if you don't see the prices in sequential order. In both cases, the sequence of the data matters.\u003c/p\u003e\n\u003cp\u003eConsider the following problem: you are given the sentence \"you are going to\" and asked to complete the sentence by generating at least 5 more words. The second word that you choose will depend heavily on the first word that you choose. The third word that you choose will depend heavily on the first and second words that you choose, and so on. Because of this, it is crucial that the models \u003cem\u003eremember\u003c/em\u003e the previous words that they generated. In computer science, you call this being \u003cstrong\u003e\u003cem\u003estateful\u003c/em\u003e\u003c/strong\u003e. This means that when the model is generating the second word, it needs to know what it generated as the first word! To do this, \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e feed their output for timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=%5Clarge%20x_t\"\u003e back into the model as input for timestep \u003cimg src=\"https://render.githubusercontent.com/render/math?math=%5Clarge%20x_%7Bt%20%2b%201%7D\"\u003e !\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/rnn.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eThere are many different kinds of sequence models, and they are most generally referred to as \u003cstrong\u003e\u003cem\u003eRecurrent Neural Networks\u003c/em\u003e\u003c/strong\u003e, or \u003cstrong\u003e\u003cem\u003eRNNs\u003c/em\u003e\u003c/strong\u003e. In the next lesson, you'll dig into how they work. Let's examine some of the things that RNNs can do!\u003c/p\u003e\n\u003ch2\u003eSequence Model Use Cases\u003c/h2\u003e\n\u003ch3\u003eText Classification\u003c/h3\u003e\n\u003cp\u003eOne of the most common applications of RNNs is for plain old text classification. Recall that all the models that you've used so far for text generation have been incapable of focusing on the order of the words, which means that they're likely to miss out on more advanced pieces of information such as connotation, context, sarcasm, etc. However, since RNNs examine the words one at a time and remember what they've seen at each time step, they're able to capture this information quite effectively in most cases! As the final part of this section, we'll actually build one of these models which will be able to detect toxic comments from real-world Wikipedia comments!\u003c/p\u003e\n\u003ch3\u003eSequence Generation\u003c/h3\u003e\n\u003cp\u003eSequence generation is probably some of the most incredible things you can do with neural networks, because they excel at coming up with wacky, almost-human sounding names for things when fed the right data. For instance, all of the following cookie names were generated by feeding a dataset of actual cookie names from recipes. The model was built to generate it's own cookie names letter by letter, based on what it saw in the recipe names. Since the model is responsible for generating its own output letter by letter, one at a time, this makes it a prime example of \u003cstrong\u003e\u003cem\u003eSequence Generation\u003c/em\u003e\u003c/strong\u003e!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/rnn_cookie_names.png\"\u003e\u003c/p\u003e\n\u003ch3\u003eSequence-to-Sequence Models\u003c/h3\u003e\n\u003cp\u003eIf you've ever used Google Translate before, then you've already interacted with a \u003cstrong\u003e\u003cem\u003eSequence to Sequence Model\u003c/em\u003e\u003c/strong\u003e. These models learn to map an input sequence to an output sequence, usually through an \u003cstrong\u003e\u003cem\u003eEncoder-Decoder\u003c/em\u003e\u003c/strong\u003e architecture. Note that although going from a sequence of English words to the corresponding sequence of French words is probably the basic example of Sequence to Sequence models, there are many other kinds of problems that are Sequence to Sequence that aren't immediately obvious. For instance, check out this example of a neural network that completes drawings of a mosquito based on how you start drawing the bug!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/multi_sketch_mosquito.gif\"\u003e\u003c/p\u003e\n\u003cp\u003eHere's another example from \u003ca href=\"https://phillipi.github.io/pix2pix/\"\u003epix2pix\u003c/a\u003e. Now, stop what you're doing, follow that link, and take a few minutes to play around with pix2pix -- watching it generate photos from your own drawings is really cool!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-sequence-model-use-cases/master/images/pix2pix.gif\"\u003e\u003c/p\u003e\n\u003ch2\u003eSummary\u003c/h2\u003e\n\u003cp\u003eIn this lesson, you learned about sequence models, and some of their more common use cases.\u003c/p\u003e","frontPage":false}],"assignments":[{"exportId":"g7a5c7a20ee6168c80c5a3b5385a1219a","title":"Amazon Recommendation System - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recomendation-systems-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recomendation-systems-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gf868208900f3e52add61497dd6c38a20","title":"ARMA Models in StatsModels","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models-statsmodels\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll use your knowledge of the autoregressive (AR) and moving average (MA) models, along with the \u003ccode\u003estatsmodels\u003c/code\u003e library to model time series data. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eFit an AR model using \u003ccode\u003estatsmodels\u003c/code\u003e \u003c/li\u003e\n\u003cli\u003eFit an MA model using \u003ccode\u003estatsmodels\u003c/code\u003e \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gc3248cd9dd99557b6439eb760221ba01","title":"ARMA Models in StatsModels - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-arma-models-statsmodels-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-arma-models-statsmodels-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll fit an ARMA model using \u003ccode\u003estatsmodels\u003c/code\u003e to a real-world dataset. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDecide the optimal parameters for an ARMA model by plotting ACF and PACF and interpreting them \u003c/li\u003e\n\u003cli\u003eFit an ARMA model using StatsModels \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g93c55fdf39a2cc133da1d60ed47dc1d4","title":"Basic Time Series Models","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-basic-time-series-models\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eWe've looked at time series and what they might look like. Now why do we need to model time series? Essentially, you're trying to find patterns and understand the data in a way that you \ncan use this information to (hopefully) make accurate predictions about the future.\u003c/p\u003e\n\n\u003cp\u003eIn this lesson you'll learn about two basic time series models: the white noise and random walk models.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the properties of a white noise model \u003c/li\u003e\n\u003cli\u003eExplain the properties of a random walk model \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g1d58818d312c4d5f9f62f3dc6c1b782b","title":"Basic Time Series Models - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-basic-time-series-models-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-basic-time-series-models-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have some basic understanding of the white noise and random walk models, its time for you to implement them! \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerate and analyze a white noise model \u003c/li\u003e\n\u003cli\u003eGenerate and analyze a random walk model \u003c/li\u003e\n\u003cli\u003eImplement differencing in a random walk model \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gc0c371179354c474eb62d3e35ada83d6","title":"Building a CNN from Scratch - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-building-a-cnn-from-scratch\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-building-a-cnn-from-scratch\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-building-a-cnn-from-scratch/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have background knowledge regarding how CNNs work and how to build them using Keras, its time to practice those skills a little more independently in order to build a CNN on your own to solve a image recognition problem. In this lab, you'll practice building an image classifier from start to finish using a CNN.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad images from a hierarchical file structure using an image datagenerator \u003c/li\u003e\n\u003cli\u003eApply data augmentation to image files before training a neural network \u003c/li\u003e\n\u003cli\u003eBuild a CNN using Keras \u003c/li\u003e\n\u003cli\u003eVisualize and evaluate the performance of CNN models \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g45c3dc138b3452c222b28c9ae7968aea","title":"Building a Recommendation System in PySpark - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"als-recommender-system-pyspark-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/als-recommender-system-pyspark-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/als-recommender-system-pyspark-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we will implement a movie recommendation system using ALS in Spark programming environment. Spark's machine learning library \u003ccode\u003eml\u003c/code\u003e comes packaged with a very efficient implementation of the ALS algorithm that we looked at in the previous lesson. The lab will require you to put into practice your Spark programming skills for creating and manipulating PySpark DataFrames. We will go through a step-by-step process into developing a movie recommendation system using ALS and PySpark using the \u003ccode\u003eMovieLens\u003c/code\u003e dataset that we used in a previous lab.\u003c/p\u003e\n\n\u003cp\u003eNote: You are advised to refer to \u003ca href=\"http://spark.apache.org/docs/2.2.0/api/python/index.html\"\u003ePySpark documentation\u003c/a\u003e heavily for completing this lab as it will introduce a few new methods. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse Spark to train and cross-validate an ALS model \u003c/li\u003e\n\u003cli\u003eIntroduce a new user with rating to a rating matrix and make recommendations for them \u003c/li\u003e\n\u003cli\u003eCreate a function that will return the top n recommendations for a user \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g4542f7e2ca39617c6d3b3e57a39c97aa","title":"Classification with Word Embeddings - Codealong","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-classification-with-word-embeddings-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g935c2c028baa43d2098a808afe5a8065","title":"Collaborative Filtering with Singular Value Decomposition","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-collaborative-filtering-singular-value-decomposition\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-collaborative-filtering-singular-value-decomposition\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-collaborative-filtering-singular-value-decomposition/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eRecommendation Systems apply IR (Information Retrieval techniques) to select some information relevant to a given user. \u003cstrong\u003eCollaborative Filtering (CF)\u003c/strong\u003e is currently the most widely used approach to build recommendation systems and uses the users‚Äô behavior in the form of user-item ratings for predictions. CF often uses \u003cstrong\u003eMatrix Factorization (MF)\u003c/strong\u003e under the hood. In this lesson, we will look at an overview of the role of the Matrix Factorization model to address the implementation of CF with \u003cstrong\u003eSingular Value Decomposition (SVD)\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare and contrast the advantages/disadvantages of memory vs. model-based recommender systems \u003c/li\u003e\n\u003cli\u003eDescribe how memory-based collaborative filtering methods work \u003c/li\u003e\n\u003cli\u003eDescribe how model-based collaborative filtering models work \u003c/li\u003e\n\u003cli\u003eExplain how SVD is able to extract meaning with latent factors \u003c/li\u003e\n\u003cli\u003eImplement SVD using SciPy \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g533c9d870df05d068e79cd3996c70b47","title":"Context-Free Grammars - Codealong","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-context-free-grammars-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-context-free-grammars-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll write our own \u003cstrong\u003e\u003cem\u003eContext-Free Grammar\u003c/em\u003e\u003c/strong\u003e (CFG) to provide a parser with rules for how sentences can be parsed. We'll also explore how we can easily obtain \u003cstrong\u003e\u003cem\u003ePart-of-Speech (POS) Tags\u003c/em\u003e\u003c/strong\u003e using NLTK!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse NLTK to create context-free grammar and part-of-speech (POS) tags\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g546a70919f77202cb729711ea35833d7","title":"Convolutional Neural Networks - Codealong","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-convolutional-neural-networks-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-convolutional-neural-networks-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this codealong, we will reinvestigate our previous Santa image classification example. To do this, we will review loading a dataset from a nested directory structure and building a baseline model. From there, we'll build a CNN and demonstrate its improved performance on image recognition tasks. It is recommended you run the cells in order to further explore variables and investigate the code snippets themselves. However, please note that some cells (particularly training cells later on) may take several minutes to run. (On a Macbook pro the entire notebook took ~15 minutes to run.)\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad images from a hierarchical file structure using an image datagenerator \u003c/li\u003e\n\u003cli\u003eExplain why one might augment image data when training a neural network \u003c/li\u003e\n\u003cli\u003eApply data augmentation to image files before training a neural network \u003c/li\u003e\n\u003cli\u003eBuild a CNN using Keras \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g884dfd7a7c655abeb9864d3e0f37cb7a","title":"Corpus Statistics - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corpus-statistics-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corpus-statistics-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corpus-statistics-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll learn how to use various NLP techniques to generate descriptive statistics to explore a text corpus!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eGenerate common corpus statistics using NLTK \u003c/li\u003e\n\u003cli\u003eUse a count vectorization strategy to create a bag of words \u003c/li\u003e\n\u003cli\u003eCompare two different text corpora using corpus statistics generated by NLTK \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g707994093d5da85ab8ed839b66896e84","title":"Correlation and Autocorrelation in Time Series","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corr-autocorr-in-time-series\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll talk about correlation, autocorrelation, and partial autocorrelation in time series. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe what role correlation plays in time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the autocorrelation function (ACF) for a time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the partial autocorrelation function (PACF) for a time series \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gff5be975b62dc44dd62d3c3e18377bd7","title":"Correlation and Autocorrelation in Time Series - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-corr-autocorr-in-time-series-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-corr-autocorr-in-time-series-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your knowledge of correlation, autocorrelation, and partial autocorrelation by working on three different datasets. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePlot and discuss the autocorrelation function (ACF) for a time series \u003c/li\u003e\n\u003cli\u003ePlot and discuss the partial autocorrelation function (PACF) for a time series \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5593261c5fe164b30874c26e98026d4c","title":"Deeper Neural Networks","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-deeper-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eSome of the most powerful neural networks use many dozens of layers of activation functions in order to model complex relationships. Let's see how we can extend neural networks even further with deeper neural networks!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain the mechanics of a deep neural network \u003c/li\u003e\n\u003cli\u003eExplain the purpose of an activation function in a neural network \u003c/li\u003e\n\u003cli\u003eList the different activation functions\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eCompare and contrast the different activation functions \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g435e4887d3bebaf536db883d19cdf707","title":"Deeper Neural Networks - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-deeper-neural-networks-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-deeper-neural-networks-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll dig deeper into the work horse of deep learning, \u003cstrong\u003e\u003cem\u003eMulti-Layer Perceptrons\u003c/em\u003e\u003c/strong\u003e! We'll build and train a couple of different MLPs with Keras and explore the tradeoffs that come with adding extra hidden layers. We'll also try switching between some of the activation functions we learned about in the previous lesson to see how they affect training and performance. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a deep neural network using Keras \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g3f13c1f812ad456b8924567383fc3f66","title":"Generating Word Embeddings - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-generating-word-embeddings-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-generating-word-embeddings-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g47cac2a10c36c2b793562d01cb0eebff","title":"Hierarchical Agglomerative Clustering - Codealong","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-hierarchical-agglomerative-clustering-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-hierarchical-agglomerative-clustering-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this codealong, you'll observe how hierarchical agglomerative clustering works by examining various visualizations at each step of the algorithm. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDetermine the best linkage strategy for a dataset by creating clusters and evaluating the results \u003c/li\u003e\n\u003cli\u003eCreate and interpret a dendrogram while using HAC to determine the optimal number of clusters \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gc5165593162487d3d1978299a82ee876","title":"Image Classification - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g41f7a6a6dd480b27090ed07c9767da64","title":"Image Classification with MLPs - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-image-classification-with-mlps-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFor the final lab in this section, we'll build a more advanced \u003cstrong\u003e\u003cem\u003eMulti-Layer Perceptron\u003c/em\u003e\u003c/strong\u003e to solve image classification for a classic dataset, MNIST!  This dataset consists of thousands of labeled images of handwritten digits, and it has a special place in the history of Deep Learning. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a multi-layer neural network image classifier using Keras \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g9e3a49e6940910d53bc3684917edf480","title":"Image Recognition with PCA - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-digital-image-processing-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll explore the classic MNIST dataset of handwritten digits. While not as large as the previous dataset on facial image recognition, it still provides a 64-dimensional dataset that is ripe for feature reduction.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse PCA to discover the principal components with images \u003c/li\u003e\n\u003cli\u003eUse the principal components of  a dataset as features in a machine learning model \u003c/li\u003e\n\u003cli\u003eCalculate the time savings and performance gains of layering in PCA as a preprocessing step in machine learning pipelines \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga6a3b7eadae54ca83ed43d893f924a25","title":"Implementing Recommendation Engines with Surprise","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-implementing-recommender-systems\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThis lesson will give you a brief introduction to implementing recommendation engines with a Python library called \u003ccode\u003esurprise\u003c/code\u003e. You'll get a chance to try out multiple different types of collaborative filtering engines, ranging from both basic neighborhood-based methods to matrix factorization methods. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse \u003ccode\u003esurprise\u003c/code\u003e's built-in reader class to process data to work with recommender algorithms \u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003esurprise\u003c/code\u003e to create and cross-validate different recommender algorithms \u003c/li\u003e\n\u003cli\u003eObtain a prediction for a specific user for a particular item \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g8899aaa2ef46cbed887e639d05c7181f","title":"Implementing Recommender Systems - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-implementing-recommender-systems-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-implementing-recommender-systems-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice creating a recommender system model using \u003ccode\u003esurprise\u003c/code\u003e. You'll also get the chance to create a more complete recommender system pipeline to obtain the top recommendations for a specific user.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse surprise's built-in reader class to process data to work with recommender algorithms \u003c/li\u003e\n\u003cli\u003eObtain a prediction for a specific user for a particular item \u003c/li\u003e\n\u003cli\u003eIntroduce a new user with rating to a rating matrix and make recommendations for them \u003c/li\u003e\n\u003cli\u003eCreate a function that will return the top n recommendations for a user \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g9f909bbb881f8a8f09562043a774c457","title":"Integrating PCA in Pipelines - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-pipelines-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-pipelines-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-pipelines-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn a previous section, you learned about how to use pipelines in scikit-learn to combine several supervised learning algorithms in a manageable pipeline. In this lesson, you will integrate PCA along with classifiers in the pipeline. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eIntegrate PCA in scikit-learn pipelines \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g0eb3977117857e24bafa2973c6d41fd6","title":"Introduction to Keras","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-keras\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eThus far we have a solid basic conceptual understanding of neural networks and their basic architecture. We've seen neural networks for classification including a neural network with no hidden layers (logistic regression), one hidden layer, and several hidden layers. From here, we'll begin to use Keras, a package that has prebuilt many of the building blocks of neural networks which we investigated in previous lessons.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine a tensor \u003c/li\u003e\n\u003cli\u003ePerform tensor slicing \u003c/li\u003e\n\u003cli\u003eExplain the different tensor operations (element-wise, broadcast, and dot product) \u003c/li\u003e\n\u003cli\u003eExplain how an epoch and batch relate to one another \u003c/li\u003e\n\u003cli\u003eExplain the steps to build a neural network in Keras \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g988d100e6dd9f0593536f8173205f9cf","title":"Introduction to NetworkX","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g6a0a3aa597d6c42d20d6798dbf5b319a","title":"Introduction to NetworkX - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-networkX-intro-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5cfd415b6c16b8a663492df51792ab17","title":"Introduction to Neural Networks","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-neural-networks\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNeural networks are becoming increasingly more popular and are responsible for some of the most cutting edge advancements in data science including image and speech recognition. They have also been transformative in reducing the need for intensive and often time intensive feature engineering needed for traditional supervised learning tasks. In this lesson, we'll investigate the architecture of neural networks.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what neural networks are and what they can achieve \u003c/li\u003e\n\u003cli\u003eList the components of a neural network \u003c/li\u003e\n\u003cli\u003eExplain forward propagation in a neural network \u003c/li\u003e\n\u003cli\u003eExplain backward propagation and discuss how it is related to forward propagation \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gf2f068c1f54bb20d5b59fed69c0b026d","title":"Introduction to Neural Networks - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-neural-networks-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-neural-networks-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice everything you have learned during the lecture. We know there is quite a bit of math involved, but don't worry! Using Python and trying things out yourself will actually make a lot of things much more clear! Before we start, let's load some necessary libraries so we can import our data.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImport images using Keras \u003c/li\u003e\n\u003cli\u003eBuild a \"shallow\" neural network from scratch \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5e241006fa4fc3b20c656f2ced7fe4dc","title":"Introduction to Time Series","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-time-series\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-time-series\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-time-series/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eFrom stock prices to climate data, time series data is found in a wide variety of domains, and being able to effectively work with such data is an increasingly important skill for data scientists. \u003c/p\u003e\n\n\u003cp\u003eIn this lecture, you will be introduced to some common techniques used to import, clean, and manipulate time series data. Additionally, you'll learn how you can effectively visualize time series data in Python.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad time series data using Pandas and perform time series indexing \u003c/li\u003e\n\u003cli\u003ePerform data cleaning operation on time series data \u003c/li\u003e\n\u003cli\u003eChange the granularity of a time series \u003c/li\u003e\n\u003cli\u003eDescribe pandas' Timestamp and Datetime datatypes \u003c/li\u003e\n\u003cli\u003eExplore the temporal structure of time series with line plots \u003c/li\u003e\n\u003cli\u003eConstruct and interpret time series histogram and density plots \u003c/li\u003e\n\u003cli\u003eCreate a time series heatmap \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gf64a29e6ba56e3918fe4a29949d8110b","title":"Keras - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-introduction-to-keras-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-introduction-to-keras-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you'll once again build a neural network, but this time you will be using Keras to do a lot of the heavy lifting.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eBuild a neural network using Keras \u003c/li\u003e\n\u003cli\u003eEvaluate performance of a neural network using Keras \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ge8a1cb59b882d6b7be9e15aeb4718b6a","title":"K-means Clustering - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-k-means-clustering-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-k-means-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll implement the k-means clustering algorithm using scikit-learn to analyze a dataset!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePerform k-means clustering in scikit-learn \u003c/li\u003e\n\u003cli\u003eDescribe the tuning parameters found in scikit-learn's implementation of k-means clustering \u003c/li\u003e\n\u003cli\u003eUse an elbow plot with various metrics to determine the optimal number of clusters \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"geb081d1079ab27f821ff41228da6e22b","title":"Machine Learning with Spark","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-machine-learning-with-spark-v2-4\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-v2-4\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-v2-4/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we've performed some data manipulation and aggregation with Spark SQL DataFrames, let's get to the really cool stuff: machine learning!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine estimators and transformers in Spark ML \u003c/li\u003e\n\u003cli\u003eCreate a Spark ML pipeline that transforms data and runs over a grid of hyperparameters \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga40052b34f7e3efc7a91e89bac792750","title":"Machine Learning with Spark - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-machine-learning-with-spark-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-machine-learning-with-spark-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003ePreviously you saw how to manipulate data with Spark DataFrames as well as create machine learning models. In this lab, you're going to practice loading data, manipulating it, preparing visualizations, and fitting it in the Spark MLlib framework. Let's get started!\u003c/p\u003e\n\n\u003ch3\u003eObjectives\u003c/h3\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad and manipulate data using Spark DataFrames \u003c/li\u003e\n\u003cli\u003eCreate a Spark ML pipeline that transforms data and runs over a grid of hyperparameters \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g98648f0b58736379c0de5fe10e862048","title":"Managing Time Series Data - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-managing-time-series-data-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-managing-time-series-data-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-managing-time-series-data-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn the previous lesson, you learned that time series data are everywhere and working with time series data is an important skill for data scientists!\u003c/p\u003e\n\n\u003cp\u003eIn this lab, you'll practice your previously learned techniques to import, clean, and manipulate time series data.\u003c/p\u003e\n\n\u003cp\u003eThe lab will cover how to perform time series analysis while working with large datasets. The dataset can be memory intensive so your computer will need at least 2GB of memory to perform some of the calculations.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad time series data using Pandas and perform time series indexing \u003c/li\u003e\n\u003cli\u003ePerform data cleaning operation on time series data \u003c/li\u003e\n\u003cli\u003eChange the granularity of a time series \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gab7e93076acfc2552dcf83a0c4d8c33c","title":"Market Segmentation with Clustering - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-market-segmentation-clustering-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-market-segmentation-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll use your knowledge of clustering to perform market segmentation on a real-world dataset!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse clustering to create and interpret market segmentation on real-world data \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g735d585333f584530e3ffdaf6d72ee19","title":"Matrix Factorization with Alternating Least Squares","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-matrix-factorization-als\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-matrix-factorization-als\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-matrix-factorization-als/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we will look at another matrix factorization technique called Alternating Least Squares (ALS). This method can prove to be much more effective and robust than the SVD we saw earlier. ALS allows you to set regularization measures and minimize a loss function while optimizing the model parameter \u003ccode\u003ek\u003c/code\u003e.  We will look at the math behind this approach in this lesson. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain how bias terms can be used to create more accurate embedding matrices \u003c/li\u003e\n\u003cli\u003eDescribe how ALS is related to matrix decomposition and why it can be parallelized so well \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gcbda9c0c8cf4870d33f4b156ea179ddf","title":"Network Clustering","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g0bdc5cf5c0a13490bce55a686a409437","title":"Network Clustering - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-clustering-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga33602690c95464485538bd4f4f79d50","title":"Network Connectivity:  Community Detection -Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-community-detection-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-community-detection-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g280f526a996dd50d5819bc4c13287887","title":"Node Centrality","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g9cebafc0818e68bfe27738a9efc0054d","title":"Node Centrality - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-node-centrality-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g228826ed11f4a16c8e008a66f71ae8d1","title":"PCA Background: Covariance Matrix and Eigendecomposition","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-covariance-matrix-eigendecomp\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-covariance-matrix-eigendecomp\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-covariance-matrix-eigendecomp/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've gotten a high-level overview of the use cases for PCA and some general notes regarding the algorithm's implementation, its time to dive deeper into the theory behind PCA. In particular, you'll break down some of the primary concepts of the algorithm, including the covariance matrix and eigenvectors.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003ePerform a covariance matrix calculation with NumPy\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eExplain eigendecomposition and its basic characteristics \u003c/li\u003e\n\u003cli\u003eExplain the role of eigenvectors and eigenvalues in eigendecomposition \u003c/li\u003e\n\u003cli\u003eDecompose and reconstruct a matrix using eigendecomposition \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g565911fd864b7ec0428d04864ab03532","title":"PCA for Facial Image Recognition","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-and-digital-image-processing\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-and-digital-image-processing/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, you'll get to explore an exciting application of PCA: PCA can be used for preprocessing facial image recognition data!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse PCA to discover the principal components of image data\u003c/li\u003e\n\u003cli\u003eUse the principal components of a dataset as features in a machine learning model \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g6747449b9e6df2c0c494613e6764ddf7","title":"Performing Principal Component Analysis (PCA)","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-performing-principle-component-analysis\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-performing-principle-component-analysis\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-performing-principle-component-analysis/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lesson, we'll write the PCA algorithm from the ground up using NumPy. This should provide you with a deeper understanding of the algorithm and help you practice your linear algebra skills.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eList the steps required to perform PCA on a given dataset \u003c/li\u003e\n\u003cli\u003eDecompose and reconstruct a matrix using eigendecomposition \u003c/li\u003e\n\u003cli\u003ePerform a covariance matrix calculation with NumPy \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5977d47bef596d1748bef4a87eeec33a","title":"Performing Principal Component Analysis (PCA) - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-numpy-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-numpy-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-numpy-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you have a high-level overview of PCA, as well as some of the details of the algorithm itself, it's time to practice implementing PCA on your own using the NumPy package. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement PCA from scratch using NumPy\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g3bc84ea730ea0626dd9fa8f8b194dbdf","title":"Phase 4 Blog Post","type":"Assignment","content":"\u003cp\u003e\u003cspan\u003ePlease put the URL to your Phase 4 Blog Post here. \u003c/span\u003e\u003cspan\u003eRefer to the \u003c/span\u003e\u003ca title=\"Blogging Overview\" href=\"pages/blogging-overview\" data-api-endpoint=\"https://learning.flatironschool.com/api/v1/courses/347/pages/blogging-overview\" data-api-returntype=\"Page\"\u003eBlogging Overview\u003c/a\u003e\u003cspan\u003e to learn about how to write good blog posts that\u003c/span\u003e\u003cspan style=\"font-family: inherit; font-size: 1rem;\"\u003e meet Flatiron School‚Äôs requirements.\u003c/span\u003e\u003c/p\u003e","submissionTypes":"a website url","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5064eeb2f06b614d0adc83eb248fe7ef","title":"Phase 4 Code Challenge","type":"Assignment","content":"","submissionTypes":"an external tool","graded":true,"pointsPossible":14.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gbe0099d3814703e5ba2b18886068f8e5","title":"Phase 4 Project - GitHub Repository URL","type":"Assignment","content":"\u003cp\u003e\u003cspan\u003ePlease put the URL to your Phase 4 Project GitHub Repository here.\u0026nbsp;\u003c/span\u003e\u003c/p\u003e","submissionTypes":"a website url","graded":true,"pointsPossible":0.0,"dueAt":"2022-10-31T23:59:00-04:00","lockAt":"2022-10-31T23:59:59-04:00","unlockAt":"2022-10-27T00:00:00-04:00"},{"exportId":"gc0f03e96ae12b9559a73a7a051856f69","title":"Principal Component Analysis in scikit-learn","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-in-scikitlearn\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen the curse of dimensionality, it's time to take a look at a dimensionality reduction technique! This will help you overcome the challenges of the curse of dimensionality (amongst other things). Essentially, PCA, or Principal Component Analysis, attempts to capture as much information from the dataset as possible while reducing the overall number of features.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain at a high level how PCA works \u003c/li\u003e\n\u003cli\u003eExplain use cases for PCA \u003c/li\u003e\n\u003cli\u003eImplement PCA using the scikit-learn library \u003c/li\u003e\n\u003cli\u003eDetermine the optimal number of n components when performing PCA by observing the explained variance \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g62781b0f81600caf7cf0ef404029b642","title":"Principal Component Analysis in scikit-learn - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-pca-in-scikitlearn-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-pca-in-scikitlearn-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've seen a brief introduction to PCA, it's time to use scikit-learn to run PCA on your own. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement PCA using the scikit-learn library \u003c/li\u003e\n\u003cli\u003eDetermine the optimal number of n components when performing PCA by observing the explained variance \u003c/li\u003e\n\u003cli\u003ePlot the decision boundary of classification experiments to visually inspect their performance \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ge49973b1f11da2d1d2ab006198d397c0","title":"Productionizing a Model with Docker and SageMaker","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-models-with-sagemaker\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-productionizing-models-with-sagemaker/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eComplete this exercise on your local computer.\u003c/p\u003e","submissionTypes":null,"graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g6c78ceda6b7362bce45a8e4e549f34c2","title":"Recommendation Systems","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recommendation-systems\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-network-recommendation-systems/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g311caf2ef8d1c4fae0d9dd5602a56818","title":"Regular Expressions - Codealong","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-regular-expressions-codealong\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-regular-expressions-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-regular-expressions-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, we'll make use of some common regex patterns to search through text. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCreate regex code to capture meaningful patterns found in text \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g119393ced24c88150154a7658ec60f95","title":"Removing Trends","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-removing-trends\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAlthough the stationarity assumption is required in several time series modeling techniques, few practical time series are stationary. In this lesson we'll discuss how you can make a time series stationary. In reality, it is almost impossible to make a series perfectly stationary, but let's try to get as close as possible!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCompare and contrast the different methods for removing trends and seasonality in time series data \u003c/li\u003e\n\u003cli\u003eUse differencing to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling means to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse a log transformation to minimize non-stationarity \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga1d0e819649ad5a415863e9dd8cd00b2","title":"Removing Trends - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-removing-trends-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-removing-trends-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your detrending skills!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse a log transformation to minimize non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling means to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse differencing to reduce non-stationarity \u003c/li\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eCreate visualizations of transformed time series as a visual aid to determine if stationarity has been achieved \u003c/li\u003e\n\u003cli\u003eUse the Dickey-Fuller test and conclude whether or not a dataset is exhibiting stationarity \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g2f77863d15f7cdaae1efb4cd6c8dd382","title":"Resilient Distributed Datasets (RDDs) - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-resilient-distributed-datasets-rdd-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-resilient-distributed-datasets-rdd-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-resilient-distributed-datasets-rdd-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003cp\u003eResilient Distributed Datasets (RDD) are fundamental data structures of Spark. An RDD is essentially the Spark representation of a set of data, spread across multiple machines, with APIs to let you act on it. An RDD can come from any data source, e.g. text files, a database, a JSON file, etc.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply the map(func) transformation to a given function on all elements of an RDD in different partitions \u003c/li\u003e\n\u003cli\u003eApply a map transformation for all elements of an RDD \u003c/li\u003e\n\u003cli\u003eCompare the difference between a transformation and an action within RDDs \u003c/li\u003e\n\u003cli\u003eUse collect(), count(), and take() actions to trigger spark transformations\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eUse filter to select data that meets certain specifications within an RDD \u003c/li\u003e\n\u003cli\u003eSet number of partitions for parallelizing RDDs \u003c/li\u003e\n\u003cli\u003eCreate RDDs from Python collections \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g6a73e37fcc782d5bb5b0a0d47b481f8a","title":"Simple and Shortest Paths","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gb2c0e874e98934e6056a2c837a348601","title":"Simple and Shortest Paths - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-graph-theory-shortest-path-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gbb401e4ed8174cf280ef12f218168b8b","title":"Spark DataFrames","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-spark-dataframes\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-dataframes\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-spark-dataframes/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eYou've now explored how to perform operations on Spark RDDs for simple MapReduce tasks. This is useful for contexts where the low-level Unstructured API is most appropriate, but now we're going to move on to using a more intuitive and powerful interface: Spark DataFrames!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad and manipulate data using Spark SQL DataFrames\u003c/li\u003e\n\u003cli\u003eDescribe the similarities and differences between RDDs, Spark SQL DataFrames, and pandas DataFrames\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gba1d403ececda39a33c1783ccce4f999","title":"Testing for Trends - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-testing-for-trends-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-testing-for-trends-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-testing-for-trends-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll practice your knowledge of testing for stationarity.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eUse the Dickey-Fuller test and conclude whether or not a dataset is exhibiting stationarity \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g27ff2fdc813a820fe3664cf8e0538f87","title":"The Curse of Dimensionality - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-curse-of-dimensionality-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-curse-of-dimensionality-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll conduct some mathematical simulations to further investigate the consequences of the curse of dimensionality.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCreate and interpret a visual demonstrating how sparsity changes with n for n-dimensional spaces \u003c/li\u003e\n\u003cli\u003eDemonstrate how training time increases exponentially as the number of features increases\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g03cc9745b85a37c968dfdc957e36819b","title":"Time Series Decomposition","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-time-series-decomposition\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-decomposition\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-time-series-decomposition/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003ePreviously, you saw how we can combine several techniques to detrend our time series. Before we move on to our time series models, let's look at another method to remove trend and seasonality, namely \u003cstrong\u003eTime Series Decomposition\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cp\u003eLet's once again import the passengers dataset and the \u003ccode\u003estationarity_check()\u003c/code\u003e function from the previous lab to use time series decomposition and its effect on detrending a time series.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDescribe the process and components of time series decomposition \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gc6aab54daaa8b90b09373a53eddfc8a3","title":"Time Series: Facebook Prophet - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-facebook-prophet-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-facebook-prophet-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g491127544b4db88dbe24733f9fe3552c","title":"Time Series: SARIMA Models - Lab","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sarima-models-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sarima-models-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g499e8e49f89e304b98ba1a620123f8a3","title":"Tuning and Optimizing Neural Networks - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-from-start-to-finish-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've practiced regularization, initialization, and optimization techniques, its time to synthesize these concepts into a cohesive modeling pipeline.  \u003c/p\u003e\n\n\u003cp\u003eWith this pipeline, you will not only fit an initial model but also attempt to improve it. Your final model selection will pertain to the test metrics across these models. This will more naturally simulate a problem you might be faced with in practice, and the various modeling decisions you are apt to encounter along the way.  \u003c/p\u003e\n\n\u003cp\u003eRecall that our end objective is to achieve a balance between overfitting and underfitting. You've seen the bias variance trade-off, and the role of regularization in order to reduce overfitting on training data and improving generalization to new cases. Common frameworks for such a procedure include train/validate/test methodology when data is plentiful, and K-folds cross-validation for smaller, more limited datasets. In this lab, you'll perform the latter, as the dataset in question is fairly limited. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply normalization as a preprocessing technique \u003c/li\u003e\n\u003cli\u003eImplement a K-folds cross validation modeling pipeline for deep learning models \u003c/li\u003e\n\u003cli\u003eApply regularization techniques to improve your model's performance \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g3f1caffeac6631bd5eec966c32c523dd","title":"Tuning Neural Networks with Normalization - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-normalization-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-normalization-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you'll build a neural network to perform a regression task.\u003c/p\u003e\n\n\u003cp\u003eIt is worth noting that getting regression to work with neural networks can be comparatively difficult because the output is unbounded (\u003cimg class=\"equation_image\" title=\"\\hat y\" src=\"https://learning.flatironschool.com/equation_images/%255Chat%20y\" alt=\"{\" data-equation-content=\"\\hat y\"\u003e can technically range from \u003cimg class=\"equation_image\" title=\"-\\infty\" src=\"https://learning.flatironschool.com/equation_images/-%255Cinfty\" alt=\"{\" data-equation-content=\"-\\infty\"\u003e to \u003cimg class=\"equation_image\" title=\"+\\infty\" src=\"https://learning.flatironschool.com/equation_images/+%255Cinfty\" alt=\"{\" data-equation-content=\"+\\infty\"\u003e), and the models are especially prone to exploding gradients. This issue makes a regression exercise the perfect learning case for tinkering with normalization and optimization strategies to ensure proper convergence!\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eFit a neural network to normalized data \u003c/li\u003e\n\u003cli\u003eImplement and observe the impact of various initialization techniques \u003c/li\u003e\n\u003cli\u003eImplement and observe the impact of various optimization techniques \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g44969ffff4b33b816b9daba862417b65","title":"Tuning Neural Networks with Regularization - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-tuning-neural-networks-with-regularization-lab-v2-1\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab-v2-1\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab-v2-1/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply early stopping criteria with a neural network \u003c/li\u003e\n\u003cli\u003eApply L1, L2, and dropout regularization on a neural network\u003cbr\u003e\n\u003c/li\u003e\n\u003cli\u003eExamine the effects of training with more data on a neural network\u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga5806767e1d56323adbce5fd975ead09","title":"Types of Trends","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-types-of-trends\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-types-of-trends\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-types-of-trends/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eOften, basic regression techniques are not sufficient to grasp the more complex, time-dependent patterns that are common when dealing with time series data. Using time series analysis techniques, the purpose is to get more insight into your data on one hand and to make predictions on the other hand. First, we'll introduce the types of trends that exist in time series models and have a look at them.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplain what stationarity means and why it is important in time series analysis \u003c/li\u003e\n\u003cli\u003eUse rolling statistics as a check for stationarity \u003c/li\u003e\n\u003cli\u003eDescribe the Dickey-Fuller test and its purpose \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g294b94461ee6e9572f786a2e6bb0659b","title":"Understanding SparkContext - Codealong","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-sparkcontext\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sparkcontext\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-sparkcontext/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eSparkContext is the entry point for using the Unstructured API of Spark. In this lesson we'll go over how SparkContext works in PySpark, create a SparkContext called \u003ccode\u003esc\u003c/code\u003e, and explore \u003ccode\u003esc\u003c/code\u003e's properties.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDefine a SparkContext and why it is important to a Spark application\u003c/li\u003e\n\u003cli\u003eCreate a SparkContext with PySpark\u003c/li\u003e\n\u003cli\u003eList the major properties and methods of SparkContext\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g07a414e2616adbbca8a771ce819c55a2","title":"Using Pretrained Networks","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g08342aab578be640fa974343cc984690","title":"Using Pretrained Networks - Codealong","type":"Assignment","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gcd231132357b7197c79a1dd8aa04b47c","title":"Visualizing Activation Functions - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-activation-functions-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-activation-functions-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-activation-functions-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that you've built your own CNN and seen how to visualize feature maps, its time to practice loading a pretrained model from file and visualize the learned features systematically. In this lab, you'll expand upon the code from the previous lesson in order to succinctly visualize all the channels from each layer in a CNN.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will: \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad a saved Keras model \u003c/li\u003e\n\u003cli\u003eUse Keras methods to visualize the activation functions in CNNs \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g133398f3cf3addbcc4503103ffaa1031","title":"Visualizing Intermediate Activations","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-intermediate-activations\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-intermediate-activations\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-intermediate-activations/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eDeep learning is extremely powerful and is helping to lead the advancement of many AI tasks. That said, deep learning is often criticized for having a lot of \u003cem\u003eblack box\u003c/em\u003e algorithms in that the components of the model itself are difficult to interpret. In the case of CNNs and image recognition, this is actually not true at all! In this lesson, you will explore how you can visualize the intermediate hidden layers within your CNN to uncover what sorts of features your deep network is uncovering through some of the various filters. With that, you'll gain interesting insights and knowledge as to how your CNN is \u003cem\u003eseeing\u003c/em\u003e the world.  \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eLoad a saved Keras model \u003c/li\u003e\n\u003cli\u003eUse Keras methods to visualize the activation functions in CNNs \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g38a7acb7ef18eec76d012e036a33d576","title":"Visualizing Time Series Data - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-visualizing-time-series-data-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-time-series-data-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-visualizing-time-series-data-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eAs mentioned in an earlier lesson, time series visualizations play an important role in the analysis of time series data. Time series are often plotted to allow data diagnostics to identify temporal structures. \u003c/p\u003e\n\n\u003cp\u003eIn this lab, we'll cover main techniques for visualizing time series data in Python using the minimum daily temperatures over 10 years (1981-1990) in the city of Melbourne, Australia. The units are in degrees Celsius and there are 3,650 observations. The \u003ca href=\"https://datamarket.com/data/set/2324/daily-minimum-temperatures-in-melbourne-australia-1981-1990\"\u003esource\u003c/a\u003e of the data is credited to the Australian Bureau of Meteorology.\u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eYou will be able to:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eExplore the temporal structure of time series with line plots \u003c/li\u003e\n\u003cli\u003eConstruct and interpret time series histogram and density plots \u003c/li\u003e\n\u003cli\u003eCreate a time series heat map\u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"gda1b3b7f840139ea7429bdb7e29b0a3f","title":"Word Count with MapReduce - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-word-count-with-map-reduce-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-count-with-map-reduce-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-count-with-map-reduce-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eNow that we have seen the key map and reduce operators in Spark, and also know when to use transformation and action operators, we can revisit the word count problem we introduced earlier in the section. In this lab, we will read a text corpus into the Spark environment, perform a word count, and try basic NLP ideas to get a good grip on how MapReduce performs. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eApply the map(func) transformation to a given function on all elements of an RDD in different partitions \u003c/li\u003e\n\u003cli\u003eApply a map transformation for all elements of an RDD \u003c/li\u003e\n\u003cli\u003eCompare the difference between a transformation and an action within RDDs \u003c/li\u003e\n\u003cli\u003eUse collect(), count(), and take() actions to trigger spark transformations \u003c/li\u003e\n\u003cli\u003eUse filter to select data that meets certain specifications within an RDD \u003c/li\u003e\n\u003cli\u003eUse Spark and the MapReduce framework to complete a full parallelized word count problem \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga30aa82d071d72e9a33e2fe1c8b59f4a","title":"Word Vectorization - Lab","type":"Assignment","content":"\u003cdiv id=\"git-data-element\" data-org=\"learn-co-curriculum\" data-repo=\"dsc-word-vectorization-lab\"\u003e\u003c/div\u003e\n\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-vectorization-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-word-vectorization-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eIn this lab, you'll tokenize and vectorize text documents, create and use a bag of words, and identify words unique to individual documents using TF-IDF vectorization. \u003c/p\u003e\n\n\u003ch2\u003eObjectives\u003c/h2\u003e\n\n\u003cp\u003eIn this lab you will:  \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eImplement tokenization and count vectorization from scratch \u003c/li\u003e\n\u003cli\u003eImplement TF-IDF from scratch \u003c/li\u003e\n\u003cli\u003eUse dimensionality reduction on vectorized text data to create and interpret visualizations \u003c/li\u003e\n\u003c/ul\u003e","submissionTypes":"an external tool","graded":true,"pointsPossible":0.0,"dueAt":null,"lockAt":null,"unlockAt":null}],"discussion_topics":[],"quizzes":[{"exportId":"gd4bb2a176d75638f44ca8a45af7b753e","title":"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab","type":"Quizzes::Quiz","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dimensionality-reduction-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-dimensionality-reduction-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003ch3\u003eSubmission Instructions\u003c/h3\u003e\n\u003cp\u003eWhen you are finished with the lab, complete the following steps to submit your work:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSave the changes to the notebook by clicking the Save icon, shown below highlighted in red\u003cbr\u003e\u003cimg src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202021-07-28%20at%205.41.06%20PM.png\" alt=\"Screenshot of lab with save button highlighted\"\u003e\u0026nbsp;\u003c/li\u003e\n\u003cli\u003eClose the notebook browser tab(s)\u003c/li\u003e\n\u003cli\u003eShut down the notebook server by typing control-C in the terminal window where it is currently running\u003c/li\u003e\n\u003cli\u003eCommit your changes in Git by typing \u003cbr\u003e\u003ccode\u003egit commit -am \"Finished lab\"\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003ePush your changes to GitHub by typing \u003cbr\u003e\u003ccode\u003egit push origin master\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003eOpen the GitHub view of your fork of the lab in the browser. For example, if your username were \u003ccode\u003ehoffm386\u003c/code\u003e, you would go to \u003ca href=\"https://github.com/hoffm386/dsc-data-serialization-lab\" target=\"_blank\"\u003ehttps://github.com/hoffm386/dsc-data-serialization-lab\u003c/a\u003e in the browser for this particular lab. Click on \u003ccode\u003eindex.ipynb\u003c/code\u003e and double-check that your code updates are there. (The updates will not be in the README, only in the \u003ccode\u003e.ipynb\u003c/code\u003e file.)\u003c/li\u003e\n\u003cli\u003eSubmit the link to your fork of the lab in the textbox on Canvas\u003cbr\u003e\u0026nbsp;\u003cimg src=\"viewer/files/Uploaded%20Media/Screen%20Shot%202021-08-24%20at%206.42.54%20PM.png\" alt=\"Screenshot of \u0026quot;Question 1\u0026quot; where the URL should be pasted\"\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eTroubleshooting\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"background-color: #fbeeb8;\"\u003eIf you are able to submit the URL successfully, you do not need to follow the below steps!\u003c/span\u003e\u003c/p\u003e\n\u003ch4\u003eNot a Git Repository\u003c/h4\u003e\n\u003cp\u003eIf you try to run \u003ccode\u003egit commit -am \"Finished lab\"\u003c/code\u003e and get the error message \u003ccode\u003efatal: not a git repository\u003c/code\u003e, double-check that you are running the code from the correct directory. If you type \u003ccode\u003epwd\u003c/code\u003e in the terminal and hit Enter, the path that is printed out should include the directory of the lab ‚Äî in this case, \u003ccode\u003edsc-data-serialization-lab\u003c/code\u003e. For example, a valid path would be \u003ccode\u003e/Users/myname/Development/DS/dsc-data-serialization-lab\u003c/code\u003e, since that ends with the lab directory, whereas \u003ccode\u003e/Users/myname/Development/DS/\u003c/code\u003e would not be a valid path. Use commands like \u003ccode\u003els\u003c/code\u003e and \u003ccode\u003ecd\u003c/code\u003e to navigate to the appropriate directory, then continue with the steps above, starting with step 4.\u003c/p\u003e\n\u003ch4\u003ePermission Denied\u003c/h4\u003e\n\u003cp\u003eIf you try to run \u003ccode\u003egit push origin master\u003c/code\u003e and get a \u003ccode\u003ePermission denied\u003c/code\u003e error message, you are likely trying to push to the curriculum version of the lab, not your personal fork. Follow these steps to fix this:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eIn the browser, go to the curriculum repository for this lab by clicking the \u003cimg src=\"viewer/files/Uploaded%20Media/GitHub-Mark-32px.png\" alt=\"GitHub octocat icon\"\u003e\u0026nbsp;icon above\u003c/li\u003e\n\u003cli\u003eClick the Fork button. If you already have a fork, this will take you to it. If you haven't made a fork yet, this will make the fork and take you to it\u003c/li\u003e\n\u003cli\u003eOn the page of your fork, copy the clone link. For example, \u003ca href=\"https://github.com/hoffm386/dsc-data-serialization-lab.git\" target=\"_blank\"\u003ehttps://github.com/hoffm386/dsc-data-serialization-lab.git\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eBack in the terminal where you were trying to run \u003ccode\u003egit push\u003c/code\u003e, type \u003cbr\u003e\u003ccode\u003egit remote add myfork \u0026lt;URL\u0026gt;\u003c/code\u003e \u003cbr\u003eWhere \u003ccode\u003e\u0026lt;URL\u0026gt;\u003c/code\u003e is replaced with the clone link you copied. For example, \u003ccode\u003egit remote add myfork https://github.com/hoffm386/dsc-data-serialization-lab.git\u003c/code\u003e. Then hit Enter. This means you have created a connection between your local repository and your fork\u003c/li\u003e\n\u003cli\u003eNow, push your code to your fork by typing \u003cbr\u003e\u003ccode\u003egit push myfork master\u003c/code\u003e \u003cbr\u003ein the terminal and hitting Enter\u003c/li\u003e\n\u003cli\u003eProceed with the steps above, starting with step 6\u003c/li\u003e\n\u003c/ol\u003e","assignmentExportId":"gff74a4f22f0eb7b53d1e8e7675bc604c","questionCount":1,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g1daef7be675ef2b7bc60c9ddf372ac38","title":"Phase 4 Project Proposal","type":"Quizzes::Quiz","content":"\u003cp\u003eFor this phase, you will choose a project that requires building one of these four models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTime Series Modeling\u003c/li\u003e\n\u003cli\u003eRecommendation System\u003c/li\u003e\n\u003cli\u003eImage Classification with Deep Learning\u003c/li\u003e\n\u003cli\u003eNatural Language Processing\u003c/li\u003e\n\u003c/ul\u003e","assignmentExportId":"g15e923edb32fb85fd62fc5c9e95b0410","questionCount":3,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":3.0,"dueAt":"2022-10-29T23:59:00-04:00","lockAt":null,"unlockAt":"2022-10-21T00:00:00-04:00"},{"exportId":"g9c577f9088ef666a272048004754cb3c","title":"Quiz: Big Data in PySpark","type":"Quizzes::Quiz","content":"","assignmentExportId":"ge5f816d782a9139758688bf12fe92fc7","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g5dfff80ace5a749b059276ee443dd711","title":"Quiz: Clustering","type":"Quizzes::Quiz","content":"","assignmentExportId":"gcc5993b6c22475a215c8cc6f881d46fb","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ge4eb3dd722fcfcc80f1f9aa87b632443","title":"Quiz: Natural Language Processing","type":"Quizzes::Quiz","content":"","assignmentExportId":"g0405b9cee60106c07d13b4ef06cf59f8","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ga45ae0602eaec10912652ed52580feb0","title":"Quiz: Neural Networks","type":"Quizzes::Quiz","content":"","assignmentExportId":"gd62c4039c560ef223ef6a6245bb3dcd0","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g3edf2c8c948b9f818582eb3cc62d6ce0","title":"Quiz: Principal Component Analysis","type":"Quizzes::Quiz","content":"","assignmentExportId":"gcce01b97a48318c1f25d9ddc9952b337","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g05d801f10914dc65584eb6465ecc0c0f","title":"Quiz: Recommendation Systems","type":"Quizzes::Quiz","content":"","assignmentExportId":"g5565dca33fa562ec752b104aca49ab30","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g6f491f0e0c0297c3b56e2a98b1f7ec9a","title":"Quiz: Time Series","type":"Quizzes::Quiz","content":"","assignmentExportId":"gd5cf3ed3933765abc49d5ce14be53715","questionCount":5,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":5.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"ge90739ce01a620cd258817433744522a","title":"SVD Exit Ticket","type":"Quizzes::Quiz","content":"","assignmentExportId":"g197ae5fb04bdef6077d3d41c39261a20","questionCount":7,"timeLimit":null,"attempts":1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null},{"exportId":"g11ad01bbe6f79a0e7287e5eb4163a824","title":"‚≠êÔ∏è Text Classification - Cumulative Lab","type":"Quizzes::Quiz","content":"\u003cheader class=\"fis-header\" style=\"visibility: hidden;\"\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-lab\" target=\"_blank\"\u003e\u003cimg id=\"repo-img\" title=\"Open GitHub Repo\" alt=\"GitHub Repo\"\u003e\u003c/a\u003e\u003ca class=\"fis-git-link\" href=\"https://github.com/learn-co-curriculum/dsc-nlp-lab/issues/new\" target=\"_blank\"\u003e\u003cimg id=\"issue-img\" title=\"Create New Issue\" alt=\"Create New Issue\"\u003e\u003c/a\u003e\u003c/header\u003e\n\u003cp\u003eWork on this lab on your local computer. If you're not sure what to do, refer to the instructions in \u003ca title=\"‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\" href=\"quizzes/gd4bb2a176d75638f44ca8a45af7b753e\"\u003e‚≠êÔ∏è Dimensionality Reduction - Cumulative Lab\u003c/a\u003e\u003c/p\u003e","assignmentExportId":"gcc72941e26479db2c74fd6ea6a876426","questionCount":1,"timeLimit":null,"attempts":-1,"graded":true,"pointsPossible":1.0,"dueAt":null,"lockAt":null,"unlockAt":null}],"files":[{"type":"folder","name":"Uploaded Media","size":null,"files":[{"type":"file","name":"GitHub-Mark-32px.png","size":1714,"files":null},{"type":"file","name":"Screen Shot 2021-07-28 at 5.41.06 PM.png","size":61484,"files":null},{"type":"file","name":"Screen Shot 2021-08-24 at 6.42.54 PM.png","size":47006,"files":null}]},{"type":"folder","name":"course_image","size":null,"files":[]}]}